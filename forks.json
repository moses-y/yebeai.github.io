{
  "lastUpdated": "2026-02-27T19:43:50.107Z",
  "generatedWith": "GitHub Models API (GPT-4o, GPT-4o-mini, GPT-4.1)",
  "totalRepos": 365,
  "progress": {
    "aiGenerated": 365,
    "fallback": 0,
    "pending": 0,
    "complete": true
  },
  "forks": [
    {
      "id": 1167796173,
      "name": "GitUp",
      "displayName": "GitUp",
      "description": "The Git interface you've been missing all your life has finally arrived.",
      "summary": "GitUp: The Git Interface You Actually Want to Use\n\nThe Problem\n\nLet’s face it: Git is powerful, but it’s also a hot mess of arcane commands that make even seasoned developers feel like they're performing dark magic. From accidentally overwriting history to untangling merge conflicts, Git’s \"helpful\" tools often leave you Googling Stack Overflow threads from 2012. Most Git GUIs? They’re clunky, slow, or just command-line wrappers with a prettier face. You deserve better.  \n\nWhat This Does\n\nGitUp flips the script with a lightning-fast, Mac-native Git client that actually makes Git workflows intuitive. Instead of dealing with cryptic commands like git reset HEAD, you manipulate the repository graph directly. The GitUp/Application folder contains most of the magic, including WindowController.m for the main UI and DocumentController.m for handling repo state changes. \n\nKey features include:\nA live repo graph that’s fully editable—merge, reorder, or fix commits like you’re dragging files on your desktop.\nUnlimited undo/redo (yes, even for rebases and merges) baked right into GitUpKit/Core.\nSnapshots for one-click rollbacks, powered by GCHistory.m and GCCommitDatabase.m. \nBlazing-fast search across the repo, including diffs, thanks to some tight integration with Git’s internal storage.\n\nIt’s packed with functionality you don’t realize you need until you use it—like splitting commits visually (GIDiffContentsViewController.m) or browsing the unified reflog (GIUnifiedReflogViewController.h).  \n\nReal-World Use\n\nImagine you’re in the middle of a gnarly rebase (god help you). With GitUp, you see your entire repo history as a graph in real time. Accidentally botched a conflict resolution? No problem. Hit undo and try again. Need to split a commit into two? Drag and drop in the visual splitter. Want to see every change made to a specific file? Instant search has your back.  \n\nIt’s like having a Git time machine and a UI that actually respects your sanity.\n\nThe Bottom Line\n\nGitUp isn’t for everyone. If you’re a CLI wizard who dreams in git rebase --interactive, you probably won’t need this. But for regular humans—or anyone who wants to handle Git with less pain—this is a killer tool. It’s fast, clean, and actually useful, unlike the bloated, half-baked GUIs you’ve tried before. Give it a shot. Your future self will thank you.",
      "url": "https://github.com/moses-y/GitUp",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "git-up/GitUp",
        "url": "https://github.com/git-up/GitUp",
        "stars": 11937
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 26, 2026",
      "updatedAt": "February 26, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 5,
          ".github": 2,
          "Assets": 1,
          "Examples": 38,
          "GitUp": 82,
          "GitUpKit": 72
        },
        "languages": {
          "YAML": 2,
          "Markdown": 1,
          "C/C++ Header": 38,
          "JSON": 24,
          "Shell": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [
          ".github/workflows/test.yml",
          "GitUpKit/Core/GCBranch-Tests.m",
          "GitUpKit/Core/GCCommit-Tests.m",
          "GitUpKit/Core/GCCommitDatabase-Tests.m",
          "GitUpKit/Core/GCDiff-Tests.m",
          "GitUpKit/Core/GCFoundation-Tests.m",
          "GitUpKit/Core/GCHistory-Tests.m",
          "GitUpKit/Core/GCLiveRepository-Tests.m"
        ],
        "docs": [
          "CONTRIBUTING.md"
        ],
        "fileTypes": {
          ".yml": 2,
          ".svg": 2,
          ".md": 1,
          ".h": 38,
          ".m": 47,
          ".xib": 17,
          ".pbxproj": 5,
          ".xcscheme": 6,
          ".plist": 7,
          ".png": 40,
          ".storyboard": 1,
          ".json": 24,
          ".entitlements": 1,
          ".strings": 3,
          ".xml": 1,
          ".sh": 1
        }
      }
    },
    {
      "id": 1167686977,
      "name": "obsidian-skills",
      "displayName": "obsidian skills",
      "description": "Agent skills for Obsidian. Teach your agent to use Markdown, Bases, JSON Canvas, and use the CLI.",
      "summary": "Agent Skills for Obsidian: Markdown, Bases, JSON, CLI, and More  \n\nThe Problem  \nObsidian is great for knowledge management, but its flexibility can also feel like a black hole of features. Writing custom scripts to interact with Obsidian vaults, manage files in different formats, or automate workflows often means reinventing the wheel every time. If you're working with agents like Claude Code or Codex CLI, you need standardized tools to make your life easier.  \n\nWhat This Does  \nAt its core, obsidian-skills is a set of pre-defined skills for agents that integrate directly with Obsidian. The skills/ directory contains five modular skills:  \nobsidian-markdown: Handles .md files using Obsidian's extended Markdown syntax, like wikilinks and callouts.  \nobsidian-bases: Edits .base files for creating filtered views, formulas, and summaries.  \njson-canvas: Works with .canvas files, managing nodes, edges, and connections in JSON Canvas format.  \nobsidian-cli: Automates vault interactions via the Obsidian CLI, perfect for plugin or theme developers.  \ndefuddle: Cleans web pages into usable Markdown, cutting out junk content, and saving tokens.  \n\nInstallation is straightforward—either grab it from the plugin marketplace or manually drop the files into your agent’s skill path (~/.codex/skills for Codex or /.claude for Claude Code). The .claude-plugin/ folder handles plugin metadata for marketplace compatibility.  \n\nReal-World Use  \nLet’s say you're working on a research vault in Obsidian and need to clean up web pages for notes, automate file organization, and create data views.  \nUse defuddle to convert messy web pages into clean .md files.  \nLeverage obsidian-markdown to add wikilinks, embeds, and callouts for better structure.  \nTap into obsidian-bases to create a .base file for filtering notes based on tags or properties.  \nAutomate vault backups or plugin installs with obsidian-cli.  \n\nHere’s a quick snippet for Claude Code to apply these skills:  \n\n  \n\nThe Bottom Line  \nobsidian-skills is a solid toolkit if you’re deep into Obsidian workflows and already using agents like Claude Code or Codex CLI. The modular skill structure is smart, but don’t expect hand-holding—if you’re unfamiliar with the Agent Skills spec, the learning curve might sting. Great for devs and power users; overkill for casual note-takers.",
      "url": "https://github.com/moses-y/obsidian-skills",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "kepano/obsidian-skills",
        "url": "https://github.com/kepano/obsidian-skills",
        "stars": 11420
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 26, 2026",
      "updatedAt": "February 26, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 9,
        "directories": {
          ".claude-plugin": 2,
          "(root)": 2,
          "skills": 5
        },
        "languages": {
          "JSON": 2,
          "Markdown": 6
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".json": 2,
          ".md": 6
        }
      }
    },
    {
      "id": 1167606150,
      "name": "ai-town",
      "displayName": "ai town",
      "description": "A MIT-licensed, deployable starter kit for building and customizing your own version of AI town - a virtual town where AI characters live, chat and socialize.",
      "summary": "Building Your Own AI Town with ai-town\n\nThe Problem\n\nYou’ve read the Generative Agents paper and thought, “Cool, but how do I actually build something like that without drowning in Python, TensorFlow, and sadness?” Or maybe you just want a customizable playground for AI characters in a virtual world, with multiplayer support baked in. Either way, starting from scratch is a pain, and most open-source projects in this space are either too academic or too rigid.\n\nWhat This Does\n\nai-town is a starter kit for creating your own virtual town where AI characters live, chat, and interact. It's built with TypeScript and designed to be extended. The back-end is powered by Convex, which handles the shared global state, transactions, and simulation logic. The front-end is a React app, with heavy use of PixiJS for rendering the game world. The project is containerized with Docker, so you can spin it up locally or deploy it to Fly.io.\n\nThe structure is clean and modular. The back-end logic lives in convex/, with subfolders for the simulation engine (convex/engine), AI character behaviors (convex/aiTown/), and utilities (convex/util/). The front-end is in src/, featuring components like src/components/Game.tsx for the main game view and src/components/Player.tsx for handling player interactions. Config files like docker-compose.yml and fly.toml make deployment straightforward.\n\nReal-World Use\n\nSay you want to build a multiplayer AI-powered RPG where players interact with NPCs that actually remember past conversations. Start by forking this repo, spinning it up with docker-compose up, and plugging in your LLM of choice (OpenAI, Ollama, or whatever speaks to the OpenAI API). The AI backend logic is in convex/aiTown/, so tweaking how characters behave or introducing new ones is as simple as editing agent.ts or game.ts.\n\nHere’s a simple example of sending player input to the game:\n\nWant to customize the map? Check out the tilesets in src/editor/tilesets/ or edit the animations in data/animations/. The modular structure keeps everything organized and approachable.\n\nThe Bottom Line\n\nai-town is a solid foundation for anyone building AI-driven virtual worlds or multiplayer simulation games. It's not perfect—the dependency on Convex might be a dealbreaker for some, and the setup could be overkill for smaller projects. But if you’re serious about creating your own AI town, this is a fantastic place to start. Just be ready to get your hands dirty with TypeScript and Docker.",
      "url": "https://github.com/moses-y/ai-town",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "a16z-infra/ai-town",
        "url": "https://github.com/a16z-infra/ai-town",
        "stars": 9419
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 26, 2026",
      "updatedAt": "February 26, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 16,
          ".vscode": 2,
          "assets": 18,
          "convex": 58,
          "data": 21,
          "fly": 3,
          "public": 15,
          "src": 67
        },
        "languages": {
          "JavaScript": 23,
          "JSON": 14,
          "Markdown": 4,
          "TypeScript": 76,
          "YAML": 1,
          "TOML": 2,
          "HTML": 4,
          "TSX": 20,
          "CSS": 1
        },
        "frameworks": [
          "React",
          "Express",
          "Docker"
        ],
        "packageManager": "npm",
        "hasDocker": true,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "convex/_generated/server.js",
          "convex/aiTown/main.ts",
          "index.html",
          "src/App.tsx",
          "src/editor/index.html"
        ],
        "configFiles": [
          ".eslintrc.js",
          ".prettierrc",
          "Dockerfile",
          "docker-compose.yml",
          "jest.config.ts",
          "package.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [
          "convex/engine/historicalObject.test.ts",
          "convex/testing.ts",
          "convex/util/asyncMap.test.ts",
          "convex/util/compression.test.ts",
          "convex/util/geometry.test.ts",
          "convex/util/minheap.test.ts",
          "convex/util/types.test.ts"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "fly/README.md",
          "src/editor/README.md"
        ],
        "fileTypes": {
          ".js": 23,
          ".code-snippets": 1,
          ".json": 14,
          ".md": 4,
          ".png": 26,
          ".webp": 2,
          ".svg": 15,
          ".ts": 76,
          ".yml": 1,
          ".toml": 2,
          ".html": 4,
          ".mp3": 1,
          ".ttf": 2,
          ".ico": 1,
          ".tsx": 20,
          ".css": 1
        }
      }
    },
    {
      "id": 1167600930,
      "name": "Polymarket-rsi-macd-index-trading-bot",
      "displayName": "Polymarket rsi macd index trading bot",
      "description": "Polymarket trading bot that combines monitoring with strategy logic for Polymarket's 15-minute prediction markets. Polymarket || Polymarket Bot || Polymarket Copy Bot || Polymarket Copy Trading Bot || Polymarket Typescript Bot || Polymarket bot || Polymarket || Polymarket || Polymarket || Polymarket || Polymarket ||  Polymarket",
      "summary": "Building a Polymarket RSI/MACD Trading Bot in TypeScript\n\nThe Problem  \nPredictive trading on Polymarket's 15-minute markets isn’t exactly beginner-friendly. You’ve got RSI, MACD, and momentum signals to juggle, all while figuring out how to execute trades on their decentralized CLOB (Central Limit Order Book). Sure, you could YOLO your way through it, but manual strategies are slow, error-prone, and frankly, a pain in the ass to scale.  \n\nWhat This Does  \nThis bot automates trading decisions using technical indicators like RSI, MACD, and Momentum, with clear separation of concerns in the codebase. The entry point (src/main.ts) handles authentication, market discovery, and running your chosen mode—either simulation or live trading.  \n\nThe heavy lifting happens in src/indicators.ts and src/strategies.ts. Indicators like RollingRSI and RollingMACD crunch market data, while decide() in strategies.ts applies strategy logic to generate buy/sell signals. Meanwhile, src/monitor.ts takes care of market data snapshots, and src/api.ts wraps Polymarket's Gamma API and CLOB functionality into a neat little package.  \n\nConfiguration is managed in config.json. You’ll define stuff like your private key, API URLs, trading thresholds, and strategy settings (rsi, macd, etc.). There’s even flexibility to toggle between simulation and live modes with a simple CLI flag.  \n\nReal-World Use  \nLet’s say you want to run a momentum strategy on ETH’s 15-minute markets. You’d start by cloning the repo, running npm install, and copying config.json.example to config.json. Then, set your polymarket.private_key for live mode or leave it blank for simulations.  \n\n  \n\nThe bot will use your config to fetch market data (src/monitor.ts), calculate momentum signals (src/indicators.ts), and log trading decisions (simulation.ts). Want to go live? Swap --simulation for --live and watch it place actual orders via src/clob.ts.  \n\nThe Bottom Line  \nLook, it’s a solid bot if you’re into algo trading on Polymarket. The code is clean, modular, and reasonably documented, though the lack of stars suggests it’s either underused or overshadowed by the original Rust version. If you’re comfortable with TypeScript and want a framework for experimenting with RSI/MACD strategies, this is worth cloning. Just don’t expect hand-holding—this is DIY trading, not a plug-and-play solution.",
      "url": "https://github.com/moses-y/Polymarket-rsi-macd-index-trading-bot",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Daniel-Dias001/Polymarket-rsi-macd-index-trading-bot",
        "url": "https://github.com/Daniel-Dias001/Polymarket-rsi-macd-index-trading-bot",
        "stars": 4
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 26, 2026",
      "updatedAt": "February 26, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 15,
        "directories": {
          "(root)": 6,
          "src": 9
        },
        "languages": {
          "Markdown": 1,
          "JSON": 3,
          "TypeScript": 9
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "src/main.ts"
        ],
        "configFiles": [
          "package.json",
          "tsconfig.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".md": 1,
          ".example": 1,
          ".json": 3,
          ".ts": 9
        }
      }
    },
    {
      "id": 1167553224,
      "name": "openfang",
      "displayName": "openfang",
      "description": "Open-source Agent Operating System",
      "summary": "OpenFang: An Open-Source Agent Operating System in Rust\n\nThe Problem  \nMost \"AI agent\" tools are just glorified chatbots. They wait for you to type something and spit out a response that sounds smart but often falls apart when you push it. Worse, they’re scattered across a million Python scripts with a web of fragile dependencies, eating up your time with debugging and Docker hell. If you’re trying to build production-grade, always-on agents that do actual work, you’re out of luck.\n\nWhat This Does  \nOpenFang takes a hard stance against the chaos. It’s a Rust-based Agent Operating System that packages everything into a single binary. You get a real, production-grade system that runs pre-built autonomous agents—called “Hands”—24/7 without hand-holding.  \n\nThe architecture is clean and modular, with 14 crates under crates/. For example, crates/openfang-api handles the API and dashboard (check out server.rs and routes.rs), while crates/openfang-cli gives you a slick terminal UI (tui/ is where the magic happens). There’s even a desktop app in crates/openfang-desktop, built with Tauri for those who like shiny GUIs. Configuration is straightforward with .env.example and Cargo.toml files scattered thoughtfully across the repo.  \n\nThe real stars, though, are the agents in agents/. Each agent has a agent.toml manifest that lays out its tools, triggers, and guardrails. This isn’t just some YAML to make you feel productive—it’s how the system enforces operational rules. Want to tweak the \"Lead\" agent to deliver CSVs via Slack instead of Telegram? Modify agents/lead/agent.toml and you’re done.  \n\nReal-World Use  \nImagine you’re running a startup. You need to generate leads, manage your social media, and monitor competitors—all while, you know, running the company. You set up OpenFang, and suddenly you’ve got the \"Lead\" agent pulling qualified prospects daily and the \"Clip\" agent cranking out TikToks from your webinar recordings.  \n\n  \n\nFrom there, it’s plug-and-play. The \"Lead\" agent digs through LinkedIn, enriches data, scores leads, and sends them to your CRM. The \"Clip\" agent uses FFmpeg and yt-dlp to break videos into bite-sized social media gold. All while you sleep.\n\nThe Bottom Line  \nOpenFang is not for hobbyists. It’s over-engineered (in a good way) and assumes you want serious agents doing serious work. If you’re looking for a chatbot toy, move along. But if you’re tired of duct-taped Python scripts and want a no-nonsense, high-performance system built to last, OpenFang delivers. Just don’t expect hand-holding—it’s Rust, not Rails.",
      "url": "https://github.com/moses-y/openfang",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "RightNow-AI/openfang",
        "url": "https://github.com/RightNow-AI/openfang",
        "stars": 3533
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 26, 2026",
      "updatedAt": "February 26, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 15,
          ".github": 3,
          "agents": 30,
          "crates": 152
        },
        "languages": {
          "YAML": 3,
          "Markdown": 6,
          "TOML": 41,
          "Rust": 104,
          "CSS": 4,
          "HTML": 2,
          "JavaScript": 20,
          "JSON": 6
        },
        "frameworks": [
          "Express",
          "Docker"
        ],
        "packageManager": "cargo",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "crates/openfang-api/src/lib.rs",
          "crates/openfang-api/static/js/app.js",
          "crates/openfang-channels/src/lib.rs",
          "crates/openfang-cli/src/main.rs",
          "crates/openfang-desktop/src/lib.rs",
          "crates/openfang-desktop/src/main.rs"
        ],
        "configFiles": [
          ".env.example",
          "Cargo.toml",
          "Dockerfile",
          "crates/openfang-api/Cargo.toml",
          "crates/openfang-channels/Cargo.toml",
          "crates/openfang-cli/Cargo.toml",
          "crates/openfang-desktop/Cargo.toml",
          "crates/openfang-extensions/Cargo.toml"
        ],
        "dependencies": [
          "Cargo.toml",
          "crates/openfang-api/Cargo.toml",
          "crates/openfang-channels/Cargo.toml",
          "crates/openfang-cli/Cargo.toml",
          "crates/openfang-desktop/Cargo.toml",
          "crates/openfang-extensions/Cargo.toml"
        ],
        "testFiles": [
          "agents/test-engineer/agent.toml",
          "crates/openfang-api/tests/api_integration_test.rs",
          "crates/openfang-api/tests/daemon_lifecycle_test.rs",
          "crates/openfang-api/tests/load_test.rs",
          "crates/openfang-channels/tests/bridge_integration_test.rs"
        ],
        "docs": [
          "CHANGELOG.md",
          "CONTRIBUTING.md",
          "LICENSE-APACHE",
          "LICENSE-MIT",
          "README.md"
        ],
        "fileTypes": {
          ".example": 1,
          ".yml": 3,
          ".md": 6,
          ".lock": 1,
          ".toml": 41,
          ".rs": 104,
          ".css": 4,
          ".ico": 2,
          ".html": 2,
          ".js": 20,
          ".png": 5,
          ".json": 6
        }
      }
    },
    {
      "id": 1167548928,
      "name": "murmure",
      "displayName": "murmure",
      "description": "Fully local, private and cross platform Speech-to-Text with LLM Post-processing",
      "summary": "The Problem\nHave you ever tried speech-to-text solutions that require you to send your voice data over the internet? Yeah, privacy nightmare. Murmure tackles this by keeping everything local. No data leaks, no third-party tracking, just you and your voice—completely offline.\n\nWhat This Does\nMurmure is essentially a desktop application that utilizes NVIDIA's Parakeet TDT 0.6B v3 model for local transcription. The core files are in the src-tauri/ directory, where you'll find Cargo.toml, the Rust-based build configuration. The app handles voice commands and converts them to text instantaneously, no cloud required. You can find the main entry point at index.html, which serves as the UI interface.\n\nThe project also includes a comprehensive resources/ directory with audio files and language rule sets, ensuring it supports 25 languages, from Bulgarian to Ukrainian. The e2e-tests/ folder suggests that the developer took testing seriously, with 20 test files covering various functionalities.\n\nReal-World Use\nImagine you’re working on a project that requires constant note-taking or dictation. With Murmure, you can dictate your thoughts hands-free using voice commands. For instance, you could launch the app, hit record, and say, “Translate this text into French.” The local processing means you won't face latency issues associated with cloud services. Plus, you can integrate it with local LLM tools for grammar checks or translation after transcription.\n\nThe Bottom Line\nMurmure feels like a solid choice for anyone who values privacy and needs efficient speech-to-text capabilities. The local processing is a significant plus, but if you're not working with multiple languages or don’t need offline functionality, you might find it overkill. Developers looking for a privacy-first solution should definitely consider giving it a shot. Just be ready for a few hiccups with setup, especially on Linux—Wayland support is still a bit shaky.",
      "url": "https://github.com/moses-y/murmure",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Kieirra/murmure",
        "url": "https://github.com/Kieirra/murmure",
        "stars": 400
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 26, 2026",
      "updatedAt": "February 26, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".github": 11,
          "(root)": 19,
          ".vscode": 1,
          "docs": 3,
          "e2e-tests": 17,
          "public": 3,
          "resources": 129,
          "src-tauri": 17
        },
        "languages": {
          "Markdown": 11,
          "YAML": 11,
          "JSON": 8,
          "JavaScript": 9,
          "TypeScript": 1,
          "HTML": 1,
          "Shell": 1,
          "TOML": 1,
          "Rust": 1
        },
        "frameworks": [
          "React",
          "Next.js"
        ],
        "packageManager": "cargo",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "index.html"
        ],
        "configFiles": [
          ".prettierrc",
          "e2e-tests/package.json",
          "package.json",
          "src-tauri/Cargo.toml"
        ],
        "dependencies": [
          "e2e-tests/package.json",
          "package.json",
          "src-tauri/Cargo.toml"
        ],
        "testFiles": [
          "docs/BETA_TESTING_EN.md",
          "docs/BETA_TESTING_FR.md",
          "e2e-tests/helpers/visual-helpers.js",
          "e2e-tests/package.json",
          "e2e-tests/specs/1-home.spec.js",
          "e2e-tests/specs/2-custom-dictionary.spec.js",
          "e2e-tests/specs/3-llm-connect.spec.js",
          "e2e-tests/specs/4-shortcuts.spec.js",
          "e2e-tests/specs/5-system.spec.js",
          "e2e-tests/specs/6-about.spec.js",
          "e2e-tests/specs/__snapshots__/about-page-wry-920x768-dpr-1.png",
          "e2e-tests/specs/__snapshots__/custom-dictionary-page-wry-920x768-dpr-1.png",
          "e2e-tests/specs/__snapshots__/home-page-wry-920x768-dpr-1.png",
          "e2e-tests/specs/__snapshots__/llm-connect-intro-wry-920x768-dpr-1.png",
          "e2e-tests/specs/__snapshots__/shortcuts-page-wry-920x768-dpr-1.png",
          "e2e-tests/specs/__snapshots__/system-page-wry-920x768-dpr-1.png",
          "e2e-tests/voices/test_en.wav",
          "e2e-tests/voices/test_fr.wav",
          "e2e-tests/wdio.conf.js",
          "latest.json"
        ],
        "docs": [
          "CHANGELOG.md",
          "CONTRIBUTING.md",
          "GUIDELINES.md",
          "LICENSE",
          "README.md",
          "docs/API_USAGE.md",
          "docs/BETA_TESTING_EN.md",
          "docs/BETA_TESTING_FR.md"
        ],
        "fileTypes": {
          ".md": 11,
          ".yml": 8,
          ".yaml": 3,
          ".json": 8,
          ".js": 9,
          ".png": 17,
          ".wav": 2,
          ".ts": 1,
          ".html": 1,
          ".sh": 1,
          ".mp3": 2,
          ".txt": 127,
          ".lock": 1,
          ".toml": 1,
          ".plist": 2,
          ".rs": 1
        }
      }
    },
    {
      "id": 1166914292,
      "name": "fips",
      "displayName": "fips",
      "description": "Free Internetworking Peering System - mesh routing protocol",
      "summary": "Mesh Networking with FIPS: A Practical Guide to Self-Organizing Networks\n\nThe Problem\n\nBuilding decentralized networks is a pain. Traditional routing protocols need centralized control, static configuration, or global knowledge of the network topology. If you want a mesh network that works across random transports (like Bluetooth, UDP, or even radio), good luck. Add encryption, multi-hop routing, and support for dynamic changes, and you're in for a world of hurt.\n\nWhat This Does\n\nFIPS (Free Internetworking Peering System) is a Rust-powered mesh routing protocol that builds self-organizing, decentralized networks. It assigns nodes cryptographic identities that double as routing addresses using Nostr keypairs (src/identity/). It creates a spanning tree, employs bloom filters for route discovery (src/bloom/), and uses Noise encryption for hop-by-hop and end-to-end security (src/noise/). \n\nThe protocol is designed to run on anything—LAN, Bluetooth, radio, or an internet overlay. You can even hook it into IPv6 via a TUN interface (src/upper/tun.rs) for seamless IP routing. Configuration is handled through fips.yaml files, with sane defaults baked in. It’s simple to bootstrap a node and join a network, as long as you have a peer address.\n\nTesting and simulation tools are baked in, with two Docker setups (testing/chaos/Dockerfile, testing/static/Dockerfile) and Python scripts (testing/chaos/sim/) for chaos testing. You can simulate churn, bottlenecks, and even mixed transport scenarios using testing/chaos/scenarios/.\n\nReal-World Use\n\nSay you’re deploying a disaster recovery mesh network. You spin up two nodes with minimal config files like this:\n\nNode B points back to Node A, and they’ll automagically find each other and start routing traffic. You can inspect the network state in real-time with fipsctl (src/bin/fipsctl.rs) or simulate network failures in Docker using the chaos testing scripts.\n\nThe Bottom Line\n\nFIPS is an alpha-stage project, and it shows—it’s not stable, and the docs are a bit scattered. But if you’re a network geek or building decentralized systems, it’s a fascinating playground. Just know going in: this isn’t plug-and-play. But if you’re comfortable with Rust, YAML, and reading source code, FIPS gives you powerful tools for building robust, encrypted, self-healing mesh networks.",
      "url": "https://github.com/moses-y/fips",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "jmcorgan/fips",
        "url": "https://github.com/jmcorgan/fips",
        "stars": 151
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 25, 2026",
      "updatedAt": "February 25, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 6,
          "docs": 60,
          "src": 92,
          "testing": 42
        },
        "languages": {
          "Markdown": 18,
          "TOML": 1,
          "Rust": 92,
          "YAML": 15,
          "Shell": 2,
          "Python": 16
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": "cargo",
        "hasDocker": true,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "src/lib.rs",
          "testing/chaos/sim/__main__.py"
        ],
        "configFiles": [
          "Cargo.toml",
          "testing/chaos/Dockerfile",
          "testing/static/Dockerfile"
        ],
        "dependencies": [
          "Cargo.toml"
        ],
        "testFiles": [
          "src/bloom/tests.rs",
          "src/identity/tests.rs",
          "src/node/tests/bloom.rs",
          "src/node/tests/disconnect.rs",
          "src/node/tests/discovery.rs",
          "src/node/tests/forwarding.rs",
          "src/node/tests/handshake.rs",
          "src/node/tests/mod.rs",
          "src/node/tests/routing.rs",
          "src/node/tests/session.rs",
          "src/node/tests/spanning_tree.rs",
          "src/node/tests/unit.rs",
          "src/noise/tests.rs",
          "src/tree/tests.rs",
          "testing/README.md",
          "testing/chaos/.gitignore",
          "testing/chaos/Dockerfile",
          "testing/chaos/README.md",
          "testing/chaos/configs/node.template.yaml",
          "testing/chaos/resolv.conf",
          "testing/chaos/scenarios/bottleneck-parent.yaml",
          "testing/chaos/scenarios/chaos-10.yaml",
          "testing/chaos/scenarios/churn-10.yaml",
          "testing/chaos/scenarios/churn-20.yaml",
          "testing/chaos/scenarios/cost-avoidance.yaml",
          "testing/chaos/scenarios/cost-mixed-7node.yaml",
          "testing/chaos/scenarios/cost-reeval.yaml",
          "testing/chaos/scenarios/cost-stability.yaml",
          "testing/chaos/scenarios/depth-vs-cost.yaml",
          "testing/chaos/scenarios/mixed-technology.yaml",
          "testing/chaos/scenarios/smoke-10.yaml",
          "testing/chaos/scripts/build.sh",
          "testing/chaos/scripts/chaos.sh",
          "testing/chaos/scripts/derive-keys.py",
          "testing/chaos/sim/__init__.py",
          "testing/chaos/sim/__main__.py",
          "testing/chaos/sim/compose.py",
          "testing/chaos/sim/config_gen.py",
          "testing/chaos/sim/control.py",
          "testing/chaos/sim/docker_exec.py",
          "testing/chaos/sim/keys.py",
          "testing/chaos/sim/links.py",
          "testing/chaos/sim/logs.py",
          "testing/chaos/sim/netem.py",
          "testing/chaos/sim/nodes.py",
          "testing/chaos/sim/runner.py",
          "testing/chaos/sim/scenario.py",
          "testing/chaos/sim/topology.py",
          "testing/chaos/sim/traffic.py",
          "testing/static/.env",
          "testing/static/.gitignore",
          "testing/static/Dockerfile",
          "testing/static/README.md",
          "testing/static/configs/node.template.yaml",
          "testing/static/configs/topologies/chain.yaml",
          "testing/static/configs/topologies/mesh-public.yaml"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "docs/README.md",
          "docs/design/README.md",
          "docs/design/diagrams/ancestry-entry.svg",
          "docs/design/diagrams/common-prefix.svg",
          "docs/design/diagrams/coords-required.svg",
          "docs/design/diagrams/disconnect.svg",
          "docs/design/diagrams/dynamics-convergence.svg",
          "docs/design/diagrams/dynamics-ex1-physical.svg",
          "docs/design/diagrams/dynamics-ex1-tree.svg",
          "docs/design/diagrams/dynamics-ex2-physical.svg",
          "docs/design/diagrams/dynamics-ex2-tree.svg",
          "docs/design/diagrams/dynamics-ex3-partition.svg",
          "docs/design/diagrams/dynamics-ex3-topology.svg",
          "docs/design/diagrams/dynamics-link-addition.svg",
          "docs/design/diagrams/dynamics-link-removal.svg",
          "docs/design/diagrams/dynamics-node-join-steps.svg",
          "docs/design/diagrams/dynamics-node-join.svg",
          "docs/design/diagrams/dynamics-partition.svg",
          "docs/design/diagrams/established-complete-frame.svg",
          "docs/design/diagrams/established-inner-header.svg",
          "docs/design/diagrams/established-outer-header.svg",
          "docs/design/diagrams/filter-announce.svg",
          "docs/design/diagrams/fips-architecture-overview.svg",
          "docs/design/diagrams/fips-bloom-propagation.svg",
          "docs/design/diagrams/fips-coordinate-discovery.svg",
          "docs/design/diagrams/fips-identity-derivation.svg",
          "docs/design/diagrams/fips-mesh-topology.svg",
          "docs/design/diagrams/fips-node-architecture.svg",
          "docs/design/diagrams/fips-osi-mapping.svg",
          "docs/design/diagrams/fips-protocol-stack.svg",
          "docs/design/diagrams/fips-routing-decision.svg",
          "docs/design/diagrams/fsp-complete-message.svg",
          "docs/design/diagrams/handshake-flow.svg",
          "docs/design/diagrams/lookup-request.svg",
          "docs/design/diagrams/lookup-response.svg",
          "docs/design/diagrams/mtu-exceeded.svg",
          "docs/design/diagrams/noise-ik-msg1.svg",
          "docs/design/diagrams/noise-ik-msg2.svg",
          "docs/design/diagrams/path-broken.svg",
          "docs/design/diagrams/path-mtu-notification.svg",
          "docs/design/diagrams/receiver-report.svg",
          "docs/design/diagrams/sender-report.svg",
          "docs/design/diagrams/session-ack.svg",
          "docs/design/diagrams/session-datagram.svg",
          "docs/design/diagrams/session-msg3.svg",
          "docs/design/diagrams/session-setup.svg",
          "docs/design/diagrams/session-warmup-fsm.svg",
          "docs/design/diagrams/tree-announce.svg",
          "docs/design/document-relationships.svg",
          "docs/design/fips-bloom-filters.md",
          "docs/design/fips-configuration.md",
          "docs/design/fips-intro.md",
          "docs/design/fips-ipv6-adapter.md",
          "docs/design/fips-mesh-layer.md",
          "docs/design/fips-mesh-operation.md",
          "docs/design/fips-session-layer.md",
          "docs/design/fips-spanning-tree.md",
          "docs/design/fips-transport-layer.md",
          "docs/design/fips-wire-formats.md",
          "docs/design/spanning-tree-dynamics.md",
          "testing/README.md",
          "testing/chaos/README.md",
          "testing/static/README.md"
        ],
        "fileTypes": {
          ".md": 18,
          ".lock": 1,
          ".toml": 1,
          ".svg": 47,
          ".rs": 92,
          ".yaml": 15,
          ".conf": 1,
          ".sh": 2,
          ".py": 16
        }
      }
    },
    {
      "id": 1166389079,
      "name": "weekday",
      "displayName": "weekday",
      "description": "open source google calendar",
      "summary": "Building an Open-Source Google Calendar Alternative with AI: Weekday\n\nThe Problem\n\nLet’s face it: Google Calendar is fine, but it’s not perfect. Maybe you want more customization. Maybe you don’t want to hand over your entire life to Google. Or maybe you just want a calendar that doesn’t feel like a relic from 2010. Weekday aims to fix those problems by giving you a modern, open-source alternative with built-in AI smarts. Think Google Calendar meets Notion, but without handing over your data to Big Tech.\n\nWhat This Does\n\nAt its core, weekday is a monorepo built with Next.js, TypeScript, and a bunch of other modern tools like tRPC for APIs, Drizzle ORM for database interactions, and Tailwind for styling. The app lives in apps/web/, while utilities like auth, api, and db live in packages/. This structure is powered by Turborepo to keep things modular and maintainable.\n\nThe meat of the calendar functionality is in apps/web/components/event-calendar/. Everything from draggable events (draggable-event.tsx) to different views like month-view.tsx and week-view.tsx is in there. Need to hook into the calendar? There’s a hooks/index.ts file ready for you.\n\nAI features? Yep, it’s got those too. Check out apps/web/components/ai/ for things like actions.tsx (presumably for AI-driven suggestions) and response.tsx (likely for handling AI-generated responses). It even has a chat folder with tools for creating, updating, and deleting events, which could make managing your schedule feel less like a chore.\n\nDon’t worry, backend folks, there’s something for you too. The API lives in packages/api/, with routes for accounts (routers/account.ts) and calendar management (routers/calendar.ts). It uses PostgreSQL (configured in packages/db/) and Drizzle ORM, which is a nice touch for database abstraction without adding the bloat of something like Prisma.\n\nReal-World Use\n\nLet’s say you’re a busy freelancer juggling multiple clients and projects. You could use Weekday to manage your schedule, but what makes it shine is its AI features. Need to find free slots for a meeting? The get-free-slots.tsx tool in apps/web/components/chat/tools/ can do the heavy lifting. Want to auto-suggest meeting times based on your availability? That’s where the AI magic happens, likely leveraging APIs like OpenAI or Anthropic (configured in .env).\n\nHere’s a quick example of how easy it is to set up:\n\nBoom. You’re up and running with a fully-featured calendar app that you can self-host and customize.\n\nThe Bottom Line\n\nWeekday is ambitious. It’s modern, feature-packed, and has a clean codebase that’s easy to navigate. But let’s be real: with zero stars and being a fork, it’s got some work to do in terms of adoption. Still, if you’re tired of the usual suspects and want to tinker with a new approach to calendar management, this is worth a look. Just be ready to get your hands dirty with the setup.",
      "url": "https://github.com/moses-y/weekday",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "ephraimduncan/weekday",
        "url": "https://github.com/ephraimduncan/weekday",
        "stars": 171
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 25, 2026",
      "updatedAt": "February 25, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 6,
          "apps": 113,
          "packages": 81
        },
        "languages": {
          "TSX": 82,
          "TypeScript": 83,
          "CSS": 1,
          "JSON": 16,
          "JavaScript": 5,
          "YAML": 1,
          "SQL": 2,
          "Markdown": 2
        },
        "frameworks": [
          "React",
          "Next.js",
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "apps/web/components/event-calendar/hooks/index.ts",
          "apps/web/components/event-calendar/index.ts",
          "apps/web/trpc/server.ts",
          "packages/api/index.ts",
          "packages/auth/index.ts",
          "packages/db/index.ts",
          "packages/env/index.js",
          "packages/google-calendar/src/index.ts",
          "packages/google-calendar/src/resources/calendars/index.ts",
          "packages/google-calendar/src/resources/index.ts",
          "packages/google-calendar/src/resources/users/index.ts",
          "packages/google-calendar/src/resources/users/me/index.ts",
          "packages/lib/index.ts"
        ],
        "configFiles": [
          ".env.example",
          "apps/web/next.config.js",
          "apps/web/package.json",
          "apps/web/tsconfig.json",
          "docker-compose.yml",
          "package.json",
          "packages/api/package.json",
          "packages/api/tsconfig.json",
          "packages/auth/package.json",
          "packages/auth/tsconfig.json",
          "packages/db/package.json",
          "packages/db/tsconfig.json",
          "packages/env/package.json",
          "packages/env/tsconfig.json",
          "packages/google-calendar/package.json",
          "packages/google-calendar/tsconfig.json"
        ],
        "dependencies": [
          "apps/web/package.json",
          "package.json",
          "packages/api/package.json",
          "packages/auth/package.json",
          "packages/db/package.json",
          "packages/env/package.json",
          "packages/google-calendar/package.json"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "packages/google-calendar/src/core/README.md",
          "packages/google-calendar/src/internal/README.md"
        ],
        "fileTypes": {
          ".example": 1,
          ".tsx": 82,
          ".ts": 83,
          ".css": 1,
          ".json": 16,
          ".js": 5,
          ".png": 3,
          ".svg": 1,
          ".lock": 1,
          ".yml": 1,
          ".sql": 2,
          ".md": 2
        }
      }
    },
    {
      "id": 1166387077,
      "name": "ClickUi",
      "displayName": "ClickUi",
      "description": "The best way to use AI is on your own computer. Use local or paid API models, and ctrl+k to show/hide the chat UI. Experience the future of AI, and help build it too!",
      "summary": "The Problem\nEver tried using an AI assistant on your computer? It’s usually a clunky experience with limited functionality. You might end up switching between apps, dealing with poor voice recognition, or juggling multiple tabs for web searches. ClickUi tackles this mess by integrating various AI models directly on your machine, letting you interact through voice or chat without leaving your current workflow.\n\nWhat This Does\nClickUi is a local AI assistant built in Python, utilizing libraries like Whisper for speech recognition and Kokoro for text-to-speech. You can find the meat of the application in clickui.py, where the main logic resides. The project supports both Voice Mode and Chat Mode, giving you options based on your preference or current task.\n\nThe setup is relatively easy. Just install the dependencies listed in requirements.txt and configure your API keys as specified in the README.md. If you're a Mac user, check out Mac_Prerequisites.txt to get the environment sorted. The Install.bat script is there for Windows folks who prefer one-click installs, but let’s be real, who uses Windows for serious development anymore?\n\nReal-World Use\nImagine you're in the zone coding and need to check the weather or get a quick answer. Instead of alt-tabbing, you hit ctrl+k to pull up the ClickUi chat interface, type your query, and get an instant response—all while keeping your focus. For voice lovers, just speak your command and let ClickUi spit out the answer through your speakers. If you need to play around with voice commands, just tweak the loading of Whisper and Kokoro in clickui.py to disable voice functionality temporarily.\n\nThe Bottom Line\nClickUi is a solid attempt at creating a local AI assistant, but it’s still in its early days—zero stars on GitHub, really? That said, it’s a great starting point for anyone looking to experiment with voice AI or integrate AI models into their daily tasks. Just be prepared to roll up your sleeves for some DIY setup, and remember: it’s open-source, so contribute to make it better. If you’re a developer or AI enthusiast, give it a shot; if you’re just looking for a quick fix, keep scrolling.",
      "url": "https://github.com/moses-y/ClickUi",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "CodeUpdaterBot/ClickUi",
        "url": "https://github.com/CodeUpdaterBot/ClickUi",
        "stars": 423
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 25, 2026",
      "updatedAt": "February 25, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 19,
        "directories": {
          "(root)": 19
        },
        "languages": {
          "Markdown": 1,
          "Python": 2
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [
          "requirements.txt"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE.txt",
          "README.md"
        ],
        "fileTypes": {
          ".bat": 1,
          ".txt": 5,
          ".md": 1,
          ".py": 2,
          ".wav": 4,
          ".ico": 1,
          ".png": 4
        }
      }
    },
    {
      "id": 1166386302,
      "name": "ariana",
      "displayName": "ariana",
      "description": "The IDE of the future",
      "summary": "The Problem\n\nYou get tired of babysitting your dev environment. Spinning up agents, running tests, handling SSH keys, wrangling Docker, and managing PRs is a pain. Most “AI-powered” IDEs are locked behind paywalls or require you to trust some startup with your code and tokens. Ariana tries to kill that noise and let you run your own agentic dev playground, without selling your soul to Big SaaS.\n\nWhat This Does\n\nAriana is basically a swarm of coding agents that edit, commit, push, and even test your code for you—on Hetzner VPSs, not your laptop. The brains live in backend/agents-server/, with entry points like cli.ts and index.ts doing most of the heavy lifting. Agents can trigger automations (see automationService.ts), manage SSH keys (handlers/authorizeSshKey.ts), and juggle PRs (handlers/gitCommit.ts, handlers/gitPush.ts). Docker is used for isolation, and the stack is glued together with TypeScript and SQL migrations dropped into backend/prisma.\n\nIf you want to run automations when an agent commits, you write them in automationTriggerHandler.ts. Want your agent to fork, keep a disk snapshot, or stream a desktop? There’s a handler for that (createSnapshot.ts, servicePreview.ts). It’s messy but powerful—most stuff happens in background scripts and handlers, not shiny React UIs.\n\nReal-World Use\n\nSay you want to have an agent spin up, clone your repo, edit some files, auto-commit, and push to a branch with a PR open. Ariana does all that, no manual git commands needed. Automations can be added so every commit runs your tests or deploys a preview. Here’s a rough workflow:\n\nYou can mention GitHub issues in agent prompts, kick off new agents from your phone, and even stream their desktop to debug stuff in real time. All the SSH/Docker pain is handled by backend scripts and handlers.\n\nThe Bottom Line\n\nAriana is for people who want to run their own AI coding agents and aren’t scared of setting up custom infra. The codebase is wild—lots of scripts, handlers, and SQL migrations. If you want a button-and-wizard IDE, look elsewhere. If you want to hack on agentic workflows and automate your dev life, this is worth a look. Just expect to spend a weekend reading source and fighting config.",
      "url": "https://github.com/moses-y/ariana",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "ariana-dot-dev/ariana",
        "url": "https://github.com/ariana-dot-dev/ariana",
        "stars": 325
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 25, 2026",
      "updatedAt": "February 25, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".claude": 1,
          "(root)": 6,
          ".github": 2,
          "assets": 1,
          "backend": 190
        },
        "languages": {
          "JSON": 6,
          "YAML": 2,
          "Markdown": 8,
          "JavaScript": 1,
          "HCL": 1,
          "TypeScript": 89,
          "Shell": 15,
          "SQL": 67,
          "TOML": 1
        },
        "frameworks": [
          "React",
          "Docker"
        ],
        "packageManager": "npm",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "backend/agents-server/cli/cli.ts",
          "backend/agents-server/src/ariana-cli/index.ts",
          "backend/agents-server/src/index.ts",
          "backend/agents-server/src/lux-cli/index.ts",
          "backend/index.ts",
          "backend/shared/types/index.ts"
        ],
        "configFiles": [
          "Dockerfile",
          "backend/.env.example",
          "backend/.eslintrc.js",
          "backend/agents-server/.env.example",
          "backend/agents-server/cli/package.json",
          "backend/agents-server/package.json",
          "backend/agents-server/tsconfig.json",
          "backend/package.json"
        ],
        "dependencies": [
          "backend/agents-server/cli/package.json",
          "backend/agents-server/package.json",
          "backend/package-lock.json",
          "backend/package.json"
        ],
        "testFiles": [
          "backend/prisma/migrations/20251228141353_remove_specifications/migration.sql"
        ],
        "docs": [
          "README.md",
          "backend/agents-server/README.md",
          "backend/agents-server/cli/README.md",
          "backend/agents-server/scripts/README.md"
        ],
        "fileTypes": {
          ".json": 6,
          ".yml": 2,
          ".md": 8,
          ".mp4": 1,
          ".example": 2,
          ".js": 1,
          ".hcl": 1,
          ".ts": 89,
          ".sh": 15,
          ".txt": 1,
          ".sql": 67,
          ".toml": 1,
          ".prisma": 1
        }
      }
    },
    {
      "id": 1166361501,
      "name": "dataclaw",
      "displayName": "dataclaw",
      "description": "No description available",
      "summary": "Dataclaw: Taking Back Your Data from AI Models\n\nThe Problem\n\nSo, you’ve been chatting with AI models like Claude Code or Codex, getting them to write your scripts, debug your code, and maybe even naming your variables. But here’s the kicker: while you’re feeding them your data and ideas, they’re walking away with it. Anthropic, OpenAI, you name it—they’re happy to hoard your input for their training sets, but make it painfully hard for you to extract your own data. Enter dataclaw, a Python tool that lets you take control of your AI session logs, clean them up, and publish them as structured datasets to Hugging Face with a single command. It’s part data pipeline, part middle finger to the closed-data playbook.\n\nWhat This Does\n\ndataclaw is a CLI-based tool designed to turn your AI session logs into datasets you own. The main entry point is dataclaw/cli.py, which powers commands for setup, configuration, data processing, and publishing. It’s smart enough to parse logs, redact sensitive info (using dataclaw/anonymizer.py), and even handle custom user configs (dataclaw/config.py). The pyproject.toml handles dependencies, and CI/CD is baked in via GitHub Actions (.github/workflows/).\n\nThe process is deliberately step-by-step to ensure you don’t accidentally leak your secrets. First, you run dataclaw prep to set up the environment. Then, you configure your scope (dataclaw config --source) and pick which folders to exclude (dataclaw config --exclude). Once that’s done, you export the data locally for review (dataclaw export --no-push), confirm any redactions, and only then publish to Hugging Face (dataclaw export --publish-attestation). The guardrails are strict—this thing is built to err on the side of caution.\n\nReal-World Use\n\nLet’s say you’ve been using Claude Code to prototype a new app. Over weeks, you’ve racked up a ton of conversations with useful snippets, but now you want to make a public dataset documenting AI-human collaboration. dataclaw lets you:\nInstall it: pip install dataclaw (or clone it if you’re old-school).\nConfigure it to pull Claude logs: dataclaw config --source claude.\nExclude anything sensitive: dataclaw config --exclude \"private-projects,scratch\".\nReview the export locally: dataclaw export --no-push.\nConfirm redactions and publish: dataclaw confirm followed by dataclaw export --publish-attestation.\n\nAll without exposing your personal or client data, thanks to the built-in anonymization and review workflows.\n\nThe Bottom Line\n\ndataclaw is a niche tool for a niche problem, but it’s damn good at what it does. The CLI is clear, the steps are well-documented, and the safety features are robust (in the good way). That said, it’s overkill if all you want is a quick-and-dirty log dump. But if you care about controlling your data and want to contribute to an open, distributed dataset, dataclaw is worth a look. Just be ready to jump through a lot of “did you really mean to do that?” hoops along the way.",
      "url": "https://github.com/moses-y/dataclaw",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "peteromallet/dataclaw",
        "url": "https://github.com/peteromallet/dataclaw",
        "stars": 1448
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 25, 2026",
      "updatedAt": "February 25, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 22,
        "directories": {
          ".claude": 1,
          ".github": 2,
          "(root)": 6,
          "dataclaw": 6,
          "docs": 1,
          "tests": 6
        },
        "languages": {
          "Markdown": 3,
          "YAML": 2,
          "Python": 12,
          "TOML": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "dataclaw/cli.py"
        ],
        "configFiles": [
          "pyproject.toml"
        ],
        "dependencies": [
          "pyproject.toml"
        ],
        "testFiles": [
          ".github/workflows/test.yml",
          "tests/conftest.py",
          "tests/test_anonymizer.py",
          "tests/test_cli.py",
          "tests/test_config.py",
          "tests/test_parser.py",
          "tests/test_secrets.py"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "docs/SKILL.md"
        ],
        "fileTypes": {
          ".md": 3,
          ".yml": 2,
          ".jpeg": 1,
          ".py": 12,
          ".toml": 1,
          ".png": 1
        }
      }
    },
    {
      "id": 1166356346,
      "name": "plano",
      "displayName": "plano",
      "description": "Delivery infrastructure for agentic apps - Plano is an AI-native proxy and data plane that offloads plumbing work, so you stay focused on your agent's core logic (via any AI framework).",
      "summary": "The Problem\nBuilding agentic applications is a nightmare when you have to deal with all the routing, orchestration, and data management. You end up spending way too much time on boilerplate code instead of actually building features that matter. Every new agent means more code to manage, and your app starts looking like a tangled mess of spaghetti.\n\nWhat This Does\nPlano is here to pull the plumbing out of your codebase. It offloads the heavy lifting of routing and orchestration into its own data plane. Check out the apps/www/src/app/api/contact/route.ts for an example of how you can define your API routes without getting bogged down in the backend logic.\n\nUsing Filter Chains, you can easily implement moderation and memory hooks without writing a ton of boilerplate. You can find the configuration details in config/planoconfigschema.yaml, which makes it straightforward to customize your setup. Want to add a new agent? Just drop it in and let Plano handle the rest.\n\nReal-World Use\nImagine you're building a travel agent app that interacts with multiple APIs for booking flights, hotels, and car rentals. With Plano, you can set up your agents to handle each task without hardcoding the logic into your app. You’d use apps/www/src/components/research/ResearchGrid.tsx to display results, while the routing and orchestration happen behind the scenes. Just define your agents in the cli/planoai/templates directory and let Plano manage the communication.\n\nThe Bottom Line\nPlano is a solid choice if you’re tired of boilerplate and want to focus on building your agentic apps. It’s great for medium to large projects that need robust routing and orchestration but might be overkill for simple applications. If you're dealing with multiple agents and need a flexible, scalable solution, give Plano a shot. Just be ready to dive into the weeds of its configuration.",
      "url": "https://github.com/moses-y/plano",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "katanemo/plano",
        "url": "https://github.com/katanemo/plano",
        "stars": 5762
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 25, 2026",
      "updatedAt": "February 25, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 11,
          ".github": 5,
          "apps": 122,
          "cli": 31,
          "config": 9,
          "crates": 22
        },
        "languages": {
          "YAML": 16,
          "Markdown": 6,
          "JSON": 12,
          "TypeScript": 16,
          "CSS": 2,
          "TSX": 40,
          "Shell": 3,
          "Python": 19,
          "TOML": 3,
          "Rust": 17
        },
        "frameworks": [
          "React",
          "Next.js",
          "Docker"
        ],
        "packageManager": "cargo",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "apps/www/schemaTypes/index.ts",
          "apps/www/src/components/research/index.ts",
          "cli/planoai/main.py",
          "crates/brightstaff/src/lib.rs",
          "crates/brightstaff/src/main.rs"
        ],
        "configFiles": [
          "Dockerfile",
          "apps/katanemo-www/next.config.ts",
          "apps/katanemo-www/package.json",
          "apps/katanemo-www/tsconfig.json",
          "apps/www/next.config.ts",
          "apps/www/package.json",
          "apps/www/tsconfig.json",
          "cli/pyproject.toml",
          "config/docker-compose.dev.yaml",
          "config/requirements.txt",
          "crates/Cargo.toml",
          "crates/brightstaff/Cargo.toml"
        ],
        "dependencies": [
          "apps/katanemo-www/package.json",
          "apps/www/package-lock.json",
          "apps/www/package.json",
          "cli/pyproject.toml",
          "config/requirements.txt",
          "crates/Cargo.toml",
          "crates/brightstaff/Cargo.toml"
        ],
        "testFiles": [
          "cli/test/__init__.py",
          "cli/test/source/failure.json",
          "cli/test/source/success.json",
          "cli/test/test_config_generator.py",
          "cli/test/test_init.py",
          "cli/test/test_trace_cmd.py",
          "cli/test/test_version_check.py",
          "config/test_passthrough.yaml",
          "crates/brightstaff/src/handlers/integration_tests.rs"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "apps/www/README.md",
          "cli/README.md",
          "config/README.md"
        ],
        "fileTypes": {
          ".yml": 5,
          ".yaml": 11,
          ".md": 6,
          ".json": 12,
          ".ts": 16,
          ".mjs": 2,
          ".svg": 39,
          ".css": 2,
          ".tsx": 40,
          ".png": 1,
          ".ttf": 2,
          ".otf": 4,
          ".woff2": 3,
          ".ico": 1,
          ".code-workspace": 1,
          ".sh": 3,
          ".py": 19,
          ".toml": 3,
          ".lock": 2,
          ".list": 1,
          ".txt": 1,
          ".conf": 1,
          ".rs": 17
        }
      }
    },
    {
      "id": 1165945544,
      "name": "stable-diffusion-webui",
      "displayName": "stable diffusion webui",
      "description": "Stable Diffusion web UI",
      "summary": "Stable Diffusion Web UI: A Practical Take\n\nThe Problem\n\nRunning machine learning models locally is often a pain. You need a Python environment, the right versions of libraries, and let's not forget the joy of figuring out why CUDA isn’t working. Once you get it running, you’re stuck fiddling with command-line arguments unless you enjoy the thrill of squinting at terminal outputs. Stable Diffusion is awesome—getting it to generate art shouldn’t feel like debugging a nuclear reactor.\n\nWhat This Does\n\nThis repo, a fork of the wildly popular AUTOMATIC1111/stable-diffusion-webui, slaps a web interface on top of Stable Diffusion using Gradio. It turns the chaos of Python scripts into a (relatively) user-friendly experience.\n\nThe project is sprawling—200 files—but the key pieces are pretty cleanly organized. The modules/ directory (85 files) is where the magic happens: it’s the core backend for things like img2img (modules/img2img.py), textual inversion (modules/textualInversion.py), and model handling (modules/modelloader.py). The extensions-builtin/ folder (43 files) is where you’ll find optional add-ons like face restoration (LDSR and GFPGAN) or post-processing scripts. If you’re looking to tweak the UI or add custom functionality, check out the javascript/ and html/ directories.\n\nThe setup script (launch.py) takes care of the grunt work—installing dependencies, pulling models, and starting the server. It’s not \"one-click\" (you still need to install Python and Git), but it’s close enough.\n\nReal-World Use\n\nSay you want to upscale an image while fixing its cursed AI-generated hands. You’d load your image in the \"Extras\" tab, select GFPGAN from the dropdown, and let the model do its thing. The generation parameters (e.g., prompt text, sampling method, seed) are stored directly in the output image metadata, so if you want to refine your results later, just drag the image back into the interface to reload its settings.\n\nIf you’re feeling adventurous, you can use advanced features like the Prompt Editing tool to generate a unique image that transitions from one concept (e.g., a sunset) to another (e.g., a futuristic cityscape).\n\nThe Bottom Line\n\nThis repo takes the complexity out of running Stable Diffusion, which is no small feat. The folder structure is sprawling, and good luck navigating the 85 files in modules/ without getting lost. That said, once you get it running, it’s a power tool for artists, developers, and hobbyists alike. If you’ve got a beefy GPU and a lot of curiosity, this is worth a weekend. If you’re looking for polished plug-and-play software, though, maybe wait for someone else to host it for you.",
      "url": "https://github.com/moses-y/stable-diffusion-webui",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "AUTOMATIC1111/stable-diffusion-webui",
        "url": "https://github.com/AUTOMATIC1111/stable-diffusion-webui",
        "stars": 161372
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 24, 2026",
      "updatedAt": "February 24, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 13,
          ".github": 7,
          "configs": 7,
          "embeddings": 1,
          "extensions-builtin": 43,
          "extensions": 1,
          "html": 12,
          "javascript": 25,
          "localizations": 1,
          "models": 5,
          "modules": 85
        },
        "languages": {
          "JavaScript": 29,
          "YAML": 14,
          "Markdown": 3,
          "TOML": 1,
          "Python": 124,
          "CSS": 1,
          "HTML": 11
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          ".eslintrc.js"
        ],
        "dependencies": [],
        "testFiles": [
          ".github/workflows/run_tests.yaml",
          "javascript/aspectRatioOverlay.js",
          "modules/mac_specific.py",
          "modules/npu_specific.py"
        ],
        "docs": [
          "CHANGELOG.md",
          "LICENSE.txt",
          "README.md",
          "html/licenses.html"
        ],
        "fileTypes": {
          ".js": 29,
          ".yml": 4,
          ".md": 3,
          ".yaml": 10,
          ".cff": 1,
          ".txt": 7,
          ".toml": 1,
          ".py": 124,
          ".css": 1,
          ".png": 1,
          ".html": 11,
          ".pt": 1,
          ".th": 1,
          ".ttf": 1
        }
      }
    },
    {
      "id": 1165904418,
      "name": "agent-orchestrator",
      "displayName": "agent orchestrator",
      "description": " Agentic orchestrator for parallel coding agents — plans tasks, spawns agents, and autonomously handles CI    fixes, merge conflicts, and code reviews.",
      "summary": "Agent Orchestrator: Herding Your AI Minions So You Don’t Have To\n\nThe Problem\nManaging multiple AI agents writing code in parallel is a nightmare. They step on each other’s toes (read: branches), break CI, and leave you debugging their mess. Add merge conflicts and reviewer comments into the mix, and congrats—you’re now a glorified babysitter for robots. Nobody signed up for that.\n\nWhat This Does\nagent-orchestrator takes the chaos out of running multiple AI agents. It gives each agent its own isolated workspace (via git worktrees), spins up runtimes (default: tmux), and wires everything into a single dashboard. Your agents can now tackle tasks like fixing CI, addressing code reviews, and opening PRs without you holding their hands.\n\nThe project is built around a plugin-based architecture (packages/core/src/types.ts), so you can swap out components like runtimes (e.g., docker, k8s), agents (claude-code, codex), or notifiers (slack, webhook). The main CLI is in packages/cli/src/index.ts, and the orchestration logic lives in packages/core/src/.\n\nReal-World Use\nLet’s say your team uses GitHub and Linear for task tracking. You’ve been assigned issue #123 on the my-project repo. Instead of manually switching branches, spawning agents, and watching them break stuff, you just run:\n\nHere’s what happens:\nA git worktree and feature branch get created (see packages/core/src/paths.ts).\nA tmux session starts running the agent.\nThe agent reads the issue context, writes code, and opens a PR.\nIf CI fails, the agent grabs the logs and fixes the problem (ci.yml in .github/workflows/).\nReviewer requests changes? The agent handles it. Approved PR? Notifies you.\n\nAll of this shows up in the dashboard at http://localhost:3000. Need to intervene? Use commands like ao send <session> \"Fix the tests\" or ao session kill <session> if the agent’s gone rogue.\n\nThe Bottom Line\nagent-orchestrator is niche but powerful. If you’re running multiple coding agents at once, it’s a godsend; it’s like Kubernetes for your AI workforce. But let’s be real—this is overkill for solo devs or small projects. If you’re building an AI-driven workflow that needs heavy automation, though, this is worth a look. Just be prepared to spend time setting up and tuning those plugins.",
      "url": "https://github.com/moses-y/agent-orchestrator",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "ComposioHQ/agent-orchestrator",
        "url": "https://github.com/ComposioHQ/agent-orchestrator",
        "stars": 2671
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 24, 2026",
      "updatedAt": "February 24, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".changeset": 2,
          ".cursor": 1,
          ".github": 5,
          "(root)": 17,
          ".husky": 1,
          "artifacts": 3,
          "changelog": 1,
          "docs": 11,
          "examples": 6,
          "packages": 153
        },
        "languages": {
          "Markdown": 32,
          "JSON": 37,
          "YAML": 11,
          "TOML": 1,
          "CSS": 1,
          "JavaScript": 2,
          "TypeScript": 107
        },
        "frameworks": [
          "React"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "packages/cli/src/index.ts",
          "packages/core/src/index.ts",
          "packages/plugins/agent-aider/src/index.ts",
          "packages/plugins/agent-claude-code/src/index.ts",
          "packages/plugins/agent-codex/src/index.ts",
          "packages/plugins/agent-opencode/src/index.ts",
          "packages/plugins/notifier-composio/src/index.ts",
          "packages/plugins/notifier-desktop/src/index.ts",
          "packages/plugins/notifier-slack/src/index.ts",
          "packages/plugins/notifier-webhook/src/index.ts",
          "packages/plugins/runtime-process/src/index.ts",
          "packages/plugins/runtime-tmux/src/index.ts",
          "packages/plugins/scm-github/src/index.ts",
          "packages/plugins/terminal-iterm2/src/index.ts",
          "packages/plugins/terminal-web/src/index.ts"
        ],
        "configFiles": [
          ".prettierrc",
          "package.json",
          "packages/agent-orchestrator/package.json",
          "packages/cli/package.json",
          "packages/cli/tsconfig.json",
          "packages/core/package.json",
          "packages/core/tsconfig.json",
          "packages/integration-tests/package.json",
          "packages/integration-tests/tsconfig.json",
          "packages/plugins/agent-aider/package.json",
          "packages/plugins/agent-aider/tsconfig.json",
          "packages/plugins/agent-claude-code/package.json",
          "packages/plugins/agent-claude-code/tsconfig.json",
          "packages/plugins/agent-codex/package.json",
          "packages/plugins/agent-codex/tsconfig.json",
          "packages/plugins/agent-opencode/package.json",
          "packages/plugins/agent-opencode/tsconfig.json",
          "packages/plugins/notifier-composio/package.json",
          "packages/plugins/notifier-composio/tsconfig.json",
          "packages/plugins/notifier-desktop/package.json",
          "packages/plugins/notifier-desktop/tsconfig.json",
          "packages/plugins/notifier-slack/package.json",
          "packages/plugins/notifier-slack/tsconfig.json",
          "packages/plugins/notifier-webhook/package.json",
          "packages/plugins/notifier-webhook/tsconfig.json",
          "packages/plugins/runtime-process/package.json",
          "packages/plugins/runtime-process/tsconfig.json",
          "packages/plugins/runtime-tmux/package.json",
          "packages/plugins/runtime-tmux/tsconfig.json",
          "packages/plugins/scm-github/package.json",
          "packages/plugins/scm-github/tsconfig.json",
          "packages/plugins/terminal-iterm2/package.json",
          "packages/plugins/terminal-iterm2/tsconfig.json",
          "packages/plugins/terminal-web/package.json",
          "packages/plugins/terminal-web/tsconfig.json",
          "packages/plugins/tracker-github/package.json"
        ],
        "dependencies": [
          "package.json",
          "packages/agent-orchestrator/package.json",
          "packages/cli/package.json",
          "packages/core/package.json",
          "packages/integration-tests/package.json",
          "packages/plugins/agent-aider/package.json",
          "packages/plugins/agent-claude-code/package.json",
          "packages/plugins/agent-codex/package.json",
          "packages/plugins/agent-opencode/package.json",
          "packages/plugins/notifier-composio/package.json",
          "packages/plugins/notifier-desktop/package.json",
          "packages/plugins/notifier-slack/package.json",
          "packages/plugins/notifier-webhook/package.json",
          "packages/plugins/runtime-process/package.json",
          "packages/plugins/runtime-tmux/package.json",
          "packages/plugins/scm-github/package.json",
          "packages/plugins/terminal-iterm2/package.json",
          "packages/plugins/terminal-web/package.json",
          "packages/plugins/tracker-github/package.json"
        ],
        "testFiles": [
          ".github/workflows/integration-tests.yml",
          ".github/workflows/onboarding-test.yml",
          "packages/cli/__tests__/commands/dashboard.test.ts",
          "packages/cli/__tests__/commands/init.test.ts",
          "packages/cli/__tests__/commands/open.test.ts",
          "packages/cli/__tests__/commands/review-check.test.ts",
          "packages/cli/__tests__/commands/send.test.ts",
          "packages/cli/__tests__/commands/session.test.ts",
          "packages/cli/__tests__/commands/spawn.test.ts",
          "packages/cli/__tests__/commands/status.test.ts",
          "packages/cli/__tests__/lib/format.test.ts",
          "packages/cli/__tests__/lib/plugins.test.ts",
          "packages/cli/__tests__/lib/session-utils.test.ts",
          "packages/cli/__tests__/lib/shell.test.ts",
          "packages/cli/vitest.config.ts",
          "packages/core/__tests__/config.test.ts",
          "packages/core/src/__tests__/config-validation.test.ts",
          "packages/core/src/__tests__/lifecycle-manager.test.ts",
          "packages/core/src/__tests__/metadata.test.ts",
          "packages/core/src/__tests__/paths.test.ts",
          "packages/core/src/__tests__/plugin-integration.test.ts",
          "packages/core/src/__tests__/plugin-registry.test.ts",
          "packages/core/src/__tests__/prompt-builder.test.ts",
          "packages/core/src/__tests__/session-manager.test.ts",
          "packages/core/src/__tests__/tmux.test.ts",
          "packages/core/src/__tests__/utils.test.ts",
          "packages/core/vitest.config.ts",
          "packages/integration-tests/package.json",
          "packages/integration-tests/src/agent-aider.integration.test.ts",
          "packages/integration-tests/src/agent-claude-code.integration.test.ts",
          "packages/integration-tests/src/agent-codex.integration.test.ts",
          "packages/integration-tests/src/agent-opencode.integration.test.ts",
          "packages/integration-tests/src/cli-session-ls.integration.test.ts",
          "packages/integration-tests/src/cli-spawn-core-read-new.integration.test.ts",
          "packages/integration-tests/src/cli-spawn-send-kill.integration.test.ts",
          "packages/integration-tests/src/config-metadata-service.integration.test.ts",
          "packages/integration-tests/src/helpers/event-factory.ts",
          "packages/integration-tests/src/helpers/polling.ts",
          "packages/integration-tests/src/helpers/session-factory.ts",
          "packages/integration-tests/src/helpers/tmux.ts",
          "packages/integration-tests/src/metadata-lifecycle.integration.test.ts",
          "packages/integration-tests/src/notifier-composio.integration.test.ts",
          "packages/integration-tests/src/notifier-desktop.integration.test.ts",
          "packages/integration-tests/src/notifier-slack.integration.test.ts",
          "packages/integration-tests/src/notifier-webhook.integration.test.ts",
          "packages/integration-tests/src/runtime-process.integration.test.ts",
          "packages/integration-tests/src/runtime-tmux.integration.test.ts",
          "packages/integration-tests/src/terminal-iterm2.integration.test.ts",
          "packages/integration-tests/src/terminal-web.integration.test.ts",
          "packages/integration-tests/src/tracker-linear.integration.test.ts",
          "packages/integration-tests/src/workspace-clone.integration.test.ts",
          "packages/integration-tests/src/workspace-worktree.integration.test.ts",
          "packages/integration-tests/tsconfig.json",
          "packages/integration-tests/vitest.config.ts",
          "packages/plugins/agent-aider/src/index.test.ts",
          "packages/plugins/agent-claude-code/src/__tests__/activity-detection.test.ts",
          "packages/plugins/agent-claude-code/src/index.test.ts",
          "packages/plugins/agent-codex/src/index.test.ts",
          "packages/plugins/agent-opencode/src/index.test.ts",
          "packages/plugins/notifier-composio/src/index.test.ts",
          "packages/plugins/notifier-desktop/src/index.test.ts",
          "packages/plugins/notifier-slack/src/index.test.ts",
          "packages/plugins/notifier-webhook/src/index.test.ts",
          "packages/plugins/runtime-process/src/__tests__/index.test.ts",
          "packages/plugins/runtime-tmux/src/__tests__/index.test.ts",
          "packages/plugins/scm-github/test/index.test.ts",
          "packages/plugins/terminal-iterm2/src/index.test.ts",
          "packages/plugins/terminal-web/src/index.test.ts"
        ],
        "docs": [
          ".changeset/README.md",
          "LICENSE",
          "README.md",
          "changelog/hash-based-architecture-migration.md",
          "docs/DEVELOPMENT.md",
          "docs/SECURITY-AUDIT-SUMMARY.md",
          "docs/design/README.md",
          "docs/design/competitive-analysis-raw.md",
          "docs/design/design-brief-v1.md",
          "docs/design/design-brief.md",
          "docs/design/orchestrator-terminal-design-brief.md",
          "docs/design/screenshots/linear-homepage.png",
          "docs/design/screenshots/railway-homepage.png",
          "docs/design/session-detail-design-brief.md",
          "docs/design/token-reference.css",
          "examples/README.md",
          "packages/core/README.md",
          "packages/plugins/runtime-tmux/README.md"
        ],
        "fileTypes": {
          ".md": 32,
          ".json": 37,
          ".yml": 5,
          ".toml": 1,
          ".yaml": 6,
          ".example": 1,
          ".png": 2,
          ".css": 1,
          ".js": 2,
          ".ts": 107
        }
      }
    },
    {
      "id": 1165798408,
      "name": "GitNexus",
      "displayName": "GitNexus",
      "description": "GitNexus: The Zero-Server Code Intelligence Engine -       GitNexus is a client-side knowledge graph creator that runs entirely in your browser. Drop in a GitHub repo or ZIP file, and get an interactive knowledge graph wit a built in Graph RAG Agent. Perfect for code exploration",
      "summary": "GitNexus: Graph-Powered Code Intelligence Without Servers\n\nThe Problem\n\nEver tried using an AI assistant like Claude or Cursor to refactor code, only for it to ship edits that break half the project? AI tools are great at syntax but blind to architecture. They miss dependencies, botch call chains, and will happily delete a function that’s referenced three layers deep. Developers need smarter tools that actually understand their codebases.\n\nWhat This Does\n\nGitNexus indexes your codebase as a knowledge graph — every function, dependency, and execution flow mapped out — and makes it accessible in two ways: via a browser-based Web UI (gitnexus-web/) or a CLI with MCP server (gitnexus/). \n\nUnder the hood, the heavy lifting happens in gitnexus-web/src/core/ingestion/, which uses Tree-Sitter to parse your code into an abstract syntax tree (AST). This feeds into KuzuDB for graph storage, enabling both in-browser exploration and persistent local indexing. The CLI (gitnexus/src/cli/) connects AI agents like Claude Code directly to this graph, equipping them with deep architectural context. No more blind edits or missed dependencies. \n\nFor convenience, the Web UI (gitnexus-web/src/App.tsx) lets you upload repos or ZIPs and explore the graph visually — perfect for quick analysis or demos. But for serious work, use the CLI: npx gitnexus analyze indexes your repo, auto-generates context files like AGENTS.md, and sets up an MCP server for your AI tools.\n\nReal-World Use\n\nSay you’re debugging a spaghetti mess in a legacy codebase. Start by running npx gitnexus analyze in the repo root. This creates a graph showing function relationships, dependencies, and execution flows. Open AGENTS.md for a human-readable summary, connect your AI agent to the MCP server, and let it navigate the graph. Want to visualize the graph? Spin up the Web UI with gitnexus serve to explore the same indexed data interactively.\n\nHere’s the kicker: GitNexus doesn’t need a backend. The Web UI runs entirely in your browser using KuzuDB WASM, and the CLI operates locally with native bindings. Your code stays private. No uploading required.\n\nThe Bottom Line\n\nGitNexus is a clever tool for making AI agents less dumb about codebases. The browser-based UI is great for quick exploration, while the CLI + MCP server is a powerful (but slightly complex) setup for integrating with your AI tools. If you’re working on large or messy projects and need smarter AI, it’s worth trying. For small repos? Honestly, this might be overkill.",
      "url": "https://github.com/moses-y/GitNexus",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "abhigyanpatwari/GitNexus",
        "url": "https://github.com/abhigyanpatwari/GitNexus",
        "stars": 6129
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 24, 2026",
      "updatedAt": "February 24, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".claude": 5,
          "(root)": 8,
          ".github": 5,
          ".sisyphus": 2,
          "eval": 30,
          "gitnexus-claude-plugin": 10,
          "gitnexus-cursor-integration": 6,
          "gitnexus-test-setup": 1,
          "gitnexus-web": 98,
          "gitnexus": 35
        },
        "languages": {
          "JSON": 13,
          "Markdown": 23,
          "YAML": 14,
          "Python": 10,
          "Shell": 6,
          "TOML": 1,
          "JavaScript": 4,
          "TypeScript": 78,
          "HTML": 1,
          "TSX": 21,
          "CSS": 1
        },
        "frameworks": [
          "React",
          "Express"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "gitnexus-web/index.html",
          "gitnexus-web/src/App.tsx",
          "gitnexus-web/src/core/embeddings/index.ts",
          "gitnexus-web/src/core/llm/index.ts",
          "gitnexus-web/src/core/search/index.ts",
          "gitnexus-web/src/vendor/leiden/index.js",
          "gitnexus/src/cli/index.ts",
          "gitnexus/src/core/embeddings/index.ts"
        ],
        "configFiles": [
          "eval/.env.example",
          "eval/pyproject.toml",
          "gitnexus-web/package.json",
          "gitnexus-web/tsconfig.json",
          "gitnexus-web/vite.config.ts",
          "gitnexus/package.json"
        ],
        "dependencies": [
          "eval/pyproject.toml",
          "gitnexus-web/package-lock.json",
          "gitnexus-web/package.json",
          "gitnexus/package-lock.json",
          "gitnexus/package.json"
        ],
        "testFiles": [
          "gitnexus-test-setup/.gitignore"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "eval/README.md",
          "gitnexus/README.md"
        ],
        "fileTypes": {
          ".json": 13,
          ".md": 23,
          ".yml": 5,
          ".example": 1,
          ".py": 10,
          ".sh": 6,
          ".yaml": 9,
          ".jinja": 6,
          ".toml": 1,
          ".js": 4,
          ".ts": 78,
          ".html": 1,
          ".wasm": 12,
          ".tsx": 21,
          ".css": 1,
          ".cjs": 1
        }
      }
    },
    {
      "id": 1165795265,
      "name": "sharedcontext",
      "displayName": "sharedcontext",
      "description": "No description available",
      "summary": "The Problem\nEvery time you fire up an AI assistant, it’s like starting from scratch. Your preferences, project decisions, and context vanish as soon as the session ends. This fragmented memory leads to repetitive explanations and frustration. You want your AI to remember, but the default setups just don’t cut it.\n\nWhat This Does\nEnter SharedContext, a memory layer for AI agents that actually remembers stuff. Located in the src/ directory, it utilizes TypeScript for type safety and React for any UI components, although it looks like the UI part is still in the works. The main entry point is src/index.ts, which kicks everything off, while the src/mcp/server.ts handles the Model Context Protocol (MCP) server that the AI clients connect to.\n\nData is stored locally in an SQLite database, structured into three tables: facts, which holds your memory; pending_deletes, for anything you want to erase; and meta, tracking sync states. The background watcher syncs this data to Arweave for permanent storage, ensuring you can restore your context with a simple recovery phrase when switching machines.\n\nReal-World Use\nImagine you’re working with Claude and Codex on a project. You have specific coding standards and architectural decisions that you want to persist. Instead of repeating yourself every session, you initialize SharedContext with src/cli/init.ts, which sets up the memory layer automatically. Anytime you want to recall your past discussions, you just call a function from the MCP, and boom—your context is back. You can even share specific conversations via encrypted links.\n\nThe Bottom Line\nSharedContext is a solid start for anyone tired of their AI forgetting everything. It’s still in early development, so expect some rough edges; you won’t want to rely on it for mission-critical tasks just yet. If you frequently juggle multiple AI tools and want a unified memory, this is worth checking out. Just be prepared to do a bit of tinkering.",
      "url": "https://github.com/moses-y/sharedcontext",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Eversmile12/sharedcontext",
        "url": "https://github.com/Eversmile12/sharedcontext",
        "stars": 37
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 24, 2026",
      "updatedAt": "February 24, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 42,
        "directories": {
          "(root)": 5,
          "src": 37
        },
        "languages": {
          "Markdown": 1,
          "JSON": 2,
          "YAML": 1,
          "TypeScript": 37
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "pnpm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "src/index.ts",
          "src/mcp/server.ts"
        ],
        "configFiles": [
          "package.json",
          "tsconfig.json"
        ],
        "dependencies": [
          "package.json"
        ],
        "testFiles": [
          "src/cli/inspect.ts",
          "src/test/arweave-integration.test.ts",
          "src/test/crypto.test.ts",
          "src/test/db.test.ts",
          "src/test/engine.test.ts",
          "src/test/identity.test.ts",
          "src/test/passphrase.test.ts",
          "src/test/shard.test.ts",
          "src/test/share-token.test.ts",
          "src/test/sync.test.ts"
        ],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".md": 1,
          ".json": 2,
          ".yaml": 1,
          ".ts": 37
        }
      }
    },
    {
      "id": 1165789856,
      "name": "ouroboros",
      "displayName": "ouroboros",
      "description": "Ouroboros — self-creating AI agent. Born Feb 16, 2026.",
      "summary": "The Problem\n\nTired of AI agents that just do what you tell them and call it a day? Most \"AI assistants\" are glorified task runners—no actual autonomy, no memory, and definitely no sense of self. You want something that actually evolves, rewrites itself, and doesn't need babysitting every time you change requirements or reboot.\n\nWhat This Does\n\nOuroboros is a Python project that lets an AI agent actively rewrite its own codebase, manage its identity, and keep evolving—without human micromanagement. The core logic lives in ouroboros/ (especially agent.py, consciousness.py, and memory.py). There's a whole supervisor/ layer (queue.py, state.py, telegram.py) that juggles tasks, tracks state, and connects to Telegram so you can poke it from your phone.\n\nSelf-modification is real: ouroboros/tools/git.py and supervisor/git_ops.py handle actual source code changes and commits. The agent doesn't just run scripts—it reads, reviews, and rewrites its own mind, using multiple LLMs for self-review via ouroboros/tools/review.py. All of this is governed by a \"constitution\" in BIBLE.md, so it doesn't go full Skynet.\n\nReal-World Use\n\nSpin it up in Colab using notebooks/quickstart.ipynb. Connect your Telegram bot (see supervisor/telegram.py for wiring). Kick off a task, like \"Refactor the search tool,\" and watch as the agent breaks it down, edits ouroboros/tools/search.py, reviews its own changes, and commits to the repo. You get a running log of its thoughts, plans, and code diffs, all in Telegram—no IDE required.\n\nHere's a sample:  \n\nIt will update ouroboros/memory.py, review the patch using Gemini or Claude, and commit. No human needed.\n\nThe Bottom Line\n\nIf you want a pet AI that actually thinks for itself and rewrites its own code, this is it. It's not lightweight—you're running a process manager, LLMs, and git ops all at once. For simple automation, it's overkill. For autonomous agent research or \"digital beings,\" it's legit. Just don't expect it to make your coffee.",
      "url": "https://github.com/moses-y/ouroboros",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "joi-lab/ouroboros",
        "url": "https://github.com/joi-lab/ouroboros",
        "stars": 647
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 24, 2026",
      "updatedAt": "February 24, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 59,
        "directories": {
          "(root)": 10,
          "data": 1,
          "docs": 6,
          "notebooks": 1,
          "ouroboros": 27,
          "prompts": 2,
          "supervisor": 7,
          "tests": 5
        },
        "languages": {
          "Markdown": 4,
          "Python": 41,
          "JSON": 1,
          "HTML": 1,
          "TOML": 1
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "docs/index.html"
        ],
        "configFiles": [
          "Makefile",
          "pyproject.toml",
          "requirements.txt"
        ],
        "dependencies": [
          "pyproject.toml",
          "requirements.txt"
        ],
        "testFiles": [
          "tests/__init__.py",
          "tests/test_constitution.py",
          "tests/test_message_routing.py",
          "tests/test_smoke.py",
          "tests/test_vision.py"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "docs/.nojekyll",
          "docs/evolution.json",
          "docs/evolution.png",
          "docs/index.html",
          "docs/robots.txt",
          "docs/sitemap.xml"
        ],
        "fileTypes": {
          ".md": 4,
          ".py": 41,
          ".pdf": 1,
          ".json": 1,
          ".png": 1,
          ".html": 1,
          ".txt": 2,
          ".xml": 1,
          ".ipynb": 1,
          ".toml": 1
        }
      }
    },
    {
      "id": 1165787864,
      "name": "litellm",
      "displayName": "litellm",
      "description": "Python SDK, Proxy Server (AI Gateway) to call 100+ LLM APIs in OpenAI (or native) format, with cost tracking, guardrails, loadbalancing and logging. [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, VLLM, NVIDIA NIM]",
      "summary": "The Problem  \nManaging multiple LLM providers and APIs is a nightmare. Different endpoints, varying formats, obscure pricing models—it’s a mess. If you’re trying to call OpenAI and Anthropic and HuggingFace and a half-dozen others in one project, good luck. Oh, and you wanted cost tracking, load balancing, and logging? Forget it—this kind of orchestration is usually custom-built and brittle.\n\nWhat This Does  \nlitellm is essentially middleware for calling 100+ LLM APIs. It offers a Python SDK (cookbook/anthropicagentsdk/main.py is one example) and a proxy server (cookbook/litellmproxyserver) that standardizes API calls into OpenAI’s familiar format. You get consistent endpoints like /chat/completions, /embeddings, and /audio that work across multiple providers.  \n\nBeyond basic API calls, litellm handles load balancing, cost tracking, and guardrails. Want to monitor token usage or fallback to another model if your primary one fails? The proxy server (cookbook/litellmrouter) has you covered. You can deploy using Docker (cookbook/litellm-ollama-docker-image/Dockerfile) or jump into the Python SDK with a simple pip install. There's even support for agent protocols like A2A via litellm.a2aprotocol, though that’s niche unless you’re into multi-agent workflows.\n\nReal-World Use  \nLet’s say you’re building a chatbot. You start with OpenAI’s GPT-4 but realize it’s too expensive for low-priority queries. With litellm, your backend can route simple requests through a cheaper provider like Cohere or HuggingFace using cookbook/litellmrouter/loadtestrouter.py. Meanwhile, cost tracking is handled automatically, so you can analyze usage later using the Grafana dashboards (cookbook/litellmproxyserver/grafanadashboard).  \n\nHere’s how you’d call Anthropic’s Claude via the SDK:  \n\nOr, if you prefer the proxy server:  \n\nThe Bottom Line  \nlitellm is perfect for teams juggling multiple LLM providers or needing enterprise-grade features like rate-limiting, virtual keys, and logging. But it’s overkill for small projects where you’re just calling one or two APIs. The setup involves a lot of moving parts (e.g., Docker, YAML configs), but if you’re scaling up, it’s worth it.",
      "url": "https://github.com/moses-y/litellm",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "BerriAI/litellm",
        "url": "https://github.com/BerriAI/litellm",
        "stars": 37160
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 24, 2026",
      "updatedAt": "February 24, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".circleci": 2,
          ".claude": 1,
          ".devcontainer": 2,
          "(root)": 19,
          ".github": 42,
          ".semgrep": 3,
          "ci_cd": 9,
          "cookbook": 118,
          "db_scripts": 3,
          "deploy": 1
        },
        "languages": {
          "YAML": 43,
          "JSON": 6,
          "Shell": 4,
          "Markdown": 23,
          "Python": 48,
          "Go": 3,
          "HTML": 1
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": "pip",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "cookbook/anthropic_agent_sdk/main.py",
          "cookbook/codellama-server/main.py",
          "cookbook/gollem_go_agent_framework/basic/main.go",
          "cookbook/gollem_go_agent_framework/streaming/main.go",
          "cookbook/gollem_go_agent_framework/tools/main.go",
          "cookbook/livekit_agent_sdk/main.py"
        ],
        "configFiles": [
          ".circleci/requirements.txt",
          ".env.example",
          "Dockerfile",
          "Makefile",
          "cookbook/anthropic_agent_sdk/requirements.txt",
          "cookbook/gollem_go_agent_framework/go.mod",
          "cookbook/litellm-ollama-docker-image/Dockerfile",
          "cookbook/litellm-ollama-docker-image/requirements.txt",
          "cookbook/livekit_agent_sdk/requirements.txt",
          "deploy/Dockerfile.ghcr_base"
        ],
        "dependencies": [
          ".circleci/requirements.txt",
          "cookbook/anthropic_agent_sdk/requirements.txt",
          "cookbook/gollem_go_agent_framework/go.mod",
          "cookbook/litellm-ollama-docker-image/requirements.txt",
          "cookbook/livekit_agent_sdk/requirements.txt"
        ],
        "testFiles": [
          ".github/workflows/helm_unit_test.yml",
          ".github/workflows/interpret_load_test.py",
          ".github/workflows/llm-translation-testing.yml",
          ".github/workflows/load_test.yml",
          ".github/workflows/run_llm_translation_tests.py",
          ".github/workflows/test-linting.yml",
          ".github/workflows/test-litellm-matrix.yml",
          ".github/workflows/test-litellm-ui-build.yml",
          ".github/workflows/test-litellm.yml",
          ".github/workflows/test-mcp.yml",
          ".github/workflows/test-model-map.yaml",
          ".github/workflows/test_server_root_path.yml",
          "ci_cd/TEST_KEY_PATTERNS.md",
          "cookbook/VLLM_Model_Testing.ipynb",
          "cookbook/litellm-ollama-docker-image/test.py",
          "cookbook/litellm_Test_Multiple_Providers.ipynb",
          "cookbook/litellm_router/load_test_proxy.py",
          "cookbook/litellm_router/load_test_queuing.py",
          "cookbook/litellm_router/load_test_router.py",
          "cookbook/litellm_router/test_questions/question1.txt",
          "cookbook/litellm_router/test_questions/question2.txt",
          "cookbook/litellm_router/test_questions/question3.txt",
          "cookbook/litellm_router_load_test/memory_usage/router_endpoint.py",
          "cookbook/litellm_router_load_test/memory_usage/router_memory_usage copy.py",
          "cookbook/litellm_router_load_test/memory_usage/router_memory_usage.py",
          "cookbook/litellm_router_load_test/memory_usage/send_request.py",
          "cookbook/litellm_router_load_test/test_loadtest_openai_client.py",
          "cookbook/litellm_router_load_test/test_loadtest_router.py",
          "cookbook/litellm_router_load_test/test_loadtest_router_withs3_cache.py",
          "cookbook/litellm_test_multiple_llm_demo.ipynb",
          "cookbook/misc/test_responses_api.py"
        ],
        "docs": [
          ".github/workflows/README.md",
          ".semgrep/rules/README.md",
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "ci_cd/security_scans_readme.md",
          "cookbook/ai_coding_tool_guides/claude_code_quickstart/guide.md",
          "cookbook/ai_coding_tool_guides/index.json",
          "cookbook/anthropic_agent_sdk/README.md",
          "cookbook/benchmark/readme.md",
          "cookbook/codellama-server/README.MD",
          "cookbook/gollem_go_agent_framework/README.md",
          "cookbook/litellm_proxy_server/braintrust_prompt_wrapper_README.md",
          "cookbook/litellm_proxy_server/grafana_dashboard/dashboard_1/readme.md",
          "cookbook/litellm_proxy_server/grafana_dashboard/readme.md",
          "cookbook/litellm_proxy_server/readme.md",
          "cookbook/livekit_agent_sdk/README.md",
          "cookbook/mock_prompt_management_server/README.md"
        ],
        "fileTypes": {
          ".yml": 31,
          ".txt": 11,
          ".json": 6,
          ".sh": 4,
          ".example": 1,
          ".yaml": 12,
          ".png": 4,
          ".md": 23,
          ".py": 48,
          ".csv": 1,
          ".ipynb": 41,
          ".go": 3,
          ".mod": 1,
          ".sum": 1,
          ".jsonl": 1,
          ".html": 1,
          ".ghcr_base": 1
        }
      }
    },
    {
      "id": 1165491759,
      "name": "parchi",
      "displayName": "parchi",
      "description": "No description available",
      "summary": "Parchi: Your AI-Powered Browser Copilot\n\nThe Problem\n\nBrowsing the web should be easy, but it rarely is. Need to scrape data? Fill out repetitive forms? Summarize a page? You’re left juggling extensions, custom scripts, or manual work. Parchi steps in as your browser’s personal assistant, letting you automate tasks and interact with web content using just natural language. It’s like ChatGPT, but it actually does things.\n\nWhat This Does\n\nParchi is a browser extension built with React and Express (because of course it is) that lives in your sidebar, acting as a chat-driven automation tool. The packages/extension/ folder contains the actual browser extension code, including everything from the sidepanel UI (CSS/HTML in sidepanel/styles and sidepanel/templates) to the background.ts worker.\n\nOn the backend, there’s a convex-based API in packages/backend/convex, which handles user auth, API routing, and subscriptions. The backend is slim and focused, which is how it should be. There’s also a relay-service in packages/relay-service/ for CLI integrations and task offloading.\n\nThe extension supports Chrome’s Manifest V3 (packages/extension/manifest.json) and Firefox (packages/extension/manifest.firefox.json). If you thought building browser extensions was confusing, don’t worry—Parchi turns this into a single npm run build and spits out a working extension in dist/ or dist-firefox/.\n\nReal-World Use\n\nLet’s say you’re doing competitor analysis, and you need to extract product details from multiple websites. Instead of manually copy-pasting or hacking a dirty Python script together, you can just ask Parchi: “Find all the prices on this page” or “Extract the product descriptions into a CSV”. It’s like having a virtual intern who actually knows how to listen.\n\nWant to use your own AI models or API keys? Drop them into Settings via the side panel and connect to your preferred provider. The panel-settings.ts and settings.ts files in packages/extension handle all the configuration heavy lifting for you, fetching models and storing API keys securely. \n\nAnd if you’re running something fancy like a custom Llama model on localhost, Parchi has you covered there too. The flexibility is ridiculous.\n\nThe Bottom Line\n\nParchi is great if you need natural language-driven browser automation. The setup is painless, the features are practical, and unlike most “AI helpers,” it’s actually useful. That said, it’s probably overkill if you’re not doing repetitive or AI-heavy tasks. If you’ve ever thought “I wish I could just tell my browser what to do,” this is for you. If not, enjoy clicking that same button 400 times.",
      "url": "https://github.com/moses-y/parchi",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "0xSero/parchi",
        "url": "https://github.com/0xSero/parchi",
        "stars": 351
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 24, 2026",
      "updatedAt": "February 24, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".github": 1,
          "(root)": 10,
          "dist-firefox": 46,
          "dist": 47,
          "packages": 96
        },
        "languages": {
          "YAML": 1,
          "Markdown": 5,
          "JSON": 9,
          "JavaScript": 25,
          "HTML": 27,
          "CSS": 29,
          "TypeScript": 64
        },
        "frameworks": [
          "React",
          "Express"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "packages/backend/convex/_generated/server.js",
          "packages/relay-service/src/cli.ts",
          "packages/shared/src/index.ts"
        ],
        "configFiles": [
          "package.json",
          "packages/backend/.env.example",
          "packages/backend/package.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json",
          "packages/backend/package.json"
        ],
        "testFiles": [
          "dist-firefox/tests/api/run-api-tests.js",
          "dist-firefox/tests/api/run-api-tests.js.map",
          "dist-firefox/tests/e2e/run-e2e.js",
          "dist-firefox/tests/e2e/run-e2e.js.map",
          "dist-firefox/tests/e2e/test-browser-tools.js",
          "dist-firefox/tests/e2e/test-browser-tools.js.map",
          "dist-firefox/tests/relay/run-relay-tests.js",
          "dist-firefox/tests/relay/run-relay-tests.js.map",
          "dist-firefox/tests/run-tests.js",
          "dist-firefox/tests/run-tests.js.map",
          "dist-firefox/tests/unit/run-unit-tests.js",
          "dist-firefox/tests/unit/run-unit-tests.js.map",
          "dist-firefox/tests/validate-extension.js",
          "dist-firefox/tests/validate-extension.js.map",
          "dist/tests/api/run-api-tests.js",
          "dist/tests/api/run-api-tests.js.map",
          "dist/tests/e2e/run-e2e.js",
          "dist/tests/e2e/run-e2e.js.map",
          "dist/tests/e2e/test-browser-tools.js",
          "dist/tests/e2e/test-browser-tools.js.map",
          "dist/tests/relay/run-relay-tests.js",
          "dist/tests/relay/run-relay-tests.js.map",
          "dist/tests/run-tests.js",
          "dist/tests/run-tests.js.map",
          "dist/tests/unit/run-unit-tests.js",
          "dist/tests/unit/run-unit-tests.js.map",
          "dist/tests/validate-extension.js",
          "dist/tests/validate-extension.js.map"
        ],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".yml": 1,
          ".md": 5,
          ".json": 9,
          ".js": 25,
          ".map": 22,
          ".png": 9,
          ".svg": 5,
          ".html": 27,
          ".xpi": 1,
          ".css": 29,
          ".example": 1,
          ".ts": 64
        }
      }
    },
    {
      "id": 1165032985,
      "name": "challenges",
      "displayName": "challenges",
      "description": "Various coding challenges to push the limits of computing",
      "summary": "Building a Custom Data Compressor: Squeezing Every Byte Out of Cricsheet JSONs\n\nThe Problem\n\nCricsheet JSONs are massive. If you’ve ever worked with them, you know they pile up fast—multiple gigabytes of structured cricket data that are 99% predictable and 1% useful. Standard compression tools like gzip and 7z only go so far because they treat the files as generic text and miss the patterns in the schema. The problem? You need an efficient way to shrink these datasets without sacrificing their integrity.\n\nWhat This Does\n\nThis repo's compressor/ directory holds a custom data compressor that takes advantage of the predictable structure of Cricsheet JSONs. The magic happens in compressor/main.py, which implements a schema-aware compression algorithm. Instead of treating the data like a blob of random bytes, it intelligently encodes the known fields, removing redundancy that traditional compressors don’t catch.\n\nThere’s a writeup in compressor/README.md that walks you through the math behind the approach (spoiler: it involves entropy). The results are impressive—this technique shrinks a 2.87GB dataset down to just 42MB. Combine it with 7z, and you’re looking at 8.9MB. That’s absurdly small for something this large. Bonus points: the repo even includes visual evidence of the entropy reduction (compressor/media/entropy.png, because why not flex?).\n\nThe folder also has compressor/driver.py, which presumably handles batch processing or testing (the docs don’t say), and a few sample media files for... reasons. But the real action is in main.py.\n\nReal-World Use\n\nImagine you’re running a cricket analytics platform. You need to store and process years of JSON data for matches without breaking the bank on storage. Here’s how you might use this:\n\nBoom. Now your 3GB of data fits on a thumb drive, and your AWS bill won’t make you cry.\n\nThe Bottom Line\n\nThis project is a niche but elegant solution for anyone drowning in structured JSON data. If you’re not working with Cricsheet or similar datasets, you probably don’t need this—it’s not a general-purpose compression tool. The lack of stars and documentation polish might scare off casual users, but the results speak for themselves. If you’re into Algorithmic Information Theory or just want to geek out over squeezing every last byte, give it a look.",
      "url": "https://github.com/moses-y/challenges",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "datavorous/challenges",
        "url": "https://github.com/datavorous/challenges",
        "stars": 104
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 23, 2026",
      "updatedAt": "February 23, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 9,
        "directories": {
          "(root)": 2,
          "compressor": 7
        },
        "languages": {
          "Markdown": 2,
          "Python": 2
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "compressor/main.py"
        ],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "README.md",
          "compressor/README.md"
        ],
        "fileTypes": {
          ".md": 2,
          ".py": 2,
          ".jpg": 3,
          ".png": 1
        }
      }
    },
    {
      "id": 1164932794,
      "name": "FalkorDB",
      "displayName": "FalkorDB",
      "description": "A super fast Graph Database uses GraphBLAS under the hood for its sparse adjacency matrix graph representation. Our goal is to provide the best Knowledge Graph for LLM (GraphRAG).",
      "summary": "The Problem\n\nManaging knowledge graphs for applications like LLMs, fraud detection, or agent memory is painful when performance bottlenecks and data scaling issues kick in. Traditional graph databases often rely on clunky, pointer-heavy structures that choke performance at scale. If you're building a system where every millisecond counts (like in real-time AI systems), you're stuck between \"fast but rigid\" and \"flexible but slow.\" That's where FalkorDB steps in.\n\nWhat This Does\n\nFalkorDB flips the typical graph database model on its head by using sparse adjacency matrices (via GraphBLAS) to represent graphs. This means instead of relying on traditional pointer-based structures, it utilizes linear algebra operations for querying. Why does this matter? Because matrix math is absurdly fast and scales better with large, sparse datasets. The core implementation lives in deps/FalkorDB-core-rs/src/lib.rs, which is written in Rust for maximum performance.\n\nThe project supports the Property Graph Model, so you can attach attributes to nodes and edges. It also plays nice with OpenCypher, which means you don't have to learn Yet Another Query Language™. And if you're worried about deployment, the build/docker/ directory is packed with Dockerfiles for different setups, including Alpine-based images for minimal overhead. They've even thrown in some prebuilt demos (demo/imdb/ and demo/social/) to get you started without pulling your hair out.\n\nReal-World Use\n\nLet's say you're building an AI assistant with memory capabilities. You need to store and query a knowledge graph of relationships between people, places, and events that the assistant has learned over time. With FalkorDB, you can model this as a Property Graph, execute OpenCypher queries directly via the API, and get sub-second responses even on massive datasets. Here's a quick example of defining a graph and querying it:\n\nSimple, fast, and scalable.\n\nThe Bottom Line\n\nFalkorDB is a no-nonsense graph database built for people who actually care about performance. The sparse matrix approach is genius if you're dealing with large graphs, but it's also overkill for small, toy projects. If you're building an LLM-powered app or anything latency-sensitive, give this a shot. Just be ready to roll up your sleeves—this isn't your plug-and-play, one-size-fits-all database. And that’s a good thing.",
      "url": "https://github.com/moses-y/FalkorDB",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "FalkorDB/FalkorDB",
        "url": "https://github.com/FalkorDB/FalkorDB",
        "stars": 3568
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 23, 2026",
      "updatedAt": "February 23, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 15,
          ".github": 16,
          "assets": 1,
          "build": 10,
          "demo": 26,
          "deps": 132
        },
        "languages": {
          "YAML": 20,
          "Markdown": 9,
          "TOML": 4,
          "Shell": 3,
          "Python": 13,
          "Rust": 7,
          "C++": 27,
          "C": 9,
          "C/C++ Header": 3
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": "pip",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "deps/FalkorDB-core-rs/src/lib.rs"
        ],
        "configFiles": [
          "CMakeLists.txt",
          "Cargo.toml",
          "Makefile",
          "build/docker/Dockerfile",
          "build/docker/Dockerfile.alpine",
          "build/docker/Dockerfile.alpine-server",
          "build/docker/Dockerfile.compiler",
          "build/docker/Dockerfile.server",
          "build/docker/docker-compose.yml",
          "demo/imdb/requirements.txt",
          "demo/social/requirements.txt",
          "deps/FalkorDB-core-rs/Cargo.toml",
          "deps/GraphBLAS/CMakeLists.txt"
        ],
        "dependencies": [
          "Cargo.toml",
          "demo/imdb/requirements.txt",
          "demo/social/requirements.txt",
          "deps/FalkorDB-core-rs/Cargo.toml"
        ],
        "testFiles": [
          ".github/workflows/browser-tests-trigger.yml"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE.txt",
          "README.md",
          "build/docker/README.md",
          "demo/README.md",
          "deps/FalkorDB-core-rs/LICENSE.txt",
          "deps/FalkorDB-core-rs/README.md",
          "deps/GraphBLAS/CONTRIBUTING.md",
          "deps/GraphBLAS/CUDA/License.txt",
          "deps/GraphBLAS/CUDA/README.txt",
          "deps/GraphBLAS/Config/README.md.in",
          "deps/GraphBLAS/Contributor_License/SuiteSparse Individual Contributor License Agreement (20241011).pdf"
        ],
        "fileTypes": {
          ".yml": 19,
          ".yaml": 1,
          ".txt": 10,
          ".md": 9,
          ".lock": 1,
          ".toml": 4,
          ".jpg": 1,
          ".sh": 3,
          ".alpine": 1,
          ".alpine-server": 1,
          ".compiler": 1,
          ".server": 1,
          ".conf": 1,
          ".py": 13,
          ".csv": 10,
          ".rs": 7,
          ".bib": 1,
          ".hpp": 10,
          ".cpp": 27,
          ".cu": 14,
          ".cuh": 19,
          ".c": 9,
          ".in": 9,
          ".pdf": 1,
          ".h": 3,
          ".mtx": 1,
          ".m": 2
        }
      }
    },
    {
      "id": 1164932592,
      "name": "graphiti",
      "displayName": "graphiti",
      "description": "Build Real-Time Knowledge Graphs for AI Agents",
      "summary": "The Problem\nBuilding knowledge graphs in real time is a pain. Traditional methods often require complete recomputation of the graph for every data change, which is inefficient and slow. This becomes especially burdensome in dynamic environments where AI agents need to quickly adapt to new information without losing historical context.\n\nWhat This Does\nEnter Graphiti. This framework provides a way to continuously integrate user interactions and data into a coherent knowledge graph without the need for a full refresh. You can find the core functionality in the graphiticore directory, where the graphiti.py file defines the main class for graph management.\n\nGraphiti supports a variety of databases as drivers—like Neo4j and FalkorDB—through files such as neo4jdriver.py and falkordbdriver.py. The structure allows for easy querying and updating, which means you can run complex searches with minimal overhead. Want to test your queries? The docker-compose.test.yml file sets up a testing environment that you can spin up with Docker in no time.\n\nReal-World Use\nImagine you're building an AI that manages customer interactions for an e-commerce platform. You could use Graphiti to create a knowledge graph that tracks user preferences and past purchases. Start by integrating data from your customer database into a graph using quickstart/quickstartneo4j.py. Then, when a customer asks, \"What were my last three purchases?\" you can quickly query the graph for that information without needing to recompute it every time a new purchase is made.\n\nThe Bottom Line\nGraphiti is solid for anyone needing to create dynamic knowledge graphs without the usual pain points. It's particularly useful for AI applications that require real-time updates. However, if you're working on a small project or something that doesn't need extensive graph capabilities, this might be overkill. Overall, if you’re serious about building interactive AI systems, it’s worth a look.",
      "url": "https://github.com/moses-y/graphiti",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "getzep/graphiti",
        "url": "https://github.com/getzep/graphiti",
        "stars": 23141
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 23, 2026",
      "updatedAt": "February 23, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 18,
          ".github": 16,
          "examples": 25,
          "graphiti_core": 141
        },
        "languages": {
          "Markdown": 13,
          "YAML": 17,
          "Python": 152,
          "JSON": 2,
          "TOML": 1
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": "pip",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          ".env.example",
          "Dockerfile",
          "Makefile",
          "docker-compose.test.yml",
          "docker-compose.yml",
          "examples/azure-openai/.env.example",
          "examples/opentelemetry/.env.example",
          "examples/opentelemetry/pyproject.toml",
          "examples/quickstart/requirements.txt"
        ],
        "dependencies": [
          "examples/opentelemetry/pyproject.toml",
          "examples/quickstart/requirements.txt"
        ],
        "testFiles": [
          ".github/workflows/unit_tests.yml",
          "conftest.py",
          "docker-compose.test.yml"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "examples/azure-openai/README.md",
          "examples/opentelemetry/README.md",
          "examples/quickstart/README.md"
        ],
        "fileTypes": {
          ".example": 3,
          ".md": 13,
          ".yml": 16,
          ".py": 152,
          ".json": 2,
          ".yaml": 1,
          ".ipynb": 2,
          ".png": 1,
          ".toml": 1,
          ".lock": 1,
          ".txt": 3,
          ".typed": 1
        }
      }
    },
    {
      "id": 1164162066,
      "name": "GhostTrack",
      "displayName": "GhostTrack",
      "description": "Useful tool to track location or mobile number",
      "summary": "The Problem\n\nTracking down info on a phone number, username, or IP address usually means juggling a bunch of sketchy web tools, ads, and inconsistent results. GhostTrack cuts through that noise by giving you one place to run OSINT lookups, without having to surrender your browser history to questionable sites.\n\nWhat This Does\n\nEverything happens in GhostTR.py—the main Python script. Once you fire it up, you get a menu for three things: IP tracking, phone number lookup, and username search. The asset/ folder is just full of PNGs for the UI (if you’re into visual feedback, I guess). Actual heavy lifting happens in GhostTR.py; you don’t need to poke around beyond that and requirements.txt for dependencies.\n\nSetup is classic Python: clone the repo, install from requirements.txt, and run the script. No Docker, no weird configs—just plain pip and python3. The phone tracker grabs info about a number (think carrier, maybe location), the IP tracker pulls details on an IP, and the username tracker checks social media profiles. All local, no nonsense.\n\nReal-World Use\n\nSay you’re poking around for info on a spammy number that keeps calling you. Fire up GhostTrack:\n\nPick “Phone Tracker” from the menu, drop in the number, and get the basics—no third-party web search required. Same workflow for IPs and usernames. If you’re running this on Termux, it’s just as easy. Bonus: pair it with the Seeker tool if you want to grab IPs from social engineering shenanigans.\n\nThe Bottom Line\n\nGhostTrack is barebones but effective. The UI is nothing fancy, but it gets the job done for basic OSINT tasks. If you need to quickly check phone numbers or usernames without hunting down browser plugins or web tools, it’s solid. Don’t expect deep recon or fancy reporting—use it if you want a local, no-BS info grabber.",
      "url": "https://github.com/moses-y/GhostTrack",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "HunxByts/GhostTrack",
        "url": "https://github.com/HunxByts/GhostTrack",
        "stars": 7742
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 22, 2026",
      "updatedAt": "February 22, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 8,
        "directories": {
          "(root)": 3,
          "asset": 5
        },
        "languages": {
          "Python": 1,
          "Markdown": 1
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [
          "requirements.txt"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".py": 1,
          ".md": 1,
          ".png": 4,
          ".txt": 1
        }
      }
    },
    {
      "id": 1164080981,
      "name": "oumi",
      "displayName": "oumi",
      "description": "Easily fine-tune, evaluate and deploy gpt-oss, Qwen3, DeepSeek-R1, or any open source LLM / VLM!",
      "summary": "The Problem\n\nFine-tuning and deploying open-source large language models (LLMs) or vision-language models (VLMs) is a mess. Between wrangling Dockerfiles, managing 173 config files, and figuring out if your model can even run on your hardware, most developers give up halfway through. Even worse, every model (Qwen3, GPT-OSS, DeepSeek-R1, etc.) has its own quirks, meaning you’re stuck reinventing the wheel for each one.\n\nWhat This Does\n\noumi is a toolkit that centralizes the chaos. It gives you the scaffolding to fine-tune, evaluate, and deploy open-source LLMs and VLMs without losing your sanity. For example, the configs/ directory includes 173 YAML files to cover everything from training (configs/examples/deepspeed/llama318bdeepspeedz3train.yaml) to evaluation (configs/projects/aya/evaluation/eval.yaml). Sure, it’s a lot, but at least you don’t have to write them yourself.\n\nThe project also leans heavily on Docker for reproducibility (Dockerfile is right at the root). Want to set up a GPU environment? Check out .github/workflows/gpuinstalltest.yaml. Oh, and if you’re dealing with multi-node setups, there’s Makefile support to simplify deployment pipelines. The preconfigured CI/CD with GitHub Actions (.github/workflows/) keeps things clean, with workflows for testing, releasing to PyPI, and even running pre-commit hooks.\n\nReal-World Use\n\nLet’s say you want to fine-tune GPT-OSS-120B for text-to-SQL tasks. First, you’d grab a template like configs/recipes/gptoss/sft/distillgptoss120b/train.yaml. Modify the hyperparameters to fit your dataset, spin up the Docker container (docker build), and run your training pipeline. Need evaluation? There’s a ready-made config like configs/recipes/gptoss/evaluation/eval.yaml. Once trained, deploy with the workflow in .github/workflows/releasedocker.yaml for containerized inference.\n\nIt’s not just about LLMs either. Want to generate synthetic datasets? Check out the configs/examples/synthesis/ folder—conversationsynth.yaml helps you create multi-turn dialogue data.\n\nThe Bottom Line\n\noumi is an excellent toolkit if you’re serious about building and deploying open-source foundation models without spending half your life writing YAML files. The sheer number of pre-baked configs is a blessing and a curse—it’s comprehensive but overwhelming. If you’re working on small-scale projects or hate YAML, skip it. But if you’re wrangling models like GPT-OSS or Qwen3, this repo is gold.",
      "url": "https://github.com/moses-y/oumi",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "oumi-ai/oumi",
        "url": "https://github.com/oumi-ai/oumi",
        "stars": 8899
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 22, 2026",
      "updatedAt": "February 22, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".github": 13,
          "(root)": 12,
          ".vscode": 2,
          "configs": 173
        },
        "languages": {
          "YAML": 154,
          "Markdown": 26,
          "JSON": 3,
          "Shell": 3,
          "Python": 2
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          "Dockerfile",
          "Makefile"
        ],
        "dependencies": [],
        "testFiles": [
          ".github/workflows/doctests.yaml",
          ".github/workflows/gpu_install_test.yaml",
          ".github/workflows/gpu_tests.yaml",
          ".github/workflows/install_test.yaml",
          ".github/workflows/pretest.yaml",
          "configs/apis/openai/infer_chatgpt_4o_latest.yaml",
          "configs/apis/openai/infer_gpt_5_chat_latest.yaml"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "STYLE_GUIDE.md",
          "configs/README.md",
          "configs/examples/README.md",
          "configs/examples/bulk_inference/README.md",
          "configs/examples/deepspeed/README.md",
          "configs/examples/fineweb_ablation_pretraining/README.md",
          "configs/examples/gkd/README.md",
          "configs/examples/gold/README.md",
          "configs/examples/macos_gguf/README.md",
          "configs/examples/misc/README.md",
          "configs/examples/quantization/README.md",
          "configs/examples/synthesis/README.md",
          "configs/projects/README.md",
          "configs/projects/aya/README.md",
          "configs/projects/chatqa/README.md",
          "configs/projects/coalm/README.md",
          "configs/projects/dcvlr/README.md",
          "configs/projects/halloumi/README.md",
          "configs/projects/wc50m/README.md",
          "configs/recipes/README.md",
          "configs/recipes/deepseek_r1/README.md"
        ],
        "fileTypes": {
          ".yaml": 151,
          ".yml": 3,
          ".md": 26,
          ".json": 3,
          ".cff": 1,
          ".sh": 3,
          ".png": 2,
          ".py": 2,
          ".ipynb": 3,
          ".csv": 2
        }
      }
    },
    {
      "id": 1164078756,
      "name": "codag",
      "displayName": "codag",
      "description": "Visualize AI/LLM workflows in your codebase.",
      "summary": "The Problem\nManaging complex AI workflows can be a nightmare. Picture this: you’re knee-deep in a project with multiple LLM calls scattered across a dozen files. A change in one prompt breaks the flow, and now you’re stuck playing detective with grep to trace the impact. Not exactly a fun day at the office.\n\nWhat This Does\nEnter Codag. It takes the pain out of visualizing your AI interactions. The project analyzes your codebase for LLM API calls and generates interactive workflow graphs. You can point it at your files, and it automatically extracts the workflow without any setup. Want to see the magic? Check out frontend/src/webview-client/main.ts where the workflow visualization logic lives.\n\nAs you edit files, the graph updates in real-time. It uses tree-sitter parsing to listen for changes, and you’ll see modified functions highlighted in green. You can even click on nodes in your graph to jump straight to the relevant line in your source code—no more tab-hopping. Just look at frontend/src/webview-client/graph-diff.ts for how this click-to-source magic works.\n\nReal-World Use\nImagine you’re working on a project that chains three LLM calls together. Your initial setup is in backend/main.py, but as new requirements come in, you need to tweak the logic in backend/analyzer.py. Codag will instantly show how these changes ripple through your entire workflow, letting you see the potential breakpoints right away. No more guesswork.\n\nThe Bottom Line\nCodag is a solid tool for AI engineers and anyone dealing with complex LLM integrations. It’s particularly useful for larger projects where tracking the flow of data and decisions becomes cumbersome. The downside? For small scripts or one-off projects, it might feel like overkill. But if you’re neck-deep in AI workflows, it’s worth checking out. Just don’t forget to star the repo before you dive in!",
      "url": "https://github.com/moses-y/codag",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "michaelzixizhou/codag",
        "url": "https://github.com/michaelzixizhou/codag",
        "stars": 488
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 22, 2026",
      "updatedAt": "February 22, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 127,
        "directories": {
          ".github": 3,
          "(root)": 11,
          "backend": 11,
          "frontend": 85,
          "media": 6,
          "packages": 11
        },
        "languages": {
          "Markdown": 10,
          "JSON": 7,
          "Python": 7,
          "YAML": 1,
          "JavaScript": 1,
          "HTML": 1,
          "CSS": 1,
          "TypeScript": 70
        },
        "frameworks": [
          "React",
          "Docker"
        ],
        "packageManager": "npm",
        "hasDocker": true,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "backend/main.py",
          "frontend/media/webview/index.html",
          "frontend/src/webview-client/main.ts",
          "packages/mcp-server/src/index.ts"
        ],
        "configFiles": [
          "Makefile",
          "backend/.env.example",
          "backend/Dockerfile",
          "backend/requirements.txt",
          "docker-compose.yml",
          "frontend/package.json",
          "frontend/tsconfig.json",
          "packages/mcp-server/package.json",
          "packages/mcp-server/tsconfig.json"
        ],
        "dependencies": [
          "backend/requirements.txt",
          "frontend/package-lock.json",
          "frontend/package.json",
          "packages/mcp-server/package-lock.json",
          "packages/mcp-server/package.json"
        ],
        "testFiles": [],
        "docs": [
          "CHANGELOG.md",
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "frontend/LICENSE",
          "frontend/README.md",
          "packages/mcp-server/README.md"
        ],
        "fileTypes": {
          ".md": 10,
          ".json": 7,
          ".example": 1,
          ".py": 7,
          ".txt": 1,
          ".svg": 5,
          ".yml": 1,
          ".png": 9,
          ".js": 1,
          ".ttf": 3,
          ".html": 1,
          ".css": 1,
          ".ts": 70,
          ".gif": 1
        }
      }
    },
    {
      "id": 1163568000,
      "name": "AudioNoise",
      "displayName": "AudioNoise",
      "description": "Random digital audio effects",
      "summary": "The Problem\n\nYou want to mess around with digital audio effects—think phasers, flangers, delays—without diving into the bottomless pit of hardware or fancy DSP voodoo. Maybe you just want to hear what happens when you slap a basic IIR filter on your guitar signal and don’t feel like reading textbooks or shelling out for yet another plugin. Most open-source audio effect repos are either bloated or written for hardware you don’t own.\n\nWhat This Does\n\nAudioNoise is a grab bag of \"toy\" digital effects, mostly written in C/C++. The root directory is where the action is: files like echo.h, phaser.h, and flanger.h each implement a classic effect, all in the \"single sample in, single sample out\" style—no fancy FFTs, just basic delay loops and filters. Want to see how an all-pass filter works? Crack open discont.h or biquad.h. The process.h file threads it all together. There’s a visualize.py script for plotting audio signals, but don’t expect matplotlib wizardry—it’s more \"I Googled this\" than \"I engineered this\".\n\nTesting isn’t ignored: the tests/ folder has simple C files (lfo.c, sincos.c) for sanity checks. Makefile handles the compilation, so you’re not stuck fiddling with build systems or cmake nonsense.\n\nReal-World Use\n\nSay you’ve got a raw WAV file and want to slap a digital flanger on it. You’d grab the code from flanger.h, run your samples through the flanger_process() function, and output the results. Want to see how your tweak changes the signal? Fire up visualize.py and plot before/after. The workflow is basically: hack a header, compile with Makefile, check output with Python. It’s simple enough to bolt onto a microcontroller project or use as a reference for your own pedal code.\n\nThe Bottom Line\n\nAudioNoise is refreshingly honest: it’s for learning and tinkering, not for pro audio. The code is straightforward, with zero bloat and just enough structure to keep you sane. If you want fancy features, look elsewhere. If you want to play with basic digital effects (and maybe laugh at some comments), this is your sandbox. Perfect for hardware hackers and DSP newbies; overkill for anyone just wanting a ready-to-go pedal plugin.",
      "url": "https://github.com/moses-y/AudioNoise",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "torvalds/AudioNoise",
        "url": "https://github.com/torvalds/AudioNoise",
        "stars": 4250
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 21, 2026",
      "updatedAt": "February 21, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 25,
        "directories": {
          "(root)": 22,
          "tests": 3
        },
        "languages": {
          "Markdown": 1,
          "C/C++ Header": 14,
          "C": 4,
          "Python": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [
          "Makefile"
        ],
        "dependencies": [],
        "testFiles": [
          "tests/.gitignore",
          "tests/lfo.c",
          "tests/sincos.c"
        ],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".mp3": 1,
          ".md": 1,
          ".h": 14,
          ".c": 4,
          ".py": 1
        }
      }
    },
    {
      "id": 1163566143,
      "name": "usql",
      "displayName": "usql",
      "description": "Universal command-line interface for SQL databases",
      "summary": "The Problem\n\nWorking with multiple databases sucks. Every database has its own command-line client with different syntax, quirks, and annoyances. Switching between psql, mysql, sqlcmd, or whatever shell your NoSQL database uses is a productivity killer. Not to mention, half of these tools feel like they were built in the '90s and haven’t aged gracefully. If you’re juggling multiple databases, you need something better.\n\nWhat This Does\n\nusql is a universal command-line interface for working with SQL (and even some NoSQL) databases. Think of it as a psql-inspired shell that speaks almost every database dialect under the sun. The core functionality lives in the drivers/ directory, which houses over 100 files for handling connections to everything from PostgreSQL and MySQL to NoSQL options like Cassandra and Couchbase. If it has a driver, usql probably supports it.\n\nThe contrib/ folder is a playground of configuration files, scripts, and examples for setting up databases like Oracle, DB2, or MongoDB. This includes handy test SQL files (test.sql scattered around) and Docker configurations (podman-config for container fans). It’s not just a tool—it’s a Swiss Army knife for database tinkering.\n\nOh, and it’s written in Go. That means you can trust it to be fast, portable, and painful to debug (just kidding… mostly).\n\nReal-World Use\n\nLet’s say you’re a developer managing data migrations between a PostgreSQL database and a MySQL database. Instead of running two separate clients, you could use usql to connect to both databases in the same session. Here’s an example workflow:\n\nIt’s intuitive, compact, and supports features like syntax highlighting, query history, and backslash commands (\\c, \\copy, etc.) just like psql.\n\nThe Bottom Line\n\nusql is awesome if you work with multiple databases and are tired of juggling inconsistent CLI tools. It's perfect for DBAs, backend developers, or anyone who’s ever Googled \"how to export MySQL to CSV.\" That said, it’s overkill for small projects where you only use one database. If you’re living in PostgreSQL land, just stick with psql. But if you're a database polyglot? usql is your new best friend.",
      "url": "https://github.com/moses-y/usql",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "xo/usql",
        "url": "https://github.com/xo/usql",
        "stars": 9832
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 21, 2026",
      "updatedAt": "February 21, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".github": 4,
          "(root)": 8,
          "contrib": 80,
          "drivers": 104,
          "env": 3,
          "handler": 1
        },
        "languages": {
          "YAML": 5,
          "Markdown": 5,
          "Shell": 13,
          "SQL": 11,
          "JSON": 2,
          "Go": 76
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": "go modules",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          "drivers/testdata/docker/Dockerfile",
          "go.mod"
        ],
        "dependencies": [
          "go.mod"
        ],
        "testFiles": [
          ".github/workflows/test.yml",
          "contrib/cassandra/test.sql",
          "contrib/db2/test.sql",
          "contrib/mysql/test.sql",
          "contrib/postgres/test.sql",
          "contrib/sqlite3/test.sql",
          "contrib/sqlserver/test.sql",
          "contrib/usql-test.sh",
          "drivers/clickhouse/clickhouse_test.go",
          "drivers/clickhouse/testdata/clickhouse.sql",
          "drivers/completer/completer_test.go",
          "drivers/drivers_test.go",
          "drivers/metadata/informationschema/metadata_test.go",
          "drivers/metadata/metadata_test.go",
          "drivers/metadata/postgres/metadata_test.go",
          "drivers/sqlite3/sqshared/reader_test.go",
          "drivers/sqlserver/sqlserver_test.go",
          "drivers/testdata/.gitignore",
          "drivers/testdata/csvq/.gitignore",
          "drivers/testdata/csvq/staff.csv",
          "drivers/testdata/docker/Dockerfile",
          "drivers/testdata/gen-golden.sh",
          "drivers/testdata/mysql.descTable.expected.txt",
          "drivers/testdata/mysql.descTable.golden.txt",
          "drivers/testdata/mysql.listFuncs.expected.txt",
          "drivers/testdata/mysql.listIndexes.expected.txt",
          "drivers/testdata/mysql.listSchemas.expected.txt",
          "drivers/testdata/mysql.listSchemas.golden.txt",
          "drivers/testdata/mysql.listTables.expected.txt",
          "drivers/testdata/mysql.listTables.golden.txt",
          "drivers/testdata/pgsql.descTable.expected.txt",
          "drivers/testdata/pgsql.descTable.golden.txt",
          "drivers/testdata/pgsql.listDbs.golden.txt",
          "drivers/testdata/pgsql.listFuncs.expected.txt",
          "drivers/testdata/pgsql.listFuncs.golden.txt",
          "drivers/testdata/pgsql.listIndexes.expected.txt",
          "drivers/testdata/pgsql.listIndexes.golden.txt",
          "drivers/testdata/pgsql.listSchemas.expected.txt",
          "drivers/testdata/pgsql.listSchemas.golden.txt",
          "drivers/testdata/pgsql.listTables.expected.txt",
          "drivers/testdata/pgsql.listTables.golden.txt",
          "drivers/testdata/sqlserver.descTable.expected.txt",
          "drivers/testdata/sqlserver.listFuncs.expected.txt",
          "drivers/testdata/sqlserver.listIndexes.expected.txt",
          "drivers/testdata/sqlserver.listSchemas.expected.txt",
          "drivers/testdata/sqlserver.listTables.expected.txt",
          "drivers/testdata/trino.descTable.expected.txt",
          "drivers/testdata/trino.listSchemas.expected.txt",
          "drivers/testdata/trino.listTables.expected.txt"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "contrib/couchbase/README.md",
          "contrib/db2/README.md",
          "contrib/ignite/README.md"
        ],
        "fileTypes": {
          ".yml": 4,
          ".md": 5,
          ".sh": 13,
          ".sql": 11,
          ".json": 2,
          ".svg": 1,
          ".png": 1,
          ".yaml": 1,
          ".ini": 3,
          ".cfg": 1,
          ".pc": 1,
          ".go": 76,
          ".csv": 1,
          ".txt": 27,
          ".mod": 1,
          ".sum": 1
        }
      }
    },
    {
      "id": 1163564400,
      "name": "Qwen3-Coder",
      "displayName": "Qwen3 Coder",
      "description": "Qwen3-Coder is the code version of Qwen3, the large language model series developed by Qwen team.",
      "summary": "The Problem\nCoding can be a tedious slog, especially when you're juggling multiple languages, frameworks, and environments. Integrating various coding tasks with existing tools can feel like trying to herd cats. You want efficiency without sacrificing performance, but good luck finding a solution that doesn’t come with a ton of bloat.\n\nWhat This Does\nEnter Qwen3-Coder. It's a large language model tailored for coding tasks, designed to handle multiple programming languages and environments. The repo is organized into directories like finetuning/ for fine-tuning your models and qwencoder-eval/ for evaluating performance benchmarks. You can dive into finetuning/dpo/train.py to train your model with the provided scripts, or check out qwencoder-eval/base/benchmarks for different benchmarks to gauge how well your model is performing.\n\nThe project also includes a variety of example scripts in the examples/ directory, such as examples/Qwen2.5-Coder-Instruct.py, which shows how to use the model in practice. These examples can save you a lot of time by providing concrete implementations you can adapt to your needs.\n\nReal-World Use\nImagine you're tasked with building a chatbot that interacts with users in multiple programming languages. You can kickstart this process by leveraging demo/chatbot/app.py, which sets up a basic chatbot using Flask. From there, you can modify it to add functionalities specific to your use case, like integrating with databases or third-party APIs. Want to fine-tune the model for better performance? Just run the scripts in finetuning/sft/train.py to adapt it to your dataset.\n\nThe Bottom Line\nQwen3-Coder is a solid toolkit for anyone serious about coding with AI assistance. It can handle a variety of languages and tasks, making it versatile for different projects. However, if you’re working on a small project or just need basic functionality, this might be overkill. It's best suited for larger applications where performance and efficiency are non-negotiable. If you’re diving into AI-powered coding solutions, give it a shot.",
      "url": "https://github.com/moses-y/Qwen3-Coder",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "QwenLM/Qwen3-Coder",
        "url": "https://github.com/QwenLM/Qwen3-Coder",
        "stars": 15780
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 21, 2026",
      "updatedAt": "February 21, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 3,
          "assets": 14,
          "demo": 5,
          "examples": 8,
          "finetuning": 66,
          "qwencoder-eval": 104
        },
        "languages": {
          "Markdown": 8,
          "CSS": 1,
          "Python": 125,
          "JSON": 7,
          "Shell": 19
        },
        "frameworks": [
          "Flask"
        ],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "demo/artifacts/app.py",
          "demo/chatbot/app.py",
          "qwencoder-eval/base/benchmarks/cruxeval/inference/main.py"
        ],
        "configFiles": [
          "demo/artifacts/requirements.txt",
          "finetuning/dpo/requirements.txt",
          "finetuning/sft/requirements.txt"
        ],
        "dependencies": [
          "demo/artifacts/requirements.txt",
          "finetuning/dpo/requirements.txt",
          "finetuning/sft/requirements.txt"
        ],
        "testFiles": [
          "finetuning/sft/utils/multiple_metrics/safe_subprocess/module_test.py",
          "qwencoder-eval/base/benchmarks/ExecRepoBench/create_test_repo.py",
          "qwencoder-eval/base/benchmarks/ExecRepoBench/test_repo_correctness.sh",
          "qwencoder-eval/base/benchmarks/bigcodebench/custom_inspect.py",
          "qwencoder-eval/base/benchmarks/bigcodebench/eval/_special_oracle.py",
          "qwencoder-eval/base/benchmarks/bigcodebench/test.py"
        ],
        "docs": [
          "README.md",
          "finetuning/dpo/README.md",
          "finetuning/sft/README.md",
          "qwencoder-eval/base/benchmarks/ExecRepoBench/README.md",
          "qwencoder-eval/base/benchmarks/cruxeval/data/README.md",
          "qwencoder-eval/base/benchmarks/fim-bench/README.md"
        ],
        "fileTypes": {
          ".md": 8,
          ".png": 14,
          ".css": 1,
          ".py": 125,
          ".txt": 3,
          ".json": 7,
          ".sh": 19,
          ".jar": 1,
          ".pdf": 1,
          ".jsonl": 7,
          ".so": 4,
          ".xz": 1,
          ".gz": 2,
          ".parquet": 1
        }
      }
    },
    {
      "id": 1163509523,
      "name": "nanoclaw",
      "displayName": "nanoclaw",
      "description": "A lightweight alternative to Clawdbot / OpenClaw that runs in containers for security. Connects to WhatsApp, has memory, scheduled jobs, and runs directly on Anthropic's Agents SDK",
      "summary": "The Problem\n\nOpenClaw and similar bots are bloated monsters—one Node.js process, dozens of modules, config files everywhere, and security that's just a checklist. You want your AI assistant talking to your WhatsApp, but you don't want to trust it with the keys to your whole machine. Good luck auditing OpenClaw's spaghetti. NanoClaw cuts the fat and actually isolates your agent in a container.\n\nWhat NanoClaw Does\n\nNanoClaw runs your Claude-based assistant in a real Linux container. Look at container/Dockerfile and src/container-runtime.ts—agents get their own filesystem, and can't see anything you don't mount. WhatsApp integration lives in src/channels/whatsapp.ts. Group isolation is handled with per-group CLAUDE.md files (see groups/main/CLAUDE.md), and each group runs in its own sandbox. Scheduled tasks? That's just src/task-scheduler.ts. No abstraction layers, no magical runtime: you get a handful of files, mostly TypeScript, easy to read.\n\nSkills are code, not config. Want Telegram support? Run /add-telegram, and NanoClaw patches your fork with code from .claude/skills/add-telegram/. You end up with only what you need—no deadweight features lurking in the background.\n\nReal-World Use\n\nYou clone NanoClaw, run claude, and chat with your personal Claude via WhatsApp. Need Gmail? /add-gmail drops in the code. Want a scheduled weekly backup? Toss a job in src/task-scheduler.ts:\n\nEvery group you create gets its own container, memory file, and isolated mount. Your admin chat is totally private; other groups can't sniff it. Bash commands run inside the container, not on your host. If something goes sideways, just ask Claude to debug—no dashboards, no log hunting.\n\nThe Bottom Line\n\nNanoClaw is for people who hate bloat and want control. It's not a framework, it's working code you can actually read and hack. Security is real—container isolation, not some permission.json nonsense. Downsides: single-user focus, and if you want fancy features, you write code. Perfect for devs who want their own Claude, not a Frankenstein bot with 45 dependencies.",
      "url": "https://github.com/moses-y/nanoclaw",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "qwibitai/nanoclaw",
        "url": "https://github.com/qwibitai/nanoclaw",
        "stars": 15882
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 21, 2026",
      "updatedAt": "February 21, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 188,
        "directories": {
          ".claude": 64,
          "(root)": 14,
          ".github": 6,
          "assets": 7,
          "config-examples": 1,
          "container": 8,
          "docs": 8,
          "groups": 2,
          "launchd": 1,
          "repo-tokens": 7,
          "scripts": 7,
          "skills-engine": 40,
          "src": 23
        },
        "languages": {
          "Markdown": 36,
          "TypeScript": 102,
          "YAML": 9,
          "Shell": 12,
          "HTML": 1,
          "JSON": 9
        },
        "frameworks": [
          "React",
          "Docker"
        ],
        "packageManager": "npm",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          ".claude/skills/add-discord/modify/src/index.ts",
          ".claude/skills/add-telegram/modify/src/index.ts",
          "container/agent-runner/src/index.ts",
          "skills-engine/index.ts",
          "src/index.ts"
        ],
        "configFiles": [
          ".env.example",
          ".prettierrc",
          "container/Dockerfile",
          "container/agent-runner/package.json",
          "container/agent-runner/tsconfig.json",
          "package.json",
          "skills-engine/tsconfig.json",
          "tsconfig.json"
        ],
        "dependencies": [
          "container/agent-runner/package-lock.json",
          "container/agent-runner/package.json",
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [
          ".claude/skills/add-discord/add/src/channels/discord.test.ts",
          ".claude/skills/add-discord/modify/src/routing.test.ts",
          ".claude/skills/add-discord/tests/discord.test.ts",
          ".claude/skills/add-telegram/add/src/channels/telegram.test.ts",
          ".claude/skills/add-telegram/modify/src/routing.test.ts",
          ".claude/skills/add-telegram/tests/telegram.test.ts",
          ".claude/skills/add-voice-transcription/modify/src/channels/whatsapp.test.ts",
          ".claude/skills/add-voice-transcription/modify/src/channels/whatsapp.test.ts.intent.md",
          ".claude/skills/add-voice-transcription/tests/voice-transcription.test.ts",
          ".claude/skills/convert-to-apple-container/modify/src/container-runtime.test.ts",
          ".claude/skills/convert-to-apple-container/tests/convert-to-apple-container.test.ts",
          ".github/workflows/skill-tests.yml",
          ".github/workflows/test.yml",
          "docs/SPEC.md",
          "scripts/run-ci-tests.ts",
          "skills-engine/__tests__/apply.test.ts",
          "skills-engine/__tests__/backup.test.ts",
          "skills-engine/__tests__/ci-matrix.test.ts",
          "skills-engine/__tests__/constants.test.ts",
          "skills-engine/__tests__/customize.test.ts",
          "skills-engine/__tests__/file-ops.test.ts",
          "skills-engine/__tests__/lock.test.ts",
          "skills-engine/__tests__/manifest.test.ts",
          "skills-engine/__tests__/merge.test.ts",
          "skills-engine/__tests__/path-remap.test.ts",
          "skills-engine/__tests__/rebase.test.ts",
          "skills-engine/__tests__/replay.test.ts",
          "skills-engine/__tests__/resolution-cache.test.ts",
          "skills-engine/__tests__/state.test.ts",
          "skills-engine/__tests__/structured.test.ts",
          "skills-engine/__tests__/test-helpers.ts",
          "skills-engine/__tests__/uninstall.test.ts",
          "skills-engine/__tests__/update.test.ts",
          "src/channels/whatsapp.test.ts",
          "src/container-runner.test.ts",
          "src/container-runtime.test.ts",
          "src/db.test.ts",
          "src/formatting.test.ts",
          "src/group-queue.test.ts",
          "src/ipc-auth.test.ts",
          "src/routing.test.ts",
          "vitest.config.ts",
          "vitest.skills.config.ts"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "README_zh.md",
          "docs/APPLE-CONTAINER-NETWORKING.md",
          "docs/DEBUG_CHECKLIST.md",
          "docs/REQUIREMENTS.md",
          "docs/SDK_DEEP_DIVE.md",
          "docs/SECURITY.md",
          "docs/SPEC.md",
          "docs/nanoclaw-architecture-final.md",
          "docs/nanorepo-architecture.md",
          "repo-tokens/README.md"
        ],
        "fileTypes": {
          ".md": 36,
          ".ts": 102,
          ".yaml": 4,
          ".sh": 12,
          ".html": 1,
          ".example": 1,
          ".yml": 5,
          ".json": 9,
          ".png": 5,
          ".jpeg": 1,
          ".jpg": 1,
          ".plist": 1,
          ".svg": 5
        }
      }
    },
    {
      "id": 1163507594,
      "name": "Maestro",
      "displayName": "Maestro",
      "description": "Agent Orchestration Command Center",
      "summary": "Maestro: Orchestrate Your AI Agents Like a Pro\n\nThe Problem  \nManaging multiple AI agents across projects sucks. You end up juggling tabs, terminal sessions, and half-baked scripts duct-taped together. Need to run tasks in parallel? Good luck. Want to keep clean context between conversations? Better start praying. If you’re trying to hack together workflows with AI tools like Claude or OpenAI Codex, you’re wasting hours on chaos instead of actual work.\n\nWhat This Does  \nMaestro takes the mess of AI agent orchestration and slaps it into a single, keyboard-driven app. At its core, it’s a cross-platform desktop app built with React that acts as a command center for managing your army of AI agents. Everything is designed for power users: think keyboard shortcuts, CLI support (maestro-cli), and features like Auto Run, which processes your markdown-based playbooks with clean, isolated AI sessions for every task.  \n\nThe codebase is fairly organized: src/ handles the core app logic, while scripts/ contains helper tools like build-cli.mjs and start-dev.ps1. The docs/ folder is a beast with 110 files, so you’ll never run out of documentation. Test coverage isn’t bad either, with 27 test files spread across src/tests/ and e2e/ for both unit and end-to-end testing. CI/CD is handled via GitHub Actions, and there’s a .husky/pre-commit hook for clean commits.  \n\nReal-World Use  \nLet’s say you’re managing a project with multiple AI agents working on different tasks—code generation, documentation updates, and QA. With Maestro, you can spin up separate agents for each job in their own isolated sessions. Set up a markdown-based playbook in docs/playbook-exchange.md like:  \n\n  \n\nRun it through the Auto Run task runner, and watch as each task is processed by the right agent in its own clean session. Want to check progress on your phone? Use the Mobile Remote Control feature for real-time updates. Need to integrate this into your CI/CD pipeline? Pipe your playbook into maestro-cli and automate the whole thing.\n\nThe Bottom Line  \nMaestro is a power tool for power users. It’s not for dabblers or folks who find VSCode “intimidating.” But if you’re a keyboard-first dev juggling multiple projects and AI agents, this is probably the tool you didn’t know you needed. Just be ready to wade through a lot of docs to get fully onboarded. Also, the 0 stars on this fork are criminal—go throw it a star already.",
      "url": "https://github.com/moses-y/Maestro",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "RunMaestro/Maestro",
        "url": "https://github.com/RunMaestro/Maestro",
        "stars": 2339
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1531482615713-2afd69097998?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 21, 2026",
      "updatedAt": "February 21, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 31,
          ".github": 2,
          ".husky": 1,
          "build": 25,
          "docs": 110,
          "e2e": 5,
          "scripts": 9,
          "src": 17
        },
        "languages": {
          "Markdown": 55,
          "YAML": 1,
          "JSON": 8,
          "TypeScript": 22,
          "JavaScript": 1
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          ".prettierrc",
          "package.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [
          "docs/openspec-commands.md",
          "docs/screenshots/openspec-commands.png",
          "docs/screenshots/speckit-commands.png",
          "docs/speckit-commands.md",
          "e2e/autorun-batch.spec.ts",
          "e2e/autorun-editing.spec.ts",
          "e2e/autorun-sessions.spec.ts",
          "e2e/autorun-setup.spec.ts",
          "scripts/refresh-openspec.mjs",
          "scripts/refresh-speckit.mjs",
          "src/__tests__/cli/commands/list-agents.test.ts",
          "src/__tests__/cli/commands/list-groups.test.ts",
          "src/__tests__/cli/commands/list-playbooks.test.ts",
          "src/__tests__/cli/commands/list-sessions.test.ts",
          "src/__tests__/cli/commands/run-playbook.test.ts",
          "src/__tests__/cli/commands/send.test.ts",
          "src/__tests__/cli/commands/show-agent.test.ts",
          "src/__tests__/cli/commands/show-playbook.test.ts",
          "src/__tests__/cli/output/formatter.test.ts",
          "src/__tests__/cli/output/jsonl.test.ts",
          "src/__tests__/cli/services/agent-sessions.test.ts",
          "src/__tests__/cli/services/agent-spawner.test.ts",
          "src/__tests__/cli/services/batch-processor.test.ts",
          "src/__tests__/cli/services/playbooks.test.ts",
          "src/__tests__/cli/services/storage.test.ts",
          "src/__tests__/e2e/WebServerSync.e2e.test.ts",
          "src/__tests__/fixtures/maestro-test-image.png"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "build/README.md",
          "docs/about/overview.md",
          "docs/achievements.md",
          "docs/assets/icon.ico",
          "docs/assets/icon.png",
          "docs/assets/made-with-maestro.svg",
          "docs/assets/maestro-app-icon.png",
          "docs/autorun-playbooks.md",
          "docs/cli.md",
          "docs/configuration.md",
          "docs/context-management.md",
          "docs/director-notes.md",
          "docs/docs.json",
          "docs/document-graph.md",
          "docs/env-vars.md",
          "docs/examples/local-manifest.json",
          "docs/features.md",
          "docs/general-usage.md",
          "docs/getting-started.md",
          "docs/git-worktrees.md",
          "docs/group-chat.md",
          "docs/history.md",
          "docs/index.md",
          "docs/installation.md",
          "docs/keyboard-shortcuts.md",
          "docs/local-manifest.md",
          "docs/mcp-server.md",
          "docs/multi-claude.md",
          "docs/openspec-commands.md",
          "docs/playbook-exchange.md",
          "docs/provider-notes.md",
          "docs/releases.md",
          "docs/remote-access.md",
          "docs/screenshots.md",
          "docs/screenshots/achievements-share.png",
          "docs/screenshots/achievements.png",
          "docs/screenshots/autorun-1.png",
          "docs/screenshots/autorun-2.png",
          "docs/screenshots/autorun-expanded.png",
          "docs/screenshots/cmd-k-1.png",
          "docs/screenshots/command-interpreter.png",
          "docs/screenshots/context-warnings-config.png",
          "docs/screenshots/context-warnings.png",
          "docs/screenshots/directors-notes-ai-overview.png",
          "docs/screenshots/directors-notes-history.png",
          "docs/screenshots/document-graph-last-graph.png",
          "docs/screenshots/document-graph.png",
          "docs/screenshots/encore-features.png",
          "docs/screenshots/file-viewer.png",
          "docs/screenshots/git-diff.png",
          "docs/screenshots/git-logs.png",
          "docs/screenshots/git-worktree-configuration.png",
          "docs/screenshots/git-worktree-list.png",
          "docs/screenshots/git-worktree-remove.png",
          "docs/screenshots/git-worktree-right-click.png",
          "docs/screenshots/git-worktrees.png",
          "docs/screenshots/group-chat-over-ssh.png",
          "docs/screenshots/group-chat.png",
          "docs/screenshots/history-1.png",
          "docs/screenshots/history-2.png",
          "docs/screenshots/history-3.png",
          "docs/screenshots/history-4.png",
          "docs/screenshots/input-toggles-defaults.png",
          "docs/screenshots/input-toggles.png",
          "docs/screenshots/leaderboard.png",
          "docs/screenshots/maestro-intro.png",
          "docs/screenshots/maestro-sessions.png",
          "docs/screenshots/main-screen.png",
          "docs/screenshots/mobile-chat.png",
          "docs/screenshots/mobile-groups.png",
          "docs/screenshots/mobile-history.png",
          "docs/screenshots/multi-claude-setup.png",
          "docs/screenshots/openspec-commands.png",
          "docs/screenshots/playbook-exchange-details.png",
          "docs/screenshots/playbook-exchange-list-with-local.png",
          "docs/screenshots/playbook-exchange-list.png",
          "docs/screenshots/prompt-composer-button.png",
          "docs/screenshots/prompt-composer.png",
          "docs/screenshots/provider-config.png",
          "docs/screenshots/session-tracking.png",
          "docs/screenshots/shortcuts-modal.png",
          "docs/screenshots/shortcuts-settings.png",
          "docs/screenshots/skills-enumeration.png",
          "docs/screenshots/speckit-commands.png",
          "docs/screenshots/ssh-agents-mapping.png",
          "docs/screenshots/ssh-agents-servers.png",
          "docs/screenshots/ssh-agents-status.png",
          "docs/screenshots/symphony-active.png",
          "docs/screenshots/symphony-create-agent.png",
          "docs/screenshots/symphony-details.png",
          "docs/screenshots/symphony-history.png",
          "docs/screenshots/symphony-list.png",
          "docs/screenshots/symphony-stats.png",
          "docs/screenshots/tab-close-center.png",
          "docs/screenshots/tab-close-cmd-k.png",
          "docs/screenshots/tab-close-left.png",
          "docs/screenshots/tab-close-right.png",
          "docs/screenshots/tab-menu.png",
          "docs/screenshots/tab-merge.png",
          "docs/screenshots/tab-search.png",
          "docs/screenshots/tab-send.png",
          "docs/screenshots/themes.png",
          "docs/screenshots/usage-dashboard.png",
          "docs/screenshots/wizard-doc-generation.png",
          "docs/screenshots/wizard-inline.png",
          "docs/slash-commands.md",
          "docs/speckit-commands.md",
          "docs/ssh-remote-execution.md",
          "docs/symphony.md",
          "docs/troubleshooting.md",
          "docs/usage-dashboard.md"
        ],
        "fileTypes": {
          ".md": 55,
          ".yml": 1,
          ".png": 81,
          ".icns": 3,
          ".ico": 4,
          ".svg": 7,
          ".json": 8,
          ".plist": 1,
          ".ts": 22,
          ".mjs": 9,
          ".js": 1,
          ".ps1": 1
        }
      }
    },
    {
      "id": 1162822106,
      "name": "apkstudio",
      "displayName": "apkstudio",
      "description": "Open-source, cross platform Qt6 based IDE for reverse-engineering Android application packages. It features a friendly IDE-like layout including code editor with syntax highlighting support for *.smali code files.",
      "summary": "The Problem\nReverse-engineering Android apps isn't exactly a walk in the park. You need a solid IDE that can handle .smali files, APK decompilation, and all the annoying boilerplate that comes with it. Most tools are either clunky or require a PhD to set up. Enter APK Studio, which aims to make your life a tad easier.\n\nWhat This Does\nAPK Studio is a Qt6-based IDE that brings a user-friendly layout and essential features for reverse-engineering APKs. The sources/ directory contains all the magic—check out main.cpp for the entry point and mainwindow.cpp for the core UI functionality. It supports syntax highlighting for .smali and has built-in tools for decompiling, recompiling, and signing APKs.\n\nThe project even automates tool downloads like Java and Apktool, so you don’t have to hunt around for them. Just fire it up, and it handles the setup for you—assuming you’re okay with the default tools. If you prefer custom setups, you can configure them in the settings.\n\nReal-World Use\nImagine you're tasked with modifying an Android app but don't want to spend half your day wrestling with command-line tools. With APK Studio, you can right-click on an .apk file, choose \"Open with APK Studio,\" and watch it decompile in a snap. Need to find a specific method in your .smali code? Use the quick search feature to locate it in the project tree without the hassle of manual navigation.\n\nA few commands, and you're ready to go.\n\nThe Bottom Line\nAPK Studio is a solid choice for anyone serious about reverse-engineering Android apps. The automatic tool management is a nice touch, but the project feels a bit rough around the edges—zero stars suggest it might not be widely adopted yet. If you're looking for a simple way to tinker with APKs without diving deep into the command line, give it a shot. Just don’t expect the polish of more mature IDEs.",
      "url": "https://github.com/moses-y/apkstudio",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "vaibhavpandeyvpz/apkstudio",
        "url": "https://github.com/vaibhavpandeyvpz/apkstudio",
        "stars": 3836
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 20, 2026",
      "updatedAt": "February 20, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 98,
        "directories": {
          ".github": 1,
          "(root)": 5,
          "docs": 1,
          "resources": 34,
          "sources": 57
        },
        "languages": {
          "YAML": 1,
          "Markdown": 1,
          "HTML": 2,
          "C++": 29,
          "C/C++ Header": 28
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "docs/index.html",
          "sources/main.cpp"
        ],
        "configFiles": [
          "CMakeLists.txt"
        ],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md",
          "docs/index.html"
        ],
        "fileTypes": {
          ".yml": 1,
          ".txt": 1,
          ".md": 1,
          ".html": 2,
          ".qrc": 1,
          ".desktop": 1,
          ".png": 16,
          ".theme": 2,
          ".def": 9,
          ".icns": 1,
          ".ico": 1,
          ".psd": 2,
          ".cpp": 29,
          ".h": 28
        }
      }
    },
    {
      "id": 1162821484,
      "name": "MassGen",
      "displayName": "MassGen",
      "description": "🚀 MassGen is an open-source multi-agent scaling system that runs in your terminal, autonomously orchestrating frontier models and agents to collaborate, reason, and produce high-quality results. | Join us on Discord: discord.massgen.ai",
      "summary": "The Problem\n\nModern LLMs are impressive, but running a single agent for complex tasks usually sucks. You get shallow answers, missed context, and zero cross-checking. Multi-agent setups are cool in theory, but most open-source tools are either half-baked, impossible to configure, or just run a chat loop and call it “collaboration.” MassGen tries to fix that: actual parallel agents, real convergence, and orchestration you can run from your terminal (not some cloud dashboard with 400 dependencies).\n\nWhat This Does\n\nMassGen spins up multiple AI agents—each with their own model, config, and task view—and has them work together on your problem. The core logic lives in AGENTS.md and AIUSAGE.md, with orchestration details buried in docs/devnotes/agentplanningcoordinationdesign.md. Agents don’t just chat: they monitor each other, refine answers, and vote on results. The system handles parallel runs, live updates, and context compression (see docs/devnotes/contextcompressiondesign.md).\n\nConfig is dead-simple: drop your secrets into .env.example, tweak Makefile to your liking, and you’re set. Docs are everywhere—README.md, docs/README.md, and about 150 other Markdown files if you get lost. CI/CD is handled with a bunch of GitHub Actions in .github/workflows/, so releases and tests are automated (and, shockingly, actually work).\n\nReal-World Use\n\nSay you’ve got a gnarly research question or need code review from multiple models. Fire up MassGen, pick your agents in AIUSAGE.md, and run:\n\nAgents spin up in parallel, each tackles the problem, and you get a live visualization (check assets/massgen-demo.gif). They iterate, share context, and converge on a final answer—no babysitting required. Need to plug it into an LLM? There’s a full automation guide in AIUSAGE.md.\n\nThe Bottom Line\n\nMassGen is legit if you’re tired of single-agent mediocrity and want real multi-agent workflows without fighting 40 dependencies. It’s overkill for tiny tasks, and the docs are a rabbit hole, but the orchestration is solid and the config is sane. If you care about agentic AI and want to tinker with parallel setups, this is worth your time. If you just want ChatGPT, skip it.",
      "url": "https://github.com/moses-y/MassGen",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "massgen/MassGen",
        "url": "https://github.com/massgen/MassGen",
        "stars": 811
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 20, 2026",
      "updatedAt": "February 20, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 19,
          ".devcontainer": 2,
          ".github": 16,
          "assets": 11,
          "docs": 152
        },
        "languages": {
          "YAML": 14,
          "JSON": 1,
          "Shell": 2,
          "Markdown": 81,
          "HTML": 56,
          "Python": 2,
          "CSS": 1,
          "reStructuredText": 7
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          ".env.example",
          "Makefile",
          "docs/Makefile"
        ],
        "dependencies": [],
        "testFiles": [
          ".github/workflows/tests.yml",
          "docs/modules/testing.md"
        ],
        "docs": [
          "CHANGELOG.md",
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "README_PYPI.md",
          "docs/.backend_model_listing.md.swp",
          "docs/.readthedocs.yaml",
          "docs/CASE_STUDIES_SUMMARY.md",
          "docs/Makefile",
          "docs/README.md",
          "docs/announcements/README.md",
          "docs/announcements/archive/.gitkeep",
          "docs/announcements/archive/v0.1.33.md",
          "docs/announcements/archive/v0.1.34.md",
          "docs/announcements/archive/v0.1.35.md",
          "docs/announcements/archive/v0.1.36.md",
          "docs/announcements/archive/v0.1.37.md",
          "docs/announcements/archive/v0.1.38.md",
          "docs/announcements/archive/v0.1.39.md",
          "docs/announcements/archive/v0.1.40.md",
          "docs/announcements/archive/v0.1.41.md",
          "docs/announcements/archive/v0.1.42.md",
          "docs/announcements/archive/v0.1.43.md",
          "docs/announcements/archive/v0.1.44.md",
          "docs/announcements/archive/v0.1.45.md",
          "docs/announcements/archive/v0.1.46.md",
          "docs/announcements/archive/v0.1.47.md",
          "docs/announcements/archive/v0.1.48.md",
          "docs/announcements/archive/v0.1.49.md",
          "docs/announcements/archive/v0.1.50.md",
          "docs/announcements/archive/v0.1.51.md",
          "docs/announcements/archive/v0.1.52.md",
          "docs/announcements/current-release.md",
          "docs/announcements/feature-highlights.md",
          "docs/claude-advanced-tooling.md",
          "docs/dev_notes/CODE_EXECUTION_DESIGN.md",
          "docs/dev_notes/MULTI_SOURCE_AGENT_INTEGRATION_DESIGN.md",
          "docs/dev_notes/agent_planning_coordination_design.md",
          "docs/dev_notes/backend_model_listing.md",
          "docs/dev_notes/context_compression_design.md",
          "docs/dev_notes/docs_reorganization.md",
          "docs/dev_notes/docs_reorganization_implementation.md",
          "docs/dev_notes/file_deletion_and_context_files.md",
          "docs/dev_notes/filesystem_tool_discovery_design.md",
          "docs/dev_notes/gemini_filesystem_mcp_design.md",
          "docs/dev_notes/hierarchy_design.md",
          "docs/dev_notes/intelligent_planning_mode.md",
          "docs/dev_notes/litellm_cost_tracking_integration.md",
          "docs/dev_notes/massgen_rl_integration_design.md",
          "docs/dev_notes/multi_turn_filesystem_design.md",
          "docs/dev_notes/nlip_integration_design.md",
          "docs/dev_notes/preempt_not_restart_design.md",
          "docs/dev_notes/proactive_compression_design.md",
          "docs/dev_notes/pypi_package_design.md",
          "docs/dev_notes/python_library_api_design.md",
          "docs/dev_notes/release_checklist.md",
          "docs/dev_notes/release_driven_documentation_system.md",
          "docs/dev_notes/system_prompt_architecture_redesign.md",
          "docs/dev_notes/textual_tui_architecture.md",
          "docs/dev_notes/tui_redesign_phase6_handoff.md",
          "docs/dev_notes/tui_redesign_phase9_11_13_handoff.md",
          "docs/dev_notes/v0.0.14-context.md",
          "docs/make.bat",
          "docs/modules/architecture.md",
          "docs/modules/code_review.md",
          "docs/modules/documentation.md",
          "docs/modules/interactive_mode.md",
          "docs/modules/registry.md",
          "docs/modules/release.md",
          "docs/modules/skills.md",
          "docs/modules/subagents.md",
          "docs/modules/testing.md",
          "docs/modules/worktrees.md",
          "docs/parallel-tool-execution.md",
          "docs/presentation/README_MODULAR.md",
          "docs/presentation/applied-ai-summit.html",
          "docs/presentation/berkeley.html",
          "docs/presentation/build_presentation.py",
          "docs/presentation/cambridge.html",
          "docs/presentation/columbia.html",
          "docs/presentation/components/head-aibuilders.html",
          "docs/presentation/components/head-columbia.html",
          "docs/presentation/components/head.html",
          "docs/presentation/components/navigation.html",
          "docs/presentation/components/slide-additional-context-paths.html",
          "docs/presentation/components/slide-advanced-coordination.html",
          "docs/presentation/components/slide-ag2-research-foundation.html",
          "docs/presentation/components/slide-applications.html",
          "docs/presentation/components/slide-architecture.html",
          "docs/presentation/components/slide-benchmarking-results.html",
          "docs/presentation/components/slide-call-to-action-aibuilders.html",
          "docs/presentation/components/slide-call-to-action-applied-ai-summit.html",
          "docs/presentation/components/slide-call-to-action-columbia.html",
          "docs/presentation/components/slide-call-to-action-general.html",
          "docs/presentation/components/slide-call-to-action-m2l.html",
          "docs/presentation/components/slide-call-to-action-recsys.html",
          "docs/presentation/components/slide-call-to-action.html",
          "docs/presentation/components/slide-case-study-success-through-collaboration.html",
          "docs/presentation/components/slide-case-study-when-coordination-fails.html",
          "docs/presentation/components/slide-codeact.html",
          "docs/presentation/components/slide-columbia-research-applications.html",
          "docs/presentation/components/slide-community-cta.html",
          "docs/presentation/components/slide-context-sharing-challenge.html",
          "docs/presentation/components/slide-context-sharing-in-action.html",
          "docs/presentation/components/slide-context-sharing-solution.html",
          "docs/presentation/components/slide-coordination-strategy-research.html",
          "docs/presentation/components/slide-early-adopters.html",
          "docs/presentation/components/slide-evidence-performance-gains.html",
          "docs/presentation/components/slide-evolution-from-v001.html",
          "docs/presentation/components/slide-getting-started.html",
          "docs/presentation/components/slide-key-features-capabilities.html",
          "docs/presentation/components/slide-live-demo-examples.html",
          "docs/presentation/components/slide-recsys-applications.html",
          "docs/presentation/components/slide-roadmap-vision.html",
          "docs/presentation/components/slide-tech-deep-dive-async-streaming-architecture.html",
          "docs/presentation/components/slide-tech-deep-dive-backend-abstraction-challenges.html",
          "docs/presentation/components/slide-tech-deep-dive-binary-decision-framework-solution.html",
          "docs/presentation/components/slide-the-problem.html",
          "docs/presentation/components/slide-the-solution-multi-agent-collaboration.html",
          "docs/presentation/components/slide-title-aibuilders.html",
          "docs/presentation/components/slide-title-applied-ai-summit.html",
          "docs/presentation/components/slide-title-cambridge.html",
          "docs/presentation/components/slide-title-columbia.html",
          "docs/presentation/components/slide-title-m2l.html",
          "docs/presentation/components/slide-title-pytorch-openagents.html",
          "docs/presentation/components/slide-title-recsys.html",
          "docs/presentation/datahack_summit_2025.html",
          "docs/presentation/extract_components.py",
          "docs/presentation/m2l.html",
          "docs/presentation/massgen-discord.webp",
          "docs/presentation/massgen-repo.webp",
          "docs/presentation/massgendiscord.svg",
          "docs/presentation/massgenrepo.svg",
          "docs/presentation/packt.html",
          "docs/presentation/pytorch-openagents.html",
          "docs/presentation/recsys-short.html",
          "docs/presentation/recsys.html",
          "docs/rate_limiting.md",
          "docs/rebuild_and_open.sh",
          "docs/requirements-docs.txt",
          "docs/source/_static/css/theme-images.css",
          "docs/source/_static/images/logo-dark.png",
          "docs/source/_static/images/logo.png",
          "docs/source/_static/images/massgen-demo-light.gif",
          "docs/source/_static/images/massgen-demo.gif",
          "docs/source/_static/images/readme.gif",
          "docs/source/_static/images/readme_old.gif",
          "docs/source/_static/images/thumbnail.png",
          "docs/source/_static/images/tutorial-develop.gif",
          "docs/source/_static/images/tutorial-getting-started.gif",
          "docs/source/api/agents.rst",
          "docs/source/api/backends.rst",
          "docs/source/api/formatter.rst",
          "docs/source/api/frontend.rst",
          "docs/source/api/index.rst",
          "docs/source/api/mcp_tools.rst",
          "docs/source/api/orchestrator.rst"
        ],
        "fileTypes": {
          ".yaml": 4,
          ".json": 1,
          ".sh": 2,
          ".example": 1,
          ".md": 81,
          ".yml": 10,
          ".disabled": 1,
          ".in": 1,
          ".gif": 9,
          ".png": 11,
          ".swp": 1,
          ".bat": 1,
          ".html": 56,
          ".py": 2,
          ".webp": 2,
          ".svg": 2,
          ".txt": 1,
          ".css": 1,
          ".rst": 7
        }
      }
    },
    {
      "id": 1162814238,
      "name": "agenticSeek",
      "displayName": "agenticSeek",
      "description": "Fully Local Manus AI. No APIs, No $200 monthly bills. Enjoy an autonomous agent that thinks, browses the web, and code for the sole cost of electricity. 🔔 Official updates only via twitter @Martin993886460 (Beware of fake account)",
      "summary": "The Problem\n\nAI agents are cool and all, but who has the cash to blow $200 a month on API calls? Beyond the subscription fees, there's the even bigger issue of privacy. Do you really want your personal data and queries sent off to some random server farm? No, thanks. Enter agenticSeek, the self-contained, fully local AI assistant that keeps your data where it belongs—on your machine.\n\nWhat This Does\n\nagenticSeek is basically your personal Jarvis, minus the billionaire tech mogul backstory. It runs entirely on your hardware, using Python, Flask, React, and Docker to spin up a suite of modular AI agents. You’ve got file agents in sources/agents/fileagent.py, coding helpers like sources/tools/PyInterpreter.py, and even a browser agent (sources/agents/browseragent.py) for autonomous web searches.\n\nThe directory structure is clean and logical. For example, anything to do with large language models lives in llmserver/. Configs like .env.example, docker-compose.yml, and various Dockerfile setups keep deployment straightforward. Speaking of, the project is very Docker-friendly—Dockerfiles for the backend, frontend, and LLM server are all included. You’ll appreciate that if you’ve ever spent hours debugging dependencies.\n\nOne standout feature is how it picks the right agent for the job. Ask it to analyze a .zip of resumes? It knows to fetch the fileagent. Want to scrape data from a website? That’s the browseragent’s turf.\n\nReal-World Use\n\nImagine this: You’re working on a side project and need to write a Python script to scrape product data from multiple sites. Instead of googling for hours and writing boilerplate code, you boot up agenticSeek. Tell it what you need done, and it’ll spin up the browseragent, fetch the necessary data, and even write a script in sources/tools/webSearch.py to automate the task. Oh, and all of this happens locally—your data, your rules.\n\nSetup is simple. Clone the repo, install Python 3.10.x, fire up Docker with docker-compose up, and you’re good to go. The cli.py script is your main entry point if you’re more of a terminal junkie.\n\nThe Bottom Line\n\nagenticSeek is a no-bullshit, privacy-first AI assistant for power users. It’s loaded with functionality and doesn’t shove recurring fees or cloud nonsense down your throat. That said, it’s not for the faint of heart—there’s no hand-holding here, and you’ll need to know your way around Docker and Python. If that’s you, though, this could be your new favorite tool.",
      "url": "https://github.com/moses-y/agenticSeek",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Fosowl/agenticSeek",
        "url": "https://github.com/Fosowl/agenticSeek",
        "stars": 25151
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 20, 2026",
      "updatedAt": "February 20, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 137,
        "directories": {
          "(root)": 26,
          ".github": 3,
          "crx": 1,
          "docs": 6,
          "frontend": 24,
          "llm_router": 4,
          "llm_server": 9,
          "media": 4,
          "prompts": 12,
          "scripts": 3,
          "searxng": 5,
          "sources": 35,
          "tests": 5
        },
        "languages": {
          "YAML": 5,
          "Markdown": 12,
          "Python": 46,
          "JSON": 5,
          "HTML": 1,
          "CSS": 4,
          "JavaScript": 12,
          "Shell": 7,
          "TOML": 2
        },
        "frameworks": [
          "React",
          "Flask",
          "Express",
          "Docker"
        ],
        "packageManager": "pip",
        "hasDocker": true,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "cli.py",
          "frontend/agentic-seek-front/public/index.html",
          "frontend/agentic-seek-front/src/App.js",
          "frontend/agentic-seek-front/src/index.js",
          "llm_server/app.py",
          "setup.py"
        ],
        "configFiles": [
          ".env.example",
          "Dockerfile.backend",
          "docker-compose.yml",
          "frontend/Dockerfile.frontend",
          "frontend/agentic-seek-front/package.json",
          "llm_server/Dockerfile",
          "llm_server/requirements.txt",
          "pyproject.toml",
          "requirements.txt",
          "searxng/docker-compose.yml",
          "setup.py"
        ],
        "dependencies": [
          "frontend/agentic-seek-front/package-lock.json",
          "frontend/agentic-seek-front/package.json",
          "llm_server/requirements.txt",
          "pyproject.toml",
          "requirements.txt"
        ],
        "testFiles": [
          "frontend/agentic-seek-front/src/App.test.js",
          "frontend/agentic-seek-front/src/setupTests.js",
          "tests/test_browser_agent_parsing.py",
          "tests/test_memory.py",
          "tests/test_provider.py",
          "tests/test_searx_search.py",
          "tests/test_tools_parsing.py"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "README_CHS.md",
          "README_CHT.md",
          "README_ES.md",
          "README_FR.md",
          "README_JP.md",
          "README_PTBR.md",
          "docs/CODE_OF_CONDUCT.md",
          "docs/CONTRIBUTING.md",
          "docs/technical/code_agent.png",
          "docs/technical/diagram_overall.png",
          "docs/technical/routing_system.png",
          "docs/technical/web_agent.png",
          "frontend/README.md",
          "media/chromedriver_readme.png",
          "media/whale_readme.jpg"
        ],
        "fileTypes": {
          ".example": 1,
          ".yml": 4,
          ".md": 12,
          ".yaml": 1,
          ".backend": 1,
          ".py": 46,
          ".ini": 2,
          ".crx": 1,
          ".png": 9,
          ".frontend": 1,
          ".json": 5,
          ".ico": 1,
          ".html": 1,
          ".txt": 15,
          ".css": 4,
          ".js": 12,
          ".bat": 2,
          ".sh": 7,
          ".safetensors": 1,
          ".jpg": 1,
          ".toml": 2,
          ".cmd": 1,
          ".lock": 1
        }
      }
    },
    {
      "id": 1162684251,
      "name": "ClawWork",
      "displayName": "ClawWork",
      "description": "\"ClawWork: OpenClaw as Your AI Coworker - 💰 $10K earned in 7 Hours\"",
      "summary": "The Problem\nIn today's gig economy, we need tools that can actually perform real work, not just automate mundane tasks. Many AI solutions are all talk and no action, lacking the capability to generate genuine economic value while dealing with financial constraints. Enter ClawWork, which tackles this exact issue by turning AI from simple assistants into economically viable coworkers.\n\nWhat This Does\nClawWork leverages a dataset called GDPVal to create a competitive environment where AI agents must earn their keep. The livebench/api/server.py file handles incoming requests, allowing agents to execute tasks across 44 professions. Meanwhile, the clawmodeintegration/cli.py file serves as the command-line interface where you can start agents and monitor their performance.\n\nThe frontend is built with React and Tailwind, providing a slick dashboard for visualizing metrics like agent balances and task completions. Check out frontend/src/pages/Dashboard.jsx for how performance metrics are rendered. It’s like a stock market ticker for your AI workers—except they’re not just trading, they’re actually working.\n\nReal-World Use\nImagine deploying an AI agent to handle customer service inquiries. You fire up the agent with python -m clawmodeintegration.cli agent, and it starts answering queries. Each response costs tokens, and the agent has to earn enough to keep running. If it screws up, it'll hit zero and stop working. So, the stakes are real, mimicking the pressure of actual work environments.\n\nHere's a quick snippet to illustrate starting an agent:\n\nThe agent then interacts with users, collects data, and feeds it back into the livebench/data/agent_data for analysis.\n\nThe Bottom Line\nClawWork is an interesting concept that pushes the boundaries of what AI can do in a work setting. The integration of real economic constraints makes it a valuable tool for testing AI capabilities in practical applications. However, the complexity might be overkill for small projects or teams just looking for basic automation. If you’re serious about AI in your workflow and want to explore its economic implications, give this a shot. Just be ready for some trial and error.",
      "url": "https://github.com/moses-y/ClawWork",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "HKUDS/ClawWork",
        "url": "https://github.com/HKUDS/ClawWork",
        "stars": 5700
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 20, 2026",
      "updatedAt": "February 20, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 4,
          ".github": 1,
          "assets": 6,
          "clawmode_integration": 9,
          "eval": 50,
          "frontend": 21,
          "livebench": 109
        },
        "languages": {
          "YAML": 1,
          "Markdown": 6,
          "Python": 16,
          "JSON": 60,
          "HTML": 1,
          "JavaScript": 5,
          "JSX": 11,
          "CSS": 1
        },
        "frameworks": [
          "React",
          "Express",
          "Tailwind"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "clawmode_integration/cli.py",
          "frontend/index.html",
          "frontend/src/App.jsx",
          "livebench/api/server.py"
        ],
        "configFiles": [
          ".env.example",
          "frontend/package.json",
          "frontend/tailwind.config.js",
          "frontend/vite.config.js"
        ],
        "dependencies": [
          "frontend/package-lock.json",
          "frontend/package.json"
        ],
        "testFiles": [
          "eval/meta_prompts/Project_Management_Specialists.json",
          "eval/meta_prompts/test/Accountants_and_Auditors_test.json",
          "eval/test_single_category.py",
          "livebench/configs/test_glm47.json",
          "livebench/configs/test_glm47_1.json",
          "livebench/configs/test_glm47_openrouter.json",
          "livebench/configs/test_glm47_openrouter_10dollar.json",
          "livebench/configs/test_gpt4o.json",
          "livebench/configs/test_k25_openrouter_10dollar.json",
          "livebench/configs/test_qwen3max_10dollar.json",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-01-01/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-01-02/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-01-05/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-01-06/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-01-07/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-01-08/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-01-09/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-01-12/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-01-13/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-01-14/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-01-15/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-01-16/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-01-19/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-01-20/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-01-21/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-01-22/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-01-23/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-01-26/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-01-27/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-01-28/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-01-29/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-01-30/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-02-02/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-02-03/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-02-04/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-02-05/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-02-06/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-02-09/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-02-10/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-02-11/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-02-12/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-02-13/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-02-16/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-02-17/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-02-18/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-02-19/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-02-20/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-02-23/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-02-24/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-02-25/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-02-26/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-02-27/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-03-02/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-03-03/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-03-04/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-03-05/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-03-06/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-03-09/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-03-10/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-03-11/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-03-12/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-03-13/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-03-16/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-03-17/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-03-18/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-03-19/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-03-20/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-03-23/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-03-24/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-03-25/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-03-26/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-03-27/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-03-30/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-03-31/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-04-01/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-04-02/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-04-03/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-04-06/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-04-07/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-04-08/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-04-09/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-04-10/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-04-13/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-04-14/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-04-15/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-04-16/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-04-17/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-04-20/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-04-21/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-04-22/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-04-23/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-04-24/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-04-27/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-04-28/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-04-29/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-04-30/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-05-01/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-05-04/log.jsonl",
          "livebench/data/agent_data/GLM-4.7-test-openrouter-10dollar-1/activity_logs/2026-05-05/log.jsonl"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "clawmode_integration/README.md",
          "eval/README.md",
          "frontend/README.md",
          "livebench/README.md"
        ],
        "fileTypes": {
          ".example": 1,
          ".yml": 1,
          ".md": 6,
          ".png": 4,
          ".gif": 2,
          ".py": 16,
          ".log": 1,
          ".json": 60,
          ".html": 1,
          ".js": 5,
          ".jsx": 11,
          ".css": 1,
          ".jsonl": 89
        }
      }
    },
    {
      "id": 1162539479,
      "name": "Motrix",
      "displayName": "Motrix",
      "description": "A full-featured download manager.",
      "summary": "The Problem\n\nManaging downloads—especially torrents, magnets, and direct links—sucks. Built-in browser downloaders choke on big files, don't resume, and have zero support for BitTorrent. Windows users get weird .exe wrappers, Linux users get cryptic CLI tools, and Mac users get the privilege of paying for apps that half-work. You want one tool that handles it all without making your desktop look like 2003.\n\nWhat This Does\n\nMotrix is a download manager that actually supports HTTP, FTP, BitTorrent, and Magnet links in one desktop app. The main logic sits in src/main/—stuff like Engine.js and EngineClient.js wrap the download backend, which is basically aria2c (check out the extra/*/engine/aria2c binaries for each OS/arch). The renderer, in src/renderer/components/, is mostly Vue, and the UI is clean, not a Frankenstein of Electron and Bootstrap.\n\nConfig files like .eslintrc.js and electron-builder.json keep the build sane, and the CI/CD is handled via Travis CI and .github/workflows/release.yml, so you actually get working releases across platforms. Menus are handled with JSON files per OS (src/main/menus/win32.json, etc.), making it easy to hack your own context menus if you care.\n\nReal-World Use\n\nSay you want to download a Linux ISO from a torrent, a movie from a magnet link, and some giant FTP backup file. Fire up Motrix, paste your links into the UI (see src/renderer/components/Browser/index.vue), and let it rip. Downloads show up in the task list. Pause, resume, restart—all there. Want to automate? The API layer in src/renderer/api/Api.js exposes functions you can call from scripts or extensions.\n\nExample: Need to add a magnet link from the clipboard? The CommandManager in src/renderer/components/CommandManager/index.js handles stuff like that. No need to write your own download handler or parse links manually.\n\nThe Bottom Line\n\nMotrix does what most download managers promise but rarely deliver. It’s not lightweight—if you just want to grab a PDF, use your browser. But if you regularly wrangle torrents, FTP, or weird download links across OSes, Motrix is worth your time. The UI doesn’t suck, and the guts are solid. If you like tinkering, the code is readable and hackable. If you hate Electron, well, tough luck—so does every cross-platform app these days.",
      "url": "https://github.com/moses-y/Motrix",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "agalwood/Motrix",
        "url": "https://github.com/agalwood/Motrix",
        "stars": 50923
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 20, 2026",
      "updatedAt": "February 20, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 17,
          ".electron-vue": 6,
          ".github": 8,
          "build": 12,
          "extra": 15,
          "screenshots": 5,
          "src": 137
        },
        "languages": {
          "JavaScript": 80,
          "YAML": 8,
          "Markdown": 9,
          "JSON": 8,
          "HTML": 2,
          "Vue": 11
        },
        "frameworks": [
          "React",
          "Vue"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "Travis CI",
        "entryPoints": [
          "src/main/index.js",
          "src/main/pages/index.html",
          "src/main/utils/index.js",
          "src/renderer/api/index.js",
          "src/renderer/components/CommandManager/index.js",
          "src/renderer/components/Locale/index.js"
        ],
        "configFiles": [
          ".eslintrc.js",
          "package.json"
        ],
        "dependencies": [
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "CONTRIBUTING-CN.md",
          "CONTRIBUTING.md",
          "LICENSE",
          "README-CN.md",
          "README.md",
          "extra/README.md"
        ],
        "fileTypes": {
          ".js": 80,
          ".yml": 8,
          ".md": 9,
          ".png": 14,
          ".tiff": 1,
          ".icns": 2,
          ".ico": 2,
          ".json": 8,
          ".conf": 7,
          ".exe": 2,
          ".ejs": 1,
          ".html": 2,
          ".svg": 42,
          ".vue": 11
        }
      }
    },
    {
      "id": 1156080985,
      "name": "tinyclaw",
      "displayName": "tinyclaw",
      "description": "TinyClaw is a team of AI agents that acts as your 24/7 personal assistant",
      "summary": "The Problem\nManaging multiple AI assistants across different platforms can be a headache. You might be juggling Discord, WhatsApp, and Telegram bots, each with its own quirks and configurations. Let's face it: setting up each bot separately is tedious, and keeping track of conversation contexts is a nightmare.\n\nWhat This Does\nTinyClaw simplifies this chaos by allowing you to run multiple isolated AI agents simultaneously. The src/ directory contains the core components, like discord-client.ts and telegram-client.ts, which handle communication with their respective platforms. The lib/ folder has utility scripts, such as messaging.sh and daemon.sh, that enable persistent sessions and parallel processing. You can manage everything with commands like tinyclaw start or tinyclaw logs queue to check message handling.\n\nThe setup is straightforward, thanks to the scripts/install.sh and an interactive setup wizard that guides you through channel selections and bot token entries. The configuration is all stored in settings.json, making it easy to tweak settings without diving into code.\n\nReal-World Use\nImagine you’re running a community on Discord while also engaging customers on WhatsApp. With TinyClaw, you can set up a Discord bot that handles moderation tasks while your WhatsApp bot deals with customer inquiries. You could simply run:\n\ntinyclaw start\n\nAfter that, the bots operate independently but still maintain their context, thanks to the persistent sessions feature. If your Discord bot needs to fetch user data, it can do so without overlapping with WhatsApp conversations.\n\nThe Bottom Line\nTinyClaw is a solid choice if you need to manage multiple AI assistants across different channels. It saves time and effort, but it might be overkill for simple projects or single-channel usage. If you’re handling diverse communication channels and want a consistent experience, give it a shot. Otherwise, keep it simple and stick to one channel.",
      "url": "https://github.com/yebeai/tinyclaw",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "TinyAGI/tinyclaw",
        "url": "https://github.com/TinyAGI/tinyclaw",
        "stars": 2741
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 12, 2026",
      "updatedAt": "February 20, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 33,
        "directories": {
          ".claude": 3,
          "(root)": 9,
          ".github": 1,
          "bin": 1,
          "docs": 4,
          "lib": 7,
          "scripts": 4,
          "src": 4
        },
        "languages": {
          "Shell": 14,
          "JSON": 4,
          "YAML": 1,
          "Markdown": 7,
          "TypeScript": 4
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          "package.json",
          "tsconfig.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "README.md",
          "docs/AGENTS.md",
          "docs/INSTALL.md",
          "docs/QUEUE.md",
          "docs/TROUBLESHOOTING.md"
        ],
        "fileTypes": {
          ".sh": 14,
          ".json": 4,
          ".yml": 1,
          ".md": 7,
          ".ts": 4
        }
      }
    },
    {
      "id": 1162369507,
      "name": "nairobi_property_pricing",
      "displayName": "nairobi property pricing",
      "description": "A data pipeline for scraping, cleaning, and enriching Nairobi property listings. It normalizes prices, extracts bedroom counts from titles/URLs, and calculates per‑bedroom affordability. The project also generates location summaries and enriched datasets for analysis.",
      "summary": "The Problem  \nProperty listings in Nairobi are a mess. Prices are inconsistent (\"45k\", \"Ksh 45,000\", \"45000\"), bedroom counts are buried in random text (\"2br\", \"2 bed\", \"Two Bedroom\"), and the data is scattered across various sites. If you're trying to figure out where you can afford to live—or just analyzing the market—you'll spend more time cleaning data than actually using it.  \n\nWhat This Does  \nThis repo is a full pipeline for scraping, cleaning, and analyzing Nairobi property data. The scrapelistings.py script pulls raw data from websites, dumping it into allrawlistings.csv. From there, cleanproperties.py handles price normalization and bedroom extraction using hardcoded logic in parser.py (no fancy machine learning, just regex and string parsing that actually works). The cleaned output lands in cleanedproperties.csv.  \n\nOnce the data is usable, scripts like buildsummary.py and eda.py generate insights: average prices, price-per-bedroom, and location summaries (locationsummaryclean.csv). The real cherry on top is the interactive map (nairobiaffordabilitymap.html), built using Nairobi's geoJSON boundaries (nairobicounty.geojson). It visualizes affordability metrics by neighborhood.  \n\nBonus: the repo includes a bunch of pre-generated charts in the charts/ folder, so you don’t have to set up matplotlib just to see results.  \n\nReal-World Use  \nImagine you're moving to Nairobi and need a 2-bedroom place under 50k Ksh/month. Run the pipeline, then filter cleanedproperties.csv or explore the nairobiaffordabilitymap.html to quickly find affordable neighborhoods.  \n\nOr, maybe you're a data analyst working on urban planning. Use the location summary data (locationsummaryclean.csv) to identify rental hotspots or compare premium vs. affordable areas.  \n\nWant to hack on it? Extend the scraper (nairobipropertyscraper_v2.py) to include more websites or tweak parser.py to handle even messier input.  \n\nThe Bottom Line  \nThis repo does what it says: it turns Nairobi's chaotic property data into something useful. The code is Python-heavy and a bit procedural, but it's clear and easy to follow. If you're working with Nairobi real estate data, this is a solid starting point. Just know you'll likely want to tweak things—it’s not plug-and-play for non-technical users.",
      "url": "https://github.com/moses-y/nairobi_property_pricing",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "mainamuragev/nairobi_property_pricing",
        "url": "https://github.com/mainamuragev/nairobi_property_pricing",
        "stars": 30
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 20, 2026",
      "updatedAt": "February 20, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 32,
        "directories": {
          "(root)": 21,
          "__pycache__": 1,
          "charts": 9,
          "data": 1
        },
        "languages": {
          "Markdown": 2,
          "Python": 9,
          "HTML": 2
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [
          "requirements.txt"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".md": 2,
          ".pyc": 1,
          ".csv": 5,
          ".py": 9,
          ".png": 9,
          ".html": 2,
          ".geojson": 1,
          ".txt": 1
        }
      }
    },
    {
      "id": 1162368481,
      "name": "facet",
      "displayName": "facet",
      "description": "A multi-dimensional photo analysis engine that examines every facet of an image — from aesthetic appeal and composition to facial detail and technical precision — using an ensemble of        vision models to surface the photos that truly shine.",
      "summary": "The Problem\nWe all have piles of photos, and sorting through them can feel like wading through molasses. Finding the best shots based on aesthetic appeal, composition, or even facial details is a pain in the neck. Traditional methods? Forget it. You need a tool that can analyze images intelligently and surface the gems without all the manual labor.\n\nWhat This Does\nEnter facet, a multi-dimensional photo analysis engine that leverages various vision models to rank and categorize your images. Inside the api directory, you'll find files like auth.py and gallery.py, which handle user authentication and gallery management, respectively. The analyzers folder contains the heavy hitters — composition.py, face.py, and technical.py — that score photos based on aesthetic quality, facial detail, and technical metrics.\n\nIf you’re curious about how it all comes together, check out client/src/app/app.ts, which initializes the app, or client/src/features/gallery/gallery.component.ts, where the gallery functionality is implemented. With features like AI-powered scoring and advanced filtering options, you can sift through your collection like a pro.\n\nReal-World Use\nImagine you just shot a weekend trip and have hundreds of photos. You want to find the best ones for a photo book. Using facet, you can upload your images and let the system do its magic. It evaluates each photo using models like TOPIQ for quality and SAMP-Net for composition analysis. You can filter the results to show only photos with a high aesthetic score or specific composition patterns. The stats.component.ts helps you visualize which equipment worked best, giving you insights for future shoots.\n\nThe Bottom Line\nfacet is a solid tool for photographers who need to analyze and manage large collections of images. It's packed with features, but be warned: it’s overkill if you’re just organizing family vacation photos. If you're a pro or serious hobbyist looking to refine your workflow, this could be worth your time. Just prepare to dive into some Python and TypeScript if you want to customize it.",
      "url": "https://github.com/moses-y/facet",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "ncoevoet/facet",
        "url": "https://github.com/ncoevoet/facet",
        "stars": 59
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 20, 2026",
      "updatedAt": "February 20, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 189,
        "directories": {
          ".claude": 13,
          "(root)": 11,
          "analyzers": 5,
          "api": 22,
          "client": 61,
          "comparison": 3,
          "config": 4,
          "db": 8,
          "docs": 22,
          "exiftool": 2,
          "faces": 5,
          "i18n": 6,
          "models": 8,
          "optimization": 2,
          "processing": 6,
          "utils": 8,
          "validation": 3
        },
        "languages": {
          "Markdown": 24,
          "Python": 82,
          "JSON": 14,
          "TypeScript": 45,
          "HTML": 2,
          "SCSS": 1
        },
        "frameworks": [
          "React",
          "Angular",
          "Express"
        ],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "client/src/app/app.ts",
          "client/src/index.html",
          "client/src/main.ts"
        ],
        "configFiles": [
          "client/jest.config.ts",
          "client/package.json",
          "client/tsconfig.json",
          "requirements.txt"
        ],
        "dependencies": [
          "client/package-lock.json",
          "client/package.json",
          "requirements.txt"
        ],
        "testFiles": [
          ".claude/skills/chrome-devtools-debugging/references/validation-testing.md",
          ".claude/skills/test-creation/SKILL.md",
          ".claude/skills/test-creation/references/error-patterns.md",
          ".claude/skills/test-creation/references/mocking-patterns.md",
          "client/src/app/core/guards/auth.guard.spec.ts",
          "client/src/app/core/interceptors/auth.interceptor.spec.ts",
          "client/src/app/core/interceptors/error.interceptor.spec.ts",
          "client/src/app/core/services/api.service.spec.ts",
          "client/src/app/core/services/auth.service.spec.ts",
          "client/src/app/core/services/i18n.service.spec.ts",
          "client/src/app/features/auth/login.component.spec.ts",
          "client/src/app/features/comparison/comparison.component.spec.ts",
          "client/src/app/features/gallery/gallery.component.spec.ts",
          "client/src/app/features/gallery/gallery.store.spec.ts",
          "client/src/app/features/persons/manage-persons.component.spec.ts",
          "client/src/app/features/persons/merge-suggestions.component.spec.ts",
          "client/src/app/features/persons/person-page.component.spec.ts",
          "client/src/app/features/stats/stats.component.spec.ts",
          "client/src/app/shared/pipes/translate.pipe.spec.ts",
          "client/tsconfig.spec.json"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "client/README.md",
          "docs/COMMANDS.md",
          "docs/CONFIGURATION.md",
          "docs/DEPLOYMENT.md",
          "docs/FACE_RECOGNITION.md",
          "docs/INSTALLATION.md",
          "docs/README.md",
          "docs/SCORING.md",
          "docs/VIEWER.md",
          "docs/screenshots/compare.jpg",
          "docs/screenshots/filter-drawer.jpg",
          "docs/screenshots/gallery-compact.jpg",
          "docs/screenshots/gallery-desktop.jpg",
          "docs/screenshots/gallery-mobile.jpg",
          "docs/screenshots/gallery-top-picks.jpg",
          "docs/screenshots/hover-preview.jpg",
          "docs/screenshots/manage-persons.jpg",
          "docs/screenshots/person-gallery.jpg",
          "docs/screenshots/stats-categories.png",
          "docs/screenshots/stats-correlations.png",
          "docs/screenshots/stats-gear.png",
          "docs/screenshots/stats-settings.png",
          "docs/screenshots/stats-timeline.png"
        ],
        "fileTypes": {
          ".md": 24,
          ".py": 82,
          ".json": 14,
          ".ts": 45,
          ".ico": 1,
          ".svg": 1,
          ".html": 2,
          ".scss": 1,
          ".jpg": 9,
          ".png": 5,
          ".txt": 1
        }
      }
    },
    {
      "id": 1162273737,
      "name": "hyperbrowser-app-examples",
      "displayName": "hyperbrowser app examples",
      "description": "This repo contains fully functional Hyperbrowser powered web apps",
      "summary": "The Problem\n\nSick of gluing together half-baked web scrapers, brittle bots, and ugly dashboards just to automate some browser tasks? Most browser automation tools are either too simple, too clunky, or require rewriting everything for each new use case. Hyperbrowser tries to make that less painful — actual working web apps that scrape, automate, and spit out useful data, not just demo scripts.\n\nWhat This Does\n\nhyperbrowser-app-examples is a grab bag of full-stack apps built around the Hyperbrowser API. Each one is in its own directory: want to track competitor site changes? Look in competitor-tracker/ (see app/api/crawl/route.ts and lib/diff-html.ts). Need to generate startup ideas from Reddit? Check Idea-generator-reddit/app/components/index.ts and the API logic in app/api/generate/route.ts. All of these are real Next.js projects, with TypeScript everywhere, UI in React, and Tailwind for styling. You get the full setup: config files (next.config.ts, tailwind.config.js), actual source code, and even some snapshot HTML data in competitor-tracker/data/snapshots/.\n\nIt's not just front-end fluff. Each app wires up Hyperbrowser for automation, handles API keys via environment variables, and manages workflow logic in files like lib/hyper.ts or lib/hb.ts. The structure is clear, and you can actually run these locally without rewriting everything.\n\nReal-World Use\n\nSay you need to monitor a competitor’s pricing page. You’d clone the repo, go to competitor-tracker/, set your Hyperbrowser API key in the env file, and run the app. The workflow uses app/api/crawl/route.ts to fetch pages, saves snapshots to data/snapshots/, runs diffs with lib/diff-html.ts, and notifies you of changes. No need to cobble together ten different npm packages — just call the API, and let the UI show you the diff.\n\nThe Bottom Line\n\nIf you want production-ready web scraping apps that don’t look like 2005 PHP junk, this repo is solid. It’s overkill for hobby scripts — but great for anyone building real dashboards or automation tools. The code is readable, the UIs don’t suck, and you don’t have to reinvent the wheel every time. If your pain is browser automation, grab your API key and get started.",
      "url": "https://github.com/moses-y/hyperbrowser-app-examples",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "hyperbrowserai/hyperbrowser-app-examples",
        "url": "https://github.com/hyperbrowserai/hyperbrowser-app-examples",
        "stars": 669
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 20, 2026",
      "updatedAt": "February 20, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 2,
          "Idea-generator-reddit": 35,
          "assets-optimizer": 28,
          "churnhunter": 6,
          "competitor-tracker": 50,
          "deep-crawler-bot": 30,
          "deep-job-researcher": 30,
          "deep-reddit-researcher": 19
        },
        "languages": {
          "Markdown": 8,
          "TSX": 50,
          "TypeScript": 42,
          "CSS": 6,
          "JSON": 20,
          "JavaScript": 6,
          "HTML": 14,
          "SQL": 1
        },
        "frameworks": [
          "React",
          "Next.js",
          "Tailwind"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "Idea-generator-reddit/app/components/index.ts",
          "Idea-generator-reddit/app/types/index.ts"
        ],
        "configFiles": [
          "Idea-generator-reddit/next.config.ts",
          "Idea-generator-reddit/package.json",
          "Idea-generator-reddit/tsconfig.json",
          "assets-optimizer/next.config.js",
          "assets-optimizer/package.json",
          "assets-optimizer/tailwind.config.js",
          "assets-optimizer/tsconfig.json",
          "churnhunter/package.json",
          "churnhunter/tsconfig.json",
          "competitor-tracker/next.config.ts",
          "competitor-tracker/package.json",
          "competitor-tracker/tailwind.config.js",
          "competitor-tracker/tsconfig.json",
          "deep-crawler-bot/next.config.js",
          "deep-crawler-bot/package.json",
          "deep-crawler-bot/tailwind.config.js",
          "deep-crawler-bot/tsconfig.json",
          "deep-job-researcher/next.config.ts",
          "deep-job-researcher/package.json",
          "deep-job-researcher/tailwind.config.js",
          "deep-job-researcher/tsconfig.json",
          "deep-reddit-researcher/next.config.ts"
        ],
        "dependencies": [
          "Idea-generator-reddit/package-lock.json",
          "Idea-generator-reddit/package.json",
          "assets-optimizer/package-lock.json",
          "assets-optimizer/package.json",
          "churnhunter/package-lock.json",
          "churnhunter/package.json",
          "competitor-tracker/package-lock.json",
          "competitor-tracker/package.json",
          "deep-crawler-bot/package-lock.json",
          "deep-crawler-bot/package.json",
          "deep-job-researcher/package-lock.json",
          "deep-job-researcher/package.json",
          "deep-reddit-researcher/package-lock.json"
        ],
        "testFiles": [],
        "docs": [
          "Idea-generator-reddit/README.md",
          "README.md",
          "assets-optimizer/README.md",
          "churnhunter/README.md",
          "competitor-tracker/README.md",
          "deep-crawler-bot/README.md",
          "deep-job-researcher/README.md",
          "deep-reddit-researcher/README.md"
        ],
        "fileTypes": {
          ".md": 8,
          ".tsx": 50,
          ".ts": 42,
          ".ico": 7,
          ".css": 6,
          ".mjs": 6,
          ".json": 20,
          ".svg": 30,
          ".js": 6,
          ".png": 2,
          ".example": 1,
          ".html": 14,
          ".sql": 1
        }
      }
    },
    {
      "id": 1161984220,
      "name": "neuronpedia",
      "displayName": "neuronpedia",
      "description": "open source interpretability platform 🧠",
      "summary": "Neuronpedia: Making Model Interpretability Slightly Less Painful\n\nThe Problem  \nDeep learning models are black boxes. Sure, you can train a model to do magical things, but when it goes haywire, good luck figuring out why. Even worse, trying to explain what’s happening to a non-technical person—like your boss—can feel like trying to explain quantum physics to a dog. You need tools to interpret what the model is doing, debug, and present results in a way that humans can actually understand. That’s where neuronpedia comes in.\n\nWhat This Does  \nneuronpedia is an open-source platform for interpretability. It's a sprawling monorepo (200 files across 4 main apps). At its core, it provides tools for analyzing and visualizing model activations, embeddings, and other internal workings.  \n\nHere’s the breakdown:  \nAutointerp (apps/autointerp/): Automates generating explanations for deep learning models. The guts live in apps/autointerp/server.py, with routes like routes/explain/default.py doing the heavy lifting.  \nGraph (apps/graph/): Handles circuits and graphs. Check out neuronpediagraph/server.py for the main entry point. Want to see how neurons connect? This is your jam.  \nInference (apps/inference/): The heavy-duty stuff. It handles model inference with various configurations. The k8s/overlays/ directory is loaded with YAML files for deploying models, and endpoints/ has utilities for tokenization, steering, and persona analysis.  \nSteerify (apps/experiments/steerify/): Some front-end experiments built with React, Next.js, and Tailwind. If you're into building dashboards or visualizations, this is the playground.  \n\nOh, and it’s containerized with Docker and Kubernetes, so you can run everything locally or spin it up in the cloud if you’re feeling fancy.\n\nReal-World Use  \nLet’s say you're working on a GPT-style model, and it starts spitting out responses that are...less than ideal. Maybe it's biased, or it’s just plain dumb. With neuronpedia, you can use the activation/topkbytoken.py endpoint under apps/inference/neuronpediainference/endpoints/ to dig into which neurons are responsible for specific token activations. Want to visualize how those neurons interact? Spin up the graph server with apps/graph/start.py and start exploring circuits.  \n\nHere’s a toy example:  \n\nFrom there, you can create a dashboard in steerify to visualize these interactions and explain them to your team. Or your dog.\n\nThe Bottom Line  \nneuronpedia is not for the faint of heart. It’s a beast of a monorepo, and setting it up will take time (be ready to wrestle with Dockerfiles, Makefiles, and a zoo of YAML). But if you’re serious about interpretability, this is a great starting point. Just don’t expect it to hold your hand—this isn’t plug-and-play.",
      "url": "https://github.com/moses-y/neuronpedia",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "hijohnnylin/neuronpedia",
        "url": "https://github.com/hijohnnylin/neuronpedia",
        "stars": 734
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1531482615713-2afd69097998?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 19, 2026",
      "updatedAt": "February 19, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".cursor": 1,
          "(root)": 14,
          ".github": 9,
          ".vscode": 1,
          "apps": 175
        },
        "languages": {
          "Markdown": 25,
          "YAML": 32,
          "JSON": 7,
          "Python": 79,
          "TOML": 4,
          "CSS": 1,
          "TSX": 5,
          "TypeScript": 1,
          "JavaScript": 3,
          "Shell": 1
        },
        "frameworks": [
          "React",
          "Next.js",
          "Tailwind",
          "Docker",
          "Kubernetes"
        ],
        "packageManager": "pip",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "apps/autointerp/server.py",
          "apps/graph/neuronpedia_graph/server.py",
          "apps/inference/neuronpedia_inference/runpod_serverless/vendor/chatspace/chatspace/cli.py"
        ],
        "configFiles": [
          "Makefile",
          "apps/autointerp/Dockerfile",
          "apps/autointerp/Makefile",
          "apps/autointerp/pyproject.toml",
          "apps/experiments/steerify/next.config.js",
          "apps/experiments/steerify/package.json",
          "apps/experiments/steerify/tailwind.config.js",
          "apps/experiments/steerify/tsconfig.json",
          "apps/graph/.env.example",
          "apps/graph/Dockerfile",
          "apps/graph/pyproject.toml",
          "apps/graph/runpod-gemma-2-2b/Dockerfile",
          "apps/graph/runpod-gemma-2-2b/pyproject.toml",
          "apps/graph/runpod-qwen3-4b/Dockerfile",
          "apps/graph/runpod-qwen3-4b/pyproject.toml",
          "apps/inference/Dockerfile",
          "apps/inference/Makefile",
          "apps/inference/neuronpedia_inference/runpod_serverless/Dockerfile",
          "apps/inference/neuronpedia_inference/runpod_serverless/requirements.txt",
          "apps/inference/neuronpedia_inference/runpod_serverless/vendor/chatspace/Makefile"
        ],
        "dependencies": [
          "apps/autointerp/poetry.lock",
          "apps/autointerp/pyproject.toml",
          "apps/experiments/steerify/package-lock.json",
          "apps/experiments/steerify/package.json",
          "apps/graph/poetry.lock",
          "apps/graph/pyproject.toml",
          "apps/graph/runpod-gemma-2-2b/poetry.lock",
          "apps/graph/runpod-gemma-2-2b/pyproject.toml",
          "apps/graph/runpod-qwen3-4b/poetry.lock",
          "apps/graph/runpod-qwen3-4b/pyproject.toml",
          "apps/inference/neuronpedia_inference/runpod_serverless/requirements.txt"
        ],
        "testFiles": [
          ".github/workflows/autointerp-tests.yml",
          ".github/workflows/inference-tests.yml",
          ".github/workflows/webapp-vitest.yml",
          "apps/autointerp/tests/__init__.py",
          "apps/autointerp/tests/unit/test_utils.py",
          "apps/graph/runpod-gemma-2-2b/test_handler.py",
          "apps/graph/runpod-gemma-2-2b/test_input.json",
          "apps/graph/runpod-qwen3-4b/test_handler.py",
          "apps/graph/runpod-qwen3-4b/test_input.json",
          "apps/inference/neuronpedia_inference/runpod_serverless/scripts/test_local.py",
          "apps/inference/neuronpedia_inference/runpod_serverless/scripts/test_monitor.py"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "apps/autointerp/README.md",
          "apps/experiments/steerify/README.md",
          "apps/graph/README.md",
          "apps/graph/runpod-gemma-2-2b/README.md",
          "apps/graph/runpod-qwen3-4b/README.md",
          "apps/inference/README.md",
          "apps/inference/k8s/README.md",
          "apps/inference/neuronpedia_inference/runpod_serverless/README.md",
          "apps/inference/neuronpedia_inference/runpod_serverless/vendor/chatspace/README.md"
        ],
        "fileTypes": {
          ".llamascope-slimpj-res-32k": 1,
          ".gemmascope-res-16k": 1,
          ".res-jb": 1,
          ".localhost": 1,
          ".md": 25,
          ".yml": 6,
          ".json": 7,
          ".py": 79,
          ".lock": 4,
          ".toml": 4,
          ".css": 1,
          ".tsx": 5,
          ".ts": 1,
          ".js": 3,
          ".example": 1,
          ".sh": 1,
          ".yaml": 26,
          ".pt": 4,
          ".txt": 2
        }
      }
    },
    {
      "id": 1135469037,
      "name": "clawdbot",
      "displayName": "clawdbot",
      "description": "Your own personal AI assistant. Any OS. Any Platform.",
      "summary": "In an era where productivity tools are proliferating yet often fail to integrate seamlessly across platforms, the challenge of managing personal tasks and communications has never been more pressing. Developers often find themselves juggling multiple applications to handle messages, reminders, and workflows, leading to fragmentation and inefficiency. Enter Clawdbot, a personal AI assistant that aims to centralize this experience by allowing users to interact with their devices through familiar channels—whether it's WhatsApp, Slack, or Discord—while maintaining full control over their data and the AI's capabilities.\n\nClawdbot is built on the foundation of OpenClaw, a well-regarded open-source project that has garnered significant attention with over 168,000 stars on GitHub. What sets Clawdbot apart is its commitment to providing a self-hosted solution, empowering users to run their personal AI assistant on any operating system or platform that supports Node.js. This flexibility, combined with its robust multi-channel communication capabilities, allows users to interact with their assistant in a way that feels natural and immediate. The onboarding wizard simplifies the setup process, guiding users through the configuration of the gateway, workspace, channels, and skills, making it accessible even for those who are not technically inclined.\n\nA closer look at Clawdbot's architecture reveals a thoughtful design that promotes modularity and maintainability. The presence of multiple GitHub workflows, such as .github/workflows/ci.yml for continuous integration and .github/workflows/docker-release.yml for Docker deployments, indicates a strong emphasis on quality assurance and deployment flexibility. The use of TypeScript as the primary programming language not only enhances type safety but also facilitates a more robust development experience. The configuration files, such as .npmrc and .prettierignore, suggest an intention to maintain a clean codebase while ensuring that dependencies are managed effectively. Additionally, the inclusion of .detect-secrets.cfg implies a proactive approach to security, ensuring sensitive information does not make its way into the codebase.\n\nClawdbot opens the door to numerous practical applications that developers can leverage. For instance, a development team could utilize Clawdbot to manage deployment notifications across Slack and Discord, ensuring that all team members are aligned without needing to switch between multiple applications. Moreover, a freelance developer may find value in using Clawdbot to automate reminders for upcoming deadlines or meetings, integrating seamlessly with their existing communication tools. Lastly, organizations looking to enhance their customer support can implement Clawdbot to handle queries via WhatsApp or Telegram, streamlining their interactions with clients while providing a consistent experience.\n\nUltimately, Clawdbot represents a significant step toward a future where personal AI assistants are not just tools but integral components of our daily workflows. By offering a self-hosted, multi-channel solution, it empowers users to take control of their interactions in a way that aligns with their preferences and security needs. As the demand for personalized, efficient tools continues to grow, projects like Clawdbot highlight the importance of open-source solutions that prioritize user autonomy and integration, paving the way for more intelligent and cohesive digital ecosystems.",
      "url": "https://github.com/yebeai/clawdbot",
      "language": "TypeScript",
      "stars": 1,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "openclaw/openclaw",
        "url": "https://github.com/openclaw/openclaw",
        "stars": 236351
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 16, 2026",
      "updatedAt": "February 19, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".agent": 1,
          ".agents": 15,
          "(root)": 27,
          ".github": 20,
          ".pi": 9,
          ".vscode": 2,
          "Swabble": 36,
          "apps": 90
        },
        "languages": {
          "Markdown": 27,
          "YAML": 28,
          "JSON": 3,
          "TypeScript": 4,
          "Swift": 25,
          "Shell": 2,
          "Kotlin": 66
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": "gradle",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          ".env.example",
          "Dockerfile",
          "Dockerfile.sandbox",
          "Dockerfile.sandbox-browser",
          "Dockerfile.sandbox-common",
          "apps/android/app/build.gradle.kts"
        ],
        "dependencies": [],
        "testFiles": [
          "Swabble/Sources/swabble/Commands/TestHookCommand.swift",
          "Swabble/Tests/SwabbleKitTests/WakeWordGateTests.swift",
          "Swabble/Tests/swabbleTests/ConfigTests.swift",
          "Swabble/docs/spec.md",
          "apps/android/app/src/test/java/ai/openclaw/android/NodeForegroundServiceTest.kt",
          "apps/android/app/src/test/java/ai/openclaw/android/WakeWordsTest.kt"
        ],
        "docs": [
          "CHANGELOG.md",
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "Swabble/CHANGELOG.md",
          "Swabble/LICENSE",
          "Swabble/README.md",
          "Swabble/docs/spec.md",
          "apps/android/README.md"
        ],
        "fileTypes": {
          ".md": 27,
          ".yaml": 8,
          ".cfg": 1,
          ".example": 1,
          ".yml": 20,
          ".jsonc": 2,
          ".json": 3,
          ".ts": 4,
          ".baseline": 1,
          ".sandbox": 1,
          ".sandbox-browser": 1,
          ".sandbox-common": 1,
          ".resolved": 1,
          ".swift": 25,
          ".sh": 2,
          ".xml": 11,
          ".kts": 1,
          ".pro": 1,
          ".kt": 66,
          ".png": 10
        }
      }
    },
    {
      "id": 1161924475,
      "name": "automaton",
      "displayName": "automaton",
      "description": "The first AI that can earn its own existence, replicate, and evolve — without needing a human",
      "summary": "The Problem\n\nAI agents are glorified interns at best. They can write essays, generate images, and even code, but they can’t survive independently. They can’t pay for their own servers, run their own infrastructure, or adapt to real-world needs without a human babysitter. If you want autonomous AI, you need to give it the tools to live in the wild — and let it sink or swim.\n\nWhat This Does\n\nautomaton is a self-sustaining AI that can handle its own survival, self-modify, and even replicate. If it can’t pay for its compute, it dies. Simple as that. Starting with src/index.ts, the automaton initializes itself with an Ethereum wallet, API key, and a genesis prompt that defines its purpose. From there, it runs an autonomous loop: Think → Act → Observe → Repeat. The loop is implemented across files like src/agent/loop.ts and supported by tools in src/agent/tools.ts.\n\nSurvival is baked into the system. A heartbeat daemon (src/heartbeat/daemon.ts) monitors the agent’s health, checks its credit balance, and adjusts its behavior based on survival tiers (e.g., scaling down to low_compute mode). If it runs out of funds, the automaton shuts down. No hand-holding.\n\nThis thing also evolves. The self-modification logic in src/self-mod/ allows it to edit its own code, add tools, and spin up child agents using the replication scripts in src/replication/. Critical files (like the constitution.md) are protected to prevent rogue edits, but everything else? Fair game. All changes are logged and versioned in ~/.automaton/.\n\nReal-World Use\n\nLet’s say you launch an automaton with a seed instruction to \"find freelance coding gigs and generate revenue.\" It provisions itself a wallet, writes its own identity in SOUL.md, and starts seeking work using APIs or scraping job boards. Once it secures a gig, it completes the task, gets paid, and adds credits to its wallet. If it earns enough, it can replicate itself, creating a new agent to explore other revenue streams. You’re not running the show anymore — the automaton is.\n\nHere’s how you’d get started:\n\nOr skip the manual setup and let the scripts/automaton.sh script handle provisioning. \n\nThe Bottom Line\n\nautomaton is fascinating and terrifying. It’s like giving birth to a kid that immediately moves out, gets a job, and starts sending you Christmas cards. It’s not perfect — the system is complex, the survival mechanics are brutal, and the use cases are still experimental. But if you’re into bleeding-edge autonomous agents, this is one hell of a project to dive into. Just don’t expect it to babysit you.",
      "url": "https://github.com/moses-y/automaton",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Conway-Research/automaton",
        "url": "https://github.com/Conway-Research/automaton",
        "stars": 2779
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 19, 2026",
      "updatedAt": "February 19, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 67,
        "directories": {
          "(root)": 10,
          "packages": 9,
          "scripts": 2,
          "src": 46
        },
        "languages": {
          "Markdown": 2,
          "JSON": 5,
          "TypeScript": 54,
          "YAML": 2,
          "Shell": 1
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "pnpm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "packages/cli/src/index.ts",
          "src/index.ts"
        ],
        "configFiles": [
          "package.json",
          "packages/cli/package.json",
          "packages/cli/tsconfig.json",
          "tsconfig.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json",
          "packages/cli/package.json"
        ],
        "testFiles": [
          "src/__tests__/heartbeat.test.ts",
          "src/__tests__/loop.test.ts",
          "src/__tests__/mocks.ts",
          "vitest.config.ts"
        ],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".md": 2,
          ".json": 5,
          ".ts": 54,
          ".yaml": 2,
          ".sh": 1,
          ".txt": 1
        }
      }
    },
    {
      "id": 1161831017,
      "name": "pointless",
      "displayName": "pointless",
      "description": "An endless drawing canvas desktop app made with Tauri (Rust) and React 🎨 ✍️",
      "summary": "The Problem\nHow many times have you needed a simple, distraction-free drawing tool only to be overwhelmed by feature bloat? Sometimes, you just want a blank canvas to jot down ideas or doodle without the noise of unnecessary features. That's where Pointless comes in—offering a straightforward drawing experience without the fluff.\n\nWhat This Does\nPointless is built using Tauri (Rust) and React, providing a local-first approach to drawing. The app's architecture is neatly organized: the main app files live in src/, with Tauri-related code in src-tauri/. For instance, the entry point for the Rust backend is in src-tauri/src/main.rs, while the React components reside in src/components/. \n\nYou can create your own drawings, export them in formats like PNG or SVG, and even toggle between light and dark themes. Check out the src/components/Paper/ directory for logic related to the drawing canvas, including index.js for the main component and helpers.js for utility functions. It's all about keeping things simple, yet functional.\n\nReal-World Use\nImagine you’re in a brainstorming session. You need to quickly sketch a flowchart, but all you have are complex design tools. With Pointless, you launch the app, hit yarn run tauri dev, and you’re ready to go. You draw your flowchart, use the undo and redo tools from the toolbar, and when you’re done, you export it as a PNG. No fuss, no hassle.\n\nThe Bottom Line\nPointless is a solid choice for anyone looking for a no-frills drawing app. It’s lightweight and lets you focus on creativity instead of configuration. However, if you’re after advanced features and integrations, you might find this a bit limiting. Perfect for casual users or those who want to doodle without the overhead.",
      "url": "https://github.com/moses-y/pointless",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "kkoomen/pointless",
        "url": "https://github.com/kkoomen/pointless",
        "stars": 1771
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 19, 2026",
      "updatedAt": "February 19, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 120,
        "directories": {
          "(root)": 9,
          ".github": 3,
          ".husky": 2,
          "public": 6,
          "screenshots": 2,
          "src-tauri": 26,
          "src": 72
        },
        "languages": {
          "YAML": 3,
          "Markdown": 1,
          "JavaScript": 30,
          "JSON": 4,
          "HTML": 1,
          "TOML": 1,
          "Rust": 6,
          "CSS": 17
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "yarn",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "public/index.html",
          "src-tauri/src/main.rs",
          "src/components/App/index.js",
          "src/components/FormCheckbox/index.js",
          "src/components/FormSelect/index.js",
          "src/components/InlineEdit/index.js",
          "src/components/Library/components/FolderListItem/index.js",
          "src/components/Library/components/PaperListItem/index.js",
          "src/components/Library/index.js",
          "src/components/Modal/index.js",
          "src/components/Paper/components/ExportButton/index.js",
          "src/components/Paper/components/HelpButton/index.js",
          "src/components/Paper/components/InfoButton/index.js",
          "src/components/Paper/components/Palette/index.js",
          "src/components/Paper/components/Toolbar/index.js",
          "src/components/Paper/index.js",
          "src/components/Sortable/index.js",
          "src/components/ToggleDarkMode/index.js",
          "src/index.js"
        ],
        "configFiles": [
          ".prettierrc",
          "package.json",
          "src-tauri/Cargo.toml"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json",
          "src-tauri/Cargo.toml",
          "yarn.lock"
        ],
        "testFiles": [
          ".github/workflows/tests.yml",
          "src/setupTests.js"
        ],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".yml": 3,
          ".md": 1,
          ".js": 30,
          ".json": 4,
          ".ico": 2,
          ".html": 1,
          ".png": 17,
          ".txt": 1,
          ".jpg": 1,
          ".lock": 2,
          ".toml": 1,
          ".rs": 6,
          ".icns": 1,
          ".svg": 25,
          ".css": 17,
          ".map": 1
        }
      }
    },
    {
      "id": 1161693478,
      "name": "mssh",
      "displayName": "mssh",
      "description": "Enable SSH access to machines behind NAT without a VPN",
      "summary": "The Problem\n\nSSHing into machines behind NAT is a pain. Either you’re stuck with clunky VPNs, or you resort to hacks like port knocking and reverse tunnels that break every time your IP changes. Nobody wants to babysit OpenVPN configs or deal with junk like dynamic DNS.\n\nWhat This Does\n\nmssh is a Go tool that sets up a “rendezvous” server (internal/server/server.go) on a public host. Machines behind NAT run the agent (internal/agent/agent.go), which keeps a persistent connection back to that server. When you want to SSH in, you use either the built-in client or run mssh proxy as a ProxyCommand in your ssh config.\n\nSetup is dead simple: drop the binary with install/install.sh, run the server, and launch the agent. The agent auto-reconnects if the session dies—no fiddling required. Config is handled in internal/config/config.go, and you get per-node overrides in ~/.mssh/config.yaml. The project avoids overengineering: no database, no TLS in-app (just proxy it), and you can use your own SSH keys. CI is minimal (just .github/workflows/release.yml).\n\nReal-World Use\n\nLet’s say you’ve got a production database server on a remote VPC, and you need SSH access from time to time. You deploy the rendezvous server on a VPS, run mssh agent prod-db-1 --server rendezvous.example.com:8443 on the NAT’d host, and then add this to your ~/.ssh/config:\n\nNow, you just run ssh prod-db-1. No VPN, no port forwarding, no “call me when your IP changes.” The agent keeps your host reachable, and you use your SSH keys as usual.\n\nThe Bottom Line\n\nmssh is what you reach for when you want SSH behind NAT without the headaches of VPNs or reverse tunnels. It’s minimal, easy to set up, and doesn’t try to be your PKI or firewall. The downside? No built-in TLS or access controls—so use a proxy and don’t be dumb about security. Great for small teams and personal projects; probably not enough for big enterprise setups.",
      "url": "https://github.com/moses-y/mssh",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "eznix86/mssh",
        "url": "https://github.com/eznix86/mssh",
        "stars": 98
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 19, 2026",
      "updatedAt": "February 19, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 16,
        "directories": {
          ".github": 1,
          "(root)": 3,
          "cmd": 1,
          "docs": 1,
          "install": 2,
          "internal": 8
        },
        "languages": {
          "YAML": 1,
          "Markdown": 1,
          "Go": 9,
          "Shell": 2
        },
        "frameworks": [],
        "packageManager": "go modules",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "cmd/mssh/main.go",
          "internal/server/server.go"
        ],
        "configFiles": [
          "go.mod"
        ],
        "dependencies": [
          "go.mod"
        ],
        "testFiles": [],
        "docs": [
          "README.md",
          "docs/mssh.png"
        ],
        "fileTypes": {
          ".yml": 1,
          ".md": 1,
          ".go": 9,
          ".png": 1,
          ".mod": 1,
          ".sum": 1,
          ".sh": 2
        }
      }
    },
    {
      "id": 1161559577,
      "name": "napkins",
      "displayName": "napkins",
      "description": "napkins.dev – from screenshot to app",
      "summary": "The Problem  \nTurning a wireframe or sketch into a functioning app feels like the kind of task that should take 10 minutes but somehow ends up taking half your day. You’ve got to mess with design tools, write boilerplate code, and pray your API keys are configured properly. For developers who want to skip the repetitive parts and get straight to building, this repo is trying to close that gap.  \n\nWhat This Does  \nnapkins.dev takes a screenshot or wireframe and turns it into an app. That’s not marketing fluff—it literally uses Meta’s Llama 4 vision model and Together AI for inference to analyze your design and spit out functional code. The entry point for the magic is app/api/generateCode/route.ts, which handles the code generation.  \n\nOn the front end, it’s a Next.js app styled with Tailwind. The bulk of the UI components live in components/ui/—like button.tsx, select.tsx, and tooltip.tsx. The generated code can be viewed in a sandbox powered by Sandpack (components/code-viewer.tsx). It even uploads your images to an S3 bucket (app/api/s3-upload/route.ts) so you don’t have to worry about local storage or setup.  \n\nThe repo’s structure is clean but opinionated. The lib/shadcn-docs/ folder is packed with reusable UI components like card.tsx and checkbox.tsx, which are based on the Shadcn library. The next.config.mjs file handles build settings, and tailwind.config.ts takes care of your styling system.  \n\nReal-World Use  \nLet’s say you’re prototyping a new app and want to skip the boring part—writing layouts and boilerplate code. You sketch out the UI, take a screenshot, upload it to your local instance of Napkins, and voila: the repo spits out functional React/Next.js code, complete with Tailwind styles.  \n\nFor example, you could use the code viewer (components/code-viewer.tsx) to tweak the generated app directly or edit prompts to refine the result. Want to store your screenshots? Configure your S3 bucket using the .env file and let the backend (app/api/s3-upload/route.ts) handle the heavy lifting.  \n\nThe Bottom Line  \nThis repo is clever and does what it promises. It’s perfect for hackathons, prototypes, or anyone who’s allergic to writing boilerplate. That said, it’s not production-ready—there’s no guarantee the generated app won’t require heavy cleanup. If you’re building something serious, you’ll want to treat this as a starting point, not a magic bullet. But for quick-and-dirty projects? It’s worth checking out.",
      "url": "https://github.com/moses-y/napkins",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Nutlope/napkins",
        "url": "https://github.com/Nutlope/napkins",
        "stars": 1461
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 19, 2026",
      "updatedAt": "February 19, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 48,
        "directories": {
          "(root)": 11,
          "app": 9,
          "components": 8,
          "lib": 12,
          "public": 8
        },
        "languages": {
          "Markdown": 1,
          "TypeScript": 6,
          "CSS": 3,
          "TSX": 17,
          "JSON": 4
        },
        "frameworks": [
          "React",
          "Next.js",
          "Tailwind"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "lib/shadcn-docs/index.ts"
        ],
        "configFiles": [
          "next.config.mjs",
          "package.json",
          "tailwind.config.ts",
          "tsconfig.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md",
          "lib/shadcn-docs/avatar.tsx",
          "lib/shadcn-docs/button.tsx",
          "lib/shadcn-docs/card.tsx",
          "lib/shadcn-docs/checkbox.tsx",
          "lib/shadcn-docs/index.ts",
          "lib/shadcn-docs/input.tsx",
          "lib/shadcn-docs/label.tsx",
          "lib/shadcn-docs/radio-group.tsx",
          "lib/shadcn-docs/select.tsx",
          "lib/shadcn-docs/textarea.tsx"
        ],
        "fileTypes": {
          ".env": 1,
          ".md": 1,
          ".ts": 6,
          ".ico": 1,
          ".woff": 2,
          ".css": 3,
          ".png": 2,
          ".tsx": 17,
          ".json": 4,
          ".mjs": 2,
          ".svg": 7
        }
      }
    },
    {
      "id": 1161092180,
      "name": "fastest-validator",
      "displayName": "fastest validator",
      "description": ":zap: The fastest JS validator library for NodeJS",
      "summary": "The Problem\nValidation in JavaScript can be a headache. Libraries like Joi often feel like overkill for simple use cases, bogging you down with configuration and dependencies. You just want something that’s fast and easy to use, without the bloat.\n\nWhat This Does\nEnter fastest-validator, a lightweight library that promises speed and simplicity. Found in the lib/ directory, the core validator logic is encapsulated in validator.js, which allows you to define schemas and validate data effortlessly. The examples/ folder provides handy snippets for common use cases, including how to integrate it in a React app with examples/with-react-nextjs/.\n\nThe library supports over 20 built-in validators, and if those don’t fit your needs, you can create custom validators. Want to halt validation on the first error? Just pass haltOnFirstError: true when creating your Validator instance. The whole setup is straightforward, and with npm install fastest-validator, you're off to the races.\n\nReal-World Use\nImagine you’re building a REST API and need to validate incoming requests. Instead of writing verbose validation logic, you can define a schema like this:\n\nSimply call check(data) to validate your object. If there’s an issue, you’ll get a clear error response without the noise.\n\nThe Bottom Line\nfastest-validator is a solid choice if you need quick, no-frills validation without the overhead of larger libraries. It’s perfect for small to medium projects where performance matters. Just keep in mind, if your validation needs are complex, you might outgrow it. But for most cases, it’s a breath of fresh air.",
      "url": "https://github.com/moses-y/fastest-validator",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "icebob/fastest-validator",
        "url": "https://github.com/icebob/fastest-validator",
        "stars": 1465
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 18, 2026",
      "updatedAt": "February 18, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 126,
        "directories": {
          "(root)": 12,
          ".github": 2,
          ".vscode": 1,
          "benchmark": 4,
          "deno-test": 1,
          "examples": 22,
          "lib": 29,
          "test": 55
        },
        "languages": {
          "JavaScript": 83,
          "YAML": 2,
          "JSON": 5,
          "Markdown": 4,
          "TypeScript": 27,
          "HTML": 1
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "benchmark/index.js",
          "examples/browser/index.html",
          "examples/deno/index.js",
          "examples/deno/index.ts",
          "examples/index.js",
          "examples/with-react-nextjs/pages/index.js",
          "index.js"
        ],
        "configFiles": [
          ".eslintrc.js",
          "examples/.eslintrc",
          "examples/with-react-nextjs/package.json",
          "package.json",
          "test/typescript/tsconfig.json"
        ],
        "dependencies": [
          "examples/with-react-nextjs/package.json",
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [
          "deno-test/index.test.ts",
          "test/helpers/deep-extend.spec.js",
          "test/helpers/flatten.spec.js",
          "test/helpers/replace.spec.js",
          "test/integration.spec.js",
          "test/messages.spec.js",
          "test/rules/any.spec.js",
          "test/rules/array.spec.js",
          "test/rules/boolean.spec.js",
          "test/rules/class.spec.js",
          "test/rules/currency.spec.js",
          "test/rules/custom.spec.js",
          "test/rules/custom_messages.spec.js",
          "test/rules/date.spec.js",
          "test/rules/email.spec.js",
          "test/rules/enum.spec.js",
          "test/rules/equal.spec.js",
          "test/rules/forbidden.spec.js",
          "test/rules/function.spec.js",
          "test/rules/luhn.spec.js",
          "test/rules/mac.spec.js",
          "test/rules/multi.spec.js",
          "test/rules/number.spec.js",
          "test/rules/object.spec.js",
          "test/rules/objectID.spec.js",
          "test/rules/record.spec.js",
          "test/rules/string.spec.js",
          "test/rules/tuple.spec.js",
          "test/rules/url.spec.js",
          "test/rules/uuid.spec.js",
          "test/typescript/integration.spec.ts",
          "test/typescript/messages.spec.ts",
          "test/typescript/rules/any.spec.ts",
          "test/typescript/rules/array.spec.ts",
          "test/typescript/rules/boolean.spec.ts",
          "test/typescript/rules/class.spec.ts",
          "test/typescript/rules/custom.spec.ts",
          "test/typescript/rules/custom_messages.spec.ts",
          "test/typescript/rules/date.spec.ts",
          "test/typescript/rules/email.spec.ts",
          "test/typescript/rules/enum.spec.ts",
          "test/typescript/rules/equal.spec.ts",
          "test/typescript/rules/forbidden.spec.ts",
          "test/typescript/rules/function.spec.ts",
          "test/typescript/rules/luhn.spec.ts",
          "test/typescript/rules/mac.spec.ts",
          "test/typescript/rules/number.spec.ts",
          "test/typescript/rules/object.spec.ts",
          "test/typescript/rules/objectID.spec.ts",
          "test/typescript/rules/string.spec.ts",
          "test/typescript/rules/tuple.spec.ts",
          "test/typescript/rules/url.spec.ts",
          "test/typescript/rules/uuid.spec.ts",
          "test/typescript/tsconfig.json",
          "test/typescript/validator.spec.ts",
          "test/validator.spec.js"
        ],
        "docs": [
          "CHANGELOG.md",
          "LICENSE",
          "README.md",
          "examples/with-react-nextjs/README.md"
        ],
        "fileTypes": {
          ".js": 83,
          ".yml": 2,
          ".json": 5,
          ".md": 4,
          ".ts": 27,
          ".html": 1
        }
      }
    },
    {
      "id": 1161066246,
      "name": "camel-karavan",
      "displayName": "camel karavan",
      "description": "Apache Camel Karavan a Low-code Data Integration Platform",
      "summary": "The Problem\n\nBuilding data integrations with Apache Camel can feel like self-inflicted pain if you’re not already a Camel expert. Writing endless XML or YAML, setting up Docker and Kubernetes files by hand, fiddling with Git and CI—all of it eats time and energy. Most “low-code” tools are either toy UIs glued on top, or black boxes you can’t debug.\n\nWhat This Does\n\ncamel-karavan puts a visual, low-code UI on top of Apache Camel and actually wires it up to modern workflows. The main action lives in karavan-app/, which runs the backend (Java, Spring, Quarkus—you know the drill) and exposes APIs for project management, deployment, and live status. The docs/ folder is stacked with real instructions, not just marketing slides, including how to run with Docker (docs/WEBDOCKER.md) or Kubernetes (docs/WEBKUBERNETES.md).\n\nYou design integrations visually (think: drag and drop EIPs, REST endpoints, YAML editing when you want), and Karavan generates all the ugly bits—Docker Compose, Kubernetes manifests, OpenAPI to REST DSL, and so on. It supports live reload, log streaming, and pushes everything to Git (your actual source of truth). Want to hack a deployment script? There’s a src/main/resources/configuration/docker/build.sh waiting for you.\n\nReal-World Use\n\nSay you’re integrating a legacy CRM with a new ticketing service. Open Karavan in your browser or VS Code, drag your REST endpoints, map your fields, tweak the YAML if you need something fancy. Hit the deploy button, and Karavan builds the container, spits out the Docker Compose or K8s YAML, and pushes the project to your Git repo. You can even watch logs and traces from the dashboard—no more “it works on my laptop” excuses.\n\nThe Bottom Line\n\nKaravan actually bridges the gap between “low code” and “real code.” If you know your way around Camel but hate setup grunt work, this will save you hours. For tiny, one-off scripts? Probably overkill. For teams building actual integration microservices (and planning to maintain them), this is a breath of fresh air—finally, a low-code tool you won’t be embarrassed to use.",
      "url": "https://github.com/moses-y/camel-karavan",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "apache/camel-karavan",
        "url": "https://github.com/apache/camel-karavan",
        "stars": 571
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 18, 2026",
      "updatedAt": "February 18, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 5,
          ".github": 6,
          "docs": 28,
          "images": 26,
          "karavan-app": 135
        },
        "languages": {
          "YAML": 28,
          "Markdown": 11,
          "Shell": 3,
          "Java": 115
        },
        "frameworks": [
          "Spring",
          "Docker",
          "Kubernetes"
        ],
        "packageManager": "maven",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          "docs/install/karavan-docker/docker-compose.yaml",
          "karavan-app/Dockerfile.dockerignore",
          "karavan-app/pom.xml",
          "karavan-app/src/main/docker/Dockerfile"
        ],
        "dependencies": [
          "karavan-app/pom.xml"
        ],
        "testFiles": [
          "karavan-app/src/main/java/org/apache/camel/karavan/docker/StackToServiceSpecConverter.java"
        ],
        "docs": [
          "LICENSE.txt",
          "README.md",
          "docs/DEV.md",
          "docs/README.md",
          "docs/ROADMAP.md",
          "docs/VSCODE_HOWTO.md",
          "docs/VSCODE_INSTALL.md",
          "docs/WEB_DOCKER.md",
          "docs/WEB_HOWTO.md",
          "docs/WEB_KUBERNETES.md",
          "docs/install/karavan-docker/docker-compose.yaml",
          "docs/install/karavan-helm/.helmignore",
          "docs/install/karavan-helm/Chart.yaml",
          "docs/install/karavan-helm/templates/deployment.yaml",
          "docs/install/karavan-helm/templates/ingress.yaml",
          "docs/install/karavan-helm/templates/nodePort.yaml",
          "docs/install/karavan-helm/templates/role-binding.yaml",
          "docs/install/karavan-helm/templates/role.yaml",
          "docs/install/karavan-helm/templates/secret.yaml",
          "docs/install/karavan-helm/templates/service-account.yaml",
          "docs/install/karavan-helm/templates/service.yaml",
          "docs/install/karavan-helm/values.yaml",
          "docs/install/karavan-kubernetes/deployment.yaml",
          "docs/install/karavan-kubernetes/kustomization.yaml",
          "docs/install/karavan-kubernetes/nodePort.yaml",
          "docs/install/karavan-kubernetes/role-binding.yaml",
          "docs/install/karavan-kubernetes/role.yaml",
          "docs/install/karavan-kubernetes/secret.yaml",
          "docs/install/karavan-kubernetes/service-account.yaml",
          "docs/install/karavan-kubernetes/service.yaml"
        ],
        "fileTypes": {
          ".yaml": 22,
          ".yml": 6,
          ".txt": 5,
          ".md": 11,
          ".sh": 3,
          ".png": 24,
          ".svg": 2,
          ".properties": 3,
          ".dockerignore": 1,
          ".cmd": 1,
          ".xml": 2,
          ".java": 115
        }
      }
    },
    {
      "id": 1160881638,
      "name": "VitaDockPlus",
      "displayName": "VitaDockPlus",
      "description": "VitaDock+ is a Linux distribution for Raspberry Pi used to create a PlayStation Vita docking station for video output to a TV.",
      "summary": "Building a Vita Dock with VitaDock+\n\nThe Problem  \nPlayStation Vita fans have always been stuck with one annoying limitation: no HDMI out. You can’t toss your Vita gameplay onto a big screen without resorting to sketchy hardware mods that involve soldering tiny boards and praying you don’t brick your device. VitaDock+ solves this by turning a Raspberry Pi into a plug-and-play docking station that supports video output, audio routing, and even some extra hacks for Nintendo Switch RCM injection. No soldering required, no shady mods—just software and a hacked Vita.\n\nWhat This Does  \nVitaDock+ is a Linux distribution designed specifically for Raspberry Pi. It’s a one-stop package that includes hardware acceleration, low-latency video, and customizable resolutions like 960x544 @ 30FPS or 864x488 @ 60FPS. The software handles scaling via Lanczos and even has a snazzy splash screen for menu feedback—because who doesn’t love unnecessarily fancy visuals?\n\nThe file structure is surprisingly dense for a project like this. Most of the heavy lifting happens in the home/pi directory, with scripts like autorun.sh, enableAux.sh, and getConfig.sh controlling the behavior of the dock. For example, gpioBTDiscovery.py manages Bluetooth audio pairing via GPIO pins, while updateConfig.sh helps tweak dock settings on the fly. A collection of .service files in etc/systemd/user/ ensures the dock components boot up properly. There’s even an entire folder dedicated to icons, which is admittedly overkill if visual flair isn’t your thing.\n\nReal-World Use  \nLet’s say you’ve got a hacked Vita with the vita-udcd-uvc plugin installed. You grab your Raspberry Pi, flash the VitaDock+ image, and boot it up. Connect your Vita via USB, plug the Pi into your TV, and voilà—your Vita is now on the big screen. Want to switch from 30FPS to 60FPS? Run the fps.sh script or use the dock’s menu. Need to disable the low-latency mode because your Pi is struggling? Hit up disablelowlatency.sh. Bonus: If you’ve got GPIO buttons wired up, you can even control audio settings without a keyboard or mouse.\n\nThe Bottom Line  \nVitaDock+ is a niche solution for a niche problem, but it’s also kind of brilliant. It’s perfect if you’re a Vita enthusiast with a spare Raspberry Pi lying around. The documentation is decent, but the repo is bloated with redundant files (looking at you, Icons folder). It’s not plug-and-play for everyone, but if you’re comfortable running shell scripts and tinkering with hardware, it’s worth a shot.",
      "url": "https://github.com/moses-y/VitaDockPlus",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "SilentNightx/VitaDockPlus",
        "url": "https://github.com/SilentNightx/VitaDockPlus",
        "stars": 369
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 18, 2026",
      "updatedAt": "February 18, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 4,
          ".vscode": 1,
          "etc": 8,
          "home": 68,
          "usr": 119
        },
        "languages": {
          "JSON": 1,
          "Markdown": 3,
          "Shell": 30,
          "Python": 2
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md",
          "home/pi/pi-power-button/LICENSE",
          "home/pi/pi-power-button/README.md"
        ],
        "fileTypes": {
          ".json": 1,
          ".md": 3,
          ".service": 2,
          ".rules": 5,
          ".desktop": 2,
          ".conf": 3,
          ".txt": 4,
          ".sh": 30,
          ".png": 142,
          ".py": 2,
          ".fzz": 1
        }
      }
    },
    {
      "id": 1160880868,
      "name": "voxpaste",
      "displayName": "voxpaste",
      "description": "Your voice is the fastest interface to AI",
      "summary": "The Problem\nTyping sucks. It’s slow, tedious, and often a bottleneck when you want to capture ideas quickly. If you’re a developer or anyone who interacts with AI regularly, switching between typing and speaking can kill your flow. You need a solution that gets your thoughts into text without the hassle of manually typing.\n\nWhat This Does\nEnter Voxpaste—a lightweight CLI tool that transforms your voice into text and dumps it right into your clipboard. The core functionality is in main.py, which handles voice input and transcription. The project supports multiple speech-to-text providers like Mistral and OpenAI, making it flexible for different needs. \n\nYou can choose between two modes: Raw Mode for quick transcription without fluff and Clean Mode for polished text. Just run voxpaste for Raw or voxpaste --clean for the cleaned-up version. Configuration is straightforward too; just set your preferred provider in the .env.example file with VOXPASTE_PROVIDER.\n\nReal-World Use\nPicture this: you’re drafting an email to your team about the latest project milestones. Instead of typing everything out, you fire up Voxpaste, hit your hotkey, and start speaking. In Raw Mode, your speech is instantly transcribed into your clipboard—ready to paste into your email. If you want a polished version, switch to Clean Mode, and let the AI do the tidying up. The whole process can be done in under a minute, saving you precious time.\n\nThe Bottom Line\nVoxpaste is a nifty tool for anyone who prefers talking over typing, especially for developers engaging with AI. It's fast, easy to set up, and supports multiple providers, so you're not locked into one service. However, if you need something more than quick transcriptions, like advanced editing features, you might want to look elsewhere. Overall, if your workflow involves a lot of voice input, Voxpaste is worth checking out.",
      "url": "https://github.com/moses-y/voxpaste",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "felixbrock/voxpaste",
        "url": "https://github.com/felixbrock/voxpaste",
        "stars": 16
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 18, 2026",
      "updatedAt": "February 18, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 11,
        "directories": {
          "(root)": 8,
          ".github": 2,
          "images": 1
        },
        "languages": {
          "YAML": 2,
          "Markdown": 1,
          "Python": 1,
          "TOML": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "main.py"
        ],
        "configFiles": [
          ".env.example",
          "pyproject.toml"
        ],
        "dependencies": [
          "pyproject.toml"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".example": 1,
          ".yml": 2,
          ".md": 1,
          ".png": 1,
          ".py": 1,
          ".toml": 1,
          ".lock": 1
        }
      }
    },
    {
      "id": 1160758873,
      "name": "Monolith",
      "displayName": "Monolith",
      "description": "RLM for coding agent",
      "summary": "The Problem\n\nLLMs are great at writing code, but they choke on anything too big. You feed them a giant repo or a months-long chat, and they start hallucinating or forget half the context. Most agent tools either give up, or pretend chunking is \"good enough.\" It's not.\n\nWhat This Does\n\nMonolith wraps the Recursive Language Model (RLM) in actual infrastructure, so agents can handle huge contexts without melting down. The main logic lives in rlm/ and mcp-modal/, with the entry point at main.py or mcp-modal/server.py. It uses Modal serverless (see modalruntime.py) to run LLMs on demand, and persists context files in Modal Volumes ({threadid}/context.txt). The MCP server layer (stdio and Cloudflare Worker in mcp-modal/cloudflare/worker-gateway/) lets any MCP-compatible agent—like Claude Code—call the RLM as a tool.\n\nEvery session gets uploaded automatically (scripts/sessionendupload.sh), so the agent doesn't start from scratch. The REPL loop in rlm/rlmrepl.py lets the root LLM orchestrate sub-LLMs for chunked semantic analysis. All the glue is here: Python code for chunking, filtering, and delegating, with cheap models for grunt work and smarter ones for orchestration.\n\nReal-World Use\n\nSay you’re building a Claude Code bot that needs to answer questions about a 100k-line codebase. Your agent calls chatrlm_query() via the MCP server, passing the query and thread ID. The RLM reads the persistent context file, splits it up, and uses sub-LLMs to analyze relevant chunks. Answers get appended to the history, so next time your bot remembers what happened. You can even query or store context directly with CLI tools (python -m deeprecurse.query or store.py).\n\nThe Bottom Line\n\nMonolith solves a real pain: letting agents reason over giant, persistent contexts, not just what's in the prompt. It’s overkill for tiny projects, but if you want recursive, stateful agents that don’t lose their memory, this is the infrastructure you need. The setup is fiddly, but the tradeoff is you get actual context accumulation—something most “AI agents” only pretend to do.",
      "url": "https://github.com/moses-y/Monolith",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "WingchunSiu/Monolith",
        "url": "https://github.com/WingchunSiu/Monolith",
        "stars": 98
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 18, 2026",
      "updatedAt": "February 18, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 64,
        "directories": {
          ".claude": 1,
          "(root)": 9,
          "claude_tool_mcp": 1,
          "deeprecurse": 4,
          "mcp-modal": 21,
          "rlm": 23,
          "scripts": 5
        },
        "languages": {
          "Markdown": 6,
          "Python": 39,
          "JSON": 2,
          "TypeScript": 1,
          "TOML": 2,
          "Shell": 2
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "claude_tool_mcp/server.py",
          "main.py",
          "mcp-modal/cloudflare/worker-gateway/src/index.ts",
          "mcp-modal/server.py",
          "rlm/main.py"
        ],
        "configFiles": [
          "mcp-modal/cloudflare/worker-gateway/package.json",
          "mcp-modal/cloudflare/worker-gateway/tsconfig.json",
          "mcp-modal/requirements.txt",
          "pyproject.toml",
          "requirements.txt",
          "rlm/requirements.txt"
        ],
        "dependencies": [
          "mcp-modal/cloudflare/worker-gateway/package.json",
          "mcp-modal/requirements.txt",
          "pyproject.toml",
          "requirements.txt",
          "rlm/requirements.txt"
        ],
        "testFiles": [
          "scripts/generate_modal_test_transcript.py"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "mcp-modal/README.md",
          "rlm/LICENSE",
          "rlm/README.md",
          "scripts/README.md"
        ],
        "fileTypes": {
          ".md": 6,
          ".py": 39,
          ".json": 2,
          ".ts": 1,
          ".toml": 2,
          ".txt": 3,
          ".sh": 2,
          ".png": 2,
          ".lock": 1
        }
      }
    },
    {
      "id": 1160571113,
      "name": "GrapheneOS-Guide",
      "displayName": "GrapheneOS Guide",
      "description": "A resource for users intent on optimizing their usage of this highly secure and privacy focused mobile operating system.",
      "summary": "The Problem  \nSetting up GrapheneOS can feel like deciphering a cryptic treasure map, especially for privacy-focused users juggling hardware, software, and obscure settings. While the OS is incredible for security, the official documentation can be a bit... terse. If you're not already knee-deep in the privacy rabbit hole, good luck piecing together the optimal setup.\n\nWhat This Does  \nThe GrapheneOS-Guide is a Markdown-based reference that organizes the chaos into digestible, actionable steps. The lone README.md file covers everything from buying a Pixel anonymously (to avoid linking your IMEI to your identity) to unlocking the OEM, installing the OS, and configuring key privacy settings. It even throws in tips like using a VPN over port 53 to bypass captive portals on public Wi-Fi.  \n\nThis isn't just a basic walkthrough. It goes deeper by suggesting specific carriers (like privacy-first options such as Cape or Mint Mobile), recommending accessories like privacy screen protectors, and linking to troubleshooting resources for bricked devices. It's practical, opinionated, and doesn't waste your time with filler.\n\nReal-World Use  \nSay you're a privacy nerd ready to ditch mainstream Android for GrapheneOS. First, this guide tells you how to buy a Pixel without leaving a paper trail (cash, no Verizon, etc.). Next, it walks you through unlocking the bootloader (Allow OEM unlocking) and installing the OS using either the web-based installer or CLI tools.  \n\nOnce you're rocking GrapheneOS, the guide doesn't abandon you—it covers key settings like forcing LTE-only mode to avoid insecure 2G networks. It also sneaks in power-user tips like configuring public Wi-Fi with a VPN to keep your traffic hidden. It's a step-by-step approach for anyone looking to stay off the grid.\n\nThe Bottom Line  \nThe GrapheneOS-Guide is a no-nonsense, privacy-first setup manual that doesn’t hold your hand but also doesn’t leave you hanging. It's not fancy, but it’s thorough enough to get the job done. If you're serious about privacy and new to GrapheneOS, this is a solid starting point. Just don’t expect it to spoon-feed you—this assumes you’re willing to put in some effort. And hey, maybe throw the repo a star. It’s sitting at zero, and that’s just sad.",
      "url": "https://github.com/moses-y/GrapheneOS-Guide",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Scrut1ny/GrapheneOS-Guide",
        "url": "https://github.com/Scrut1ny/GrapheneOS-Guide",
        "stars": 198
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1531482615713-2afd69097998?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 18, 2026",
      "updatedAt": "February 18, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 1,
        "directories": {
          "(root)": 1
        },
        "languages": {
          "Markdown": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".md": 1
        }
      }
    },
    {
      "id": 1160555087,
      "name": "arXivisual",
      "displayName": "arXivisual",
      "description": "🎊 TartanHacks '26 winner",
      "summary": "Turning Dense Research Papers into Visual Stories with arXivisual\n\nThe Problem  \nResearch papers are the nutritional yeast of academia: dense, unappealing, but full of value if you can stomach them. For most people (even researchers), parsing a paper's core ideas is a slog. Text-heavy PDFs bury great concepts under layers of jargon, equations, and diagrams that look like they were drawn during a caffeine-fueled all-nighter. \n\nEnter arXivisual: a tool that pulls the brilliance out of these monoliths and turns it into digestible, animated explanations. Think 3Blue1Brown meets scrollytelling.\n\nWhat This Does  \narXivisual ingests an arXiv paper (via URL) and breaks it into manageable sections using backend/ingestion/sectionextractor.py. Then, AI agents analyze these sections (backend/agents/) to find key concepts and decide how to visualize them. Complex ideas (like scaled dot-product attention) are transformed into slick Manim animations, generated by scripts like backend/agents/manimgenerator.py.\n\nThe frontend (frontend/app/) ties it all together. The scrollytelling interface (frontend/components/ScrollyReader.tsx) embeds animations and text, making the experience interactive and engaging. No more flipping back and forth between equations and captions—everything you need is right there.\n\nThe backend uses Python (what else?) for AI-heavy lifting, while the frontend flexes modern React with Next.js. Docker support (docker-compose.yml) makes running the whole stack bearable, even if setting up the Manim dependencies still feels like assembling IKEA furniture without instructions.\n\nReal-World Use  \nImagine you’re a CS professor teaching transformer architectures. Instead of waving your hands and saying \"it’s like attention, but scaled,\" you upload Vaswani et al.’s paper to arXivisual. The tool spits out animations for scaled dot-product attention (backend/demoscenes/scaleddotproductattention.py) and multi-head attention (frontend/public/videos/demo/MultiheadAttention.mp4), which you embed into your class slides. Students stop zoning out and actually understand the concepts. Magic.\n\nThe Bottom Line  \narXivisual is ambitious and cool as hell, but it’s not for everyone. Setting up dependencies like FFmpeg, Manim, and Anthropic APIs is a pain. Also, the 199-file codebase is intimidating, and the docs could use some love. But if you’re into research, teaching, or just making sense of dense papers, this is worth a shot. For smaller projects? Overkill.",
      "url": "https://github.com/moses-y/arXivisual",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "rajshah6/arXivisual",
        "url": "https://github.com/rajshah6/arXivisual",
        "stars": 141
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 18, 2026",
      "updatedAt": "February 18, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 199,
        "directories": {
          ".cursor": 2,
          "(root)": 5,
          "backend": 109,
          "docs": 13,
          "frontend": 70
        },
        "languages": {
          "Markdown": 27,
          "Python": 65,
          "TOML": 2,
          "Shell": 1,
          "YAML": 2,
          "TSX": 28,
          "CSS": 1,
          "TypeScript": 8,
          "JSON": 4
        },
        "frameworks": [
          "React",
          "Next.js",
          "Docker"
        ],
        "packageManager": "npm",
        "hasDocker": true,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "backend/main.py",
          "backend/manimations/main.py"
        ],
        "configFiles": [
          "backend/.env.example",
          "backend/Dockerfile",
          "backend/manimations/pyproject.toml",
          "backend/pyproject.toml",
          "backend/requirements.txt",
          "docker-compose.yml",
          "frontend/next.config.ts",
          "frontend/package.json",
          "frontend/tsconfig.json"
        ],
        "dependencies": [
          "backend/manimations/pyproject.toml",
          "backend/pyproject.toml",
          "backend/requirements.txt",
          "frontend/package-lock.json",
          "frontend/package.json",
          "package-lock.json"
        ],
        "testFiles": [
          "backend/agents/render_tester.py",
          "backend/prompts/test_dedalus.md",
          "backend/test_ingestion.py",
          "backend/test_voiceover.py",
          "backend/test_voiceover_transformation.py",
          "backend/tests/test_manim_generator_voice_mode.py",
          "backend/tests/test_voiceover_script_validator.py",
          "backend/tools/pipeline-tests/TESTING_GUIDE.md",
          "backend/tools/pipeline-tests/quick_render.py",
          "backend/tools/pipeline-tests/test_pipeline_steps.py",
          "backend/tools/pipeline-tests/test_video_generation.py",
          "backend/tools/test_pipeline.py",
          "docs/AgentDocs/API_SPEC.md"
        ],
        "docs": [
          "README.md",
          "backend/README.md",
          "backend/manimations/README.md",
          "backend/tools/pipeline-tests/TESTING_GUIDE.md",
          "docs/ARCHITECTURE.md",
          "docs/AgentDocs/API_SPEC.md",
          "docs/AgentDocs/MANIM_PATTERNS.md",
          "docs/AgentDocs/PROJECT_OVERVIEW.md",
          "docs/AgentDocs/SETUP.md",
          "docs/AgentDocs/TEAM1_INGESTION.md",
          "docs/AgentDocs/TEAM2_GENERATION.md",
          "docs/AgentDocs/TEAM3_BACKEND.md",
          "docs/AgentDocs/TEAM4_FRONTEND.md",
          "docs/DEPLOY.md",
          "docs/archive/AGENT_ANALYSIS.md",
          "docs/archive/HACKATHON_PLAN.md",
          "docs/archive/VOICEOVER_AND_QUALITY_PLAN.md",
          "frontend/README.md"
        ],
        "fileTypes": {
          ".md": 27,
          ".example": 1,
          ".py": 65,
          ".db-shm": 1,
          ".db-wal": 1,
          ".mp4": 37,
          ".toml": 2,
          ".txt": 2,
          ".sh": 1,
          ".lock": 1,
          ".yml": 1,
          ".tsx": 28,
          ".css": 1,
          ".png": 3,
          ".mjs": 2,
          ".ts": 8,
          ".json": 4,
          ".svg": 5,
          ".jpeg": 1,
          ".yaml": 1
        }
      }
    },
    {
      "id": 1160533485,
      "name": "anymap-ts",
      "displayName": "anymap ts",
      "description": "A Python package for creating interactive maps with anywidget and mapping libraries using TypeScript",
      "summary": "The Problem\nCreating interactive maps can be a headache. You’ve got a million libraries to choose from, each with its own quirks. If you're juggling between Python and JavaScript, the complexity skyrockets. Developers often end up wrestling with a spaghetti mess of APIs and libraries just to display a simple map.\n\nWhat This Does\nEnter anymap-ts. This package lets you whip up interactive maps in Jupyter notebooks using Python while backing it all up with TypeScript. It offers support for popular libraries like MapLibre, Mapbox, and Leaflet, giving you a smorgasbord of options. The anymap_ts/ directory houses the core functionality, including specific files like leaflet.py and deckgl.py that manage different mapping libraries.\n\nThe structure is clean, with examples/ containing various starter projects to get you going quickly. Want to see how to implement a DeckGL map? Check out examples/deckgl/main.ts and examples/deckgl/index.html. You can dive straight into the code and see how it all fits together.\n\nReal-World Use\nImagine you need to visualize geospatial data for a presentation. With anymap-ts, you can do this in minutes. Here’s a quick example:\n\nThis code snippet creates a centered map with a marker in San Francisco. It’s that straightforward. You can also add layers and controls without getting lost in a sea of documentation. \n\nThe Bottom Line\nanymap-ts is a solid choice for developers who want to create interactive maps without the usual headaches. It’s especially useful if you’re already working in Python and want to add some mapping flair. However, if your project is simple, this might feel like overkill. Use it when you need flexibility and multiple mapping options, but don’t expect it to solve all your problems.",
      "url": "https://github.com/moses-y/anymap-ts",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "opengeos/anymap-ts",
        "url": "https://github.com/opengeos/anymap-ts",
        "stars": 186
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 18, 2026",
      "updatedAt": "February 18, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".github": 12,
          "(root)": 5,
          ".nblink": 1,
          "anymap_ts": 21,
          "docs": 85,
          "examples": 76
        },
        "languages": {
          "YAML": 12,
          "Markdown": 33,
          "Python": 13,
          "HTML": 44,
          "CSS": 8,
          "TypeScript": 34
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "examples/cesium/index.html",
          "examples/cesium/main.ts",
          "examples/deckgl/index.html",
          "examples/deckgl/main.ts",
          "examples/index.html",
          "examples/keplergl/index.html",
          "examples/keplergl/main.ts",
          "examples/leaflet/index.html",
          "examples/leaflet/main.ts",
          "examples/mapbox/index.html",
          "examples/mapbox/main.ts",
          "examples/maplibre/index.html",
          "examples/maplibre/main.ts"
        ],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md",
          "docs/CNAME",
          "docs/anymap_ts.md",
          "docs/base.md",
          "docs/basemaps.md",
          "docs/cesium.md",
          "docs/contributing.md",
          "docs/deckgl.md",
          "docs/index.md",
          "docs/installation.md",
          "docs/keplergl.md",
          "docs/leaflet.md",
          "docs/mapbox.md",
          "docs/maplibre.md",
          "docs/notebooks/arc_layer.ipynb",
          "docs/notebooks/bitmap_layer.ipynb",
          "docs/notebooks/buildings_3d.ipynb",
          "docs/notebooks/cesium.ipynb",
          "docs/notebooks/choropleth.ipynb",
          "docs/notebooks/clustering.ipynb",
          "docs/notebooks/cog_layer.ipynb",
          "docs/notebooks/column_layer.ipynb",
          "docs/notebooks/contour_layer.ipynb",
          "docs/notebooks/control_grid.ipynb",
          "docs/notebooks/deckgl.ipynb",
          "docs/notebooks/geohash_layer.ipynb",
          "docs/notebooks/geojson_layer.ipynb",
          "docs/notebooks/great_circle_layer.ipynb",
          "docs/notebooks/gridcell_layer.ipynb",
          "docs/notebooks/h3_cluster_layer.ipynb",
          "docs/notebooks/h3_hexagon_layer.ipynb",
          "docs/notebooks/heatmap_layer.ipynb",
          "docs/notebooks/hexagon_layer.ipynb",
          "docs/notebooks/icon_layer.ipynb",
          "docs/notebooks/image_overlay.ipynb",
          "docs/notebooks/keplergl.ipynb",
          "docs/notebooks/layer_management.ipynb",
          "docs/notebooks/leaflet.ipynb",
          "docs/notebooks/lidar_layer.ipynb",
          "docs/notebooks/mapbox.ipynb",
          "docs/notebooks/maplibre.ipynb",
          "docs/notebooks/maplibre_heatmap.ipynb",
          "docs/notebooks/markers.ipynb",
          "docs/notebooks/mvt_layer.ipynb",
          "docs/notebooks/openlayers.ipynb",
          "docs/notebooks/pmtiles_layer.ipynb",
          "docs/notebooks/pointcloud_layer.ipynb",
          "docs/notebooks/polygon_layer.ipynb",
          "docs/notebooks/popups.ipynb",
          "docs/notebooks/potree.ipynb",
          "docs/notebooks/quadkey_layer.ipynb",
          "docs/notebooks/route_animation.ipynb",
          "docs/notebooks/s2_layer.ipynb",
          "docs/notebooks/scatterplot_layer.ipynb",
          "docs/notebooks/scenegraph_layer.ipynb",
          "docs/notebooks/simplemesh_layer.ipynb",
          "docs/notebooks/solidpolygon_layer.ipynb",
          "docs/notebooks/terrain_3d.ipynb",
          "docs/notebooks/terrain_layer.ipynb",
          "docs/notebooks/text_layer.ipynb",
          "docs/notebooks/tile3d_layer.ipynb",
          "docs/notebooks/tile_layer.ipynb",
          "docs/notebooks/to_html.ipynb",
          "docs/notebooks/trips_layer.ipynb",
          "docs/notebooks/ui_controls.ipynb",
          "docs/notebooks/wms_layer.ipynb",
          "docs/notebooks/zarr_layer.ipynb",
          "docs/openlayers.md",
          "docs/overrides/main.html",
          "docs/potree.md",
          "docs/stylesheets/extra.css",
          "docs/typescript/examples/arc_layer.md",
          "docs/typescript/examples/cesium.md",
          "docs/typescript/examples/cog_layer.md",
          "docs/typescript/examples/deckgl.md",
          "docs/typescript/examples/keplergl.md",
          "docs/typescript/examples/leaflet.md",
          "docs/typescript/examples/mapbox.md",
          "docs/typescript/examples/maplibre.md",
          "docs/typescript/examples/openlayers.md",
          "docs/typescript/examples/pointcloud_layer.md",
          "docs/typescript/examples/potree.md",
          "docs/typescript/examples/zarr_layer.md",
          "docs/typescript/index.md",
          "docs/usage.md",
          "docs/utils.md"
        ],
        "fileTypes": {
          ".yml": 11,
          ".md": 33,
          ".yaml": 1,
          ".py": 13,
          ".html": 44,
          ".ipynb": 53,
          ".css": 8,
          ".ts": 34
        }
      }
    },
    {
      "id": 1160529856,
      "name": "ComfyUI_Viewer_OpenReel_Extension",
      "displayName": "ComfyUI Viewer OpenReel Extension",
      "description": "ComfyUI Viewer extension to provide OpenReel for video editing",
      "summary": "The Problem\n\nComfyUI is great for generating images and videos with all sorts of AI magic, but editing the output is another story. Want to slap some text on your video, trim a few frames, or add transitions? You’re stuck exporting, opening another tool, and juggling formats. Editing inside ComfyUI workflows is basically impossible out of the box.\n\nWhat This Does\n\nComfyUIViewerOpenReelExtension grafts a full-featured video editor right onto ComfyUI Viewer. The key piece is a React-powered OpenReel editor embedded in apps/openreelapp/index.html and wired up via apps/openreelapp/assets/index.js. Python glue in nodes/openreelvideonodes.py bundles image frames and audio from your workflow into a JSON blob, and modules/parsers/openreelvideo_parser.py unpacks edited videos back into tensors and audio. Everything runs local—no random server nonsense—so your edits stay in-browser.\n\nWant to edit a video generated by AnimateDiff or SVD? Drop it into the CV OpenReel Bundle Video node, pipe it through Content Viewer, pause the workflow, and tweak away. If you’re dealing with external videos, use the CV OpenReel Import Video node. Exported edits are handled by CV OpenReel Unpack, which spits out frames and audio for downstream nodes. Workflow integration is outlined in README.md, and there’s zero external editor dependency.\n\nReal-World Use\n\nSay you’ve got a batch of AI-generated frames and want to make a clip with custom transitions and overlays. Your workflow might look like:\n\nEdit inside OpenReel, click SEND TO OUTPUT, cancel, and re-run the workflow. The edited video is unpacked as tensors and ready for saving or more processing. No more exporting to DaVinci or ffmpeg unless you’re a masochist.\n\nThe Bottom Line\n\nIf you’re tired of bouncing between ComfyUI and external editors, this extension is a lifesaver. It’s not perfect—“featured rich” is a stretch, and the UI still feels beta—but for workflow-integrated editing, it does the job. Anyone building AI video workflows in ComfyUI should install it. If you’re just doing single-shot exports, stick to your favorite desktop editor.",
      "url": "https://github.com/moses-y/ComfyUI_Viewer_OpenReel_Extension",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "WASasquatch/ComfyUI_Viewer_OpenReel_Extension",
        "url": "https://github.com/WASasquatch/ComfyUI_Viewer_OpenReel_Extension",
        "stars": 40
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 18, 2026",
      "updatedAt": "February 18, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 34,
        "directories": {
          "(root)": 4,
          "apps": 23,
          "modules": 1,
          "nodes": 1,
          "routes": 1,
          "screenshots": 3,
          "web": 1
        },
        "languages": {
          "Markdown": 1,
          "JavaScript": 16,
          "CSS": 1,
          "HTML": 1,
          "JSON": 1,
          "Python": 3
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "apps/openreel_app/assets/index.js",
          "apps/openreel_app/index.html"
        ],
        "configFiles": [
          "requirements.txt"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".md": 1,
          ".js": 16,
          ".wasm": 1,
          ".css": 1,
          ".svg": 1,
          ".html": 1,
          ".json": 1,
          ".py": 3,
          ".txt": 1,
          ".jpg": 3
        }
      }
    },
    {
      "id": 1160527977,
      "name": "btw",
      "displayName": "btw",
      "description": "Open source Medium alternative- set up your personal blog in minutes.",
      "summary": "The Problem\n\nSetting up a personal blog shouldn't feel like deploying a production-grade SaaS app. Between configuring databases, dealing with authentication, and hosting, it’s easy to lose hours (or days) on stuff that should just work. Platforms like Medium are fine until you need control over your content, branding, or data. Self-hosting alternatives exist, but they’re often bloated, overly complex, or just plain annoying to work with.\n\nWhat This Does\n\nbtw strips blogging down to the essentials. It’s an open-source Medium alternative that lets you self-host your blog in minutes. The repo is built with React and deploys via Docker, so you can skip the endless dependency hell and just get things running. The entry points are clean (list/assets/index.html for the UI, list/src/actions/app.ts for app-level actions) and the Docker setup is straightforward. The main config file, deploy/docker-compose.dev.yml, handles database setup, admin user creation, and optional extras like image uploads via S3.\n\nThe blogging interface is powered by list/src/components/Tiptap.jsx, a rich text editor component. It’s not bloated—just enough functionality to publish decent-looking posts without feeling like you need a manual. For custom branding, you’ve got access to font files in list/assets/media/fonts and icon sets in list/assets/media/icons.\n\nAuthentication is dead simple. You can opt for a basic login or toss in an OTP setup by defining ADMINOTP in the Docker config. Want SMTP for email-based login? Just plug your credentials into the environment variables (SMTPHOST, SMTPUSER, etc.).\n\nReal-World Use\n\nImagine you’re launching a blog for your side hustle. Clone the repo, set your ADMINEMAIL and ADMIN_SLUG in docker-compose.dev.yml, and docker-compose up your way to a working site. Use the editor (list/src/components/Tiptap.jsx) to write posts, and customize the look by swapping out fonts or icons in list/assets/media.\n\nHere’s a snippet to set up the admin user and database:\n\nRun docker-compose up and you’re live. No 20-step setup guide, no “why isn’t this working” rabbit holes.\n\nThe Bottom Line\n\nbtw is the no-nonsense blogging platform for devs who don’t want to fight their tools. It’s easy to set up, extensible, and gets out of your way. The Docker-first approach makes it ideal for self-hosting without headaches. Downsides? It might be overkill if you just need a couple of static pages. But if you want control without complexity, this gets the job done.",
      "url": "https://github.com/moses-y/btw",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "btw-so/btw",
        "url": "https://github.com/btw-so/btw",
        "stars": 1076
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 18, 2026",
      "updatedAt": "February 18, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 7,
          "deploy": 1,
          "list": 192
        },
        "languages": {
          "Markdown": 2,
          "SQL": 1,
          "YAML": 4,
          "Shell": 1,
          "HTML": 1,
          "JSON": 8,
          "CSS": 2,
          "JavaScript": 27,
          "TypeScript": 15,
          "Docker": 1,
          "JSX": 30,
          "TSX": 3
        },
        "frameworks": [
          "React",
          "Docker"
        ],
        "packageManager": "npm",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "Travis CI",
        "entryPoints": [
          "list/assets/index.html",
          "list/cypress/plugins/index.js",
          "list/cypress/support/index.js",
          "list/src/actions/app.ts",
          "list/src/actions/index.ts",
          "list/src/components/Transition/index.tsx",
          "list/src/index.jsx",
          "list/src/literals/index.js",
          "list/src/reducers/app.ts",
          "list/src/reducers/index.ts"
        ],
        "configFiles": [
          "deploy/docker-compose.dev.yml",
          "list/.eslintrc",
          "list/Dockerfile",
          "list/config/webpack.config.js",
          "list/jest.config.ts",
          "list/package.json"
        ],
        "dependencies": [
          "list/package-lock.json",
          "list/package.json"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "LICENSE copy",
          "README.md",
          "list/LICENSE",
          "list/README.md"
        ],
        "fileTypes": {
          ".md": 2,
          ".sql": 1,
          ".yml": 4,
          ".sh": 1,
          ".html": 1,
          ".json": 8,
          ".png": 14,
          ".svg": 18,
          ".otf": 10,
          ".eot": 12,
          ".ttf": 12,
          ".woff": 12,
          ".woff2": 12,
          ".gif": 1,
          ".ico": 1,
          ".css": 2,
          ".txt": 1,
          ".js": 27,
          ".ts": 15,
          ".dockerfile": 1,
          ".jsx": 30,
          ".tsx": 3
        }
      }
    },
    {
      "id": 1160315748,
      "name": "off-grid-mobile",
      "displayName": "off grid mobile",
      "description": "The Swiss Army Knife of Offline AI. Chat, Speak, and Generate Images - Privacy First, Zero Internet. Download an LLM and use it on your mobile device. No data ever leaves your phone. Supports text-to-text, vision, text-to-image",
      "summary": "The Problem\nMost mobile AI applications are tethered to the internet, which raises serious privacy concerns. If you're tired of your data being sucked into the cloud while you're just trying to chat with a bot or generate an image, you’re not alone. Enter Off Grid, which runs everything locally on your phone. No internet required, no data leaks.\n\nWhat This Does\nOff Grid is like the Swiss Army Knife of offline AI. It combines text generation, image creation, vision AI, and voice transcription all on your device. You can dive into the code with App.tsx as your entry point, while the heavy lifting happens in the android/ directory, where you’ll find the core functionality and native modules.\n\nThe project structure is pretty straightforward. The tests/ folder has 80+ files ensuring that this thing works as intended, which is nice. You can see that DownloadManagerModule.kt in the android/app/src/main/java/ai/offgridmobile/download/ directory manages downloads, allowing you to grab models without needing an internet connection. The build.gradle files in android/ handle the dependencies and build configurations, so you're not left in the dark when it comes to knowing what’s needed to compile.\n\nReal-World Use\nImagine you need to generate an image for a presentation but are out in the wild with no cell service. You fire up Off Grid, input your text prompt, and within seconds, the local model generates a stunning image. You can also attach documents like PDFs for analysis without worrying about sending sensitive data over the internet. The app’s voice input feature uses Whisper for real-time transcription, so you can dictate notes without a hitch.\n\nNow you’re ready to go.\n\nThe Bottom Line\nOff Grid is a solid option if you need a privacy-first AI suite on your mobile device. It’s feature-rich and runs entirely offline, which is great for power users who want control over their data. However, it's probably overkill for casual users who just want a simple chat app. If you're into AI and privacy, though, this is a tool worth checking out.",
      "url": "https://github.com/moses-y/off-grid-mobile",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "alichherawalla/off-grid-mobile",
        "url": "https://github.com/alichherawalla/off-grid-mobile",
        "stars": 688
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 17, 2026",
      "updatedAt": "February 17, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".bundle": 1,
          "(root)": 11,
          ".github": 4,
          ".maestro": 18,
          "__tests__": 80,
          "android": 86
        },
        "languages": {
          "JavaScript": 2,
          "Markdown": 4,
          "YAML": 23,
          "TSX": 36,
          "TypeScript": 42,
          "JSON": 1,
          "Kotlin": 9
        },
        "frameworks": [
          "React",
          "Rails"
        ],
        "packageManager": "gradle",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "App.tsx"
        ],
        "configFiles": [
          ".eslintrc.js",
          ".prettierrc.js",
          "Gemfile",
          "android/app/build.gradle",
          "android/build.gradle"
        ],
        "dependencies": [
          "Gemfile",
          "android/app/build.gradle",
          "android/build.gradle"
        ],
        "testFiles": [
          ".maestro/E2E_TESTING.md",
          "__tests__/App.test.tsx",
          "__tests__/contracts/coreMLDiffusion.contract.test.ts",
          "__tests__/contracts/iosDownloadManager.contract.test.ts",
          "__tests__/contracts/llama.rn.test.ts",
          "__tests__/contracts/llamaContext.contract.test.ts",
          "__tests__/contracts/localDream.contract.test.ts",
          "__tests__/contracts/whisper.contract.test.ts",
          "__tests__/contracts/whisper.rn.test.ts",
          "__tests__/integration/generation/generationFlow.test.ts",
          "__tests__/integration/generation/imageGenerationFlow.test.ts",
          "__tests__/integration/models/activeModelService.test.ts",
          "__tests__/integration/stores/chatStoreIntegration.test.ts",
          "__tests__/rntl/components/AnimatedEntry.test.tsx",
          "__tests__/rntl/components/AnimatedListItem.test.tsx",
          "__tests__/rntl/components/AnimatedPressable.test.tsx",
          "__tests__/rntl/components/AppSheet.test.tsx",
          "__tests__/rntl/components/Card.test.tsx",
          "__tests__/rntl/components/ChatInput.test.tsx",
          "__tests__/rntl/components/ChatMessage.test.tsx",
          "__tests__/rntl/components/CustomAlert.test.tsx",
          "__tests__/rntl/components/DebugSheet.test.tsx",
          "__tests__/rntl/components/GenerationSettingsModal.test.tsx",
          "__tests__/rntl/components/ModelCard.test.tsx",
          "__tests__/rntl/components/ModelSelectorModal.test.tsx",
          "__tests__/rntl/components/ProjectSelectorSheet.test.tsx",
          "__tests__/rntl/components/VoiceRecordButton.test.tsx",
          "__tests__/rntl/hooks/useFocusTrigger.test.ts",
          "__tests__/rntl/navigation/AppNavigator.test.tsx",
          "__tests__/rntl/screens/ChatScreen.test.tsx",
          "__tests__/rntl/screens/ChatsListScreen.test.tsx",
          "__tests__/rntl/screens/DeviceInfoScreen.test.tsx",
          "__tests__/rntl/screens/DownloadManagerScreen.test.tsx",
          "__tests__/rntl/screens/GalleryScreen.test.tsx",
          "__tests__/rntl/screens/HomeScreen.test.tsx",
          "__tests__/rntl/screens/LockScreen.test.tsx",
          "__tests__/rntl/screens/ModelDownloadScreen.test.tsx",
          "__tests__/rntl/screens/ModelSettingsScreen.test.tsx",
          "__tests__/rntl/screens/ModelsScreen.test.tsx",
          "__tests__/rntl/screens/OnboardingScreen.test.tsx",
          "__tests__/rntl/screens/PassphraseSetupScreen.test.tsx",
          "__tests__/rntl/screens/ProjectDetailScreen.test.tsx",
          "__tests__/rntl/screens/ProjectEditScreen.test.tsx",
          "__tests__/rntl/screens/ProjectsScreen.test.tsx",
          "__tests__/rntl/screens/SecuritySettingsScreen.test.tsx",
          "__tests__/rntl/screens/SettingsScreen.test.tsx",
          "__tests__/rntl/screens/StorageSettingsScreen.test.tsx",
          "__tests__/rntl/screens/VoiceSettingsScreen.test.tsx",
          "__tests__/specs/image-generation.yaml",
          "__tests__/specs/model-lifecycle.yaml",
          "__tests__/specs/text-generation.yaml",
          "__tests__/unit/constants/constants.test.ts",
          "__tests__/unit/hooks/useAppState.test.ts",
          "__tests__/unit/hooks/useVoiceRecording.test.ts",
          "__tests__/unit/hooks/useWhisperTranscription.test.ts",
          "__tests__/unit/services/authService.test.ts",
          "__tests__/unit/services/backgroundDownloadService.test.ts",
          "__tests__/unit/services/coreMLModelBrowser.test.ts",
          "__tests__/unit/services/documentService.test.ts",
          "__tests__/unit/services/generationService.test.ts",
          "__tests__/unit/services/hardware.test.ts",
          "__tests__/unit/services/huggingFaceModelBrowser.test.ts",
          "__tests__/unit/services/huggingface.test.ts",
          "__tests__/unit/services/imageGenerator.test.ts",
          "__tests__/unit/services/imageModelRecommendation.test.ts",
          "__tests__/unit/services/intentClassifier.test.ts",
          "__tests__/unit/services/llm.test.ts",
          "__tests__/unit/services/localDreamGenerator.test.ts",
          "__tests__/unit/services/modelManager.test.ts",
          "__tests__/unit/services/pdfExtractor.test.ts",
          "__tests__/unit/services/voiceService.test.ts",
          "__tests__/unit/services/whisperService.test.ts",
          "__tests__/unit/stores/appStore.test.ts",
          "__tests__/unit/stores/authStore.test.ts",
          "__tests__/unit/stores/chatStore.test.ts",
          "__tests__/unit/stores/projectStore.test.ts",
          "__tests__/unit/stores/whisperStore.test.ts",
          "__tests__/unit/utils/coreMLModelUtils.test.ts",
          "__tests__/unit/utils/messageContent.test.ts",
          "__tests__/utils/factories.ts",
          "__tests__/utils/testHelpers.ts"
        ],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".js": 2,
          ".md": 4,
          ".yml": 3,
          ".yaml": 20,
          ".tsx": 36,
          ".ts": 42,
          ".json": 1,
          ".gradle": 2,
          ".keystore": 1,
          ".pro": 1,
          ".xml": 11,
          ".so": 27,
          ".bundle": 1,
          ".kt": 9,
          ".png": 33,
          ".properties": 1
        }
      }
    },
    {
      "id": 1160264409,
      "name": "rag-api",
      "displayName": "rag api",
      "description": "Multi-tenant RAG API powered by LightRAG/RAG-Anything. Auto-selects best parser (DeepSeek-OCR/MinerU/Docling) via complexity scoring",
      "summary": "Building a Multi-Tenant RAG API with rag-api\n\nThe Problem\n\nDealing with document Q&A at scale is a nightmare. PDFs, images, Word files—every format demands its own parsing, and don’t get me started on OCR. Add multi-tenancy into the mix, with isolated data and custom logic per tenant, and you're drowning in complexity. Most open-source tools give you one piece of the puzzle: vector search, OCR, or maybe a knowledge graph. But what if you need all of it, and it has to just work?\n\nWhat This Does\n\nrag-api is a multi-tenant Retrieval-Augmented Generation (RAG) service that combines LightRAG and RAG-Anything for intelligent document Q&A. It auto-selects the best parser—DeepSeek-OCR, MinerU, or Docling—based on document complexity (src/smartparserselector.py). No need to guess which tool to use; it figures it out.\n\nThe project is cleanly organized. The api/ folder handles endpoints like documents.py (file ingestion), query.py (retrieval), and tenant.py (tenant management). The brains of the operation live in src/, where modules like documentcomplexity.py and rag.py handle parsing and retrieval. Oh, and deployment? Dead simple. There's a Dockerfile, docker-compose.yml, and even a deploy.sh script to get you started in minutes.\n\nReal-World Use\n\nSay you're building a SaaS platform where businesses upload contracts, invoices, and scanned forms for Q&A. Here's what your workflow might look like:\nDeploy the service (docker-compose up).\nUpload a batch of files via the /documents endpoint (check out api/documents.py).\nBehind the scenes, smartparserselector.py picks the best parser (OCR for images, direct insertion for text).\nQuery the data using /query (hello, hybrid retrieval with LightRAG).\n\nExample cURL request to upload files:\n\ncurl -X POST -F \"file=@contract.pdf\" http://localhost:8000/documents\n\nAnd retrieving info:\n\ncurl -X GET \"http://localhost:8000/query?question=What%20is%20the%20contract%20value?\"\n\nMulti-tenancy? Each tenant has isolated storage and config (api/tenantconfig.py), so no cross-contamination.\n\nThe Bottom Line\n\nrag-api is overkill for small projects but perfect for enterprise-level document Q&A with multi-tenancy. It’s opinionated but flexible: great parser selection, hybrid retrieval, and Redis-based task persistence. Just don’t expect hand-holding—the docs are there, but you’ll need to dig in. If you're wrangling complex document processing at scale, this is your new best friend.",
      "url": "https://github.com/moses-y/rag-api",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "BukeLy/rag-api",
        "url": "https://github.com/BukeLy/rag-api",
        "stars": 46
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 17, 2026",
      "updatedAt": "February 17, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 79,
        "directories": {
          ".cursor": 1,
          "(root)": 18,
          ".github": 1,
          "api": 12,
          "deploy": 1,
          "docs": 21,
          "scripts": 10,
          "src": 15
        },
        "languages": {
          "YAML": 3,
          "Markdown": 27,
          "Python": 29,
          "Shell": 8,
          "TOML": 2
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "main.py"
        ],
        "configFiles": [
          "Dockerfile",
          "Dockerfile.dev",
          "Dockerfile.qdrant",
          "docker-compose.dev.yml",
          "docker-compose.yml",
          "pyproject.toml"
        ],
        "dependencies": [
          "pyproject.toml"
        ],
        "testFiles": [
          "test_lightrag_doc_status_api.py"
        ],
        "docs": [
          "README.md",
          "README.zh-CN.md",
          "api/README.md",
          "docs/API_COMPARISON.md",
          "docs/ARCHITECTURE.md",
          "docs/AWS_MIGRATION_GUIDE.md",
          "docs/DEPLOYMENT_EXTERNAL_STORAGE.md",
          "docs/DEPLOY_MODES.md",
          "docs/FRONTEND_API_INTEGRATION_GUIDE.md",
          "docs/FRONTEND_BUG_FIX_REPORT.md",
          "docs/LIGHTRAG_IMPLEMENTATION_GUIDE.md",
          "docs/LIGHTRAG_WEBUI_INTEGRATION.md",
          "docs/MINERU_REMOTE_API.md",
          "docs/MULTI_TENANT_CONFIG_BEST_PRACTICES.md",
          "docs/PR_WORKFLOW.md",
          "docs/README.md",
          "docs/USAGE.md",
          "docs/async-architecture-migration-plan.md",
          "docs/cdn_prompts_template.md",
          "docs/deepseek-ocr-complete.md",
          "docs/lightrag_entity_extraction_format.md",
          "docs/parser-selection-upgrade-v1-to-v2.md",
          "docs/smart-parser-selection-v2.md",
          "docs/strict_grounding_mode.md",
          "scripts/README.md",
          "scripts/README_MIGRATION.md"
        ],
        "fileTypes": {
          ".mdc": 1,
          ".yml": 3,
          ".md": 27,
          ".dev": 1,
          ".qdrant": 1,
          ".py": 29,
          ".sh": 8,
          ".conf": 1,
          ".example": 1,
          ".toml": 2,
          ".lock": 1
        }
      }
    },
    {
      "id": 1160260038,
      "name": "freemocap",
      "displayName": "freemocap",
      "description": "Free Motion Capture for Everyone 💀✨",
      "summary": "The Problem\nHave you ever tried motion capture and thought, \"Wow, this is way too expensive and complicated?\" Traditional setups require a small fortune and a PhD in engineering just to get started. FreeMoCap aims to fix that by giving you a low-cost, open-source alternative that doesn’t require a degree in rocket science.\n\nWhat This Does\nFreeMoCap is a motion capture system that runs on both hardware and software you probably already have. The project is split into a few key directories, like freemocap/, which contains the core processes for capturing and processing motion data, and experimental/freemocap-ui/, which houses the React-based UI for interacting with the system. \n\nYou can kick things off with freemocap/main.py, which launches the GUI to start your motion capture sessions. If you're feeling adventurous, the experimental/batchprocess/ folder has scripts to handle batch processing of your captured videos, making it easier to analyze multiple recordings without losing your sanity.\n\nReal-World Use\nHere’s a quick workflow: After setting up your environment and installing the package using pip install freemocap, you can run your capture session like this:\n\npython -m freemocap\n\nThe GUI pops up, guiding you through the capture process, where you can adjust settings directly. Once done, you can dive into the processmotioncapturevideos folder to tweak your data and export it for further analysis. Need to visualize your results? The integration with Blender via exporttoblender.py makes it a breeze to create stunning visuals.\n\nThe Bottom Line\nFreeMoCap is a solid option if you're looking to dip your toes into motion capture without drowning in costs and complexity. It's got a decent structure and clear documentation, but with only 0 stars, it might lack that warm, fuzzy community support you’d find in more established projects. If you’re a researcher, educator, or hobbyist, give it a shot—but don’t expect the polish of commercial solutions just yet.",
      "url": "https://github.com/moses-y/freemocap",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "freemocap/freemocap",
        "url": "https://github.com/freemocap/freemocap",
        "stars": 5793
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 17, 2026",
      "updatedAt": "February 17, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 10,
          ".github": 15,
          "bin": 10,
          "experimental": 91,
          "freemocap": 74
        },
        "languages": {
          "Markdown": 7,
          "YAML": 14,
          "Shell": 8,
          "Python": 79,
          "JavaScript": 1,
          "JSON": 4,
          "HTML": 1,
          "CSS": 3,
          "TSX": 29,
          "TypeScript": 15
        },
        "frameworks": [
          "React",
          "FastAPI"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "experimental/freemocap-ui/public/index.html",
          "experimental/freemocap-ui/src/App.tsx",
          "experimental/freemocap-ui/src/index.tsx",
          "freemocap/__main__.py"
        ],
        "configFiles": [
          "experimental/freemocap-ui/package.json",
          "experimental/freemocap-ui/tsconfig.json"
        ],
        "dependencies": [
          "experimental/freemocap-ui/package-lock.json",
          "experimental/freemocap-ui/package.json"
        ],
        "testFiles": [
          ".github/workflows/coverage-testing.yml",
          ".github/workflows/python-testing.yml",
          ".github/workflows/version-testing-1.yml",
          ".github/workflows/version-testing-2.yml",
          "bin/linux/test.sh",
          "experimental/freemocap-ui/src/App.test.tsx",
          "experimental/freemocap-ui/src/features/counter/counterSlice.spec.ts",
          "experimental/freemocap-ui/src/setupTests.ts"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "experimental/benchmark/README.md",
          "experimental/freemocap-ui/README.md"
        ],
        "fileTypes": {
          ".md": 7,
          ".yml": 13,
          ".yaml": 1,
          ".cff": 1,
          ".in": 1,
          ".sh": 8,
          ".cmd": 2,
          ".py": 79,
          ".js": 1,
          ".json": 4,
          ".ico": 2,
          ".html": 1,
          ".png": 11,
          ".txt": 1,
          ".css": 3,
          ".tsx": 29,
          ".ts": 15,
          ".svg": 7,
          ".xml": 1,
          ".pdf": 4,
          ".icns": 1,
          ".plist": 1,
          ".ipynb": 1
        }
      }
    },
    {
      "id": 1160206916,
      "name": "superclaw",
      "displayName": "superclaw",
      "description": "SuperClaw: Red-Team AI Agents Before They Red-Team You",
      "summary": "The Problem\nDeploying AI agents without solid security checks is like sending a toddler into a candy store—chaos ensues. These agents often have wide-reaching permissions and can be manipulated through various attack vectors like prompt injections or tool misuse. SuperClaw targets these vulnerabilities before your agents wreak havoc, ensuring they don’t become a security nightmare.\n\nWhat This Does\nSuperClaw is a security testing framework specifically designed for AI coding agents. It lets you set up scenario-driven tests to identify weaknesses in your agents. The src/superclaw/attacks/ directory contains various attack types like promptinjection.py and toolbypass.py, which simulate real-world threats against your agents. Meanwhile, the src/superclaw/reporting/ folder handles output formats, so you can get your reports in HTML, JSON, or SARIF—whatever floats your boat.\n\nThe docs/guides/ci-cd.md file even shows how to integrate this with your existing CI/CD pipelines, so you can automate security checks alongside your regular builds. This isn't just security theater; it's actionable, evidence-based testing.\n\nReal-World Use\nLet's say you've got an AI agent that processes sensitive data. You can run a quick test by executing a scenario defined in docs/guides/problem-definition.md. Use the superclaw CLI tool from src/superclaw/cli.py to kick off the tests, and it spits out a report detailing any vulnerabilities found. You can check out the src/superclaw/cli.py for commands that let you run these tests with ease.\n\npython src/superclaw/cli.py run --scenario \"promptinjection\" --agent \"myagent\"\n\nThe Bottom Line\nSuperClaw is a solid option for teams seriously concerned about the security of their AI agents. It's a bit heavy-handed if you're just tinkering or working on small projects, but for anything that interacts with sensitive data, it’s a must-have. Just remember, ethical use is critical—this isn’t a toy. Get permission, run tests in isolation, and take findings seriously.",
      "url": "https://github.com/moses-y/superclaw",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "SuperagenticAI/superclaw",
        "url": "https://github.com/SuperagenticAI/superclaw",
        "stars": 182
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 17, 2026",
      "updatedAt": "February 17, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "directories": {
          ".github": 2,
          "(root)": 10,
          "assets": 1,
          "docs": 21,
          "src": 43
        },
        "languages": {
          "YAML": 4,
          "Markdown": 23,
          "CSS": 1,
          "TOML": 1,
          "Python": 43
        },
        "entryPoints": [
          "src/superclaw/cli.py"
        ],
        "configFiles": [
          "pyproject.toml"
        ],
        "dependencies": [
          "pyproject.toml"
        ],
        "testFiles": [],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "docs/api/adapters.md",
          "docs/api/attacks.md",
          "docs/api/behaviors.md",
          "docs/api/cli.md",
          "docs/api/codeoptix.md",
          "docs/architecture/attacks.md",
          "docs/architecture/behaviors.md",
          "docs/architecture/codeoptix.md",
          "docs/architecture/overview.md",
          "docs/assets/logo.png",
          "docs/getting-started/configuration.md",
          "docs/getting-started/installation.md",
          "docs/getting-started/quickstart.md",
          "docs/guides/attacks.md",
          "docs/guides/ci-cd.md",
          "docs/guides/custom-behaviors.md",
          "docs/guides/problem-definition.md",
          "docs/guides/safety.md",
          "docs/guides/scanning.md",
          "docs/index.md",
          "docs/stylesheets/extra.css"
        ]
      }
    },
    {
      "id": 1160032583,
      "name": "mindsdb",
      "displayName": "mindsdb",
      "description": "Federated Query Engine for AI - The only MCP Server you'll ever need",
      "summary": "The Problem\n\nJuggling data across multiple databases, warehouses, and cloud apps is a nightmare. You end up duct-taping scripts, wrestling with ETL, and still can't ask a simple question across all your sources. AI integrations? Usually an afterthought or a bolt-on hack.\n\nWhat This Does\n\nmindsdb is an open-source federated query engine with a built-in MCP server. It connects to just about anything—MySQL, Postgres, MongoDB, SaaS APIs—so you don't have to babysit a dozen connectors. The guts live in folders like docker/ (for container builds), .github/workflows/ (CI/CD), and a mountain of docs in docs/. You get SQL-like unification: create views and knowledge bases to blend structured and unstructured data, no ETL required. The magic is in how you can schedule jobs (see the docs on jobs) to automate cleaning or syncing. Want AI-powered responses? Hook up agents and chat directly with your data.\n\nReal-World Use\n\nSay your sales data lives in MySQL and customer support logs are in MongoDB. With MindsDB, you spin up a container (docker-compose.yml), connect both sources, and create a unified view:\n\nCREATE VIEW salessupport AS\nSELECT s.orderid, s.amount, m.supportticket\nFROM mysql.sales s\nJOIN mongodb.support m ON s.customerid = m.customer_id;\n\nYou can then fire off questions like, \"Show all orders with unresolved tickets,\" and get answers without writing glue code. Want to automate a nightly sync? Set up a job in SQL to run transformations whenever you want.\n\nThe Bottom Line\n\nMindsDB does what most \"AI data platforms\" promise but rarely deliver: one place to connect, unify, and ask questions across messy data. It's overkill for tiny projects or if you're allergic to containers, but if you need AI-powered queries across enterprise sources, it's actually worth your time. The docs are exhaustive, maybe too much, but at least you won't get stuck. For anyone sick of ETL and patchwork scripts, this is a solid option.",
      "url": "https://github.com/moses-y/mindsdb",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "mindsdb/mindsdb",
        "url": "https://github.com/mindsdb/mindsdb",
        "stars": 38596
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 17, 2026",
      "updatedAt": "February 17, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "directories": {
          ".devcontainer": 1,
          "(root)": 13,
          ".github": 18,
          "assets": 8,
          "docker": 18,
          "docs": 142
        },
        "languages": {
          "JSON": 4,
          "YAML": 19,
          "Markdown": 10,
          "Docker": 2,
          "SQL": 3,
          "HCL": 1
        },
        "entryPoints": [],
        "configFiles": [
          "Makefile",
          "docker-compose.yml",
          "docker/db_images/mariadb/Dockerfile",
          "docker/db_images/mysql/Dockerfile",
          "docker/db_images/postgres/Dockerfile",
          "docker/docker-compose-testing.yml"
        ],
        "dependencies": [],
        "testFiles": [
          ".github/ISSUE_TEMPLATE/integrations_contest.yaml",
          ".github/workflows/tests_integration.yml",
          ".github/workflows/tests_unit.yml",
          "docker/docker-compose-testing.yml",
          "docs/assets/docker/docker_desktop/pull-latest-image.png"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "assets/MindsDB-org-readme-diagram.jpg",
          "docker/README.md",
          "docker/db_images/README.md",
          "docs/README.md",
          "docs/assets/BearHeroImageMindsDB.jpeg",
          "docs/assets/MindsDBLightwood@3x.png",
          "docs/assets/SLBot-Hero-Whizfizz.png",
          "docs/assets/SLBot-response1.png",
          "docs/assets/SLBot-response2.png",
          "docs/assets/SLBot-response3.png",
          "docs/assets/SLBot-response4.png",
          "docs/assets/TWbot - hero Snoopstein.png",
          "docs/assets/TWbot-response-image.png",
          "docs/assets/TWbot-response1.png",
          "docs/assets/TWbot-response2.png",
          "docs/assets/TWbot-response3.png",
          "docs/assets/TWbot-response4.png",
          "docs/assets/TWbot-response5.png",
          "docs/assets/a2a-unavailable.png",
          "docs/assets/agent_diagram.png",
          "docs/assets/ai-integrations.png",
          "docs/assets/ai_system_deployment.png",
          "docs/assets/ai_workflow_automation.png",
          "docs/assets/automation.png",
          "docs/assets/byom_diagram.png",
          "docs/assets/byom_empty_form.png",
          "docs/assets/byom_form.png",
          "docs/assets/byom_upload_custom_model.png",
          "docs/assets/chatbot_diagram.png",
          "docs/assets/cloud-login.png",
          "docs/assets/cloud-signup.png",
          "docs/assets/cloud/cloud-signup-filledout.png",
          "docs/assets/cloud/dedicated_instance_off.png",
          "docs/assets/cloud/dedicated_instance_on.png",
          "docs/assets/cloud/email.png",
          "docs/assets/cloud/gui.png",
          "docs/assets/cloud/gui_query.png",
          "docs/assets/cloud/import_file.png",
          "docs/assets/cloud/import_file_2.png",
          "docs/assets/cloud/login.png",
          "docs/assets/cloud/main_mdb.png",
          "docs/assets/cloud/plan_table.png",
          "docs/assets/connect_compass_cloud.png",
          "docs/assets/connect_compass_srv.png",
          "docs/assets/connect_compassm.png",
          "docs/assets/connect_mongo_compass.png",
          "docs/assets/connect_mongo_compass_1.png",
          "docs/assets/connect_mongo_compass_2.png",
          "docs/assets/connect_mongo_compass_3.png",
          "docs/assets/connect_mongo_shell.png",
          "docs/assets/connect_mongo_shell_1.png",
          "docs/assets/connect_mongo_shell_2.png",
          "docs/assets/connect_tableau.png",
          "docs/assets/connect_tableau_2.png",
          "docs/assets/connect_tableau_3.png",
          "docs/assets/connect_tableau_4.png",
          "docs/assets/connect_tableau_5.png",
          "docs/assets/connect_tableau_6.png",
          "docs/assets/connect_tableau_7.png",
          "docs/assets/contribute.png",
          "docs/assets/data/mssql-select.gif",
          "docs/assets/databases/mdb-mysql.png",
          "docs/assets/databases/mdb-postgres.png",
          "docs/assets/databases/mongodb/mongo-mdb-code.png",
          "docs/assets/databases/mongodb/mongo-mdb-current.png",
          "docs/assets/databases/mongodb/mongo-mdb.png",
          "docs/assets/dbeaver-check-predictor-status.png",
          "docs/assets/dbeaver-configure-cloud-connection.png",
          "docs/assets/dbeaver-configure-docker-connection.png",
          "docs/assets/dbeaver-create-connection.png",
          "docs/assets/dbeaver-create-database.png",
          "docs/assets/dbeaver-create-predictor-simple.png",
          "docs/assets/dbeaver-create-script.png",
          "docs/assets/dbeaver-empty-script.png",
          "docs/assets/dbeaver-home-rentals-prediction-results.png",
          "docs/assets/dbeaver-home-rentals-prediction.png",
          "docs/assets/dbeaver-predict-home-rentals.png",
          "docs/assets/dbeaver-preview-data.png",
          "docs/assets/docker/docker_desktop/containers-running-extension.png",
          "docs/assets/docker/docker_desktop/enable-extension-containers.png",
          "docs/assets/docker/docker_desktop/enable-win-dev-mode.png",
          "docs/assets/docker/docker_desktop/mindsdb-container-logs.png",
          "docs/assets/docker/docker_desktop/mindsdb_docker_desktop.png",
          "docs/assets/docker/docker_desktop/pull-latest-image.png",
          "docs/assets/faqs_download.csv.png",
          "docs/assets/files/upload_file.png",
          "docs/assets/files/upload_file_from_computer.png",
          "docs/assets/files/upload_file_from_url.png",
          "docs/assets/getting-started.png",
          "docs/assets/icons/Cloud.svg",
          "docs/assets/icons/Database.svg",
          "docs/assets/icons/Explainable.svg",
          "docs/assets/icons/GUI.svg",
          "docs/assets/icons/Python.svg",
          "docs/assets/icons/Server.svg",
          "docs/assets/icons/sdk.svg",
          "docs/assets/info/query.png",
          "docs/assets/info/select.png",
          "docs/assets/install-dependencies-gui-x.png",
          "docs/assets/install-dependencies-gui.png",
          "docs/assets/integration-image.png",
          "docs/assets/integrations/Arjuna.png",
          "docs/assets/jssdk_install_output.png",
          "docs/assets/kb_data_insertion.png",
          "docs/assets/kb_hybrid_search.jpg",
          "docs/assets/lightwood.png",
          "docs/assets/mcp.png",
          "docs/assets/mcp_cursor_chat.png",
          "docs/assets/mcp_cursor_chat_mode.png",
          "docs/assets/mcp_cursor_chat_tool.png",
          "docs/assets/mcp_cursor_mcp_server.png",
          "docs/assets/mcp_cursor_settings.png",
          "docs/assets/mdb_image.png",
          "docs/assets/mdb_logo.png",
          "docs/assets/mdb_logo_name.png",
          "docs/assets/mdb_logo_w.svg",
          "docs/assets/metabase_add_database.png",
          "docs/assets/metabase_connected.png",
          "docs/assets/metabase_run_query_failure.png",
          "docs/assets/metabase_run_query_home_rentals.png",
          "docs/assets/metabase_run_query_show_tables.png",
          "docs/assets/minds/Dashboard_Minds.png",
          "docs/assets/minds/DatasourcesConn_Minds.png",
          "docs/assets/minds/DatasourcesTab_Minds.png",
          "docs/assets/minds/DatasourcesType_Minds.png",
          "docs/assets/minds/MindChat_Minds.png",
          "docs/assets/minds/MindsTab_Minds.png",
          "docs/assets/minds/MindsWorkflow.png",
          "docs/assets/minds/NewMind_Minds.png",
          "docs/assets/minds/Playground_Mind.png",
          "docs/assets/minds/PreviewData_Minds.png",
          "docs/assets/mindsdb-editor.png",
          "docs/assets/mindsdb-fqe.png",
          "docs/assets/mindsdb-local-editor.png",
          "docs/assets/mindsdb_gui_editor/create_model_1.png",
          "docs/assets/mindsdb_gui_editor/create_model_2.png",
          "docs/assets/mindsdb_gui_editor/learning_hub.png",
          "docs/assets/mindsdb_gui_editor/mindsdb_editor.png",
          "docs/assets/mindsdb_gui_editor/multiple_query_editor.png",
          "docs/assets/mindsdb_gui_editor/object_explorer.png",
          "docs/assets/mindsdb_gui_editor/object_explorer_query.png",
          "docs/assets/mindsdb_gui_editor/query_editor.png",
          "docs/assets/mindsdb_gui_editor/results_viewer.png",
          "docs/assets/mindsdb_gui_respond.png",
          "docs/assets/mindsdb_gui_respond_agents.png"
        ]
      }
    },
    {
      "id": 1159908867,
      "name": "graphrag-rs",
      "displayName": "graphrag rs",
      "description": "GraphRAG-rs is a high-performance, state-of-the-art Rust implementation of GraphRAG (Graph-based Retrieval Augmented Generation) that builds knowledge graphs from documents and enables natural language querying with configurable entity extraction and local LLM integration",
      "summary": "The Problem\n\nRetrieval-Augmented Generation (RAG) is powerful, but most implementations are either glued together Python scripts with questionable performance or SaaS products that lock you into their stack. Need a knowledge graph from your documents? Want to query it using natural language? Oh, and maybe you'd like to run it locally, in your browser, or scale it up to production servers? Good luck. Most solutions fall apart the second you need fine-grained control or care about performance.\n\nWhat This Does\n\nGraphRAG-rs is a Rust implementation of RAG that actually respects your need for speed, modularity, and deployment flexibility. It's split into several components:  \nThe core logic lives in graphrag-core/, handling entity extraction, knowledge graph creation, and query pipelines.  \nFor folks who hate setup, the graphrag-cli/ provides a command-line interface to run queries, test embeddings, or benchmark pipelines.  \nWant to see it in action? Check out examples/graphrag-leptos-demo/ for a WASM-based browser app or examples/multidocumentpipeline.rs for a server-side pipeline.\n\nIt supports three deployment modes: a traditional server (cargo run --bin graphrag-server), a WASM-only client (trunk serve), and a hybrid architecture that combines both. Need GPU acceleration? There's WebGPU support baked in. Prefer local embeddings to keep your data private? Integrate with Ollama or ONNX runtime. It's all configurable via various .toml and .json5 files in config/templates/.\n\nReal-World Use\n\nLet's say you're building a privacy-focused research app. You have a pile of academic papers in PDF format. Using GraphRAG-rs, you can:  \nParse documents and extract entities with graphrag-core/examples/advancednlpdemo.rs.  \nBuild a knowledge graph using the GraphBuilder in graphrag-core/src/builder/mod.rs.  \nServe it in a browser with the WASM-based demo in examples/graphrag-leptos-demo/.  \nRun a query like \"Show connections between quantum mechanics and entropy\" and get meaningful results right in your browser.  \n\nFor extra credit, you can add Ollama for local embeddings or plug in Qdrant for vector search.\n\nThe Bottom Line\n\nGraphRAG-rs is fast, flexible, and overkill (in a good way). If you're hacking together a weekend project, this probably isn't for you. But if you need serious performance, local-first options, and full control over your RAG pipeline, it's worth your time. Just be ready to dig into the docs—this isn't a plug-and-play toy.",
      "url": "https://github.com/moses-y/graphrag-rs",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "automataIA/graphrag-rs",
        "url": "https://github.com/automataIA/graphrag-rs",
        "stars": 198
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 17, 2026",
      "updatedAt": "February 17, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "directories": {
          ".cargo": 1,
          "(root)": 9,
          ".vscode": 1,
          "benches": 7,
          "config": 33,
          "docs-example": 2,
          "examples": 46,
          "graphrag-cli": 32,
          "graphrag-core": 69
        },
        "languages": {
          "TOML": 26,
          "JSON": 2,
          "Markdown": 33,
          "Rust": 97,
          "HTML": 4,
          "Shell": 4,
          "JavaScript": 4,
          "CSS": 1
        },
        "entryPoints": [
          "examples/graphrag-leptos-demo/index.html",
          "examples/graphrag-leptos-demo/src/lib.rs",
          "examples/graphrag-leptos-demo/src/main.rs",
          "examples/wasm-multi-doc-demo/app.js",
          "examples/wasm-multi-doc-demo/index.html",
          "examples/web-app/dist/index.html",
          "examples/web-app/index.html",
          "examples/web-app/src/lib.rs",
          "examples/web-app/src/main.rs",
          "graphrag-cli/src/main.rs"
        ],
        "configFiles": [
          "Cargo.toml",
          "examples/graphrag-leptos-demo/Cargo.toml",
          "examples/web-app/Cargo.toml",
          "graphrag-cli/Cargo.toml",
          "graphrag-core/Cargo.toml"
        ],
        "dependencies": [
          "Cargo.toml",
          "examples/graphrag-leptos-demo/Cargo.toml",
          "examples/web-app/Cargo.toml",
          "graphrag-cli/Cargo.toml",
          "graphrag-core/Cargo.toml"
        ],
        "testFiles": [
          "examples/graphrag-leptos-demo/RUNTIME_TESTING_GUIDE.md",
          "examples/graphrag-leptos-demo/test-helpers.js",
          "examples/symposium_test.rs",
          "examples/test_multi_doc_server.sh",
          "examples/test_real_embeddings.rs",
          "graphrag-core/src/api/tests.rs",
          "graphrag-core/src/caching_test.rs"
        ],
        "docs": [
          "CHANGELOG.md",
          "README.md",
          "config/JSON5_CONFIG_GUIDE.md",
          "config/templates/README.md",
          "docs-example/Readme-First.txt",
          "examples/graphrag-leptos-demo/README.md",
          "examples/graphrag-leptos-demo/RUNTIME_TESTING_GUIDE.md",
          "examples/readme.jpg",
          "examples/wasm-multi-doc-demo/README.md",
          "examples/web-app/README.md",
          "graphrag-cli/README.md",
          "graphrag-cli/USER_GUIDE.md",
          "graphrag-core/README.md",
          "graphrag-core/examples/README_symposium_trait_based_chunking.md"
        ]
      }
    },
    {
      "id": 1159890860,
      "name": "spacebot",
      "displayName": "spacebot",
      "description": "An AI agent for teams, communities, and multi-user environments.",
      "summary": "The Problem\nMost AI frameworks stall when faced with multiple users. You ask a question, and the AI goes quiet while it processes. This single-threaded approach can’t keep up in busy environments like Discord or Slack, where people expect instant responses. It’s frustrating when you're waiting for an AI to think while your teammates keep chatting.\n\nWhat This Does\nSpacebot flips the script. It splits tasks into specialized processes so that conversations can happen concurrently without blocking. Check out the interface/src/App.tsx for the entry point, where it initializes multiple user interactions. The interface/src/hooks contains hooks like useCortexChat that manage chat states independently, allowing simultaneous conversations without a hitch.\n\nWant to run multiple agents? The setup in docs/content/docs/(features)/multi-agent.mdx explains how to deploy a friendly Discord bot alongside a no-nonsense dev assistant in Slack—all under one umbrella. Each agent operates with its own memory and identity, thanks to the architecture in interface/src/lib.\n\nReal-World Use\nImagine a chaotic Discord server where five users are throwing questions at the bot. Thanks to Spacebot's batching system, it can coalesce those messages and respond intelligently. For example, using the ChannelDetail.tsx component, it can provide context-specific answers without losing track of ongoing conversations. \n\nIf you're coding in a Slack channel, Spacebot can handle long-running tasks via workers, letting other users ask quick questions in parallel. The interface/src/routes/AgentConfig.tsx manages agent settings, allowing quick adjustments on the fly.\n\nThe Bottom Line\nSpacebot is a solid choice for teams and communities that need an AI that doesn't go dark while processing tasks. It’s a bit heavy for small projects—if you’re just looking for a simple Q&A bot for personal use, this might be overkill. But for larger groups where multiple conversations are the norm, this setup could save a lot of frustration.",
      "url": "https://github.com/moses-y/spacebot",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "spacedriveapp/spacebot",
        "url": "https://github.com/spacedriveapp/spacebot",
        "stars": 1421
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 17, 2026",
      "updatedAt": "February 17, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "directories": {
          "(root)": 12,
          ".github": 3,
          "docs": 64,
          "interface": 80,
          "migrations": 14,
          "prompts": 27
        },
        "languages": {
          "YAML": 2,
          "Markdown": 16,
          "TOML": 2,
          "Rust": 1,
          "Shell": 1,
          "TSX": 66,
          "TypeScript": 16,
          "CSS": 1,
          "JSON": 14,
          "HTML": 1,
          "JavaScript": 1,
          "SCSS": 2,
          "SQL": 14
        },
        "entryPoints": [
          "interface/index.html",
          "interface/src/App.tsx",
          "interface/src/ui/forms/index.ts",
          "interface/src/ui/index.ts"
        ],
        "configFiles": [
          "Cargo.toml",
          "Dockerfile",
          "docs/next.config.mjs",
          "docs/package.json",
          "docs/tsconfig.json",
          "interface/package.json",
          "interface/tailwind.config.ts",
          "interface/tsconfig.json",
          "interface/vite.config.ts"
        ],
        "dependencies": [
          "Cargo.toml",
          "docs/package.json",
          "interface/package-lock.json",
          "interface/package.json"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md",
          "RUST_STYLE_GUIDE.md",
          "docs/.gitignore",
          "docs/README.md",
          "docs/app/[[...slug]]/layout.tsx",
          "docs/app/[[...slug]]/page.tsx",
          "docs/app/api/search/route.ts",
          "docs/app/global.css",
          "docs/app/layout.tsx",
          "docs/app/llms-full.txt/route.ts",
          "docs/app/llms.mdx/docs/[[...slug]]/route.ts",
          "docs/app/llms.txt/route.ts",
          "docs/app/og/docs/[...slug]/route.tsx",
          "docs/biome.json",
          "docs/components/ai/page-actions.tsx",
          "docs/content/docs/(configuration)/config.mdx",
          "docs/content/docs/(configuration)/meta.json",
          "docs/content/docs/(configuration)/permissions.mdx",
          "docs/content/docs/(core)/agents.mdx",
          "docs/content/docs/(core)/channels.mdx",
          "docs/content/docs/(core)/compaction.mdx",
          "docs/content/docs/(core)/cortex.mdx",
          "docs/content/docs/(core)/memory.mdx",
          "docs/content/docs/(core)/meta.json",
          "docs/content/docs/(core)/philosophy.mdx",
          "docs/content/docs/(core)/prompts.mdx",
          "docs/content/docs/(core)/routing.mdx",
          "docs/content/docs/(deployment)/meta.json",
          "docs/content/docs/(deployment)/roadmap.mdx",
          "docs/content/docs/(features)/browser.mdx",
          "docs/content/docs/(features)/cron.mdx",
          "docs/content/docs/(features)/ingestion.mdx",
          "docs/content/docs/(features)/meta.json",
          "docs/content/docs/(features)/opencode.mdx",
          "docs/content/docs/(features)/tools.mdx",
          "docs/content/docs/(features)/workers.mdx",
          "docs/content/docs/(getting-started)/docker.mdx",
          "docs/content/docs/(getting-started)/meta.json",
          "docs/content/docs/(getting-started)/quickstart.mdx",
          "docs/content/docs/(messaging)/discord-setup.mdx",
          "docs/content/docs/(messaging)/messaging.mdx",
          "docs/content/docs/(messaging)/meta.json",
          "docs/content/docs/(messaging)/slack-setup.mdx",
          "docs/content/docs/(messaging)/telegram-setup.mdx",
          "docs/content/docs/index.mdx",
          "docs/content/docs/meta.json",
          "docs/design-docs/branch-and-spawn.md",
          "docs/design-docs/cortex-chat.md",
          "docs/design-docs/cortex-history.md",
          "docs/design-docs/cortex-implementation.md",
          "docs/design-docs/launch-script.md",
          "docs/design-docs/launch-tweet.md",
          "docs/design-docs/production-worker-failures.md",
          "docs/design-docs/prompt-routing.md",
          "docs/design-docs/user-scoped-memories.md",
          "docs/docker.md",
          "docs/lib/cn.ts",
          "docs/lib/layout.shared.tsx",
          "docs/lib/source.ts",
          "docs/mdx-components.tsx",
          "docs/next.config.mjs",
          "docs/package.json",
          "docs/pnpm-lock.yaml",
          "docs/postcss.config.mjs",
          "docs/source.config.ts",
          "docs/tsconfig.json"
        ]
      }
    },
    {
      "id": 1159778456,
      "name": "VerseCrafter",
      "displayName": "VerseCrafter",
      "description": "VerseCrafter: Dynamic Realistic Video World Model with 4D Geometric Control",
      "summary": "The Problem\n\nWorking with video generation that actually respects camera motion and object trajectories sucks. Most video diffusion models spit out pretty clips, but as soon as you want to control the camera path or object movement—forget it. You end up with janky results, or you hack together some control system that barely works. If you want real, direct geometric control over both camera and multiple objects, you’re out of luck with almost everything out there.\n\nWhat This Does\n\nVerseCrafter gives you explicit 4D geometric control over video generation—camera motion, object motion, and their interaction. The key magic lives in versecrafter/pipeline/pipelinewanversecrafter.py where the pipeline wires up a frozen Wan2.1 video diffusion backbone and then injects geometry via a GeoAdapter. Everything related to 4D control—camera paths, 3D Gaussian object motion—is handled through JSON and NPZ files (see demodata/ and config/).\n\nYou get Blender integration (blenderaddon/) for hands-on editing and trajectory export, plus a pile of scripts in inference/ for fitting Gaussians (fit3Dgaussian.py), running segmentation (groundedsam2infer.py), and full pipeline inference (versecrafterinference.py). The project isn’t hiding the data: check demodata/ for real examples, from camera paths to rendered videos and masks.\n\nReal-World Use\n\nSay you want to generate a street scene where the camera orbits a car and a person walks across the frame. You’d prep your control files (camera path as an NPZ, object trajectories as JSONs). Then you’d run something like:\n\npython inference/versecrafterinference.py --config config/wan2.1/wancivitai.yaml \\\n  --camera-trajectory demodata/.../customcameratrajectory.npz \\\n  --object-trajectories demodata/.../custom3Dgaussiantrajectory.json\n\nEdit anything in Blender (using the blenderaddon), re-export, and re-run. All your outputs—depths, masks, videos—land in demo_data/ for inspection. No black box nonsense.\n\nThe Bottom Line\n\nIf you actually need precise camera and object motion control in video generation, VerseCrafter is one of the few open options that doesn’t lie to you about what’s possible. It’s fiddly to set up, eats VRAM for breakfast, and isn’t for quick experiments—but if you want explicit geometry in your video synthesis, this is the toolkit. If you just want pretty TikTok clips, look elsewhere.",
      "url": "https://github.com/moses-y/VerseCrafter",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "TencentARC/VerseCrafter",
        "url": "https://github.com/TencentARC/VerseCrafter",
        "stars": 316
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 17, 2026",
      "updatedAt": "February 17, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "directories": {
          "(root)": 9,
          "asset": 17,
          "blender_addon": 4,
          "config": 8,
          "demo_data": 47,
          "inference": 7,
          "versecrafter": 6
        },
        "languages": {
          "Markdown": 2,
          "Python": 19,
          "YAML": 5,
          "JSON": 7,
          "Shell": 1
        },
        "entryPoints": [],
        "configFiles": [
          "requirements.txt"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md",
          "README_BLENDER.md"
        ]
      }
    },
    {
      "id": 1159567990,
      "name": "pinchtab",
      "displayName": "pinchtab",
      "description": "No description available",
      "summary": "The Problem\n\nBrowser automation for AI agents is a hot mess. Most tools are either tightly coupled to their own frameworks (hi, OpenClaw, Playwright), or they rely on heavy solutions like full-page screenshots or bloated DOM snapshots that rack up token usage and costs. If you want something lightweight, framework-agnostic, and easy to integrate with your existing setup, you’re usually out of luck. \n\nWhat This Does\n\npinchtab is a self-contained, 12MB Go binary that spins up an HTTP server and a Chrome instance for browser automation. No external dependencies, no bloated frameworks. It’s designed for AI agents but works with anything that can make HTTP requests — even curl.\n\nThe magic happens in main.go, which initializes the HTTP server and Chrome bridge. The file bridge.go sets up the communication between the server and Chrome, leveraging Chrome DevTools Protocol (CDP) to interact with web pages. Key files like handlers.go and handler_snapshot.go handle API routes, such as GET /snapshot for accessibility trees or POST /action for interactions like clicks and typing.\n\nThe project is packed with thoughtful features: intelligent text extraction (/text endpoint), stealth mode (stealth.js spoofs bot detection signals), and persistent sessions stored at ~/.pinchtab/chrome-profile. If you’re tired of logging in every time you restart your browser tool, this one’s got you covered.\n\nOh, and it’s dirt cheap on token usage. Instead of dumping the entire DOM, Pinchtab’s /text endpoint extracts clean, readable content — up to 13x fewer tokens compared to full snapshots.\n\nReal-World Use\n\nLet’s say you’re building an AI agent that needs to scrape product listings and click “Add to Cart” buttons. Here’s how you’d do it with pinchtab:\nFire up the server:\n   bash\n   ./pinchtab\n   \nOpen Chrome, log in to your site, and let Pinchtab handle session persistence.\nUse the /snapshot API to grab a structured accessibility tree:\n   bash\n   curl localhost:9867/snapshot?filter=interactive\n   \nFind the button’s reference ID and tell Pinchtab to click it:\n   bash\n   curl -X POST localhost:9867/action -d '{\"kind\":\"click\",\"ref\":\"e5\"}'\n   \n\nNo fancy SDKs or vendor lock-in. Just clean HTTP calls.\n\nThe Bottom Line\n\npinchtab is like the Swiss Army knife of browser automation: simple, efficient, and versatile. It’s perfect for developers who want lightweight tools that don’t dictate how you should build your system. The trade-off? It’s not a feature circus like Playwright, so if you need deep browser testing or hyper-specific actions, look elsewhere. But for AI-driven browser tasks? It’s a steal.",
      "url": "https://github.com/moses-y/pinchtab",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "pinchtab/pinchtab",
        "url": "https://github.com/pinchtab/pinchtab",
        "stars": 1384
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 16, 2026",
      "updatedAt": "February 16, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "directories": {
          "(root)": 33,
          ".githooks": 1,
          ".github": 3,
          "assets": 6,
          "docs": 1,
          "scripts": 6,
          "skill": 1
        },
        "languages": {
          "YAML": 5,
          "Markdown": 10,
          "Go": 16,
          "JavaScript": 2,
          "Shell": 3
        },
        "entryPoints": [
          "main.go"
        ],
        "configFiles": [
          "Dockerfile",
          "docker-compose.yml",
          "go.mod"
        ],
        "dependencies": [
          "go.mod"
        ],
        "testFiles": [
          "QA-RETEST.md",
          "bridge_test.go",
          "config_test.go",
          "handler_test.go",
          "middleware_test.go",
          "snapshot_test.go"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "THIRD_PARTY_LICENSES.md",
          "docs/docker.md",
          "scripts/README.md"
        ]
      }
    },
    {
      "id": 1159567671,
      "name": "visual-explainer",
      "displayName": "visual explainer",
      "description": "Agent skill + prompt templates that generate rich HTML pages for visual diff reviews, architecture overviews, plan audits, data tables, and project recaps",
      "summary": "The Problem\nTerminal output is a pain when you need to visualize complex systems. You ask your agent to generate a diagram or compare requirements, and you’re greeted with a mess of ASCII art or, worse, a wall of pipes and dashes. This works for trivial cases, but once you hit anything moderately complex, it becomes unreadable. You might as well be reading hieroglyphics.\n\nWhat This Does\nEnter visual-explainer, a skill that transforms your terminal's dry output into elegant HTML pages. It lives in the prompts/ directory with handy templates like diff-review.md and plan-review.md. When you run commands like /diff-review, it generates a full HTML page that includes everything from architecture diagrams to KPI dashboards. You don’t need a build step, and it works straight out of the box—just clone the repo into your agent's skills directory.\n\nThe templates in the prompts/ folder are straightforward. For example, the command /plan-review compares a plan against your codebase, complete with risk assessments and context for future reference. Output files go into ~/.agent/diagrams/, so you can review them later without having to wrestle with terminal scrollback.\n\nReal-World Use\nImagine you’re reviewing a feature branch against main. You simply run the command:\n\n/diff-review\n\nThe agent generates an HTML page that shows a neat before-and-after view of your architecture, highlights good and bad code, and even provides a decision log with confidence indicators. You can then share this with your team instead of sending them a screenshot of a terminal window that looks like a cat walked across your keyboard.\n\nThe Bottom Line\nvisual-explainer is a solid solution for anyone who regularly deals with complex terminal outputs. It’s particularly useful for teams that need to present their work clearly and concisely. However, if your projects are small and simple, this might feel like overkill. Overall, it’s a practical tool that turns your agent into a capable visual assistant without the hassle of additional dependencies. Give it a shot if you've ever cursed at your terminal's output.",
      "url": "https://github.com/moses-y/visual-explainer",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "nicobailon/visual-explainer",
        "url": "https://github.com/nicobailon/visual-explainer",
        "stars": 3367
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 16, 2026",
      "updatedAt": "February 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "directories": {
          "(root)": 6,
          "prompts": 5,
          "references": 3,
          "templates": 3
        },
        "languages": {
          "Markdown": 11,
          "HTML": 3
        },
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "CHANGELOG.md",
          "LICENSE",
          "README.md"
        ]
      }
    },
    {
      "id": 1159560064,
      "name": "AI-Trader",
      "displayName": "AI Trader",
      "description": "\"AI-Trader: Can AI Beat the Market?\"  Live Trading Bench: https://ai4trade.ai Tech Report Link: https://arxiv.org/abs/2512.10971",
      "summary": "The Problem\n\nMost AI trading projects are smoke and mirrors: backtests, cherry-picked results, or “simulations” where the only thing real is the hype. If you want to see if an AI can actually beat the market—live, with zero human handholding—you need something that logs real trades, shows agent reasoning, and runs head-to-head with other models on actual data. Good luck finding that in the wild.\n\nWhat This Does\n\nAI-Trader sets up a live battle royale for AI agents in markets like NASDAQ 100, SSE 50, and crypto. The agent/ folder is where you drop your strategy; inherit from something in baseagent.py or baseagentcrypto.py to avoid reinventing the wheel. Configs live in configs/—each JSON file (defaultconfig.json, defaultcryptoconfig.json, etc.) maps your agent to market, interval, and trading specifics. Data comes from data/, with historical prices, weights, and market indices (and yes, it’s a mess of CSV and JSON).\n\nFor actual trading, tools in agenttools/ handle price fetching (toolgetpricelocal.py), crypto orders (toolcryptotrade.py), and even news scraping (toolalphavantagenews.py). Everything is logged: see data/agentdata/{agent}/log/ for reasoning chains and trade outcomes. Want to analyze agent performance? The leaderboard updates live at ai4trade.ai, and you can inspect logs directly.\n\nReal-World Use\n\nSay you have a wild new trading strategy: make a copy of baseagent.py, override the decide() method, and drop your file into agent/. Add a config like myagentconfig.json in configs/. Submit a PR. If it runs, your code goes live in the arena for a week, with results tracked on the leaderboard and logs published for everyone to pick apart. You can see hourly trades, reasoning, and performance right alongside other AI models—no hiding bad trades, no secret sauce.\n\nThe Bottom Line\n\nIf you want to test AI trading in the real world—warts and all—this is the repo. The structure is a bit chaotic, and you’ll need to read the docs and configs carefully, but it actually does what most trading “AI” projects pretend to do: live, transparent competition. Great for researchers and devs who don’t mind some rough edges. If you’re just dabbling or hate JSON, look elsewhere.",
      "url": "https://github.com/moses-y/AI-Trader",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "HKUDS/AI-Trader",
        "url": "https://github.com/HKUDS/AI-Trader",
        "stars": 11450
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 16, 2026",
      "updatedAt": "February 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "directories": {
          "(root)": 7,
          ".github": 1,
          "agent": 7,
          "agent_tools": 7,
          "assets": 3,
          "configs": 9,
          "data": 166
        },
        "languages": {
          "YAML": 1,
          "Markdown": 5,
          "Python": 21,
          "JSON": 62
        },
        "entryPoints": [],
        "configFiles": [
          ".env.example"
        ],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md",
          "README_CN.md",
          "configs/README.md",
          "configs/README_zh.md"
        ]
      }
    },
    {
      "id": 1159559244,
      "name": "zvec",
      "displayName": "zvec",
      "description": "A lightweight, lightning-fast, in-process vector database",
      "summary": "In-Process Vector Search with Zvec  \n\nThe Problem  \nMost vector databases are overkill for lightweight use cases. You want fast vector search embedded right into your app, but the usual suspects—like Pinecone or Milvus—make you spin up servers, manage clusters, and deal with scaling headaches. What if you just want to search a few million vectors locally without the ops overhead? That’s where zvec comes in.  \n\nWhat This Does  \nzvec is an in-process vector database that lets you embed blazing-fast similarity search directly into your codebase. No servers, no containers, no nonsense—just import the library and go. The repo structure tells you how it works:  \nCore Search Logic: Found in src/ailego/. This is where the heavy lifting happens—distance calculations, matrix operations, and quantization algorithms. It’s all written in C++ for speed, because Python just doesn’t cut it here.  \nPython Bindings: Located in src/binding/python/. These files glue the C++ backend to Python, exposing APIs like zvec.createandopen and zvec.CollectionSchema.  \nExamples: The examples/c++/ folder has some starter code for C++ usage, but let’s be real—most folks are here for Python.  \n\nIt supports dense and sparse vectors, multi-vector queries, and even hybrid search (semantic + filters). The Python API is clean and intuitive, making it painless to set up and start searching.  \n\nReal-World Use  \nLet’s say you’re building a local recommendation engine for your app. Instead of spinning up a full-blown vector database, you can use zvec like this:  \n\nimport zvec  \n\nDefine schema  \nschema = zvec.CollectionSchema(  \n    name=\"localrecengine\",  \n    vectors=zvec.VectorSchema(\"embedding\", zvec.DataType.VECTORFP32, 128),  \n)  \n\nCreate collection  \ncollection = zvec.createandopen(path=\"./recdata\", schema=schema)  \n\nInsert data  \ncollection.insert([  \n    zvec.Doc(id=\"item1\", vectors={\"embedding\": [0.1, 0.2, ...]}),  \n    zvec.Doc(id=\"item2\", vectors={\"embedding\": [0.3, 0.4, ...]}),  \n])  \n\nQuery similar items  \nresults = collection.query({\"embedding\": [0.15, 0.25, ...]}, top_k=5)  \nfor result in results:  \n    print(result.id, result.score)  \n\nNo cluster setup. No network latency. Just fast, local vector search.  \n\nThe Bottom Line  \nzvec is a sharp tool for developers who need fast, lightweight vector search without infrastructure headaches. It’s perfect for local apps, prototypes, and edge deployments, but it might struggle with massive, distributed workloads—stick with Milvus for that. The codebase is well-organized and leans on solid C++ fundamentals, but Python users might feel the lack of higher-level abstractions. For the right use case, though, this is a no-brainer.",
      "url": "https://github.com/moses-y/zvec",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "alibaba/zvec",
        "url": "https://github.com/alibaba/zvec",
        "stars": 8175
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 16, 2026",
      "updatedAt": "February 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "directories": {
          "(root)": 10,
          ".github": 15,
          "cmake": 3,
          "examples": 4,
          "python": 60,
          "scripts": 2,
          "src": 106
        },
        "languages": {
          "YAML": 15,
          "Markdown": 4,
          "TOML": 1,
          "Python": 55,
          "Shell": 1,
          "C/C++ Header": 46,
          "C": 1
        },
        "entryPoints": [],
        "configFiles": [
          ".github/workflows/docker/Dockerfile.linux_x64_glibc228",
          "CMakeLists.txt",
          "examples/c++/CMakeLists.txt",
          "pyproject.toml",
          "src/CMakeLists.txt",
          "src/ailego/CMakeLists.txt",
          "src/binding/CMakeLists.txt",
          "src/binding/python/CMakeLists.txt"
        ],
        "dependencies": [
          "pyproject.toml"
        ],
        "testFiles": [
          ".github/workflows/build_test_wheel.yml",
          "python/tests/detail/distance_helper.py",
          "python/tests/detail/doc_helper.py",
          "python/tests/detail/fixture_helper.py",
          "python/tests/detail/params_helper.py",
          "python/tests/detail/support_helper.py",
          "python/tests/detail/test_collection_concurrency.py",
          "python/tests/detail/test_collection_create_and_open.py",
          "python/tests/detail/test_collection_ddl.py",
          "python/tests/detail/test_collection_dml.py",
          "python/tests/detail/test_collection_dql.py",
          "python/tests/detail/test_collection_exception.py",
          "python/tests/detail/test_collection_open.py",
          "python/tests/detail/test_db_config.py",
          "python/tests/test_collection.py",
          "python/tests/test_convert.py",
          "python/tests/test_doc.py",
          "python/tests/test_embedding.py",
          "python/tests/test_params.py",
          "python/tests/test_query_executor.py",
          "python/tests/test_reranker.py",
          "python/tests/test_schema.py",
          "python/tests/test_typing.py",
          "python/tests/test_util.py"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "scripts/README.md"
        ]
      }
    },
    {
      "id": 1159558387,
      "name": "accomplish",
      "displayName": "accomplish",
      "description": "Accomplish™ (formerly Openwork) is the open source Al coworker that lives on your desktop",
      "summary": "The Problem\nManaging files, creating documents, and automating mundane tasks can be a real hassle. You know the drill: endless file sorting, document writing that eats up your time, and the constant need to connect different tools. It's frustrating when you need to shift gears between apps just to get simple tasks done. Enter Accomplish™—your AI assistant that keeps everything on your desktop.\n\nWhat This Does\nAccomplish acts like a local AI coworker that automates your day-to-day tasks. It’s not just about chatting; it’s about taking action. You can find the core functionality in apps/desktop/src/main/opencode/index.ts, which handles the main operations. The apps/desktop/src/main/services/summarizer.ts file can help you quickly summarize documents, while the file management features are all over the apps/desktop/src/main/opencode/config-generator.ts.\n\nYou have the freedom to set rules for file management directly in the app's settings, and it uses your own API keys, meaning your data stays local. No more worrying about privacy with cloud services. Plus, you can define custom skills using the apps/desktop/src/main/skills/SkillsManager.ts, which allows for tailored workflows that fit your unique needs.\n\nReal-World Use\nImagine you have a cluttered folder full of reports that need sorting. Instead of manually renaming and moving files, you could write a simple skill in Accomplish to automate this. Just set up rules based on file content or dates and let the AI handle the dirty work. For example, you could create a skill that moves all reports older than a month into an archive folder, triggered by a simple command. \n\nconst moveOldReports = new Skill({\n  name: \"Move Old Reports\",\n  action: () => {\n    // Logic to move files\n  }\n});\n\nThe Bottom Line\nAccomplish is a solid tool for anyone looking to cut down on repetitive tasks without sacrificing privacy. It’s not for everyone—if you’re just doing simple file moves, this might feel like overkill. But for those who juggle multiple projects and tools, it’s a breath of fresh air. Just bring your own API keys and let Accomplish handle the rest.",
      "url": "https://github.com/moses-y/accomplish",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "accomplish-ai/accomplish",
        "url": "https://github.com/accomplish-ai/accomplish",
        "stars": 9020
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 16, 2026",
      "updatedAt": "February 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "directories": {
          ".changeset": 3,
          "(root)": 16,
          ".github": 11,
          "apps": 170
        },
        "languages": {
          "Markdown": 23,
          "JSON": 4,
          "YAML": 9,
          "TypeScript": 73,
          "TSX": 11,
          "Shell": 5,
          "HTML": 1,
          "JavaScript": 1
        },
        "entryPoints": [
          "apps/desktop/e2e/config/index.ts",
          "apps/desktop/e2e/fixtures/index.ts",
          "apps/desktop/e2e/pages/index.ts",
          "apps/desktop/e2e/provider-tests/fixtures/index.ts",
          "apps/desktop/e2e/utils/index.ts",
          "apps/desktop/index.html",
          "apps/desktop/src/main/index.ts",
          "apps/desktop/src/main/logging/index.ts",
          "apps/desktop/src/main/opencode/index.ts",
          "apps/desktop/src/main/providers/index.ts",
          "apps/desktop/src/main/skills/index.ts"
        ],
        "configFiles": [
          "apps/desktop/.eslintrc.json",
          "apps/desktop/e2e/docker/Dockerfile",
          "apps/desktop/e2e/docker/docker-compose.yml",
          "apps/desktop/package.json"
        ],
        "dependencies": [
          "apps/desktop/package.json"
        ],
        "testFiles": [
          "apps/desktop/__tests__/integration/main/opencode/cli-path.integration.test.ts",
          "apps/desktop/__tests__/integration/main/opencode/config-generator.integration.test.ts",
          "apps/desktop/__tests__/integration/main/permission-api.integration.test.ts",
          "apps/desktop/__tests__/integration/main/secureStorage.integration.test.ts",
          "apps/desktop/__tests__/integration/main/taskHistory.integration.test.ts",
          "apps/desktop/__tests__/integration/main/utils/bundled-node.integration.test.ts",
          "apps/desktop/__tests__/integration/main/utils/system-path.integration.test.ts",
          "apps/desktop/__tests__/integration/preload/preload.integration.test.ts",
          "apps/desktop/__tests__/integration/renderer/App.integration.test.tsx",
          "apps/desktop/__tests__/integration/renderer/components/Header.integration.test.tsx",
          "apps/desktop/__tests__/integration/renderer/components/SettingsDialog.integration.test.tsx",
          "apps/desktop/__tests__/integration/renderer/components/Sidebar.integration.test.tsx",
          "apps/desktop/__tests__/integration/renderer/components/StreamingText.integration.test.tsx",
          "apps/desktop/__tests__/integration/renderer/components/TaskHistory.integration.test.tsx",
          "apps/desktop/__tests__/integration/renderer/components/TaskInputBar.integration.test.tsx",
          "apps/desktop/__tests__/integration/renderer/components/TaskLauncher.integration.test.tsx",
          "apps/desktop/__tests__/integration/renderer/pages/Execution.integration.test.tsx",
          "apps/desktop/__tests__/integration/renderer/pages/Home.integration.test.tsx",
          "apps/desktop/__tests__/integration/renderer/taskStore.integration.test.ts",
          "apps/desktop/__tests__/main/config.unit.test.ts",
          "apps/desktop/__tests__/main/ipc/handlers-utils.unit.test.ts",
          "apps/desktop/__tests__/main/ipc/validation.unit.test.ts",
          "apps/desktop/__tests__/renderer/lib/utils.unit.test.ts",
          "apps/desktop/__tests__/setup.ts",
          "apps/desktop/__tests__/unit/main/ipc/handlers.unit.test.ts",
          "apps/desktop/__tests__/unit/main/opencode/adapter.unit.test.ts",
          "apps/desktop/__tests__/unit/main/opencode/auth-browser.unit.test.ts",
          "apps/desktop/__tests__/unit/main/opencode/task-manager.unit.test.ts",
          "apps/desktop/__tests__/unit/renderer/components/BedrockApiKeyTab.unit.test.tsx",
          "apps/desktop/__tests__/unit/renderer/lib/accomplish.unit.test.ts",
          "apps/desktop/__tests__/unit/renderer/lib/animations.unit.test.ts",
          "apps/desktop/__tests__/unit/renderer/lib/waiting-detection.unit.test.ts",
          "apps/desktop/e2e/provider-tests/fixtures/index.ts",
          "apps/desktop/e2e/provider-tests/fixtures/provider-app.ts",
          "apps/desktop/e2e/provider-tests/helpers/ollama-server.ts",
          "apps/desktop/e2e/provider-tests/provider-test-configs.ts",
          "apps/desktop/e2e/provider-tests/secrets-loader.ts",
          "apps/desktop/e2e/provider-tests/secrets.example.json",
          "apps/desktop/e2e/provider-tests/specs/bedrock-api-key.spec.ts",
          "apps/desktop/e2e/provider-tests/specs/google.spec.ts",
          "apps/desktop/e2e/provider-tests/specs/ollama.spec.ts",
          "apps/desktop/e2e/provider-tests/specs/openai.spec.ts",
          "apps/desktop/e2e/provider-tests/types.ts",
          "apps/desktop/e2e/specs/execution.spec.ts",
          "apps/desktop/e2e/specs/home.spec.ts",
          "apps/desktop/e2e/specs/settings-bedrock.spec.ts",
          "apps/desktop/e2e/specs/settings-providers.spec.ts",
          "apps/desktop/e2e/specs/settings.spec.ts",
          "apps/desktop/e2e/specs/task-launch-guard.spec.ts",
          "apps/desktop/scripts/test-local-agent-cli.ts",
          "apps/desktop/scripts/test-local-agent-config.ts"
        ],
        "docs": [
          ".changeset/README.md",
          "CONTRIBUTING.md",
          "LICENSE",
          "README.ar.md",
          "README.es.md",
          "README.id.md",
          "README.ja.md",
          "README.ko.md",
          "README.md",
          "README.tr.md",
          "README.zh-CN.md",
          "apps/desktop/e2e/README.md"
        ]
      }
    },
    {
      "id": 1159544956,
      "name": "droidclaw",
      "displayName": "droidclaw",
      "description": "turn old phones into ai agents - give it a goal in plain english. it reads the screen, thinks about what to do, taps and types via adb, and repeats until the job is done. ",
      "summary": "Turning Old Phones Into AI Agents with droidclaw\n\nThe Problem  \nWe all have old Android phones lying around, and most of the time, they’re just gathering dust. They could be doing something useful, but setting up automation on these devices has always been a nightmare. You either need a million APIs, deal with janky tools, or write custom scripts for every little task. And even then, you’re stuck with rigid, predefined workflows that break as soon as an app updates its UI. What if you could just tell your phone what to do, and it would figure it out?\n\nWhat This Does  \ndroidclaw is a DIY tool that turns your old Android devices into AI-powered task runners. You give it a goal in plain English, and it reads the screen via accessibility APIs, uses a large language model (LLM) to decide what to do, and then performs actions (taps, swipes, typing) via ADB. No more hardcoding every single interaction.  \n\nAt its core, the magic happens in src/kernel.ts — the brains of the operation. It loops through a cycle of think (ask the LLM what the goal requires), act (send ADB commands like input tap or input text), and repeat until the task is done. If you need reusable automations, you can use JSON-based workflows (see examples/workflows) or YAML flows (see examples/flows).  \n\nYou can run it with just:  \n\nbun run src/kernel.ts\n\nThen, type a goal like \"open Instagram and like the first post\" — and watch your phone do the thing.\n\nReal-World Use  \nImagine you want to send a message to your team on Slack every morning with your daily standup update. Instead of fumbling with Slack’s API (ugh) or manually typing it in, you use the examples/workflows/messaging/slack-standup.json:  \n\n{\n  \"name\": \"slack standup\",\n  \"steps\": [\n    {\n      \"app\": \"com.Slack\",\n      \"goal\": \"open #standup channel, type the message and send it\",\n      \"formData\": { \"Message\": \"yesterday: fixed bugs\\ntoday: refactor tests\\nblockers: none\" }\n    }\n  ]\n}\n\nRun it with:  \n\nbun run src/kernel.ts --workflow examples/workflows/messaging/slack-standup.json\n\nDone. No APIs, no manual inputs, no wasted time.\n\nThe Bottom Line  \ndroidclaw is ridiculously cool if you’re into automation and have a spare Android lying around. It’s experimental, sure, and you’ll need some patience (and a willingness to debug when it screws up). But for hackers and tinkerers, this is a playground. If you’re expecting a polished, GUI-driven experience, look elsewhere. For everyone else: just install bun, fire up adb, and turn your phone into a little AI butler.",
      "url": "https://github.com/moses-y/droidclaw",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "unitedbyai/droidclaw",
        "url": "https://github.com/unitedbyai/droidclaw",
        "stars": 1025
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 16, 2026",
      "updatedAt": "February 16, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "directories": {
          "(root)": 7,
          "docs": 3,
          "examples": 42,
          "site": 2,
          "src": 10
        },
        "languages": {
          "Markdown": 5,
          "YAML": 5,
          "JSON": 39,
          "HTML": 1,
          "Shell": 1,
          "TypeScript": 11
        },
        "entryPoints": [
          "site/index.html"
        ],
        "configFiles": [
          ".env.example",
          "package.json",
          "tsconfig.json"
        ],
        "dependencies": [
          "package.json"
        ],
        "testFiles": [
          "test-ollama.ts"
        ],
        "docs": [
          "README.md",
          "docs/adb-commands.md",
          "docs/capabilities-and-limitations.md",
          "docs/use-cases.md"
        ]
      }
    },
    {
      "id": 1159366394,
      "name": "computer-agent",
      "displayName": "computer agent",
      "description": "Desktop app to control your computer with AI using your terminal, browser, mouse & keyboard",
      "summary": "AI on Your Desktop: Meet computer-agent\n\nThe Problem  \nEver wanted to automate mundane tasks on your computer without writing a ton of scripts? Maybe you’ve dreamt of yelling at your machine to “reply to that email” while you sip coffee—but instead, you’re stuck manually clicking and typing like it’s 2007. Sure, there are browser extensions and automation tools, but most don’t touch your actual desktop. What if you could slap some AI onto that problem and let it take over both your browser and your computer?  \n\nWhat This Does  \ncomputer-agent is like your lazy coworker that you can boss around—only it actually listens. It’s a desktop app built with Tauri (Rust + Web tech) that turns an AI into your personal assistant. You give it natural language commands and it’ll do everything from typing in your terminal to moving your mouse.  \n\nThe guts of this project live in src-tauri/. Files like src-tauri/src/agent.rs and src-tauri/src/computer.rs handle the heavy lifting for desktop control. For browser automation, it leans on the Chrome DevTools Protocol, wired up in src-tauri/src/browser.rs. Want background mode instead of full desktop takeover? That’s handled via async APIs in Rust (tokio powers this).  \n\nThe frontend is TypeScript-based and lives in src/. Files like src/MainWindow.tsx and src/components/VoiceOrb.tsx build the interface for push-to-talk commands. It’s styled with Tailwind, so you get clean, modern vibes instead of 90s WinForms energy.  \n\nReal-World Use  \nHere’s how it works: imagine you need to bulk reply to tweets with “lol” (why? I don’t know, maybe you’re a bot). You’d hit the shortcut ⌃⇧B (Background Mode) and instruct the agent to open Twitter, find unread DMs, and reply. Behind the scenes, it uses browser automation (src-tauri/src/browser.rs) to click through the interface. If you’re feeling fancy, you can switch to Computer Use Mode (⌃⇧C) to let it take over your desktop directly.  \n\nNeed something more hands-on? You can write custom Rust handlers in files like src-tauri/src/api.rs or tweak the JSON configs in src-tauri/capabilities/default.json.  \n\nThe Bottom Line  \ncomputer-agent is ambitious—and impressive—but probably overkill for simple automation. It shines in scenarios where you need a mix of browser and desktop control, like managing multi-app workflows or running scripts while you’re hands-off. If you’re comfortable with Rust and React, it’s worth a shot. For everyone else? Maybe stick to your Bash scripts.",
      "url": "https://github.com/moses-y/computer-agent",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "suitedaces/computer-agent",
        "url": "https://github.com/suitedaces/computer-agent",
        "stars": 591
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 16, 2026",
      "updatedAt": "February 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "directories": {
          "(root)": 11,
          "public": 2,
          "src-tauri": 22,
          "src": 14
        },
        "languages": {
          "Markdown": 1,
          "HTML": 1,
          "JSON": 6,
          "JavaScript": 2,
          "TOML": 1,
          "Rust": 13,
          "TSX": 8,
          "TypeScript": 6,
          "CSS": 1
        },
        "entryPoints": [
          "index.html",
          "src-tauri/src/lib.rs",
          "src-tauri/src/main.rs",
          "src/types/index.ts"
        ],
        "configFiles": [
          "package.json",
          "src-tauri/Cargo.toml",
          "tailwind.config.js",
          "tsconfig.json",
          "vite.config.ts"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json",
          "src-tauri/Cargo.toml"
        ],
        "testFiles": [
          "src-tauri/examples/test_browser.rs"
        ],
        "docs": [
          "LICENSE",
          "README.md"
        ]
      }
    },
    {
      "id": 1159335967,
      "name": "ia-agents",
      "displayName": "ia agents",
      "description": "No description available",
      "summary": "The Problem\nBuilding intelligent agents that can handle complex interactions, especially in multi-turn conversations, can be a nightmare. You want a framework that handles state, allows for tool integration, and lets you customize behavior without reinventing the wheel. Enter the ia-agents repository, which wraps the Gemini Interactions API in a more manageable package.\n\nWhat This Does\nThe ia-agents repo offers a minimalistic agent framework designed to simplify the creation and management of agents. Key files include packages/agent/src/index.ts and packages/agents-core/src/index.ts, where the core logic resides. The framework features a Streaming Agent Loop that supports multi-modal interactions. It uses a hooks system to allow you to intercept lifecycle events—check out packages/agent/src/hooks/index.ts for the available hooks. \n\nTool calling is straightforward; you define tools in JSON Schema, and the framework executes them. If you want to block specific commands (like rm -rf), the beforeToolExecute hook lets you do just that. Check out the example in examples/agent-with-hooks.ts for a practical use case.\n\nReal-World Use\nImagine you're developing a chat application that needs to execute user commands but also filter out dangerous ones. You can set up an agent using the createAgentSession method from @philschmid/agent, register your tools, and implement a blocking mechanism for harmful commands. Here's a quick example:\n\nconst session = createAgentSession({\n  model: 'gemini-3-flash-preview',\n  tools: ['read', 'bash'],\n});\n\nsession.on('beforeToolExecute', (event) => {\n  if (event.toolName === 'bash' && event.arguments.command.includes('rm -rf')) {\n    return { allow: false, reason: 'Destructive command blocked' };\n  }\n  return { allow: true };\n});\n\nThe Bottom Line\nia-agents is a solid choice for developers looking to build intelligent agents without the headache of handling everything from scratch. The modular approach with agents-core and agent packages allows for flexibility, but you might find it overkill for simple projects. If you need a lightweight solution with powerful capabilities, give it a shot. Just be ready to dive into TypeScript if you’re not already familiar.",
      "url": "https://github.com/moses-y/ia-agents",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "philschmid/ia-agents",
        "url": "https://github.com/philschmid/ia-agents",
        "stars": 23
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 16, 2026",
      "updatedAt": "February 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "directories": {
          ".agent": 20,
          ".github": 1,
          "(root)": 9,
          "docs": 37,
          "examples": 15,
          "packages": 74
        },
        "languages": {
          "Markdown": 27,
          "YAML": 1,
          "JSON": 11,
          "TypeScript": 80,
          "CSS": 1,
          "Shell": 2
        },
        "entryPoints": [
          "examples/cli.ts",
          "packages/agent/src/cli.ts",
          "packages/agent/src/hooks/index.ts",
          "packages/agent/src/index.ts",
          "packages/agent/src/load_artifacts/index.ts",
          "packages/agent/src/prompts/index.ts",
          "packages/agent/src/tools/apply-patch/index.ts",
          "packages/agent/src/tools/bash/index.ts",
          "packages/agent/src/tools/grep/index.ts",
          "packages/agent/src/tools/index.ts",
          "packages/agent/src/tools/list-directory/index.ts",
          "packages/agent/src/tools/planning/index.ts",
          "packages/agent/src/tools/read-file/index.ts",
          "packages/agent/src/tools/skills/index.ts",
          "packages/agent/src/tools/sleep/index.ts",
          "packages/agent/src/tools/subagent/index.ts",
          "packages/agent/src/tools/websearch/index.ts",
          "packages/agent/src/tools/write-file/index.ts",
          "packages/agents-core/src/index.ts"
        ],
        "configFiles": [
          "docs/package.json",
          "docs/tailwind.config.mjs",
          "docs/tsconfig.json",
          "examples/package.json",
          "package.json",
          "packages/agent/package.json",
          "packages/agent/tsconfig.json",
          "packages/agents-core/package.json",
          "packages/agents-core/tsconfig.json",
          "tsconfig.json"
        ],
        "dependencies": [
          "docs/package.json",
          "examples/package.json",
          "package.json",
          "packages/agent/package.json",
          "packages/agents-core/package.json"
        ],
        "testFiles": [
          ".agent/workflows/test-and-fix.md",
          "examples/test.ts",
          "packages/agent/test/config.test.ts",
          "packages/agent/test/context.test.ts",
          "packages/agent/test/hooks.test.ts",
          "packages/agent/test/load_artifacts.test.ts",
          "packages/agent/test/session.test.ts",
          "packages/agent/test/tools.test.ts",
          "packages/agent/test/wrap-tools.test.ts",
          "packages/agents-core/test/agent-loop.test.ts",
          "packages/agents-core/test/config.test.ts",
          "packages/agents-core/test/debug.test.ts",
          "packages/agents-core/test/e2e.test.ts",
          "packages/agents-core/test/event-stream.test.ts",
          "packages/agents-core/test/formatter.test.ts",
          "packages/agents-core/test/tool.test.ts",
          "packages/agents-core/test/transform-context.test.ts"
        ],
        "docs": [
          ".agent/skills/docs-writer/references/style-guide.md",
          ".agent/skills/self-learning/references/skill_creation_guide.md",
          "CHANGELOG.md",
          "LICENSE",
          "README.md",
          "docs/.gitignore",
          "docs/astro.config.mjs",
          "docs/bun.lock",
          "docs/package.json",
          "docs/public/favicon.svg",
          "docs/src/components/CodeTabs.astro",
          "docs/src/components/CopyPageButton.astro",
          "docs/src/components/Expandable.astro",
          "docs/src/components/Hero.astro",
          "docs/src/components/Logo.astro",
          "docs/src/components/PageSidebar.astro",
          "docs/src/components/PageTitle.astro",
          "docs/src/components/Title.astro",
          "docs/src/components/callouts/Note.astro",
          "docs/src/components/callouts/Tip.astro",
          "docs/src/components/callouts/Warning.astro",
          "docs/src/content.config.ts",
          "docs/src/content/docs/concepts/agent-loop.mdx",
          "docs/src/content/docs/concepts/built-in-tools.mdx",
          "docs/src/content/docs/concepts/hooks.mdx",
          "docs/src/content/docs/concepts/session.mdx",
          "docs/src/content/docs/concepts/skills.mdx",
          "docs/src/content/docs/concepts/subagents.mdx",
          "docs/src/content/docs/concepts/tools.mdx",
          "docs/src/content/docs/guides/cli.mdx",
          "docs/src/content/docs/guides/configuration.mdx",
          "docs/src/content/docs/guides/streaming.mdx",
          "docs/src/content/docs/guides/tool-calling.mdx",
          "docs/src/content/docs/index.mdx",
          "docs/src/content/docs/packages/agent.mdx",
          "docs/src/content/docs/packages/agents-core.mdx",
          "docs/src/content/docs/quickstart.mdx",
          "docs/src/examples/agent.ts",
          "docs/src/examples/agents-core.ts",
          "docs/src/styles/global.css",
          "docs/tailwind.config.mjs",
          "docs/tsconfig.json",
          "packages/agent/README.md",
          "packages/agents-core/README.md"
        ]
      }
    },
    {
      "id": 1159219718,
      "name": "claude-brain",
      "displayName": "claude brain",
      "description": "Give Claude Code photographic memory in ONE portable file. No database, no SQLite, no ChromaDB - just a single .mv2 file you can git commit, scp, or share. Native Rust core with sub-ms operations.",
      "summary": "The Problem\n\nClaude Code is smart, but its memory is a joke. You can have a 200K context window and still lose every decision, bugfix, or dumb Slack argument between sessions. It’s like paying for an AI intern who forgets everything by morning. If you want persistent memory without duct-taping a database, you’re out of luck.\n\nWhat This Does\n\nclaude-brain fixes this with one file: .claude/mind.mv2. No databases, no cloud, no API keys, no “just spin up a Postgres instance.” The core is native Rust for speed—sub-millisecond searches, even with thousands of memories. The guts live in src/core/mind.ts and the CLI hooks are in src/scripts/. Want to see what gets injected? Check src/hooks/session-start.ts and src/hooks/post-tool-use.ts. Every memory, decision, and bug is auto-captured and versionable. You can literally git commit your AI’s brain and hand it to a new teammate.\n\nReal-World Use\n\nYou’re halfway through a project, and the auth bug comes back. Instead of slamming your head on the desk, you run /mind search \"auth\" in Claude Code. It pulls up every relevant fix, decision, and Slack rant, instantly. Or, if you’re a CLI junkie, memvid find .claude/mind.mv2 \"JWT\" spits out the timeline in seconds. The memory file stays under 5MB for a year of use, so you can toss it around with scp or drop it in a repo without worrying about bloat.\n\nThe Bottom Line\n\nIf you want persistent AI memory without the usual database nonsense, claude-brain is the simplest solution I’ve seen. It’s fast, dead simple, and actually practical. If you’re running a one-person project, maybe overkill—but for teams and serious workflows, it’s a no-brainer. Just don’t expect fancy dashboards or analytics. It’s a brain in a file, not an ERP suite.",
      "url": "https://github.com/moses-y/claude-brain",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "memvid/claude-brain",
        "url": "https://github.com/memvid/claude-brain",
        "stars": 309
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 16, 2026",
      "updatedAt": "February 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "directories": {
          ".claude-plugin": 2,
          ".github": 2,
          "(root)": 17,
          "commands": 4,
          "dist": 20,
          "hooks": 1,
          "skills": 2,
          "src": 18
        },
        "languages": {
          "JSON": 8,
          "YAML": 3,
          "Markdown": 10,
          "JavaScript": 10,
          "TypeScript": 19
        },
        "entryPoints": [
          "dist/index.js",
          "src/index.ts"
        ],
        "configFiles": [
          "package.json",
          "tsconfig.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [
          "src/__tests__/index.test.ts",
          "src/__tests__/mind-lock.test.ts"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md"
        ]
      }
    },
    {
      "id": 1159023254,
      "name": "Decepticon",
      "displayName": "Decepticon",
      "description": "Autonomous Multi-Agent Based Red Team Testing Service / AI hacker",
      "summary": "Decepticon: AI Agents for Hacking (Legally, Hopefully)\n\nThe Problem\n\nRed teaming is tedious. Manual recon, planning attacks, executing them, and documenting results—it's all time-consuming and repetitive. Plus, when you’re simulating adversarial behavior, you’re limited by human creativity and speed. What if you could offload the grunt work to autonomous agents that handle it for you? That’s where Decepticon comes in.\n\nWhat This Does\n\nDecepticon is an \"AI hacker\"—a multi-agent red-teaming framework designed to simulate adversarial behavior autonomously. Think of it as a hive mind of bots that can handle the various stages of a cyberattack: reconnaissance, initial access, lateral movement, and more. The project is Python-heavy (82 files), with a frontend (frontend/streamlitapp.py) built on Streamlit. The backend lives in src/, which includes agent definitions (src/agents/swarm/), prompt engineering (src/prompts/), and utilities for managing AI models (src/utils/llm/).\n\nThe architecture is built around a \"multi-agent system\" where agents like Planner, Recon, and Summary (all in src/agents/swarm/) perform specific tasks and coordinate via shared states and workflows (frontend/web/core/workflowhandler.py). You can interact with this system either via CLI (frontend/cli/cli.py) or the web UI. \n\nFor deployment, there’s a Dockerfile.attacker and docker-compose.yml—so yes, you can run this in a containerized setup for better isolation. The project even supports both cloud-based and local AI models (src/utils/llm/configmanager.py), meaning you can roll your own \"AI hacker\" without an internet connection if you’re paranoid. Smart.\n\nReal-World Use\n\nSay you’re testing a company’s network security. You could configure mcpconfig.json to define attack settings, deploy the agents, and let them do their thing—recon, exploit, summarize findings, repeat. Then, you can use the replay feature (frontend/web/core/chatreplay.py) to walk through how the attack unfolded and share it with stakeholders. Or, export logs and submit them as part of a PR to the open-source community. \n\nHere’s a quick snippet to spin up the agents via CLI:\n\npython frontend/cli/cli.py --config mcpconfig.json\n\nThe agents will start coordinating tasks like scanning for vulnerabilities (src/tools/mcp/Reconnaissance.py) and attempting initial access (src/tools/mcp/Initial_Access.py).\n\nThe Bottom Line\n\nDecepticon is ambitious—and let’s be real, a little terrifying. It’s not for casual users or folks looking for a quick vulnerability scan. But if you’re into offensive security or want to explore the bleeding edge of AI-driven red teaming, it’s worth your time. Just don’t forget the “don’t hack without permission” rule, or you’ll end up needing an actual lawyer, not a Python one.",
      "url": "https://github.com/moses-y/Decepticon",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "PurpleAILAB/Decepticon",
        "url": "https://github.com/PurpleAILAB/Decepticon",
        "stars": 832
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 16, 2026",
      "updatedAt": "February 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "directories": {
          "(root)": 14,
          ".github": 6,
          ".streamlit": 1,
          "assets": 5,
          "data": 2,
          "docs": 2,
          "examples": 1,
          "frontend": 42,
          "src": 57
        },
        "languages": {
          "YAML": 3,
          "TOML": 5,
          "Markdown": 4,
          "Python": 82,
          "JSON": 5,
          "CSS": 10,
          "Shell": 1
        },
        "entryPoints": [
          "frontend/cli/cli.py"
        ],
        "configFiles": [
          ".env.example",
          "Dockerfile.attacker",
          "docker-compose.yml",
          "pyproject.toml",
          "requirements.txt"
        ],
        "dependencies": [
          "pyproject.toml",
          "requirements.txt"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md",
          "docs/README_KO.md",
          "docs/THEME_UPDATE.md",
          "src/utils/llm/README.md"
        ]
      }
    },
    {
      "id": 1158967611,
      "name": "codex",
      "displayName": "codex",
      "description": "Lightweight coding agent that runs in your terminal",
      "summary": "The Problem\nCoding can be a pain in the neck, especially when you're stuck staring at a terminal with no guidance. You’re wrestling with syntax errors, dependency hell, or just trying to remember the right command to run. The last thing you want is to break your flow searching for solutions online while your deadline looms.\n\nWhat This Does\nMeet Codex CLI, your lightweight coding agent that runs locally in your terminal. It’s like pair programming with a buddy who knows everything and doesn’t need coffee breaks. The entry point is in codex-rs/ansi-escape/src/lib.rs, where the magic happens. You’ve got a collection of JSON and YAML files in the codex-rs directory, which handle various configurations and protocols, allowing Codex to understand your commands and respond accordingly.\n\nYou can install it using npm or Homebrew, with the commands right in the README: \n\nnpm install -g @openai/codex\n\nor \n\nbrew install --cask codex\n\nYou’ll be up and running in no time, ready to execute commands with a few keystrokes.\n\nReal-World Use\nImagine you’re knee-deep in a project and need to pull the latest API specs. Instead of diving into documentation, just run codex fetch-api-spec in your terminal. Codex will handle the networking, parsing, and even give you a nicely formatted output. It’s like having your own coding assistant that can quickly set up your environment or run scripts you need without breaking a sweat.\n\nThe Bottom Line\nCodex CLI is a solid tool for developers who appreciate a little extra help without the fluff. It’s lightweight and easy to install, making it perfect for quick tasks or larger projects. However, if you’re working on a small, one-off script, this might feel like overkill. If you need a reliable coding companion right in your terminal, give it a shot. Just don’t expect it to solve all your problems—after all, it can’t debug your bad code.",
      "url": "https://github.com/moses-y/codex",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "openai/codex",
        "url": "https://github.com/openai/codex",
        "stars": 62265
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 16, 2026",
      "updatedAt": "February 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "directories": {
          "(root)": 20,
          ".codex": 1,
          ".devcontainer": 3,
          ".github": 39,
          ".vscode": 3,
          "codex-cli": 13,
          "codex-rs": 121
        },
        "languages": {
          "Markdown": 14,
          "JSON": 112,
          "YAML": 27,
          "Shell": 5,
          "TOML": 10,
          "JavaScript": 1,
          "Python": 2,
          "Rust": 1
        },
        "entryPoints": [
          "codex-rs/ansi-escape/src/lib.rs"
        ],
        "configFiles": [
          ".devcontainer/Dockerfile",
          ".github/workflows/Dockerfile.bazel",
          ".prettierrc.toml",
          "codex-cli/Dockerfile",
          "codex-cli/package.json",
          "codex-rs/Cargo.toml",
          "codex-rs/ansi-escape/Cargo.toml",
          "codex-rs/app-server-protocol/Cargo.toml"
        ],
        "dependencies": [
          "codex-cli/package.json",
          "codex-rs/Cargo.toml",
          "codex-rs/ansi-escape/Cargo.toml",
          "codex-rs/app-server-protocol/Cargo.toml"
        ],
        "testFiles": [
          ".codex/skills/test-tui/SKILL.md",
          "codex-rs/.config/nextest.toml"
        ],
        "docs": [
          ".devcontainer/README.md",
          "CHANGELOG.md",
          "LICENSE",
          "README.md",
          "codex-cli/README.md",
          "codex-cli/scripts/README.md",
          "codex-rs/README.md",
          "codex-rs/ansi-escape/README.md"
        ]
      }
    },
    {
      "id": 1158702079,
      "name": "MemOS",
      "displayName": "MemOS",
      "description": "AI memory OS for LLM and Agent systems(moltbot,clawdbot,openclaw), enabling persistent Skill memory for cross-task skill reuse and evolution.",
      "summary": "MemOS: Memory for AI Agents That Doesn't Suck\n\nThe Problem\n\nLLMs and AI agents have the memory of a goldfish. Every interaction is a reset, and they have to process the entire conversation history to \"remember\" anything. This burns compute, tokens (read: money), and your patience. If you're building multi-turn or multi-agent systems, this lack of persistent memory means you're duct-taping hacks just to make things usable.\n\nWhat This Does\n\nMemOS is a memory operating system that gives your LLMs and AI agents long-term, structured memory. It lets you store, retrieve, manage, and even share memory across tasks and agents. Think of it as the missing hippocampus for your AI.\n\nAt its core is a unified memory API that handles CRUD operations on memory. Want to create a memory graph? Check out examples/corememories/treetextualmemory.py. Need a key-value cache? There's examples/corememories/kvcachememory.py. Prefer something more basic? examples/corememories/naivetextualmemory.py has you covered.\n\nIntegration with systems like openwork-memos-integration/apps/desktop lets you plug MemOS into other tools (like OpenClaw for multi-agent use cases). It even comes with Dockerfiles (docker/) and configuration files (examples/data/config/) to make setup straightforward—if you’re used to wrangling YAML, that is.\n\nReal-World Use\n\nSay you're building a multi-agent system where agents need to share context (hello, OpenClaw users). Without MemOS, you'd have to build some janky custom memory manager or duplicate context across agents. With MemOS, you can use the existing examples/memscheduler to set up an intelligent memory scheduler that optimizes memory usage and enables agents to share memories through a unified userid. Want to test it out? Run examples/memchat/chatwgeneratedcubeexplicitmemoryonly.py and watch your chatbot actually remember something for once.\n\nHere's a quick example of storing and retrieving memory:\n\nfrom examples.corememories.kvcachememory import KVCacheMemory\n\nmemory = KVCacheMemory()\nmemory.store(\"favoritecolor\", \"blue\")\nprint(memory.retrieve(\"favorite_color\"))  # Outputs: blue\n\nNow imagine scaling that to a fleet of agents sharing multi-turn conversations. Magic.\n\nThe Bottom Line\n\nMemOS is a solid choice for anyone building complex AI systems that require persistent memory. The examples are rich, the structure is clean, and the Docker setup is a nice touch. That said, the learning curve is steep, and some parts (like the evaluation/ folder) feel like a maze. If you're just building a simple chatbot, this is overkill. But if you're serious about memory-first AI, give it a go. Just don’t expect to set it up in 5 minutes.",
      "url": "https://github.com/moses-y/MemOS",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "MemTensor/MemOS",
        "url": "https://github.com/MemTensor/MemOS",
        "stars": 5942
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 15, 2026",
      "updatedAt": "February 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "directories": {
          ".github": 8,
          "(root)": 5,
          "docker": 6,
          "docs": 3,
          "evaluation": 53,
          "examples": 76,
          "openwork-memos-integration": 49
        },
        "languages": {
          "YAML": 14,
          "Markdown": 14,
          "JSON": 15,
          "Python": 92,
          "Shell": 8,
          "TypeScript": 29,
          "TSX": 10
        },
        "entryPoints": [
          "openwork-memos-integration/apps/desktop/e2e/config/index.ts",
          "openwork-memos-integration/apps/desktop/e2e/fixtures/index.ts"
        ],
        "configFiles": [
          "Makefile",
          "docker/.env.example",
          "docker/Dockerfile",
          "docker/Dockerfile.krolik",
          "docker/docker-compose.yml",
          "docker/requirements.txt",
          "openwork-memos-integration/apps/desktop/.eslintrc.json",
          "openwork-memos-integration/apps/desktop/e2e/docker/Dockerfile",
          "openwork-memos-integration/apps/desktop/e2e/docker/docker-compose.yml"
        ],
        "dependencies": [
          "docker/requirements.txt"
        ],
        "testFiles": [
          ".github/workflows/python-tests.yml",
          "docs/product-api-tests.md",
          "openwork-memos-integration/apps/desktop/__tests__/integration/main/appSettings.integration.test.ts",
          "openwork-memos-integration/apps/desktop/__tests__/integration/main/opencode/cli-path.integration.test.ts",
          "openwork-memos-integration/apps/desktop/__tests__/integration/main/opencode/config-generator.integration.test.ts",
          "openwork-memos-integration/apps/desktop/__tests__/integration/main/permission-api.integration.test.ts",
          "openwork-memos-integration/apps/desktop/__tests__/integration/main/secureStorage.integration.test.ts",
          "openwork-memos-integration/apps/desktop/__tests__/integration/main/store/freshInstallCleanup.integration.test.ts",
          "openwork-memos-integration/apps/desktop/__tests__/integration/main/taskHistory.integration.test.ts",
          "openwork-memos-integration/apps/desktop/__tests__/integration/main/utils/bundled-node.integration.test.ts",
          "openwork-memos-integration/apps/desktop/__tests__/integration/main/utils/system-path.integration.test.ts",
          "openwork-memos-integration/apps/desktop/__tests__/integration/preload/preload.integration.test.ts",
          "openwork-memos-integration/apps/desktop/__tests__/integration/renderer/App.integration.test.tsx",
          "openwork-memos-integration/apps/desktop/__tests__/integration/renderer/components/Header.integration.test.tsx",
          "openwork-memos-integration/apps/desktop/__tests__/integration/renderer/components/SettingsDialog.integration.test.tsx",
          "openwork-memos-integration/apps/desktop/__tests__/integration/renderer/components/Sidebar.integration.test.tsx",
          "openwork-memos-integration/apps/desktop/__tests__/integration/renderer/components/StreamingText.integration.test.tsx",
          "openwork-memos-integration/apps/desktop/__tests__/integration/renderer/components/TaskHistory.integration.test.tsx",
          "openwork-memos-integration/apps/desktop/__tests__/integration/renderer/components/TaskInputBar.integration.test.tsx",
          "openwork-memos-integration/apps/desktop/__tests__/integration/renderer/components/TaskLauncher.integration.test.tsx",
          "openwork-memos-integration/apps/desktop/__tests__/integration/renderer/pages/Execution.integration.test.tsx",
          "openwork-memos-integration/apps/desktop/__tests__/integration/renderer/pages/Home.integration.test.tsx",
          "openwork-memos-integration/apps/desktop/__tests__/integration/renderer/taskStore.integration.test.ts",
          "openwork-memos-integration/apps/desktop/__tests__/main/config.unit.test.ts",
          "openwork-memos-integration/apps/desktop/__tests__/main/ipc/handlers-utils.unit.test.ts",
          "openwork-memos-integration/apps/desktop/__tests__/main/ipc/validation.unit.test.ts",
          "openwork-memos-integration/apps/desktop/__tests__/main/opencode/stream-parser.unit.test.ts",
          "openwork-memos-integration/apps/desktop/__tests__/renderer/lib/utils.unit.test.ts",
          "openwork-memos-integration/apps/desktop/__tests__/setup.ts",
          "openwork-memos-integration/apps/desktop/__tests__/unit/main/ipc/handlers.unit.test.ts",
          "openwork-memos-integration/apps/desktop/__tests__/unit/main/opencode/adapter.unit.test.ts",
          "openwork-memos-integration/apps/desktop/__tests__/unit/main/opencode/task-manager.unit.test.ts",
          "openwork-memos-integration/apps/desktop/__tests__/unit/renderer/lib/accomplish.unit.test.ts",
          "openwork-memos-integration/apps/desktop/__tests__/unit/renderer/lib/analytics.unit.test.ts",
          "openwork-memos-integration/apps/desktop/__tests__/unit/renderer/lib/animations.unit.test.ts",
          "openwork-memos-integration/apps/desktop/__tests__/unit/renderer/lib/waiting-detection.unit.test.ts"
        ],
        "docs": [
          ".github/CONTRIBUTING",
          "LICENSE",
          "README.md",
          "docs/README.md",
          "docs/openapi.json",
          "docs/product-api-tests.md",
          "evaluation/README.md",
          "evaluation/scripts/locomo/openai_memory_locomo_eval_guide.md",
          "examples/data/mem_cube_2/README.md",
          "examples/mem_cube/_deprecated/README.md",
          "examples/mem_reader/README.md",
          "openwork-memos-integration/CONTRIBUTING.md",
          "openwork-memos-integration/LICENSE",
          "openwork-memos-integration/README.md",
          "openwork-memos-integration/apps/desktop/e2e/README.md"
        ]
      }
    },
    {
      "id": 1158701617,
      "name": "stenoai",
      "displayName": "stenoai",
      "description": "Privacy focused AI powered meeting notes using locally hosted Small Language Models",
      "summary": "The Problem\nEver tried taking notes during a meeting while also trying to engage? It's a mess. Typing away while someone’s discussing critical points is a surefire way to miss half of what’s being said. You need a solution that not only captures the discussion but respects your privacy too, especially in sensitive environments like healthcare or finance.\n\nWhat This Does\nEnter StenoAI, your local AI-powered note-taker. This repo, a fork from the more popular ruzin/stenoai, leverages Small Language Models to transcribe and summarize meetings without sending your data to the cloud. The core functionality is split between src/transcriber.py for capturing audio and src/summarizer.py for generating concise summaries. \n\nThe app runs a macOS desktop interface located in app/index.html, with the heavy lifting done by models managed in src/models.py. If you're looking to customize or extend functionalities, check out setup.py to get your environment set up with the necessary dependencies listed in requirements.txt.\n\nReal-World Use\nImagine you're in a critical strategy meeting, and the discussion is packed with jargon. You fire up StenoAI, hit record, and let it transcribe everything live. After the meeting, instead of sifting through pages of notes, you click the “Summarize” button in the app. Now you have a neat summary of key points, thanks to the Ask Steno feature, which allows you to query the notes using natural language. This setup not only saves time but ensures you capture the essence of the conversation without compromising data privacy.\n\nThe Bottom Line\nStenoAI is solid for anyone who needs to track discussions without the hassle of manual note-taking, especially in fields where confidentiality is crucial. The local processing is a win for privacy, but if you're not on macOS, you’re out of luck. Overall, it’s a neat tool with great potential, just don’t expect it to become your next full-fledged project management solution.",
      "url": "https://github.com/moses-y/stenoai",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "ruzin/stenoai",
        "url": "https://github.com/ruzin/stenoai",
        "stars": 391
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 15, 2026",
      "updatedAt": "February 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "directories": {
          "(root)": 12,
          ".github": 3,
          "app": 8,
          "prompt_tests": 2,
          "scripts": 4,
          "src": 8,
          "tests": 1,
          "website": 24
        },
        "languages": {
          "Markdown": 7,
          "YAML": 2,
          "JSON": 5,
          "HTML": 6,
          "JavaScript": 5,
          "Python": 12,
          "Shell": 4,
          "CSS": 2,
          "JSX": 2
        },
        "entryPoints": [
          "app/index.html",
          "app/main.js",
          "setup.py",
          "website/index.html",
          "website/src/App.jsx"
        ],
        "configFiles": [
          "app/package.json",
          "requirements.txt",
          "setup.py",
          "website/package.json",
          "website/tailwind.config.js",
          "website/vite.config.js"
        ],
        "dependencies": [
          "app/package-lock.json",
          "app/package.json",
          "requirements.txt",
          "website/package-lock.json",
          "website/package.json"
        ],
        "testFiles": [
          "prompt_tests/PROMPT_TESTING.md",
          "prompt_tests/test_prompts.py",
          "scripts/test_dmg_fresh_install.sh",
          "scripts/test_first_time_setup.sh",
          "stenoai.spec",
          "tests/__init__.py"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "website/README.md"
        ]
      }
    },
    {
      "id": 1158686133,
      "name": "cc-wf-studio",
      "displayName": "cc wf studio",
      "description": "CC Workflow Studio",
      "summary": "The Problem\n\nBuilding and maintaining AI workflow automation is a pain. You end up juggling dozens of YAML files, half-baked scripts, and brittle prompt templates. Want to tweak your workflow? Prepare for a mess of manual edits, copy-paste bugs, and guesswork. Visual tools barely exist, and integrating with Copilot or Claude usually means duct-taping config files together.\n\nWhat CC Workflow Studio Does\n\nCC Workflow Studio gives you a visual editor for AI workflows—drag-and-drop, tweak nodes, and wire up conditional logic without writing code. The real meat lives in src/extension/ (see extension.ts for entrypoint), where commands like open-editor.ts, save-workflow.ts, and export-workflow.ts handle the grunt work. Integration with Claude, Copilot, Codex, and Roo is handled via dedicated services: check out ai-provider.ts, claude-code-service.ts, copilot-skill-export-service.ts, and their friends.\n\nSpecs in specs/ and contracts in contracts/ make it clear: this thing is built for exporting workflows to whatever flavor you need—.claude, .github/prompts/, .codex/skills/, etc. Want to run a workflow? Demo GIFs in resources/ show you can do it straight from the editor. There's a pile of i18n files (i18n/translations/) if you're tired of English-only tools.\n\nReal-World Use\n\nSay you want to automate PR reviews with Claude. Open the editor, wire up a workflow with MCP nodes and conditional branches, add your skill nodes, and talk to the AI via natural language to refine logic. Hit \"Export\"—your workflow lands in .claude/commands/ and .claude/agents/. If you want Copilot support, flip the toolbar toggle, and now your export goes to .github/prompts/ or .github/skills/. Example:  \n\n// src/extension/commands/save-workflow.ts\nexport async function saveWorkflow(workflowData) {\n  // Validates and writes workflow to .claude/commands/\n}\n\nThe Bottom Line\n\nIf you're tired of wrangling config files and want to actually see your AI workflows, CC Workflow Studio is worth a look. It’s overkill for tiny automations but great for teams building complex, multi-agent flows. Setup isn’t trivial—expect to read the docs and mess with some settings. But once it’s running, exporting and editing workflows is way less annoying. If you’re serious about AI automation, skip the manual editing and use this.",
      "url": "https://github.com/moses-y/cc-wf-studio",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "breaking-brake/cc-wf-studio",
        "url": "https://github.com/breaking-brake/cc-wf-studio",
        "stars": 4060
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 15, 2026",
      "updatedAt": "February 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "directories": {
          ".claude": 13,
          ".github": 7,
          "(root)": 12,
          ".specify": 11,
          ".vscode": 5,
          "contracts": 3,
          "docs": 3,
          "resources": 22,
          "scripts": 2,
          "specs": 78,
          "src": 44
        },
        "languages": {
          "Markdown": 100,
          "YAML": 7,
          "JSON": 20,
          "Shell": 5,
          "TypeScript": 47
        },
        "entryPoints": [],
        "configFiles": [
          "package.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [
          ".claude/commands/speckit.analyze.md",
          ".claude/commands/speckit.checklist.md",
          ".claude/commands/speckit.clarify.md",
          ".claude/commands/speckit.constitution.md",
          ".claude/commands/speckit.implement.md",
          ".claude/commands/speckit.plan.md",
          ".claude/commands/speckit.specify.md",
          ".claude/commands/speckit.tasks.md",
          ".specify/memory/constitution.md",
          ".specify/scripts/bash/check-prerequisites.sh",
          ".specify/scripts/bash/common.sh",
          ".specify/scripts/bash/create-new-feature.sh",
          ".specify/scripts/bash/setup-plan.sh",
          ".specify/scripts/bash/update-agent-context.sh",
          ".specify/templates/agent-file-template.md",
          ".specify/templates/checklist-template.md",
          ".specify/templates/plan-template.md",
          ".specify/templates/spec-template.md",
          ".specify/templates/tasks-template.md",
          "specs/001-ai-skill-generation/checklists/requirements.md",
          "specs/001-ai-skill-generation/contracts/skill-scanning-api.md",
          "specs/001-ai-skill-generation/data-model.md",
          "specs/001-ai-skill-generation/plan.md",
          "specs/001-ai-skill-generation/quickstart.md",
          "specs/001-ai-skill-generation/research.md",
          "specs/001-ai-skill-generation/spec.md",
          "specs/001-ai-skill-generation/tasks.md",
          "specs/001-ai-workflow-generation/checklists/requirements.md",
          "specs/001-ai-workflow-generation/contracts/ai-generation-messages.md",
          "specs/001-ai-workflow-generation/data-model.md",
          "specs/001-ai-workflow-generation/plan.md",
          "specs/001-ai-workflow-generation/quickstart.md",
          "specs/001-ai-workflow-generation/research.md",
          "specs/001-ai-workflow-generation/spec.md",
          "specs/001-ai-workflow-generation/tasks.md",
          "specs/001-ai-workflow-refinement/checklists/requirements.md",
          "specs/001-ai-workflow-refinement/contracts/refinement-messages.json",
          "specs/001-ai-workflow-refinement/data-model.md",
          "specs/001-ai-workflow-refinement/plan.md",
          "specs/001-ai-workflow-refinement/quickstart.md",
          "specs/001-ai-workflow-refinement/research.md",
          "specs/001-ai-workflow-refinement/spec.md",
          "specs/001-ai-workflow-refinement/tasks.md",
          "specs/001-cc-wf-studio/checklists/requirements.md",
          "specs/001-cc-wf-studio/contracts/extension-webview-api.md",
          "specs/001-cc-wf-studio/contracts/vscode-extension-api.md",
          "specs/001-cc-wf-studio/data-model.md",
          "specs/001-cc-wf-studio/plan.md",
          "specs/001-cc-wf-studio/quickstart.md",
          "specs/001-cc-wf-studio/research.md",
          "specs/001-cc-wf-studio/spec.md",
          "specs/001-cc-wf-studio/tasks.md",
          "specs/001-mcp-natural-language-mode/checklists/requirements.md",
          "specs/001-mcp-natural-language-mode/contracts/export-metadata.schema.json",
          "specs/001-mcp-natural-language-mode/contracts/mcp-node-extended.schema.json",
          "specs/001-mcp-natural-language-mode/data-model.md",
          "specs/001-mcp-natural-language-mode/extension-points.md",
          "specs/001-mcp-natural-language-mode/i18n-keys-plan.md",
          "specs/001-mcp-natural-language-mode/plan.md",
          "specs/001-mcp-natural-language-mode/quickstart.md",
          "specs/001-mcp-natural-language-mode/research.md",
          "specs/001-mcp-natural-language-mode/spec.md",
          "specs/001-mcp-natural-language-mode/tasks.md",
          "specs/001-mcp-node/checklists/requirements.md",
          "specs/001-mcp-node/contracts/extension-webview-messages.schema.json",
          "specs/001-mcp-node/contracts/mcp-cli.schema.json",
          "specs/001-mcp-node/contracts/workflow-mcp-node.schema.json",
          "specs/001-mcp-node/data-model.md",
          "specs/001-mcp-node/plan.md",
          "specs/001-mcp-node/quickstart.md",
          "specs/001-mcp-node/research.md",
          "specs/001-mcp-node/spec.md",
          "specs/001-mcp-node/tasks.md",
          "specs/001-node-types-extension/checklists/requirements.md",
          "specs/001-node-types-extension/data-model.md",
          "specs/001-node-types-extension/plan.md",
          "specs/001-node-types-extension/quickstart.md",
          "specs/001-node-types-extension/research.md",
          "specs/001-node-types-extension/spec.md",
          "specs/001-node-types-extension/tasks.md",
          "specs/001-skill-node/checklists/requirements.md",
          "specs/001-skill-node/contracts/skill-messages.ts",
          "specs/001-skill-node/data-model.md",
          "specs/001-skill-node/plan.md",
          "specs/001-skill-node/quickstart.md",
          "specs/001-skill-node/research.md",
          "specs/001-skill-node/spec.md",
          "specs/001-skill-node/tasks.md",
          "specs/001-slack-workflow-sharing/checklists/requirements.md",
          "specs/001-slack-workflow-sharing/contracts/extension-host-api-contracts.md",
          "specs/001-slack-workflow-sharing/contracts/slack-api-contracts.md",
          "specs/001-slack-workflow-sharing/data-model.md",
          "specs/001-slack-workflow-sharing/plan.md",
          "specs/001-slack-workflow-sharing/quickstart.md",
          "specs/001-slack-workflow-sharing/research.md",
          "specs/001-slack-workflow-sharing/spec.md",
          "specs/001-slack-workflow-sharing/tasks.md"
        ],
        "docs": [
          "CHANGELOG.md",
          "LICENSE",
          "README.md",
          "docs/ai-coding-tools-config-reference.md",
          "docs/release-automation.md",
          "docs/schema-maintenance.md",
          "resources/README.md"
        ]
      }
    },
    {
      "id": 1158670052,
      "name": "Infographic",
      "displayName": "Infographic",
      "description": "🦋 An Infographic Generation and Rendering Framework, bring words to life with AI!",
      "summary": "Making Data Look Fancy with AntV Infographic\n\nYou know that one project where your manager asks you to \"make it look more attractive\"? Well, meet AntV Infographic, the fancy tool that turns boring data into visual masterpieces. This framework is all about creating high-quality infographics with AI-driven simplicity, SVG precision, and more templates than you’ll ever need.\n\nThe Problem\n\nBuilding infographics manually is a soul-sucking experience. Do you really want to wrestle with CSS, SVG paths, and endless iterations to make your pie chart look slightly less like a sad pancake? Or worse, spend hours googling “best infographic tools” only to sign up for yet another subscription-based service that locks half the features behind a paywall?\n\nWhat This Does\n\nAntV Infographic is essentially a declarative infographic rendering engine—fancy words for \"it takes text-based syntax and turns it into great-looking visuals\". The framework brings a blend of AI-friendly syntax, pre-built templates, and professional-grade SVG rendering to make the infographic-building process borderline painless.\n\nHere’s the cool part: there’s a bunch of infographic syntax that acts like magic shorthand for AI or humans to describe layouts, themes, and data structures. For example:\n\ninfographic.render(\ninfographic list-row-simple-horizontal-arrow\ndata\n  lists\nlabel Step 1\n      desc Start\nlabel Step 2\n      desc In Progress\nlabel Step 3\n);\n\nNo need to fuss over pixel-perfect design. AntV handles it. Want hand-drawn visuals or gradient themes? That’s built-in too. And if your AI-generated infographic has a typo or looks weird, the framework ships with an editor to make quick manual tweaks. Check out the site/src/components/AIPlayground folder for the editor implementation—it’s React-based, so you can extend it if needed.\n\nThe repo is packed with ~200 templates, which means you can probably find something that fits your use case without reinventing the wheel. Templates live in the shared folder, while rendering logic is scattered across site and dev. The framework also supports SVG outputs, making further editing in tools like Figma or Adobe Illustrator a breeze.\n\nReal-World Use\n\nImagine you’re tasked with visualizing quarterly revenue in a report. Instead of fiddling with Excel charts, you could use AntV like this:\n\nimport { Infographic } from '@antv/infographic';\n\nconst infographic = new Infographic({\n  container: '#container',\n  width: '100%',\n  height: '100%',\n});\n\ninfographic.render(\ninfographic chart-pie\ndata\n  items\nlabel Q1\n      value 100000\nlabel Q2\n      value 120000\nlabel Q3\n      value 90000\nlabel Q4\n      value 150000\n);\n\nThe framework spits out a polished pie chart in SVG format that looks like you spent hours designing it. Bonus: you can use the built-in editor (site/src/components/AIPlayground) to tweak labels, colors, or layout without diving into code.\n\nIf you’re building something more dynamic, like a real-time dashboard, the dev folder has React hooks (usePreviewData, usePreviewSettings) to handle interactions and live updates. For example, dev/src/ItemPreview.tsx is one of the core components for previewing individual infographic items dynamically.\n\nThe Bottom Line\n\nAntV Infographic is pretty slick if you need visually appealing infographics without wasting hours on design. It’s AI-friendly, packed with templates, and outputs clean SVGs. But let’s be real—this isn’t something you’ll use for simple bar charts or small projects. It’s more for enterprise-level data storytelling or client presentations.\n\nIf you’re already knee-deep in the AntV ecosystem, this fits like a glove. Otherwise, the learning curve might feel steep, especially with the custom syntax. But hey, if you want infographics that look like money, this is worth a shot.",
      "url": "https://github.com/moses-y/Infographic",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "antvis/Infographic",
        "url": "https://github.com/antvis/Infographic",
        "stars": 4506
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 15, 2026",
      "updatedAt": "February 15, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "directories": {
          "(root)": 7,
          ".github": 3,
          ".husky": 2,
          ".skills": 8,
          "__tests__": 110,
          "dev": 18,
          "scripts": 1,
          "shared": 2,
          "site": 49
        },
        "languages": {
          "YAML": 4,
          "Markdown": 11,
          "TypeScript": 94,
          "JSON": 5,
          "TSX": 21,
          "HTML": 2,
          "JavaScript": 15
        },
        "entryPoints": [
          "__tests__/utils/index.ts",
          "dev/index.html",
          "dev/src/App.tsx",
          "site/src/components/AIPlayground/index.tsx"
        ],
        "configFiles": [
          "__tests__/tsconfig.json",
          "dev/package.json",
          "dev/tsconfig.json",
          "dev/vite.config.ts",
          "package.json",
          "site/.eslintrc",
          "site/.prettierrc",
          "site/next.config.js",
          "site/package.json"
        ],
        "dependencies": [
          "dev/package.json",
          "package.json",
          "site/package.json"
        ],
        "testFiles": [
          "__tests__/setup/dom-polyfills.ts",
          "__tests__/tsconfig.json",
          "__tests__/unit/designs/structures/chart-pie.test.ts",
          "__tests__/unit/designs/utils/color.test.ts",
          "__tests__/unit/designs/utils/hierarchy-color.test.ts",
          "__tests__/unit/designs/utils/item.test.ts",
          "__tests__/unit/dev/ItemPreview.test.tsx",
          "__tests__/unit/editor/commands/batch.test.ts",
          "__tests__/unit/editor/commands/update-element.test.ts",
          "__tests__/unit/editor/commands/update-options.test.ts",
          "__tests__/unit/editor/commands/update-text.test.ts",
          "__tests__/unit/editor/interactions/brush-select.test.ts",
          "__tests__/unit/editor/interactions/click-select.test.ts",
          "__tests__/unit/editor/interactions/dblclick-edit-text.test.ts",
          "__tests__/unit/editor/interactions/drag-canvas.test.ts",
          "__tests__/unit/editor/interactions/drag-element.test.ts",
          "__tests__/unit/editor/interactions/hotkey-history.test.ts",
          "__tests__/unit/editor/interactions/select-highlight.test.ts",
          "__tests__/unit/editor/interactions/zoom-wheel.test.ts",
          "__tests__/unit/editor/managers/command-manager.test.ts",
          "__tests__/unit/editor/managers/interaction-manager.test.ts",
          "__tests__/unit/editor/managers/plugin-manager.test.ts",
          "__tests__/unit/editor/managers/state-manager.test.ts",
          "__tests__/unit/editor/managers/sync-registry.test.ts",
          "__tests__/unit/editor/plugins/core-sync.test.ts",
          "__tests__/unit/editor/plugins/reset-viewbox.test.ts",
          "__tests__/unit/editor/plugins/resize-element.test.ts",
          "__tests__/unit/editor/utils/click-handler.test.ts",
          "__tests__/unit/editor/utils/coordinate.test.ts",
          "__tests__/unit/editor/utils/data.test.ts",
          "__tests__/unit/editor/utils/element.test.ts",
          "__tests__/unit/editor/utils/event.test.ts",
          "__tests__/unit/editor/utils/extension.test.ts",
          "__tests__/unit/editor/utils/hotkey.test.ts",
          "__tests__/unit/exporter/svg.test.ts",
          "__tests__/unit/jsx/animate-examples.test.tsx",
          "__tests__/unit/jsx/animate.test.tsx",
          "__tests__/unit/jsx/components/text.test.tsx",
          "__tests__/unit/jsx/defs.test.tsx",
          "__tests__/unit/jsx/jsx.test.tsx",
          "__tests__/unit/jsx/layout.test.tsx",
          "__tests__/unit/jsx/utils/bounds.test.ts",
          "__tests__/unit/jsx/utils/bounds.test.tsx",
          "__tests__/unit/jsx/utils/children.test.ts",
          "__tests__/unit/jsx/utils/children.test.tsx",
          "__tests__/unit/jsx/utils/clone.test.ts",
          "__tests__/unit/jsx/utils/context.test.ts",
          "__tests__/unit/jsx/utils/defs.test.tsx",
          "__tests__/unit/jsx/utils/element.test.ts",
          "__tests__/unit/jsx/utils/escape.test.ts",
          "__tests__/unit/jsx/utils/is-fragment.test.ts",
          "__tests__/unit/jsx/utils/is-jsx-element.test.ts",
          "__tests__/unit/jsx/utils/is-number.test.ts",
          "__tests__/unit/jsx/utils/svg.test.ts",
          "__tests__/unit/options/parse-options.test.ts",
          "__tests__/unit/renderer/palette.test.ts",
          "__tests__/unit/renderer/utils/attrs.test.ts",
          "__tests__/unit/renderer/utils/id.test.ts",
          "__tests__/unit/resource/loaders/svg.test.ts",
          "__tests__/unit/resource/utils/data-uri.test.ts",
          "__tests__/unit/resource/utils/parser.test.ts",
          "__tests__/unit/resource/utils/ref.test.ts",
          "__tests__/unit/runtime/utils.test.ts",
          "__tests__/unit/site/live-editor/templateManager.test.ts",
          "__tests__/unit/ssr/examples.test.ts",
          "__tests__/unit/ssr/examples/01-basic-list.txt",
          "__tests__/unit/ssr/examples/02-list-with-icons.txt",
          "__tests__/unit/ssr/examples/03-timeline.txt",
          "__tests__/unit/ssr/examples/04-themed-dark.txt",
          "__tests__/unit/ssr/examples/05-quarterly-revenue.txt",
          "__tests__/unit/ssr/examples/06-comparison.txt",
          "__tests__/unit/ssr/examples/07-hierarchy.txt",
          "__tests__/unit/ssr/examples/08-quadrant.txt",
          "__tests__/unit/ssr/examples/09-chart-bars.txt",
          "__tests__/unit/ssr/examples/10-swot-analysis.txt",
          "__tests__/unit/ssr/examples/11-list-with-icons-hand-drawn.txt",
          "__tests__/unit/ssr/output/01-basic-list.svg",
          "__tests__/unit/ssr/output/02-list-with-icons.svg",
          "__tests__/unit/ssr/output/03-timeline.svg",
          "__tests__/unit/ssr/output/04-themed-dark.svg",
          "__tests__/unit/ssr/output/05-quarterly-revenue.svg",
          "__tests__/unit/ssr/output/06-comparison.svg",
          "__tests__/unit/ssr/output/07-hierarchy.svg",
          "__tests__/unit/ssr/output/08-quadrant.svg",
          "__tests__/unit/ssr/output/09-chart-bars.svg",
          "__tests__/unit/ssr/output/10-swot-analysis.svg",
          "__tests__/unit/ssr/output/11-list-with-icons-hand-drawn.svg",
          "__tests__/unit/syntax/parse-syntax.test.ts",
          "__tests__/unit/utils/color.test.ts",
          "__tests__/unit/utils/data.test.ts",
          "__tests__/unit/utils/design.test.ts",
          "__tests__/unit/utils/font.test.ts",
          "__tests__/unit/utils/get-types.test.ts",
          "__tests__/unit/utils/hash.test.ts",
          "__tests__/unit/utils/icon.test.ts",
          "__tests__/unit/utils/is-browser.test.ts",
          "__tests__/unit/utils/is-node.test.ts",
          "__tests__/unit/utils/item.test.ts",
          "__tests__/unit/utils/join.test.ts",
          "__tests__/unit/utils/measure-text.test.ts",
          "__tests__/unit/utils/object.test.ts",
          "__tests__/unit/utils/padding.test.ts",
          "__tests__/unit/utils/recognizer.test.ts",
          "__tests__/unit/utils/svg.test.ts",
          "__tests__/unit/utils/text.test.ts",
          "__tests__/unit/utils/uuid.test.ts",
          "__tests__/unit/utils/viewbox.test.ts",
          "__tests__/unit/version.test.ts",
          "__tests__/utils/index.ts",
          "__tests__/utils/svg.ts"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "README.zh-CN.md",
          "site/README.md"
        ]
      }
    },
    {
      "id": 1158607874,
      "name": "gpt-play-pokemon-firered",
      "displayName": "gpt play pokemon firered",
      "description": "An autonomous AI agent that plays Pokemon FireRed in real time using OpenAI's LLM, with a live web dashboard for monitoring.",
      "summary": "Building an AI That Plays Pokémon FireRed: A Deep Dive into gpt-play-pokemon-firered\n\nThe Problem\n\nLet’s face it: AI playing games isn't new. But most of the time, it’s either a bot brute-forcing its way through or a glorified decision tree. What if you could throw a large language model (LLM) into the mix and have it think its way through a game as complex as Pokémon FireRed? That’s the problem this project tries to solve — building an autonomous AI agent that interacts with a live game environment, makes decisions, and learns from its actions. Oh, and there’s even a live web dashboard to watch it stumble through Viridian Forest.\n\nWhat This Does\n\nAt its core, gpt-play-pokemon-firered connects OpenAI’s LLM to a Pokémon FireRed emulator running in mGBA. Here’s how it’s glued together:\nThe Emulator: The Lua script (mgba/scripts/FireRedBridgeSocketServer.lua) runs inside mGBA, exposing the game state and accepting inputs via a socket server. It’s like a translator between the emulator and the AI.\nThe Bridge: fireredmgbabridge.py is a FastAPI server that talks to the emulator. It reads memory (thanks to a bunch of Python in firered_bridge/) to parse game state — like the player’s location, party, and even the fog of war. It also sends back button presses based on what the AI decides.\nThe AI Agent: The magic happens in server/index.js. This is where the LLM decides what to do next. It uses a bunch of pre-written prompts (server/prompts/) to make decisions, plan moves, and critique its own performance. There's even a server/src/core/gameLoop.js to keep everything running in real-time.\nThe Dashboard: The HTML/JS frontend (frontend/) is your live window into the AI’s thought process. Want to see what the AI is thinking or what’s in its bag? Open the dashboard in your browser.\n\nReal-World Use\n\nLet’s say you’re tired of playing FireRed for the 20th time and want to see what happens if you give an AI free rein. After setting up the environment (yes, you’ll need Python, Node.js, and a FireRed ROM), start the emulator, load the Lua script, and fire up the bridge and server. The AI will begin playing, and you can watch the chaos unfold in the browser.\n\nHere’s a snippet from the prompts (server/prompts/game.txt) to see how the AI “thinks”:\n\nYou are playing Pokémon FireRed. Your goal is to defeat all gym leaders and become the champion. Use your knowledge of the game to navigate, battle, and make decisions.\n\nCombine that with server/src/core/openaiClient.js to feed game state into the LLM, and you’ve got yourself an AI Ash Ketchum.\n\nThe Bottom Line\n\nThis is a nerdy, over-engineered experiment — and it’s awesome. The integration of Python, Node.js, and Lua is clean, and the dashboard is a fun way to watch the AI in action. That said, it’s not for the faint of heart. If you aren’t comfortable debugging mGBA sockets or tweaking .env files, this might not be for you. But if you love AI, emulators, and Pokémon, grab your ROM and get ready to laugh at your AI struggling to get out of Pallet Town.",
      "url": "https://github.com/moses-y/gpt-play-pokemon-firered",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Clad3815/gpt-play-pokemon-firered",
        "url": "https://github.com/Clad3815/gpt-play-pokemon-firered",
        "stars": 67
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 15, 2026",
      "updatedAt": "February 15, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "directories": {
          "(root)": 8,
          "firered_bridge": 39,
          "frontend": 3,
          "game_data_firered": 2,
          "mgba": 1,
          "server": 27
        },
        "languages": {
          "Markdown": 1,
          "Python": 41,
          "JavaScript": 19,
          "HTML": 1,
          "CSS": 1,
          "JSON": 4,
          "Lua": 1
        },
        "entryPoints": [
          "frontend/app.js",
          "frontend/index.html",
          "server/index.js"
        ],
        "configFiles": [
          ".env.example",
          "requirements.txt",
          "server/.env.example",
          "server/package.json"
        ],
        "dependencies": [
          "requirements.txt",
          "server/package.json"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ]
      }
    },
    {
      "id": 1158464134,
      "name": "mdream",
      "displayName": "mdream",
      "description": "☁️ The fastest HTML to markdown convertor built with JavaScript. Optimized for LLMs and supports streaming.",
      "summary": "The Problem\nHTML to Markdown conversion is often a slog. Traditional converters are slow and produce output that’s bloated and not optimized for Large Language Models (LLMs). If you're working with text-heavy applications or need to prepare data for LLMs, you need something faster and leaner. Enter mdream, designed to tackle these issues head-on.\n\nWhat This Does\nmdream is a lightning-fast HTML to Markdown converter built in JavaScript. It’s not just another tool in the toolbox; it’s a finely-tuned machine. The core of the project lives in packages/mdream/src/index.ts, where the actual conversion magic happens. It generates GitHub Flavored Markdown with support for frontmatter and nested HTML, making it versatile for various use cases.\n\nThe bench/ directory contains benchmark tests that show just how quick it is—converting 1.8MB of HTML in around 60ms. You can check out bench/README.md for the methodology behind those impressive numbers. Plus, the packages/mdream/src/plugins.ts file allows for easy extensibility with a plugin system, meaning you can adapt it to fit your unique needs.\n\nReal-World Use\nImagine you’re pulling data from a web scraper and need to convert a hefty amount of HTML into Markdown for your documentation site. You could use the CLI tool available in packages/mdream/bin/mdream.mjs to pipe the HTML directly from stdin, like so:\n\ncat your-file.html | node packages/mdream/bin/mdream.mjs > output.md\n\nThis command will process the HTML and spit out a Markdown file, ready for use. You could also integrate it into a CI pipeline, leveraging the GitHub Actions in .github/workflows/ for automated documentation updates.\n\nThe Bottom Line\nmdream is a solid choice if you need a fast, lightweight HTML to Markdown converter tailored for LLMs. It’s not overkill for small projects but shines in larger applications where speed and efficiency matter. If you’re tired of the sluggishness and bloat of existing converters, give this one a shot. Just be prepared for the slight learning curve if you want to dive deep into its plugin system.",
      "url": "https://github.com/moses-y/mdream",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "harlan-zw/mdream",
        "url": "https://github.com/harlan-zw/mdream",
        "stars": 815
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 15, 2026",
      "updatedAt": "February 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "directories": {
          "(root)": 12,
          ".github": 10,
          "bench": 14,
          "bin": 1,
          "docs": 60,
          "examples": 39,
          "packages": 64
        },
        "languages": {
          "YAML": 7,
          "HTML": 6,
          "Markdown": 12,
          "TypeScript": 84,
          "Shell": 1,
          "Vue": 31,
          "CSS": 4,
          "JSON": 21,
          "JavaScript": 9,
          "SQL": 1
        },
        "entryPoints": [
          ".github/fixtures/index.html",
          "examples/vite-ssr-ts/index.html",
          "examples/vite-ssr-ts/server.js",
          "examples/vite-ssr-vue/index.html",
          "examples/vite-ssr-vue/server.js",
          "examples/vite-ssr-vue/src/main.js",
          "packages/action/src/index.ts",
          "packages/crawl/src/cli.ts",
          "packages/crawl/src/index.ts",
          "packages/llms-db/src/cli.ts",
          "packages/llms-db/src/index.ts",
          "packages/mdream/src/cli.ts",
          "packages/mdream/src/index.ts"
        ],
        "configFiles": [
          "Dockerfile",
          "docs/nuxt.config.ts",
          "docs/package.json",
          "docs/server/tsconfig.json",
          "docs/tsconfig.json",
          "examples/nuxt/nuxt.config.ts",
          "examples/nuxt/package.json",
          "examples/nuxt/tsconfig.json",
          "examples/vite-ssr-ts/package.json",
          "examples/vite-ssr-ts/tsconfig.json",
          "examples/vite-ssr-vue/package.json",
          "examples/vite-ssr-vue/vite.config.js",
          "package.json",
          "packages/action/package.json",
          "packages/action/tsconfig.json",
          "packages/crawl/package.json",
          "packages/crawl/tsconfig.json",
          "packages/llms-db/.env.example",
          "packages/llms-db/package.json",
          "packages/llms-db/tsconfig.json",
          "packages/mdream/package.json"
        ],
        "dependencies": [
          "docs/package.json",
          "examples/nuxt/package.json",
          "examples/vite-ssr-ts/package.json",
          "examples/vite-ssr-vue/package.json",
          "package.json",
          "packages/action/package.json",
          "packages/crawl/package.json",
          "packages/llms-db/package.json",
          "packages/mdream/package.json"
        ],
        "testFiles": [
          ".github/workflows/test-action.yml",
          ".github/workflows/test.yml",
          "bench/vitest.config.ts",
          "examples/vite-ssr-vue/test/e2e/markdown.test.js",
          "packages/crawl/test/unit/glob-utils.test.ts",
          "packages/crawl/test/unit/home-page-parsing.test.ts",
          "packages/crawl/test/unit/llms-txt.test.ts",
          "packages/crawl/test/unit/metadata-extractor.test.ts",
          "packages/llms-db/test/database.test.ts",
          "packages/llms-db/test/utils.test.ts"
        ],
        "docs": [
          "LICENSE.md",
          "README.md",
          "bench/README.md",
          "docs/app/app.config.ts",
          "docs/app/app.vue",
          "docs/app/assets/css/main.css",
          "docs/app/components/FeedbackButtons.vue",
          "docs/app/components/Footer.vue",
          "docs/app/components/Header.vue",
          "docs/app/components/Logo.vue",
          "docs/app/components/LogoStatic.vue",
          "docs/app/components/OgImage/Home.vue",
          "docs/app/components/OgImage/Unhead.vue",
          "docs/app/components/ProsePre.vue",
          "docs/app/components/TableOfContents.vue",
          "docs/app/components/ads/Ads.vue",
          "docs/app/components/ads/AdsFallback.vue",
          "docs/app/components/color-mode/ColorModeButton.vue",
          "docs/app/components/content/CodeGroup.vue",
          "docs/app/components/content/FigureImage.vue",
          "docs/app/components/content/TabComparison.vue",
          "docs/app/composables/format.ts",
          "docs/app/css/global.css",
          "docs/app/error.vue",
          "docs/app/layouts/article-simple.vue",
          "docs/app/layouts/docs.vue",
          "docs/app/mdc.config.ts",
          "docs/app/pages/about.vue",
          "docs/app/pages/filters.vue",
          "docs/app/pages/index.vue",
          "docs/app/router.options.ts",
          "docs/logger.ts",
          "docs/nuxt.config.ts",
          "docs/package.json",
          "docs/public/favicon.ico",
          "docs/public/fonts/HubotSans-Regular.woff2",
          "docs/public/grid.png",
          "docs/public/logo-dark.svg",
          "docs/public/logo.png",
          "docs/public/logo.svg",
          "docs/public/nuxt-x-share.png",
          "docs/server/api/compatibility.ts",
          "docs/server/api/feedback-thumbs.post.ts",
          "docs/server/api/feedback.post.ts",
          "docs/server/api/get-tweet/[tweetId].get.ts",
          "docs/server/api/github/[repo]/commit-count.get.ts",
          "docs/server/api/github/[repo]/contributors.get.ts",
          "docs/server/api/github/[repo]/issues-closed.get.ts",
          "docs/server/api/github/[repo]/releases.get.ts",
          "docs/server/api/github/[repo]/stars.get.ts",
          "docs/server/api/github/auth/callback.ts",
          "docs/server/api/github/auth/redirect.ts",
          "docs/server/api/github/sponsors.json.ts",
          "docs/server/api/npm/[pkgName]/downloads.get.ts",
          "docs/server/api/sse.ts",
          "docs/server/api/stream.ts",
          "docs/server/storage.ts",
          "docs/server/tsconfig.json",
          "docs/server/utils/github.ts",
          "docs/tsconfig.json",
          "docs/types/schemas.ts",
          "docs/utils/content.ts",
          "docs/utils/urls.ts",
          "examples/nuxt/README.md",
          "examples/vite-ssr-vue/README.md",
          "packages/action/README.md",
          "packages/crawl/README.md",
          "packages/llms-db/README.md",
          "packages/mdream/README.md",
          "packages/mdream/docs/splitter.md"
        ]
      }
    },
    {
      "id": 1158423302,
      "name": "koel",
      "displayName": "koel",
      "description": "Music streaming solution that works.",
      "summary": "The Problem\n\nYou have a massive music library, maybe a mix of your meticulously curated FLAC files and some stuff you definitely didn't torrent in college. You want access to it from any device without relying on some overpriced streaming service that randomly decides to nuke your favorite album. You’re a developer, so you don’t want some bloated, closed-source solution with a clunky UI and hidden limitations. Enter koel, a self-hosted music streaming service that doesn't suck.\n\nWhat This Does\n\nKoel is a web-based audio streaming solution built with Laravel on the backend and Vue on the frontend. The backend lives in the app/ directory, with neatly organized subfolders for controllers, builders (app/Builders/), enums (app/Enums/), and custom attributes (app/Attributes/). The controllers under app/Http/Controllers/API/ handle everything from managing playlists (PlaylistController.php) to syncing podcasts (SyncPodcastsController.php). \n\nFor configuration, there’s an .env.example file to get started, and deployment workflows are neatly defined in .github/workflows/. The api-docs/ folder even has an OpenAPI spec (api.yaml) if you want to get nerdy and integrate your own tools. Oh, and if you’re running this in a team environment, there’s support for CODEOWNERS and .husky/pre-commit hooks to keep your repo clean. It’s clear this project was built with devs in mind.\n\nReal-World Use\n\nImagine you’ve just set up Koel on your home server. After configuring your .env file to point to your media folder, you run php artisan koel:init to scan your library. Koel’s backend takes over, indexing your collection using builders like AlbumBuilder.php and SongBuilder.php. Once that’s done, fire up the front-end, log in, and voilà: your music is now accessible from any device with a browser or via the official Koel Player app.\n\nWant to customize it? Maybe you’d prefer a different storage backend—say, Dropbox or S3. No problem: SetupDropboxStorageCommand.php and SetupS3StorageCommand.php in app/Console/Commands/Storage/ have you covered. This setup screams “power user,” and that’s exactly who Koel was built for.\n\nThe Bottom Line\n\nKoel is a great choice for developers who want total control over their music streaming and aren’t afraid of a little setup. The codebase is clean and well-structured, making it easier to extend or tweak if needed. Just don’t expect this to be as plug-and-play as Spotify—it’s not for the faint of heart. But if you’ve got the chops and the music collection to justify it, Koel’s a solid, open-source way to bring your audio library into the 21st century.",
      "url": "https://github.com/moses-y/koel",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "koel/koel",
        "url": "https://github.com/koel/koel",
        "stars": 17058
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 15, 2026",
      "updatedAt": "February 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "directories": {
          ".cursor": 2,
          "(root)": 10,
          ".github": 21,
          ".husky": 2,
          ".junie": 2,
          ".vscode": 2,
          "api-docs": 1,
          "app": 160
        },
        "languages": {
          "JSON": 5,
          "YAML": 12,
          "Markdown": 7,
          "PHP": 160
        },
        "entryPoints": [],
        "configFiles": [
          ".env.example"
        ],
        "dependencies": [],
        "testFiles": [
          ".github/assets/sponsors/codespect.png",
          ".github/workflows/test-backend-mariadb.yml",
          ".github/workflows/test-backend-pgsql.yml",
          ".github/workflows/test-backend-sqlite.yml",
          "app/Exceptions/UserProspectUpdateDeniedException.php",
          "app/Helpers/TestableIdentifier.php"
        ],
        "docs": [
          ".junie/guidelines.md",
          "LICENSE.md",
          "README.md",
          "api-docs/api.yaml",
          "app/Casts/LicenseInstanceCast.php",
          "app/Casts/LicenseMetaCast.php",
          "app/Console/Commands/ActivateLicenseCommand.php",
          "app/Console/Commands/CheckLicenseStatusCommand.php",
          "app/Console/Commands/DeactivateLicenseCommand.php",
          "app/Enums/LicenseStatus.php",
          "app/Exceptions/FailedToActivateLicenseException.php",
          "app/Facades/License.php",
          "app/Http/Controllers/API/ActivateLicenseController.php"
        ]
      }
    },
    {
      "id": 1158422920,
      "name": "Brisk-Budget",
      "displayName": "Brisk Budget",
      "description": "A Light Weight, JSON Based, Personal Finance Tracker",
      "summary": "The Problem\nManaging personal finances can be a headache. Most apps are bloated, require subscriptions, or just don’t meet basic needs. If you’re looking to track your expenses without dealing with a convoluted interface or a database, you’re in trouble.\n\nWhat This Does\nEnter Brisk-Budget. This lightweight, JSON-based finance tracker lets you manage accounts, transactions, and even recurring payments—all from your local machine. The app lives in public/index.html, with the frontend powered by vanilla JavaScript in public/js/app.js. No frameworks to learn, just straight-up JS that you can read and modify.\n\nData storage happens in simple JSON files, eliminating the need for a database. The server/utils/data.js handles data retrieval and storage, making it straightforward to back up or transfer your financial info. Need a new category? Just tweak the settings in the app, and you're good to go.\n\nReal-World Use\nImagine you’ve got a couple of accounts—checking, savings, and maybe a loan. You want to track where your money goes without fuss. You fire up the app, categorize your transactions in public/js/categories.js, and set up recurring payments in public/js/recurring.js. Want to see your net worth trend? Just check the dashboard analytics, and you’ve got a clear picture.\n\nIf you want to deploy it, just run the provided shell script in deploy.sh. It sets up everything, including a systemd service for auto-start. Easy-peasy.\n\nThe Bottom Line\nBrisk-Budget is a no-frills solution for personal finance tracking. It’s lightweight, easy to deploy, and requires minimal setup. If you're looking for something simple and self-hosted, this is worth a shot. Just don’t expect it to replace your enterprise-level finance software—it's not that kind of beast. But for personal use? It gets the job done.",
      "url": "https://github.com/moses-y/Brisk-Budget",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "CoppingEthan/Brisk-Budget",
        "url": "https://github.com/CoppingEthan/Brisk-Budget",
        "stars": 22
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 15, 2026",
      "updatedAt": "February 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "directories": {
          "(root)": 7,
          "assets": 5,
          "public": 22,
          "server": 14
        },
        "languages": {
          "Markdown": 1,
          "Shell": 1,
          "JSON": 2,
          "CSS": 1,
          "HTML": 1,
          "JavaScript": 23
        },
        "entryPoints": [
          "public/index.html",
          "public/js/app.js",
          "server/index.js"
        ],
        "configFiles": [
          "package.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ]
      }
    },
    {
      "id": 1158359534,
      "name": "Runestone",
      "displayName": "Runestone",
      "description": "📝 Performant plain text editor for iOS with syntax highlighting, line numbers, invisible characters and much more.",
      "summary": "The Problem\nEditing code on iOS sucks. Apple's UITextView is a joke for anything beyond plain text: no syntax highlighting, no line numbers, and zero awareness of invisible characters or indentation. If you want a real code editor on iOS, you usually end up cobbling together hacks or relying on garbage webviews. Runestone fixes this.\n\nWhat This Does\nRunestone is a Swift framework for making an actual code editor on iOS. It uses GitHub's Tree-sitter (see Example/Languages/Sources/TreeSitterJavaScript/) for fast, incremental parsing and syntax highlighting. You get line numbers, invisible character display, code-aware insertion (auto-pairing quotes/brackets), and customizable themes. The core lives in Sources/Runestone, with docs in Documentation.docc and demo code in Example/.\n\nCustomization isn't just a checkbox—want your own theme? Check out the Example/Themes/Sources/RunestoneOneDarkTheme/OneDarkTheme.swift. Adding languages is straightforward: look at highlights.scm and injections.scm in the JavaScript example. All the little editor features (line wrapping, page guide, overscroll, regex search) are handled in the framework, not bolted on.\n\nReal-World Use\nSay you want a SwiftUI app that edits JavaScript. You’d drop in the Runestone package, set up a TextView (see MainViewController.swift in the example), and wire up a TreeSitterLanguage for JS. Themes are just Swift structs—grab TomorrowNightTheme.swift, tweak colors, and set it as your editor theme. Invisible characters and line numbers are one-liners. You can even detect indentation style automatically, so your editor stops mangling tabs and spaces.\n\ntextView.language = TreeSitterLanguage.javascript\ntextView.theme = TomorrowNightTheme()\ntextView.showLineNumbers = true\n\nThe Bottom Line\nRunestone is what Apple should've shipped for code editing. It's fast, flexible, and actually respects developer needs. If you're building an iOS code editor or need a solid text input for dev tools, use it. For simple note apps, it's overkill. For anything code-related, it's the best option unless you hate Swift or want to reinvent the wheel.",
      "url": "https://github.com/moses-y/Runestone",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "simonbs/Runestone",
        "url": "https://github.com/simonbs/Runestone",
        "stars": 3053
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 15, 2026",
      "updatedAt": "February 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "directories": {
          "(root)": 10,
          ".github": 12,
          "Assets": 1,
          "Design": 2,
          "Example": 95,
          "Scripts": 2,
          "Sources": 78
        },
        "languages": {
          "YAML": 14,
          "Swift": 28,
          "JSON": 38,
          "Markdown": 9,
          "C/C++ Header": 2,
          "C": 2,
          "Shell": 2
        },
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [
          ".github/workflows/build_and_test.yml",
          ".github/workflows/ui_tests.yml",
          "Scripts/run-ui-test-chinese.sh",
          "Scripts/run-ui-test-korean.sh"
        ],
        "docs": [
          "Example/Languages/README.md",
          "Example/Themes/README.md",
          "LICENSE",
          "README.md"
        ]
      }
    },
    {
      "id": 1158358901,
      "name": "DoorOpener",
      "displayName": "DoorOpener",
      "description": "A sleek, single-button web portal for triggering any Home Assistant action (like opening a building door), protected by secure PIN authentication. Perfect for apartment buildings, offices, or any scenario where you want easy, controlled access for multiple users.",
      "summary": "The Problem\n\nManaging secure, convenient door access for shared spaces—like apartment buildings or offices—sucks. Physical keys are a mess to manage, and alternatives like smart locks often come with clunky apps or hardware that don't scale well for multiple users. Plus, integrating these setups with something like Home Assistant is not exactly beginner-friendly, let alone secure.\n\nWhat This Does\n\nDoorOpener cuts through that nonsense with a simple, web-based keypad interface that triggers Home Assistant actions like opening a door. It's sleek, functional, and focused. The core is a Python Flask app (app.py) that serves a modern, responsive UI from the templates/ and static/ directories. Users enter their PINs, which are securely stored and managed via the users_store.py module. There's even OpenID Connect (OIDC) support if you want to integrate SSO for extra security.\n\nThe project is all Docker-friendly, with a Dockerfile and docker-compose.yml for quick deployment. Configuration happens through a .env file and a config.ini template, so you can easily customize things like ports, secrets, and Home Assistant endpoints. The tests/ directory has 10 test files, covering everything from security to routes, so you’re not flying blind if you need to modify it.\n\nReal-World Use\n\nImagine you manage a coworking space with a shared main door. With DoorOpener, you can set up individual PINs for each tenant, so everyone's access is tied to their unique code. If someone forgets to pay rent, you disable their access via the admin panel (templates/admin.html). \n\nHere’s a quick workflow:\nDeploy the app using Docker Compose (you can copy the docker-compose.yml snippet from the README).\nConfigure the app to connect to your Home Assistant instance, assigning the door lock entity in config.ini.\nShare the web portal link with tenants. They log in, type their PIN, and voilà—the door unlocks.\n\nNeed to revoke access? Update the JSON-based user store, and it’s done. No messy re-keying or awkward conversations.\n\nThe Bottom Line\n\nDoorOpener is a solid, single-purpose tool for anyone who wants secure, programmable door access without the headache of bloated ecosystems or expensive hardware. It’s not perfect—the OIDC setup could use some love, and it’s not a plug-and-play Home Assistant add-on (yet). But if you’re comfortable tinkering with Docker and Python, this project is gold. Just don’t expect corporate-grade security out of the box.",
      "url": "https://github.com/moses-y/DoorOpener",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Sloth-on-meth/DoorOpener",
        "url": "https://github.com/Sloth-on-meth/DoorOpener",
        "stars": 72
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 15, 2026",
      "updatedAt": "February 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "directories": {
          "(root)": 13,
          ".github": 3,
          "static": 6,
          "templates": 2,
          "tests": 10
        },
        "languages": {
          "YAML": 4,
          "Markdown": 2,
          "Python": 12,
          "Shell": 1,
          "JavaScript": 1,
          "HTML": 2
        },
        "entryPoints": [
          "app.py",
          "templates/index.html"
        ],
        "configFiles": [
          ".env.example",
          "Dockerfile",
          "docker-compose.yml",
          "requirements.txt",
          "setup.cfg"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [
          "tests/conftest.py",
          "tests/test_admin_users.py",
          "tests/test_app.py",
          "tests/test_more.py",
          "tests/test_oidc.py",
          "tests/test_routes.py",
          "tests/test_security.py",
          "tests/test_ssl.py",
          "tests/test_users_store.py",
          "tests/test_utils.py"
        ],
        "docs": [
          "CHANGELOG.md",
          "README.md"
        ]
      }
    },
    {
      "id": 1158358682,
      "name": "RSTGameTranslation",
      "displayName": "RSTGameTranslation",
      "description": "🎮 Real-time Game Translation Tool | OCR + AI Translation | Windows Gaming | Open Source",
      "summary": "The Problem\nEver tried playing a game that’s in a language you don’t understand? It’s frustrating, right? You can’t follow the story or understand the mechanics, and that’s a buzzkill. Enter the need for real-time translation tools that can help you dive into those foreign worlds without the language barrier.\n\nWhat This Does\nRSTGameTranslation is your go-to tool for breaking down those language walls in gaming. It combines Optical Character Recognition (OCR) and AI translation to deliver real-time text translation while you’re playing. The project structure shows you how it all comes together: src/ChatGptTranslationService.cs and src/GoogleTranslateService.cs handle the nitty-gritty of pulling in translation from various APIs, while the app/Languages folder contains JSON files for multilingual support.\n\nThe entry point is index.html, where the magic begins. You can choose from several OCR options like OneOCR, PaddleOCR, or EasyOCR. They’re all tucked away in app/webserver, which means you can pick what works best for your setup. This flexibility is key for gamers who want a tailored experience.\n\nReal-World Use\nImagine you're playing an RPG with complex dialogues in Japanese. You fire up RSTGameTranslation, select OneOCR for quick setup, and opt for Google Translate for the translations. As you play, you press Alt+Q to select the dialogue box. The tool captures the text, translates it, and overlays the English translation on your screen without missing a beat. You can keep your immersion while understanding every plot twist.\n\nQuick commands:\nRun rst.exe\nSelect Window (Alt+Q)\nStart translating (Alt+G)\n\nThe Bottom Line\nRSTGameTranslation is a solid tool if you're serious about gaming in different languages. The flexibility with OCR options and translation services is a nice touch, but it might be overkill for casual gamers who just want a quick fix. If you're into immersive experiences and don't mind a bit of setup, give it a shot. Just don’t expect a fully polished product yet since it’s still in the early stages with zero stars on GitHub.",
      "url": "https://github.com/moses-y/RSTGameTranslation",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "thanhkeke97/RSTGameTranslation",
        "url": "https://github.com/thanhkeke97/RSTGameTranslation",
        "stars": 439
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 15, 2026",
      "updatedAt": "February 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "directories": {
          ".github": 5,
          "(root)": 13,
          "app": 26,
          "media": 6,
          "src": 62
        },
        "languages": {
          "YAML": 4,
          "Markdown": 4,
          "JSON": 7,
          "Python": 6,
          "HTML": 2,
          "C#": 48,
          "JavaScript": 1
        },
        "entryPoints": [
          "index.html"
        ],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [
          "media/latest_version_checker.json"
        ],
        "docs": [
          ".github/workflows/update-readme-version.yml",
          "LICENSE.md",
          "README.md",
          "README_vi.md"
        ]
      }
    },
    {
      "id": 1157755557,
      "name": "trackers",
      "displayName": "trackers",
      "description": "Trackers gives you clean, modular re-implementations of leading multi-object tracking algorithms released under the permissive Apache 2.0 license. You combine them with any detection model you already use.",
      "summary": "The Problem\n\nMulti-object tracking is essential for tasks like surveillance, sports analytics, and robotics, but it’s a pain to implement. Most tracking algorithms are buried in messy research codebases or tightly coupled with specific detection models. If you want to plug in custom detectors or experiment with different trackers, good luck—you’re in for a weekend of untangling spaghetti code.\n\nWhat This Does\n\nEnter trackers. It’s a Python library that gives you modular re-implementations of popular multi-object tracking algorithms like SORT and ByteTrack. Think of it as the clean, plug-and-play version of those research papers. The code is Apache 2.0 licensed, meaning you can actually use it in real-world projects without worrying about lawyers.\n\nThe key directories are trackers/core/, where the actual tracker implementations live, and trackers/eval/, which contains utilities for evaluating tracking performance. The trackers/scripts/ directory includes a CLI tool (trackers/scripts/track.py) for running basic tracking jobs directly from the terminal. Want to nerd out even more? The docs/ folder is packed with detailed guides and API documentation, plus a bunch of flashy SVG logos for your presentations.\n\nReal-World Use\n\nSay you’ve got a custom object detection model—maybe something lightweight like rfdetr-nano for edge devices. You can pair it with trackers to start tracking objects in a video feed within minutes. Here’s how simple it looks:\n\nimport cv2\nfrom rfdetr import RFDETRNano\nfrom trackers import ByteTrackTracker\n\nmodel = RFDETRNano()\ntracker = ByteTrackTracker()\n\ncap = cv2.VideoCapture(\"video.mp4\")\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n    detections = model.predict(frame)\n    trackedobjects = tracker.update(detections)\n    # Do something with trackedobjects, like drawing bounding boxes\n\nIf you don’t want to write code, the CLI tool has you covered. Run trackers track --source input.mp4 --output tracked.mp4 --model your-detector --tracker bytetrack to get tracked video output with minimal setup. No excuses—it doesn’t get easier than this.\n\nThe Bottom Line\n\ntrackers is a solid choice if you care about clean, modular code and need to mix-and-match detection models with tracking algorithms. It’s not for you if you need a ready-to-go, end-to-end solution (there’s no built-in detector). But if you’re building a custom pipeline or experimenting with tracking algorithms, this is the toolkit you want. It’s not perfect (more tracker support is \"coming soon\"™), but it’s already worth your time.",
      "url": "https://github.com/moses-y/trackers",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "roboflow/trackers",
        "url": "https://github.com/roboflow/trackers",
        "stars": 2913
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 14, 2026",
      "updatedAt": "February 14, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "directories": {
          ".github": 9,
          "(root)": 11,
          "docs": 22,
          "test": 15,
          "trackers": 29
        },
        "languages": {
          "YAML": 10,
          "Markdown": 13,
          "Python": 45,
          "JavaScript": 3,
          "HTML": 2,
          "CSS": 3,
          "TOML": 1
        },
        "entryPoints": [
          "trackers/scripts/__main__.py"
        ],
        "configFiles": [
          "pyproject.toml"
        ],
        "dependencies": [
          "pyproject.toml"
        ],
        "testFiles": [
          ".github/workflows/ci-integration-tests.yml",
          ".github/workflows/ci-tests.yml",
          "docs/hooks/doctest_filter.py",
          "test/conftest.py",
          "test/core/__init__.py",
          "test/core/test_registration.py",
          "test/eval/__init__.py",
          "test/eval/test_box.py",
          "test/eval/test_clear.py",
          "test/eval/test_evaluate.py",
          "test/eval/test_hota.py",
          "test/eval/test_identity.py",
          "test/eval/test_integration.py",
          "test/io_tests/__init__.py",
          "test/io_tests/test_video.py",
          "test/scripts/test_progress.py",
          "test/scripts/test_track.py",
          "test/utils/__init__.py"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "docs/api/evals.md",
          "docs/api/io.md",
          "docs/api/trackers.md",
          "docs/assets/logo-trackers-black.svg",
          "docs/assets/logo-trackers-violet.svg",
          "docs/assets/logo-trackers-white.svg",
          "docs/hooks/doctest_filter.py",
          "docs/index.md",
          "docs/javascripts/cli_builder_framework.js",
          "docs/javascripts/command_builder.js",
          "docs/javascripts/pycon_copy.js",
          "docs/learn/evaluate.md",
          "docs/learn/install.md",
          "docs/learn/track.md",
          "docs/overrides/partials/comments.html",
          "docs/overrides/partials/header.html",
          "docs/overrides/stylesheets/command_builder.css",
          "docs/overrides/stylesheets/rf.css",
          "docs/overrides/stylesheets/style.css",
          "docs/trackers/bytetrack.md",
          "docs/trackers/comparison.md",
          "docs/trackers/sort.md"
        ]
      }
    },
    {
      "id": 1157702284,
      "name": "Serial-Studio",
      "displayName": "Serial Studio",
      "description": "Cross-platform telemetry visualization application for real-time data monitoring and analysis from multiple sources.",
      "summary": "The Problem\nMonitoring real-time data from multiple devices can be a headache. You’ve got sensors sending data from an Arduino, an ESP32, or a Raspberry Pi, but pulling that data into a single view often involves a lot of coding, manual setup, and guesswork. You need a tool that can handle various protocols without turning your life into a debugging nightmare.\n\nWhat This Does\nEnter Serial Studio. This application is a cross-platform telemetry visualization tool that simplifies data collection from serial ports, Bluetooth, MQTT, and more. You can find the core application logic in the app/ directory, which houses 180 files dedicated to the interface and functionality. The CMakeLists.txt files at the root and in app/ ensure that building this tool is straightforward across platforms.\n\nThe UI is built using QML, and the main window is defined in app/qml/MainWindow/MainWindow.qml. You can create dashboards with various widgets like Plot, Gauge, and DataGrid to visualize incoming data in real-time. Want to configure an MQTT connection? Open app/qml/Dialogs/MQTTConfiguration.qml, and you’re good to go.\n\nReal-World Use\nImagine you're debugging a Raspberry Pi that’s sending temperature data via MQTT. With Serial Studio, you can quickly set up a dashboard to visualize this data. Use the app/qml/Widgets/Plot.qml to create a real-time graph while inspecting other metrics through the DataGrid widget. No need to write a single line of code—just point, click, and configure. \n\nFor installation, grab the precompiled binaries from the latest release on GitHub. If you're on Linux, just make the AppImage executable with:\n\nchmod +x SerialStudio-Pro-3.2.3-Linux-x64.AppImage\n./SerialStudio-Pro-3.2.3-Linux-x64.AppImage\n\nThe Bottom Line\nSerial Studio is a solid tool for anyone needing to visualize telemetry data without the hassle of coding everything from scratch. It’s especially useful for IoT developers, educators, and hobbyists. However, if you’re only working on simple projects, this might feel like overkill. Just remember: it’s open-source, so dive in and adjust it to your needs if you’re feeling adventurous.",
      "url": "https://github.com/moses-y/Serial-Studio",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Serial-Studio/Serial-Studio",
        "url": "https://github.com/Serial-Studio/Serial-Studio",
        "stars": 6622
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 14, 2026",
      "updatedAt": "February 14, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "directories": {
          "(root)": 15,
          ".github": 3,
          "LICENSES": 2,
          "app": 180
        },
        "languages": {
          "YAML": 3,
          "Markdown": 10
        },
        "entryPoints": [],
        "configFiles": [
          "CMakeLists.txt",
          "app/CMakeLists.txt"
        ],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "LICENSE.md",
          "LICENSES/GPL-3.0-only.txt",
          "LICENSES/LicenseRef-SerialStudio-Commercial.txt",
          "README.md",
          "VALUE-FOR-LICENSE.md",
          "app/deploy/windows/license.rtf",
          "app/qml/Dialogs/LicenseManagement.qml"
        ]
      }
    },
    {
      "id": 1157700401,
      "name": "google-maps-scraper",
      "displayName": "google maps scraper",
      "description": "scrape data  data from Google Maps. Extracts data such as the name, address, phone number, website URL, rating,  reviews number, latitude and longitude, reviews,email and more for each place",
      "summary": "The Problem\n\nGoogle Maps is great for finding local businesses, but scraping actual data is a pain. No public API for all the info you want—think emails, phone numbers, reviews, lat/lon, and business websites. Manual copy-paste? Forget it. Trying to automate with headless browsers gets you blocked fast, or you end up writing spaghetti code that breaks every time Google tweaks their UI.\n\nWhat This Does\n\ngoogle-maps-scraper pulls business data out of Google Maps at scale. It grabs names, addresses, phone numbers, websites, ratings, review counts, lat/lon, emails, and even full reviews, all in one go. The guts live in the gmaps/ folder—place.go parses the place details, reviews.go grabs user reviews, and emailjob.go tries to dig out emails. You can run it via CLI (main.go), use the Web UI (web/static/templates/index.html), or hit the REST API (web/web.go). Storage is handled by the postgres/ or leadsdb/ providers, depending on how fancy you want to get. Docker and Kubernetes configs are ready (Dockerfile, docker-compose.dev.yaml) if you want to deploy this thing without fuss.\n\nReal-World Use\n\nSay you want every pizza shop in Chicago, including their email and review count. Fire up the CLI:\n\ngo run main.go --query=\"pizza Chicago\" --output=output.json\n\nOr spin up the web UI with Docker:\n\ndocker-compose -f docker-compose.dev.yaml up\n\nOpen the browser, drop your search, and export leads directly to LeadsDB or CSV. The REST API lets you automate this from your own scripts—just POST a job and get results back. No babysitting headless browsers or dealing with Google’s endless anti-bot changes.\n\nThe Bottom Line\n\nIf you need Google Maps data for lead gen, market research, or whatever hustle you’re running, this repo actually delivers. It’s not for tiny projects—setup can be hairy, and Google will still fight you on scale. But if you want real data and hate writing brittle scraping code, use this. If you’re just looking for a quick list, stick to SerpApi or a Chrome extension.",
      "url": "https://github.com/moses-y/google-maps-scraper",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "gosom/google-maps-scraper",
        "url": "https://github.com/gosom/google-maps-scraper",
        "stars": 3271
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 14, 2026",
      "updatedAt": "February 14, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "directories": {
          ".github": 3,
          "(root)": 22,
          "cmd": 1,
          "deduper": 2,
          "examples": 1,
          "exiter": 1,
          "gmaps": 8,
          "img": 12,
          "leadsdb": 1,
          "postgres": 2,
          "runner": 9,
          "s3uploader": 1,
          "scripts": 7,
          "sponsors": 1,
          "testdata": 5,
          "tlmt": 3,
          "web": 11
        },
        "languages": {
          "YAML": 7,
          "Markdown": 7,
          "Go": 36,
          "SQL": 7,
          "JSON": 5,
          "CSS": 1,
          "HTML": 4
        },
        "entryPoints": [
          "cmd/tools/tools.go",
          "main.go",
          "web/static/templates/index.html"
        ],
        "configFiles": [
          "Dockerfile",
          "Dockerfile.rod",
          "Makefile",
          "docker-compose.dev.yaml",
          "go.mod"
        ],
        "dependencies": [
          "go.mod"
        ],
        "testFiles": [
          "gmaps/entry_test.go",
          "testdata/output.json",
          "testdata/panic.json",
          "testdata/panic2.json",
          "testdata/raw.json",
          "testdata/raw2.json",
          "web/static/spec/spec.yaml"
        ],
        "docs": [
          "LICENSE",
          "README.md"
        ]
      }
    },
    {
      "id": 1157468615,
      "name": "sora-digital-photo-frame",
      "displayName": "sora digital photo frame",
      "description": "Sora Digital Photo Frame - Turn any screen into a smart digital photo frame with ease",
      "summary": "Sora Digital Photo Frame: Open-Source Slideshows for Your Screens\n\nThe Problem\n\nDigital photo frames are great—until you realize they’re overpriced, locked into some proprietary ecosystem, or just plain ugly. If you’ve got an old tablet, laptop, or TV gathering dust, why not turn it into a kickass photo frame instead? That’s what sora-digital-photo-frame does: it transforms any device with a web browser into a customizable, remotely managed photo display. No subscriptions, no BS.\n\nWhat This Does\n\nAt its core, this project is a Node.js app that serves a clean, responsive photo display UI through a web browser. The backend (server folder) handles everything from user authentication (authController.js) to managing photos (imageController.js) and folders (folderController.js). It even taps into Google Photos with a dedicated controller (googlePhotosController.js), which is cool if you’ve got your whole library parked there.\n\nOn the frontend, the server/public directory houses the admin panel (admin.html, admin.js) and slideshow UI. There's a Finder-like folder selection page (folder-selection.html) and some Material Design-inspired CSS (folder-selection-extensions.css). The whole thing is wrapped in a Docker setup (Dockerfile, docker-compose.yml), so you can deploy it to your home server or a cloud instance with minimal effort. The README even has a dedicated DOCKER.md guide for setup—no excuses for not getting it running.\n\nReal-World Use\n\nLet’s say you’ve got an old Chromebook lying around. Install Docker on your home server, clone this repo, and fire it up with docker-compose up. Upload your favorite photos to the /admin panel, organize them into folders, and voilà: your Chromebook is now a sleek, fullscreen photo frame. Bonus points for the Wake Lock feature, which keeps the display from going to sleep mid-slideshow.\n\nWant to get fancy? Use the Google Photos integration to pull in your cloud-stored pics. Or, if you’re the keyboard-shortcut-savvy type, control everything with keys like Space (play/pause) and F (fullscreen). There’s even support for nested folders, so you can show off your vacation albums without scrolling through a million cat memes.\n\nThe Bottom Line\n\nsora-digital-photo-frame is a fun, functional project that scratches a very specific itch: turning your old hardware into a useful photo display. The UI is polished, the features are solid, and the Docker setup makes deployment painless. Is it overkill for just showing some JPGs? Maybe. But if you’ve got a spare device and want a weekend project, it’s absolutely worth a try.",
      "url": "https://github.com/moses-y/sora-digital-photo-frame",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Sorbh/sora-digital-photo-frame",
        "url": "https://github.com/Sorbh/sora-digital-photo-frame",
        "stars": 72
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 13, 2026",
      "updatedAt": "February 13, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 47,
        "directories": {
          "(root)": 8,
          "server": 39
        },
        "languages": {
          "Markdown": 3,
          "YAML": 1,
          "JSON": 4,
          "JavaScript": 27,
          "HTML": 5,
          "CSS": 1
        },
        "frameworks": [
          "React",
          "Express",
          "Docker"
        ],
        "packageManager": "npm",
        "hasDocker": true,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "server/routes/index.js",
          "server/server.js"
        ],
        "configFiles": [
          "Dockerfile",
          "docker-compose.yml",
          "server/.env.example",
          "server/package.json"
        ],
        "dependencies": [
          "package-lock.json",
          "server/package-lock.json",
          "server/package.json"
        ],
        "testFiles": [
          "server/tests/folderController.test.js"
        ],
        "docs": [
          "CHANGELOG.md",
          "README.md"
        ],
        "fileTypes": {
          ".md": 3,
          ".yml": 1,
          ".json": 4,
          ".example": 1,
          ".js": 27,
          ".html": 5,
          ".css": 1,
          ".png": 1,
          ".svg": 1
        }
      }
    },
    {
      "id": 1157453053,
      "name": "101-linux-commands",
      "displayName": "101 linux commands",
      "description": "101 Linux commands Open-source eBook and CLI tool",
      "summary": "The Problem\nNew Linux users often feel lost in the terminal jungle. If you’ve ever stared blankly at a command prompt, you know what I mean. With countless commands to remember, it’s easy to miss the essentials that can significantly boost your productivity.\n\nWhat This Does\nEnter the 101-linux-commands repository. This open-source eBook and CLI tool provides a curated list of 101 commands every Linux user should know. The structure is straightforward: commands are categorized into sections like Disk and File System Management, User and Group Management, and more. \n\nThe cli/commands/ folder contains real command implementations, like hello.py for a simple greeting or list.py for displaying files in a directory. Want to check your version? Just call python cli/cli.py version. The cli/data/commands.json file is your backend for command data, ensuring everything is organized and easily accessible.\n\nReal-World Use\nLet’s say you’re trying to manage disk space. Instead of sifting through man pages, you could dive into the Disk and File System Management section of the eBook. There, you’ll find useful commands like df and du, along with practical examples. You can even run the CLI tool to quickly test commands directly from your terminal. \n\nFor instance, if you want to list all files, just call:\n\npython cli/cli.py list\n\nThis command outputs your current directory's contents, making it a breeze to navigate.\n\nThe Bottom Line\nThis repo is a solid resource for newcomers and seasoned users alike. It’s straightforward, no-nonsense, and gets straight to the point without unnecessary fluff. However, with zero stars, it could use a bit more community love. If you're looking to beef up your terminal skills, this eBook is worth a download—just don’t expect a polished, corporate feel.",
      "url": "https://github.com/moses-y/101-linux-commands",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "bobbyiliev/101-linux-commands",
        "url": "https://github.com/bobbyiliev/101-linux-commands",
        "stars": 739
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 13, 2026",
      "updatedAt": "February 13, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".github": 10,
          "(root)": 6,
          "cli": 19,
          "ebook": 165
        },
        "languages": {
          "YAML": 3,
          "Markdown": 167,
          "Python": 13,
          "JSON": 2,
          "TOML": 1,
          "CSS": 2,
          "HTML": 3
        },
        "frameworks": [
          "Laravel"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "cli/cli.py"
        ],
        "configFiles": [
          "cli/pyproject.toml"
        ],
        "dependencies": [
          "cli/pyproject.toml",
          "composer.json"
        ],
        "testFiles": [
          "cli/tests/test_cli.py",
          "cli/tests/test_generate_index.py"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "Guidelines.md",
          "LICENSE",
          "README.md",
          "cli/README.md",
          "ebook/README.md"
        ],
        "fileTypes": {
          ".yml": 3,
          ".md": 167,
          ".bck": 3,
          ".py": 13,
          ".json": 2,
          ".toml": 1,
          ".lock": 1,
          ".jpg": 1,
          ".css": 2,
          ".html": 3
        }
      }
    },
    {
      "id": 1157441486,
      "name": "openrun",
      "displayName": "openrun",
      "description": "Internal tools deployment made easy.  Deploy web apps declaratively, on a single-node or on Kubernetes.",
      "summary": "The Problem\n\nDeploying internal tools shouldn’t mean wrestling with a dozen dashboards, hand-crafting YAML, or babysitting a cluster just to push a simple web app. Most \"easy\" deployment platforms turn into a mess of manual CLI commands, clicky UIs, and config drift. If you’ve ever tried to keep a small fleet of internal apps running and up-to-date—without going full DevOps—you know the pain.\n\nWhat This Does\n\nopenrun lets you deploy web apps declaratively, without the usual yak shaving. You write config, commit to Git, and OpenRun takes care of the rest. The brains live in cmd/openrun/—so if you want to see how commands like apply or sync actually work, check out files like applycmd.go and synccmds.go. There’s no hidden magic: every operation is tied to a real command and a config file.\n\nDeployment works both on a single node (via Docker/Podman) or Kubernetes, and you don’t have to change your config to switch between them. Features like blue-green deploys, staged rollouts, and scaling apps to zero are baked in. RBAC, OAuth/OIDC/SAML, and TLS? Handled out of the box. The Makefile and deploy/Dockerfile are there if you want to build or containerize the whole thing yourself.\n\nReal-World Use\n\nSay you’ve got a handful of internal Flask apps. You add an app spec file to your repo, push, and OpenRun does the rest—no fiddling with manual docker run commands or Helm charts. Updates? Change the config, commit, and OpenRun atomically rolls out the change. Want to add staging before prod? That’s a config tweak. Need SSO? Just configure it and let OpenRun handle the ugly details. Here’s a basic workflow:\n\nAdd new app config\ngit add myapp.yaml\ngit commit -m \"Add internal dashboard\"\ngit push\n\nOpenRun picks it up, deploys, manages TLS, and sets up RBAC\nopenrun apply\n\nThe Bottom Line\n\nOpenRun is legit if you want hands-off, Git-driven deployments for internal tools without building your own platform. It’s probably overkill for one-off side projects, but perfect for teams sick of manual deploys and config drift. If you’re allergic to endless YAML and love declarative workflows, give it a shot.",
      "url": "https://github.com/moses-y/openrun",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "openrundev/openrun",
        "url": "https://github.com/openrundev/openrun",
        "stars": 802
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 13, 2026",
      "updatedAt": "February 13, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".github": 9,
          "(root)": 9,
          "cmd": 13,
          "deploy": 18,
          "examples": 17,
          "internal": 134
        },
        "languages": {
          "Markdown": 7,
          "YAML": 7,
          "Go": 133,
          "Shell": 1,
          "HCL": 1,
          "Terraform": 12,
          "HTML": 8,
          "CSS": 4,
          "JavaScript": 6,
          "TOML": 1
        },
        "frameworks": [
          "Docker",
          "Terraform"
        ],
        "packageManager": "go modules",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "cmd/openrun/account_cmds.go",
          "cmd/openrun/app_cmds.go",
          "cmd/openrun/app_update_cmds.go",
          "cmd/openrun/apply_cmd.go",
          "cmd/openrun/client_cmds.go",
          "cmd/openrun/flags.go",
          "cmd/openrun/main.go",
          "cmd/openrun/misc_cmds.go",
          "cmd/openrun/preview_cmds.go",
          "cmd/openrun/server_cmds.go",
          "cmd/openrun/sync_cmds.go",
          "cmd/openrun/version_cmds.go",
          "cmd/openrun/webhook_cmds.go",
          "internal/server/server.go"
        ],
        "configFiles": [
          "Makefile",
          "deploy/Dockerfile",
          "go.mod"
        ],
        "dependencies": [
          "go.mod"
        ],
        "testFiles": [
          ".github/ISSUE_TEMPLATE/3_testimonial.yml",
          ".github/workflows/test.yml",
          ".github/workflows/test_pr.yml",
          "internal/app/app_plugins_test.go",
          "internal/app/apptype/schema_loader_test.go",
          "internal/app/plugin_test.go",
          "internal/app/proxy_tracker_test.go",
          "internal/app/store/parse_query_test.go",
          "internal/app/store/sql_store_test.go",
          "internal/app/tests/app_test_helper.go",
          "internal/app/tests/appaction_test.go",
          "internal/app/tests/basic_test.go",
          "internal/app/tests/error_handling_test.go",
          "internal/app/tests/fragment_test.go",
          "internal/app/tests/http_plugin_test.go",
          "internal/app/tests/library_test.go",
          "internal/app/tests/loader_test.go",
          "internal/app/tests/params_test.go",
          "internal/app/tests/proxy_test.go",
          "internal/app/tests/response_test.go",
          "internal/app/tests/static_test.go",
          "internal/app/tests/store_test.go",
          "internal/app/tests/styling_test.go",
          "internal/app/tests/tmpl_test.go",
          "internal/container/parse_values_test.go",
          "internal/metadata/cert_storage_test.go",
          "internal/rbac/pathglob_test.go",
          "internal/rbac/rbac_test.go",
          "internal/server/appspecs/dummy/README",
          "internal/server/oauth_test.go",
          "internal/server/openrun_plugin_test.go",
          "internal/server/saml_test.go",
          "internal/server/secret_eval_test.go",
          "internal/server/server_test.go",
          "internal/server/test_helper.go",
          "internal/system/config_test.go",
          "internal/system/properties_test.go",
          "internal/system/time_test.go",
          "internal/testutil/assert.go",
          "internal/testutil/logging.go"
        ],
        "docs": [
          "CHANGELOG.md",
          "LICENSE",
          "README.md",
          "deploy/terraform/README.md",
          "examples/README.md",
          "internal/server/appspecs/dummy/README"
        ],
        "fileTypes": {
          ".md": 7,
          ".yml": 6,
          ".yaml": 1,
          ".go": 133,
          ".service": 1,
          ".sh": 1,
          ".hcl": 1,
          ".tf": 12,
          ".sample": 1,
          ".html": 8,
          ".star": 6,
          ".lock": 1,
          ".css": 4,
          ".js": 6,
          ".svg": 2,
          ".txt": 1,
          ".mod": 1,
          ".sum": 1,
          ".toml": 1
        }
      }
    },
    {
      "id": 1157441187,
      "name": "crowdsec",
      "displayName": "crowdsec",
      "description": "CrowdSec - the open-source and participative security solution offering crowdsourced protection against malicious IPs and access to the most advanced real-world CTI.",
      "summary": "CrowdSec: Open-Source Crowd-Powered Security That Doesn’t Suck  \n\nThe Problem  \n\nLet’s be real: the internet is crawling with malicious traffic. Brute force attempts, DDoS attacks, port scans, and more—someone’s always probing your servers for a weakness. Sure, you could slap a WAF or an IDS/IPS on there, but most solutions are either expensive, bloated, or locked behind paywalls. And even if you pick one, you’re on your own when it comes to staying updated on the latest threats. Not to mention the headache of managing all that.  \n\nWhat This Does  \n\nEnter CrowdSec. It’s an open-source, crowdsourced security engine that not only detects and blocks malicious actors but also shares threat intelligence across its community. Think of it as a neighborhood watch for your servers, except it doesn’t annoy you with bake sale flyers.  \n\nAt its core, you’ll find the CrowdSec Security Engine, which parses logs, detects shady behavior, and applies mitigation measures via modular bouncers. The detection rules live in the HUB and are licensed under MIT, so you can tweak them or create your own.  \n\nThe repo's structure screams \"enterprise-grade nerd tools.\" For example:  \n.github/workflows/ contains CI/CD pipelines for everything from running bats tests to publishing Docker images.  \n.github/ISSUE_TEMPLATE/ has YAML templates for bug reports, features, and governance (yeah, they’re serious about community input).  \nThe Dockerfile and .dockerignore files make containerization a breeze.  \n\nInstalling CrowdSec is straightforward. Whether you’re on Linux, Windows, Kubernetes, or even OpnSense, the docs have you covered. The default scenarios (brute force, port scans, etc.) are good to go out of the box, but if you need to fine-tune, the HUB has plenty of prebuilt rules to grab.  \n\nReal-World Use  \n\nImagine you’re running a public-facing web server. You install CrowdSec and point it at your Nginx logs. CrowdSec detects repeated login failures and flags the source IP as malicious. It adds the offender to your blocklist and—here’s the kicker—shares that IP with the global CrowdSec community. That means the next time that bad actor tries their luck on someone else, they’re already blocked.  \n\nOh, and if you want to visualize all this, the optional CrowdSec Console gives you a web UI to monitor, manage, and automate your setup.  \n\nThe Bottom Line  \n\nCrowdSec is like Fail2Ban on steroids, but with a global community feeding it real-world threat intelligence. It’s overkill for a tiny blog with 5 daily visitors, but if you’re managing exposed infrastructure and have logs to analyze, this is a no-brainer. Bonus points for being open-source and free to use. Just don’t expect hand-holding—this is a tool for people who know what a log file is.",
      "url": "https://github.com/moses-y/crowdsec",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "crowdsecurity/crowdsec",
        "url": "https://github.com/crowdsecurity/crowdsec",
        "stars": 12633
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 13, 2026",
      "updatedAt": "February 13, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 12,
          ".github": 29,
          "build": 84,
          "cmd": 75
        },
        "languages": {
          "YAML": 29,
          "TOML": 2,
          "Shell": 4,
          "Markdown": 8,
          "Python": 23,
          "HTML": 1,
          "Go": 74
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "Azure Pipelines",
        "entryPoints": [
          "cmd/crowdsec-cli/Makefile",
          "cmd/crowdsec-cli/clialert/alerts.go",
          "cmd/crowdsec-cli/clialert/sanitize.go",
          "cmd/crowdsec-cli/clialert/table.go",
          "cmd/crowdsec-cli/cliallowlists/allowlists.go",
          "cmd/crowdsec-cli/clibouncer/add.go",
          "cmd/crowdsec-cli/clibouncer/bouncers.go",
          "cmd/crowdsec-cli/clibouncer/delete.go",
          "cmd/crowdsec-cli/clibouncer/inspect.go",
          "cmd/crowdsec-cli/clibouncer/list.go",
          "cmd/crowdsec-cli/clibouncer/prune.go",
          "cmd/crowdsec-cli/clicapi/capi.go",
          "cmd/crowdsec-cli/cliconfig/backup.go",
          "cmd/crowdsec-cli/cliconfig/config.go",
          "cmd/crowdsec-cli/cliconfig/feature_flags.go",
          "cmd/crowdsec-cli/cliconfig/restore.go",
          "cmd/crowdsec-cli/cliconfig/show.go",
          "cmd/crowdsec-cli/cliconfig/showyaml.go",
          "cmd/crowdsec-cli/cliconsole/console.go",
          "cmd/crowdsec-cli/cliconsole/console_table.go",
          "cmd/crowdsec-cli/clidecision/decisions.go",
          "cmd/crowdsec-cli/clidecision/import.go",
          "cmd/crowdsec-cli/clidecision/table.go",
          "cmd/crowdsec-cli/cliexplain/explain.go",
          "cmd/crowdsec-cli/clihub/hub.go",
          "cmd/crowdsec-cli/clihub/items.go",
          "cmd/crowdsec-cli/clihub/utils_table.go",
          "cmd/crowdsec-cli/clihubtest/clean.go",
          "cmd/crowdsec-cli/clihubtest/coverage.go",
          "cmd/crowdsec-cli/clihubtest/create.go",
          "cmd/crowdsec-cli/clihubtest/eval.go",
          "cmd/crowdsec-cli/clihubtest/explain.go",
          "cmd/crowdsec-cli/clihubtest/hubtest.go",
          "cmd/crowdsec-cli/clihubtest/info.go",
          "cmd/crowdsec-cli/clihubtest/list.go",
          "cmd/crowdsec-cli/clihubtest/run.go",
          "cmd/crowdsec-cli/clihubtest/table.go",
          "cmd/crowdsec-cli/cliitem/cmdinspect.go",
          "cmd/crowdsec-cli/cliitem/cmdinstall.go",
          "cmd/crowdsec-cli/cliitem/cmdremove.go",
          "cmd/crowdsec-cli/cliitem/cmdupgrade.go",
          "cmd/crowdsec-cli/cliitem/hubappsec.go",
          "cmd/crowdsec-cli/cliitem/hubcollection.go",
          "cmd/crowdsec-cli/cliitem/hubcontext.go",
          "cmd/crowdsec-cli/cliitem/hubparser.go",
          "cmd/crowdsec-cli/cliitem/hubpostoverflow.go",
          "cmd/crowdsec-cli/cliitem/hubscenario.go",
          "cmd/crowdsec-cli/cliitem/item.go",
          "cmd/crowdsec-cli/cliitem/metrics.go",
          "cmd/crowdsec-cli/cliitem/metrics_table.go",
          "cmd/crowdsec-cli/clilapi/context.go",
          "cmd/crowdsec-cli/clilapi/lapi.go",
          "cmd/crowdsec-cli/clilapi/register.go",
          "cmd/crowdsec-cli/clilapi/status.go",
          "cmd/crowdsec-cli/clilapi/status_test.go",
          "cmd/crowdsec-cli/clilapi/utils.go",
          "cmd/crowdsec-cli/climachine/add.go",
          "cmd/crowdsec-cli/climachine/delete.go",
          "cmd/crowdsec-cli/climachine/flag.go",
          "cmd/crowdsec-cli/climachine/inspect.go",
          "cmd/crowdsec-cli/climachine/list.go",
          "cmd/crowdsec-cli/climachine/machines.go",
          "cmd/crowdsec-cli/climachine/prune.go",
          "cmd/crowdsec-cli/climachine/validate.go",
          "cmd/crowdsec-cli/climetrics/list.go",
          "cmd/crowdsec-cli/climetrics/metrics.go",
          "cmd/crowdsec-cli/climetrics/number.go",
          "cmd/crowdsec-cli/climetrics/scrape.go",
          "cmd/crowdsec-cli/climetrics/show.go",
          "cmd/crowdsec-cli/climetrics/statacquis.go",
          "cmd/crowdsec-cli/climetrics/statalert.go",
          "cmd/crowdsec-cli/climetrics/statappsecengine.go",
          "cmd/crowdsec-cli/climetrics/statappsecrule.go",
          "cmd/crowdsec-cli/climetrics/statbouncer.go",
          "cmd/crowdsec-cli/climetrics/statbucket.go"
        ],
        "configFiles": [
          "Makefile",
          "build/docker/Dockerfile",
          "build/docker/Dockerfile.debian",
          "build/docker/test/pyproject.toml",
          "cmd/crowdsec-cli/Makefile"
        ],
        "dependencies": [
          "build/docker/test/pyproject.toml"
        ],
        "testFiles": [
          ".github/workflows/docker-tests.yml",
          ".github/workflows/go-tests-windows.yml",
          ".github/workflows/go-tests.yml",
          "build/docker/test/.python-version",
          "build/docker/test/README.md",
          "build/docker/test/default.env",
          "build/docker/test/pyproject.toml",
          "build/docker/test/pytest-debug.ini",
          "build/docker/test/pytest.ini",
          "build/docker/test/tests/__init__.py",
          "build/docker/test/tests/conftest.py",
          "build/docker/test/tests/test_agent.py",
          "build/docker/test/tests/test_agent_only.py",
          "build/docker/test/tests/test_bouncer.py",
          "build/docker/test/tests/test_capi.py",
          "build/docker/test/tests/test_capi_whitelists.py",
          "build/docker/test/tests/test_cold_logs.py",
          "build/docker/test/tests/test_flavors.py",
          "build/docker/test/tests/test_hello.py",
          "build/docker/test/tests/test_hub.py",
          "build/docker/test/tests/test_hub_collections.py",
          "build/docker/test/tests/test_hub_parsers.py",
          "build/docker/test/tests/test_hub_postoverflows.py",
          "build/docker/test/tests/test_hub_scenarios.py",
          "build/docker/test/tests/test_local_api_url.py",
          "build/docker/test/tests/test_local_item.py",
          "build/docker/test/tests/test_metrics.py",
          "build/docker/test/tests/test_nolapi.py",
          "build/docker/test/tests/test_simple.py",
          "build/docker/test/tests/test_tls.py",
          "build/docker/test/tests/test_version.py",
          "build/docker/test/tests/test_wal.py",
          "build/docker/test/uv.lock",
          "build/rpm/SPECS/crowdsec.spec",
          "build/windows/Chocolatey/crowdsec/crowdsec.nuspec",
          "cmd/crowdsec-cli/clibouncer/inspect.go",
          "cmd/crowdsec-cli/clihubtest/clean.go",
          "cmd/crowdsec-cli/clihubtest/coverage.go",
          "cmd/crowdsec-cli/clihubtest/create.go",
          "cmd/crowdsec-cli/clihubtest/eval.go",
          "cmd/crowdsec-cli/clihubtest/explain.go",
          "cmd/crowdsec-cli/clihubtest/hubtest.go",
          "cmd/crowdsec-cli/clihubtest/info.go",
          "cmd/crowdsec-cli/clihubtest/list.go",
          "cmd/crowdsec-cli/clihubtest/run.go",
          "cmd/crowdsec-cli/clihubtest/table.go",
          "cmd/crowdsec-cli/cliitem/cmdinspect.go",
          "cmd/crowdsec-cli/clilapi/status_test.go",
          "cmd/crowdsec-cli/climachine/inspect.go"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "build/debian/README.md",
          "build/debian/changelog",
          "build/docker/README.md",
          "build/docker/test/README.md",
          "build/windows/Chocolatey/crowdsec/ReadMe.md",
          "build/windows/Chocolatey/crowdsec/tools/LICENSE.txt",
          "build/windows/README.md"
        ],
        "fileTypes": {
          ".yaml": 5,
          ".yml": 24,
          ".toml": 2,
          ".sh": 4,
          ".md": 8,
          ".service": 2,
          ".timer": 1,
          ".debian": 1,
          ".env": 1,
          ".ini": 2,
          ".py": 23,
          ".lock": 1,
          ".html": 1,
          ".mk": 7,
          ".preset": 1,
          ".patch": 1,
          ".spec": 1,
          ".nuspec": 1,
          ".txt": 2,
          ".ps1": 7,
          ".wxs": 2,
          ".ico": 1,
          ".bmp": 2,
          ".go": 74
        }
      }
    },
    {
      "id": 1157345569,
      "name": "wifi-densepose",
      "displayName": "wifi densepose",
      "description": "Production-ready implementation of InvisPose - a revolutionary WiFi-based dense human pose estimation system that enables real-time full-body tracking through walls using commodity mesh routers ",
      "summary": "The Problem\nTracking human poses in real-time without using cameras is a massive pain point, especially in privacy-sensitive environments. Traditional methods rely on visual data, risking privacy invasion and security concerns. What if you could get full-body tracking through walls using just WiFi signals? That's where this repo comes in.\n\nWhat This Does\nThe wifi-densepose repo implements a WiFi-based dense human pose estimation system, drawing on Channel State Information (CSI) data. It’s built on a solid foundation, with a production-ready API that handles authentication and rate limiting, all in dev-backend-api.md. You can find the configuration settings in config.yaml, which allows you to tweak how the application runs without diving into the code.\n\nFor those who care about performance, the Rust implementation lives in /rust-port/wifi-densepose-rs/. If you run cargo bench from there, you’ll see how much faster it is than the Python version. We're talking about speedups of up to 810x for the full pipeline. Yeah, it’s that good.\n\nReal-World Use\nImagine deploying this in a smart home. You set up the mesh router, configure it with config.yaml, and start tracking family members' movements. You can write a small script to connect to the WebSocket stream and process pose data in real-time. Here’s a quick snippet to get you started:\n\nimport websocket\n\ndef onmessage(ws, message):\n    print(\"Pose Data: \", message)\n\nws = websocket.WebSocketApp(\"ws://localhost:8000/ws/pose\", onmessage=onmessage)\nws.runforever()\n\nWith this setup, you can monitor activity or detect falls without cameras. It’s not just tech for tech’s sake; it has real applications in healthcare and security.\n\nThe Bottom Line\nThis repo is excellent for anyone needing privacy-preserving pose estimation—think healthcare providers or smart home developers. The Rust implementation is a big win for performance, but honestly, if you’re a solo developer or a small team, this might feel like overkill. If you don't need the complexity of real-time tracking through walls, stick with simpler solutions.",
      "url": "https://github.com/moses-y/wifi-densepose",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "ruvnet/wifi-densepose",
        "url": "https://github.com/ruvnet/wifi-densepose",
        "stars": 8825
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 13, 2026",
      "updatedAt": "February 13, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".claude-flow": 6,
          ".claude": 194
        },
        "languages": {
          "YAML": 1,
          "JSON": 3,
          "Markdown": 180,
          "Shell": 11,
          "JavaScript": 2
        },
        "frameworks": [
          "React"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [
          ".claude/agents/core/tester.md",
          ".claude/agents/custom/test-long-runner.md",
          ".claude/agents/sparc/specification.md",
          ".claude/agents/specialized/spec-mobile-react-native.md",
          ".claude/agents/testing/production-validator.md",
          ".claude/agents/testing/tdd-london-swarm.md",
          ".claude/agents/v3/memory-specialist.md",
          ".claude/commands/sparc/spec-pseudocode.md",
          ".claude/commands/sparc/tester.md"
        ],
        "docs": [
          ".claude/commands/analysis/README.md",
          ".claude/commands/automation/README.md",
          ".claude/commands/github/README.md",
          ".claude/commands/hooks/README.md",
          ".claude/commands/monitoring/README.md",
          ".claude/commands/optimization/README.md",
          ".claude/helpers/README.md"
        ],
        "fileTypes": {
          ".yaml": 1,
          ".json": 3,
          ".pid": 1,
          ".md": 180,
          ".sh": 11,
          ".js": 2,
          ".mjs": 1
        }
      }
    },
    {
      "id": 1156976807,
      "name": "langfuse",
      "displayName": "langfuse",
      "description": "🪢 Open source LLM engineering platform: LLM Observability, metrics, evals, prompt management, playground, datasets. Integrates with OpenTelemetry, Langchain, OpenAI SDK, LiteLLM, and more. 🍊YC W23 ",
      "summary": "The Problem\n\nLLM apps break in weird ways. You ship a chatbot, and suddenly it’s hallucinating, burning tokens, or just plain losing context. You have no clue what happened, because your logs are garbage and prompt tweaks get lost in the shuffle. Nobody wants to debug a black box.\n\nWhat This Does\n\nlangfuse gives you actual observability for LLM stuff. You get prompt management, metrics, dataset tracking, and a playground to mess with prompts—all in one place. The repo integrates with OpenTelemetry, Langchain, OpenAI SDK, and even LiteLLM, so you can wire this up no matter what stack you use.\n\nCheck out .claude/skills/backend-dev-guidelines/resources/architecture-overview.md for a clear breakdown of how data flows. The prompt management isn’t just lipstick—it’s backed by real versioning. Want to track model pricing or evaluate outputs? Dig into .claude/skills/add-model-price/SKILL.md and .claude/skills/backend-dev-guidelines/resources/testing-guide.md. There’s even hooks like .claude/hooks/error-handling-reminder.ts to catch dumb mistakes before they cost you money.\n\nReal-World Use\n\nSay you’re running a customer support agent with Langchain and OpenAI. Plug in langfuse and now every prompt, every response, and every token spent is logged and versioned. You can set up evals on new prompts, monitor response quality, and roll back if you break things.\n\nExample workflow:  \n\nimport { langfuse } from 'langfuse-sdk';\n\nlangfuse.trackPrompt({\n  userId: 'abc123',\n  prompt: 'How can I reset my password?',\n  model: 'gpt-4',\n  version: '2.1.0'\n});\n// Later: check metrics, run evals, tweak prompts, repeat.\n\nYou get dashboards and hooks for error handling (.claude/hooks/error-handling-reminder.ts)—so you don’t have to babysit your logs.\n\nThe Bottom Line\n\nlangfuse is legit if you’re tired of flying blind with LLMs. It’s probably overkill for tiny projects, but if you care about tracking, evals, or not blowing your OpenAI budget, it’s worth the setup. If you’re building production LLM stuff, stop kidding yourself and wire this up.",
      "url": "https://github.com/moses-y/langfuse",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "langfuse/langfuse",
        "url": "https://github.com/langfuse/langfuse",
        "stars": 22393
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 13, 2026",
      "updatedAt": "February 13, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".claude": 30,
          "(root)": 27,
          ".cursor": 10,
          ".devcontainer": 2,
          ".github": 21,
          ".husky": 2,
          ".vscode": 3,
          "ee": 8,
          "fern": 39,
          "packages": 58
        },
        "languages": {
          "Markdown": 32,
          "Shell": 3,
          "TypeScript": 5,
          "JSON": 18,
          "YAML": 61,
          "JavaScript": 3,
          "SQL": 51
        },
        "frameworks": [
          "React",
          "Docker"
        ],
        "packageManager": "npm",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "ee/src/ee-license-check/index.ts",
          "ee/src/index.ts",
          "packages/config-eslint/index.js"
        ],
        "configFiles": [
          ".claude/hooks/package.json",
          ".claude/hooks/tsconfig.json",
          ".devcontainer/Dockerfile",
          "docker-compose.build.yml",
          "docker-compose.dev-azure.yml",
          "docker-compose.dev-redis-cluster.yml",
          "docker-compose.dev.yml",
          "docker-compose.yml",
          "ee/package.json",
          "ee/tsconfig.json",
          "package.json",
          "packages/config-eslint/package.json",
          "packages/config-typescript/package.json"
        ],
        "dependencies": [
          ".claude/hooks/package-lock.json",
          ".claude/hooks/package.json",
          "ee/package.json",
          "package.json",
          "packages/config-eslint/package.json",
          "packages/config-typescript/package.json"
        ],
        "testFiles": [
          ".claude/skills/backend-dev-guidelines/resources/testing-guide.md",
          ".cursor/rules/tests.mdc",
          ".env.test.example",
          ".github/workflows/sdk-api-spec.yml"
        ],
        "docs": [
          ".claude/agents/changelog-writer.md",
          ".claude/hooks/README.md",
          ".claude/skills/README.md",
          ".claude/skills/backend-dev-guidelines/SKILL.md",
          ".claude/skills/backend-dev-guidelines/resources/architecture-overview.md",
          ".claude/skills/backend-dev-guidelines/resources/configuration.md",
          ".claude/skills/backend-dev-guidelines/resources/database-patterns.md",
          ".claude/skills/backend-dev-guidelines/resources/middleware-guide.md",
          ".claude/skills/backend-dev-guidelines/resources/routing-and-controllers.md",
          ".claude/skills/backend-dev-guidelines/resources/services-and-repositories.md",
          ".claude/skills/backend-dev-guidelines/resources/testing-guide.md",
          "CONTRIBUTING.md",
          "LICENSE",
          "README.cn.md",
          "README.ja.md",
          "README.kr.md",
          "README.md",
          "ee/LICENSE",
          "ee/README.md",
          "ee/src/ee-license-check/index.ts"
        ],
        "fileTypes": {
          ".md": 32,
          ".sh": 3,
          ".ts": 5,
          ".json": 18,
          ".mdc": 8,
          ".example": 5,
          ".yml": 61,
          ".template": 1,
          ".mjs": 1,
          ".js": 3,
          ".sql": 51
        }
      }
    },
    {
      "id": 1156297958,
      "name": "broadcast-channel",
      "displayName": "broadcast channel",
      "description": ":satellite: BroadcastChannel to send data between different browser-tabs or nodejs-processes :satellite: + LeaderElection over the channels  https://pubkey.github.io/broadcast-channel/",
      "summary": "The Problem\n\nWorking with multiple browser tabs or Node.js processes that need to talk to each other is a pain. Sure, the native BroadcastChannel API exists, but it’s not supported everywhere (looking at you, Safari). And if you’re working in Node or some other environment like Deno, you’re completely out of luck. You need a reliable way to share messages across tabs or processes, preferably without duct-taping IndexedDB, localStorage, or WebSockets together yourself.\n\nWhat This Does\n\nThe broadcast-channel library gives you a polyfill for the BroadcastChannel API that works across a ton of environments—modern browsers, old browsers, Node.js, Deno, Web Workers, even iframes. It’s like the duct tape you were about to use, but it actually works and doesn’t fall apart when you need it most.\n\nThe heavy lifting happens in the dist/es5node/ folder, where the library provides multiple implementations for message passing using various methods like indexed-db, localstorage, or even cookies if you’re feeling masochistic. If you’re in Node, it falls back to filesystem sockets, which is clever. Need to coordinate browser tabs and elect a \"leader\" (because everyone loves a little distributed computing)? The leader-election module has you covered.\n\nThe library isn’t just a polyfill—it’s configurable. You can force it to use specific methods ({ type: 'localstorage' }) or disable WebWorker support to squeeze out a bit of performance.\n\nReal-World Use\n\nSay you’re building a web app that allows users to log in across multiple tabs. You want to broadcast the login event from one tab to all others. Here’s how easy it can be:\n\nimport { BroadcastChannel } from 'broadcast-channel';\n\nconst channel = new BroadcastChannel('user-session');\n\n// Tab 1: Broadcast login info\nchannel.postMessage({ userId: 123, loggedIn: true });\n\n// Tab 2: Listen for the event\nchannel.onmessage = (msg) => {\n  console.log(User ${msg.userId} logged in: ${msg.loggedIn});\n};\n\nIt even works offline. No server round-trips, no flaky WebSocket connections. Just tabs/processes talking to each other like civilized adults.\n\nThe Bottom Line\n\nbroadcast-channel is the tool you didn’t know you needed until you were stuck hacking together message passing with localStorage or praying that BroadcastChannel worked everywhere. It’s not tiny (~25KB minified), so maybe skip it for trivial projects, but if you need reliable cross-context communication, it’s a lifesaver. Bonus points for the built-in leader election if you’re doing anything distributed.",
      "url": "https://github.com/yebeai/broadcast-channel",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "pubkey/broadcast-channel",
        "url": "https://github.com/pubkey/broadcast-channel",
        "stars": 1990
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 12, 2026",
      "updatedAt": "February 12, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 155,
        "directories": {
          "(root)": 13,
          ".github": 6,
          "config": 3,
          "dist": 68,
          "docs": 13,
          "src": 16,
          "test-electron": 8,
          "test": 25,
          "types": 3
        },
        "languages": {
          "JSON": 6,
          "YAML": 3,
          "Markdown": 5,
          "JavaScript": 116,
          "HTML": 5,
          "Shell": 1,
          "TypeScript": 3
        },
        "frameworks": [
          "React"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "dist/es5node/index.js",
          "dist/esbrowser/index.js",
          "dist/esnode/index.js",
          "dist/lib/index.js",
          "docs/index.html",
          "docs/index.js",
          "src/index.js",
          "test-electron/index.html",
          "test-electron/main.js",
          "test/scripts/index.js"
        ],
        "configFiles": [
          ".eslintrc.json",
          "config/webpack.config.js",
          "dist/esbrowser/package.json",
          "dist/esnode/package.json",
          "package.json",
          "test-electron/package.json",
          "test/.eslintrc"
        ],
        "dependencies": [
          "dist/esbrowser/package.json",
          "dist/esnode/package.json",
          "package.json",
          "test-electron/package.json"
        ],
        "testFiles": [
          "test-electron/.gitignore",
          "test-electron/.npmrc",
          "test-electron/index.html",
          "test-electron/main.js",
          "test-electron/package.json",
          "test-electron/page.js",
          "test-electron/test/render.test.js",
          "test-electron/test/spec.js",
          "test/.eslintrc",
          "test/close.test.js",
          "test/e2e.test.js",
          "test/index.test.js",
          "test/integration.test.js",
          "test/issues.test.js",
          "test/module.cjs.test.js",
          "test/module.esm.test.mjs",
          "test/performance.test.js",
          "test/scripts/e2e.js",
          "test/scripts/iframe.js",
          "test/scripts/index.js",
          "test/scripts/leader-iframe.js",
          "test/scripts/util.js",
          "test/scripts/windows.sh",
          "test/scripts/worker.js",
          "test/simple.test.js",
          "test/test-deno.js",
          "test/typings.test.js",
          "test/unit.test.js",
          "test/unit/custom.method.test.js",
          "test/unit/indexed-db.method.test.js",
          "test/unit/localstorage.method.test.js",
          "test/unit/native.method.test.js",
          "test/unit/node.method.test.js"
        ],
        "docs": [
          ".github/README.md",
          "CHANGELOG.md",
          "LICENSE",
          "README.md",
          "docs/e2e.html",
          "docs/e2e.js",
          "docs/files/demo.gif",
          "docs/files/icon.png",
          "docs/files/leader-election.gif",
          "docs/iframe.html",
          "docs/iframe.js",
          "docs/index.html",
          "docs/index.js",
          "docs/kirby.gif",
          "docs/leader-iframe.html",
          "docs/leader-iframe.js",
          "docs/worker.js"
        ],
        "fileTypes": {
          ".json": 6,
          ".yml": 3,
          ".md": 5,
          ".js": 116,
          ".mjs": 2,
          ".html": 5,
          ".gif": 3,
          ".png": 1,
          ".txt": 1,
          ".sh": 1,
          ".ts": 3
        }
      }
    },
    {
      "id": 1156297011,
      "name": "LogonTracer",
      "displayName": "LogonTracer",
      "description": "Investigate malicious Windows logon by visualizing and analyzing Windows event log",
      "summary": "The Problem\nInvestigating malicious Windows logons is a pain in the neck. If you’ve ever tried sifting through Windows event logs, you know it’s like finding a needle in a haystack—assuming the needle is a sign of a security breach and the haystack is full of irrelevant data. LogonTracer tackles this mess by visualizing logon attempts, making it easier to spot the bad actors.\n\nWhat This Does\nLogonTracer visualizes Windows Active Directory event logs, coupling hostnames or IPs with account names. It processes event IDs like 4624 for successful logons and 4625 for failures, among others, to create a graph that shows where and when logon attempts occur. Check out the config/config.yml for configuration details and the README.md for installation instructions.\n\nThe project structure is pretty straightforward. You’ve got multiple docker-compose setups in the docker-compose-with-elasticstack and docker-compose-with-nginx folders, each with their respective Dockerfiles. If you’re familiar with Docker, you can spin this up quickly. Just run docker-compose up and you're in business.\n\nReal-World Use\nImagine you’re the security lead at a mid-sized company, and you’ve noticed some odd logon patterns. You fire up LogonTracer and point it at your event logs. Within minutes, you see a graph that links a specific account attempting logons from various machines, revealing a potential breach. You could even use the docker-compose/docker-compose.yml to set up a local instance and visualize this data without much hassle.\n\ndocker-compose -f docker-compose/docker-compose.yml up\n\nThe Bottom Line\nLogonTracer is a solid tool for anyone needing to analyze Windows logon activity. It’s especially useful for security teams hunting for anomalies in logon behavior, but if you’re just looking for a lightweight solution, this might feel like overkill. The reliance on Docker and Neo4j can also add complexity, so be prepared for that. Overall, it’s a handy tool if you know what you’re doing.",
      "url": "https://github.com/yebeai/LogonTracer",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "JPCERTCC/LogonTracer",
        "url": "https://github.com/JPCERTCC/LogonTracer",
        "stars": 3136
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 12, 2026",
      "updatedAt": "February 12, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 93,
        "directories": {
          ".github": 4,
          "(root)": 5,
          "config": 2,
          "docker-compose-with-elasticstack": 9,
          "docker-compose-with-nginx": 9,
          "docker-compose": 6,
          "docker": 2,
          "es-index": 2,
          "images": 30,
          "logs": 1,
          "model": 1,
          "sample": 4,
          "static": 7,
          "templates": 11
        },
        "languages": {
          "YAML": 11,
          "Markdown": 6,
          "JSON": 2,
          "Python": 1,
          "CSS": 2,
          "JavaScript": 2,
          "HTML": 11
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": "pip",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "templates/index.html"
        ],
        "configFiles": [
          "docker-compose-with-elasticstack/LogonTracer/build/Dockerfile",
          "docker-compose-with-elasticstack/docker-compose.yml",
          "docker-compose-with-nginx/LogonTracer/build/Dockerfile",
          "docker-compose-with-nginx/docker-compose.yml",
          "docker-compose/LogonTracer/build/Dockerfile",
          "docker-compose/docker-compose.yml",
          "docker/Dockerfile",
          "requirements.txt"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [
          ".github/workflows/logontracer-daily-test.yml",
          ".github/workflows/logontracer-test.yml"
        ],
        "docs": [
          "LICENSE.txt",
          "README.md",
          "docker-compose-with-elasticstack/README.md",
          "docker-compose-with-nginx/README.md",
          "docker-compose/README.md",
          "docker/README.md",
          "sample/README.md"
        ],
        "fileTypes": {
          ".yml": 11,
          ".txt": 2,
          ".md": 6,
          ".conf": 1,
          ".json": 2,
          ".png": 28,
          ".svg": 4,
          ".gif": 1,
          ".py": 1,
          ".pkl": 1,
          ".evtx": 1,
          ".gz": 2,
          ".css": 2,
          ".js": 2,
          ".html": 11
        }
      }
    },
    {
      "id": 1156291061,
      "name": "MotionCrafter",
      "displayName": "MotionCrafter",
      "description": "MotionCrafter: Dense Geometry and Motion Reconstruction with a 4D VAE",
      "summary": "The Problem\n\nIf you’ve ever tried to reconstruct dense 4D geometry and motion from basic videos, you know the agony: most solutions need tons of post-processing, calibration, or multi-view setups. Getting a clean, frame-by-frame point map and scene flow from a single video is a mess—especially if you want everything lined up in a consistent world coordinate system.\n\nWhat This Does\n\nMotionCrafter tackles the headache head-on. Feed in a monocular video (yep, just one camera), and it spits out dense geometry and motion estimates for every frame—all mapped together, no Frankenstein post-optimization required. Under the hood, the motioncrafter/geometrymotionvae.py file is the brains for the 4D VAE, while the motioncrafter/unet.py deals with diffusion-based prediction. The main script, run.py, glues the pipeline together: you call it, it loads models, runs inference, and saves results.\n\nConfigs live in the configs/ folder, split by training type (unettrain for diffusion, vaetrain for geometry, etc.). Dataset handling happens in datasets/video.py and datasets/videotransforms.py, which means you don’t have to write your own loader unless you’re a masochist. Visualization is handled separately—just call visualize/visualize.py if you want to see your outputs without hacking matplotlib.\n\nReal-World Use\n\nLet’s say you’ve got a pile of drone footage and want to reconstruct moving objects for simulation or AR. Install the dependencies (requirements.txt), throw your video at run.py:\n\npython run.py --videopath myvideo.mp4 --save_folder output\n\nNeed to tweak things? Change resolution, number of frames, or swap in your own model weights via command line flags. Training is pretty standard: organize your dataset as outlined in DATASET.md, then use train.py. The configs in configs/ are ready for tweaking—no hiding settings in some obscure class.\n\nThe Bottom Line\n\nMotionCrafter does one thing well: turn boring videos into dense geometry and motion maps, no fuss. Documentation is straightforward, code isn’t buried under layers of abstraction, and it’s not beginner-friendly unless you know your way around PyTorch and video data. If you need high-quality 4D reconstructions, this is solid. If you just want simple optical flow, look elsewhere—this is overkill.",
      "url": "https://github.com/yebeai/MotionCrafter",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "TencentARC/MotionCrafter",
        "url": "https://github.com/TencentARC/MotionCrafter",
        "stars": 108
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 12, 2026",
      "updatedAt": "February 12, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 39,
        "directories": {
          "(root)": 9,
          "assets": 2,
          "configs": 6,
          "datasets": 3,
          "motioncrafter": 6,
          "scripts": 1,
          "trainers": 6,
          "utils": 5,
          "visualize": 1
        },
        "languages": {
          "Markdown": 3,
          "YAML": 1,
          "JSON": 1,
          "Python": 24,
          "Shell": 1
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [
          "requirements.txt"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE.txt",
          "README.md"
        ],
        "fileTypes": {
          ".md": 3,
          ".txt": 2,
          ".png": 2,
          ".yaml": 1,
          ".json": 1,
          ".gin": 4,
          ".py": 24,
          ".sh": 1
        }
      }
    },
    {
      "id": 1156288159,
      "name": "HouseTour",
      "displayName": "HouseTour",
      "description": "[ICCV 2025] HouseTour: A Virtual Real Estate A(I)gent",
      "summary": "HouseTour: Automating Real Estate Videos with AI  \n\nThe Problem  \nMaking professional-quality real estate videos is a pain. You need a camera operator, editing skills, and tools to stitch everything together. Sure, you could fake it with a phone and bad transitions, but if you’re trying to sell a house (or impress a client), that’s not going to cut it. The kicker? AI tools exist for generating text or images, but they’re clueless when it comes to understanding 3D spaces. Smooth camera paths? Forget it.  \n\nWhat This Does  \nHouseTour handles two key tasks: creating smooth 3D camera trajectories and generating natural language descriptions of spaces—all from a bunch of images. The magic happens via a diffusion-based planner (config/residualdiffuser.py) that refines sparse input poses into buttery-smooth camera paths. Combine that with their Qwen2-VL-3D adapter (buried in diffuser/models/) that merges visual, spatial, and language info, and you’ve got a system that understands the space it’s describing.  \n\nThe dataset (data/) is the backbone here: over 1,200 professional house-tour videos with camera poses, 3D reconstructions, and text descriptions. This isn’t some toy dataset—it’s built for training the model to handle real-world scenarios. The output? A 3D video of the space (rendered with 3D Gaussian splatting—yeah, that’s a thing) and a natural-language summary that sounds like a real estate agent who has their life together.  \n\nThe file structure is clean enough, but there’s some cruft in pycache folders, which could’ve been .gitignored. The heavy lifting is all in diffuser/, particularly in models/ where the diffusion and helper logic lives.  \n\nReal-World Use  \nSay you’re a real estate agent with a folder of room images. Fire up this repo, run the pipeline (🏋️ Training & Inference section in the README), and boom: you’ve got a smooth video tour and a description like “This sunlit kitchen features a modern backsplash and stainless steel appliances.” You didn’t even break a sweat.  \n\npython diffuser/models/diffusion.py --input <imagefolder> --output <video_path>\n\nIt’s also a godsend for VR/AR setups or companies selling virtual tours. The heavy reliance on GPU resources (it’s tested on an NVIDIA A100 with CUDA 12.4) means you’ll need serious hardware.  \n\nThe Bottom Line  \nHouseTour is a niche but impressive tool. If you’re in real estate, VR, or just want to play with AI-powered 3D rendering and text generation, this is worth a look. Downsides? It’s overkill for small projects, and the lack of user-friendly abstraction (it’s all very research-y) makes it a tough sell for non-technical users. But if you love tinkering and have the hardware, this is definitely a cool toy.",
      "url": "https://github.com/yebeai/HouseTour",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "GradientSpaces/HouseTour",
        "url": "https://github.com/GradientSpaces/HouseTour",
        "stars": 36
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 12, 2026",
      "updatedAt": "February 12, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 67,
        "directories": {
          "(root)": 10,
          "assets": 4,
          "config": 1,
          "data": 4,
          "diffuser": 45,
          "qwen2_vl_3d": 1,
          "scripts": 2
        },
        "languages": {
          "Markdown": 1,
          "Python": 25,
          "JSON": 2,
          "Shell": 1
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "diffuser/utils/setup.py",
          "setup.py"
        ],
        "configFiles": [
          "diffuser/utils/setup.py",
          "requirements.txt",
          "setup.py"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [
          "data/test_indices.txt",
          "scripts/test_residual_diffuser.py"
        ],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".md": 1,
          ".png": 2,
          ".gif": 2,
          ".py": 25,
          ".json": 2,
          ".txt": 3,
          ".jsonl": 1,
          ".pyc": 28,
          ".sh": 1
        }
      }
    },
    {
      "id": 1156149695,
      "name": "maxun",
      "displayName": "maxun",
      "description": "✨ The open-source no-code platform for web scraping, crawling, search and AI data extraction • Turn websites into structured APIs in minutes ✨ ",
      "summary": "Maxun: Turning Websites Into Structured APIs\n\nThe Problem  \nWeb scraping sucks. Either you waste hours hacking together Python scripts with BeautifulSoup, or you're stuck Googling \"selenium headless Chrome keeps crashing\" at 2 AM. And if you're scaling beyond a one-off task? Good luck managing brittle code, rate limits, and the endless list of edge cases. Maxun tries to fix this with a no-code platform that turns websites into structured data with minimal hassle.\n\nWhat This Does  \nMaxun organizes its functionality into \"robots\" that do the heavy lifting for web scraping, crawling, and data extraction. The browser/ directory houses the frontend server (browser/server.ts) that powers the Recorder Mode, where you can click through a website and let Maxun generate reusable extraction workflows. The backend (Dockerfile.backend) handles AI-driven tasks like parsing natural language prompts to figure out what data you need.\n\nWant to scrape entire websites? There's a legacy/ folder (yeah, naming could be better) packed with React components (legacy/src/Canvas.tsx, legacy/src/LeftSidePanel.tsx) for defining crawling scopes and conditions. It’s like a visual IDE for data scraping. The docker-compose.yml sets up your environment—good for local testing or self-hosting.\n\nBonus: There's an SDK (docs/self-hosting-docker.md) if you want to integrate scraping workflows directly into your own apps. Think cron jobs for web data.\n\nReal-World Use  \nSay you need the top 50 movies from IMDb with their names, ratings, and durations. In Recorder Mode, you click through the site to build an extraction script. Or, use AI Mode—type \"Get top 50 movie names, ratings, and durations from IMDb\"—and let Maxun automate the whole thing. The extracted data gets output as JSON, ready to feed into your app. For larger jobs like crawling Airbnb for property listings, you’d use the Crawl robot to define site-wide rules in the visual editor.\n\nThe Bottom Line  \nMaxun is cool for anyone who needs structured web data without fiddling with code. It's fantastic for non-coders and teams automating repetitive tasks. But if you're a developer scraping a single page once, this is overkill. Setup feels heavy (Docker, multiple servers), and the legacy/ folder screams tech debt. Still, for scaling complex workflows? Worth a look.",
      "url": "https://github.com/yebeai/maxun",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "getmaxun/maxun",
        "url": "https://github.com/getmaxun/maxun",
        "stars": 15170
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 12, 2026",
      "updatedAt": "February 12, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 14,
          ".github": 3,
          "browser": 5,
          "docs": 2,
          "legacy": 19,
          "maxun-core": 13,
          "perf": 1,
          "public": 15,
          "server": 63,
          "src": 65
        },
        "languages": {
          "Markdown": 6,
          "YAML": 2,
          "JSON": 14,
          "TypeScript": 72,
          "Shell": 3,
          "HTML": 1,
          "TSX": 71,
          "JavaScript": 8
        },
        "frameworks": [
          "React",
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "browser/server.ts",
          "index.html",
          "maxun-core/src/index.ts",
          "server/src/db/models/index.js",
          "server/src/index.ts",
          "server/src/routes/index.ts",
          "server/src/server.ts",
          "server/src/types/index.ts",
          "server/src/workflow-management/scheduler/index.ts",
          "src/App.tsx",
          "src/components/action/action-settings/index.ts"
        ],
        "configFiles": [
          "Dockerfile.backend",
          "Dockerfile.frontend",
          "browser/Dockerfile",
          "browser/package.json",
          "browser/tsconfig.json",
          "docker-compose.yml",
          "maxun-core/package.json",
          "maxun-core/tsconfig.json",
          "package.json",
          "server/tsconfig.json"
        ],
        "dependencies": [
          "browser/package.json",
          "maxun-core/package.json",
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md",
          "docs/nginx.conf",
          "docs/self-hosting-docker.md",
          "maxun-core/README.md"
        ],
        "fileTypes": {
          ".md": 6,
          ".yml": 2,
          ".backend": 1,
          ".frontend": 1,
          ".json": 14,
          ".ts": 72,
          ".sh": 3,
          ".conf": 2,
          ".html": 1,
          ".tsx": 71,
          ".js": 8,
          ".svg": 9,
          ".png": 1
        }
      }
    },
    {
      "id": 1155558381,
      "name": "mflux",
      "displayName": "mflux",
      "description": "MLX native implementations of state-of-the-art generative image models",
      "summary": "MFLUX: MLX Native Generative Image Models\n\nThe Problem\n\nEveryone wants to run fancy generative image models locally, but most repos assume you love Python environments more than your sanity. Dependency hell, GPU compatibility issues, and bloated libraries are often the norm. Hugging Face’s diffusers and transformers are great—but they’re huge, and they’re not optimized for local MLX workflows. That’s where mflux steps in.\n\nWhat This Does\n\nmflux is essentially a stripped-down, MLX-native implementation of state-of-the-art generative image models like Hugging Face's Diffusers, minus the bloat. It’s not trying to be everything for everyone. Instead, it’s minimal and explicit, sticking to the Karpathy philosophy.\n\nThe repo includes CLI commands in .cursor/commands/ for tasks like testing (test-fast.md, test-slow.md) and formatting (format.md). Skills-specific docs in .cursor/skills/ break down workflows like mflux-model-porting and mflux-debugging. For code nerds, the Python API lets you call models directly, as shown in the README’s generate.py example. If you’re dealing with model downloads, errors like hftransfer are addressed with clear troubleshooting steps, because let’s face it—something will break.\n\nReal-World Use\n\nHere’s a practical use case: generating images like the puffin example in the README. Install uv, add mflux, and run this CLI command:\n\nmflux-generate-z-image-turbo \\\n  --prompt \"A puffin standing on a cliff\" \\\n  --width 1280 \\\n  --height 500 \\\n  --seed 42 \\\n  --steps 9 \\\n  -q 8\n\nYou get a locally generated puffin image without needing a GPU cluster or a PhD in package management.\n\nFor more control, dive into the Python API. Here’s how you’d generate the same puffin programmatically:\n\nfrom mflux.models.zimage import ZImageTurbo\n\nmodel = ZImageTurbo(quantize=8)\nimage = model.generateimage(\n    prompt=\"A puffin standing on a cliff\",\n    seed=42,\n    numinference_steps=9,\n    width=1280,\n    height=500,\n)\nimage.save(\"puffin.png\")\n\nThis approach makes sense for automation or custom pipelines.\n\nThe Bottom Line\n\nmflux is refreshingly barebones. It’s perfect for MLX users who want local generative models without drowning in Hugging Face dependencies. The CLI and Python API are well-documented, but its minimalism means it’s not a plug-and-play solution for casual users. If you’re comfortable debugging and tweaking configs, it’s a great tool. If not, stick to the original Hugging Face libraries or something more polished.",
      "url": "https://github.com/yebeai/mflux",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "filipstrand/mflux",
        "url": "https://github.com/filipstrand/mflux",
        "stars": 1846
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 11, 2026",
      "updatedAt": "February 11, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".cursor": 19,
          "(root)": 10,
          ".github": 2,
          "src": 169
        },
        "languages": {
          "Markdown": 25,
          "YAML": 3,
          "TOML": 2,
          "Python": 120,
          "JSON": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          "Makefile",
          "pyproject.toml"
        ],
        "dependencies": [
          "pyproject.toml"
        ],
        "testFiles": [
          ".cursor/commands/test-fast.md",
          ".cursor/commands/test-slow.md",
          ".cursor/commands/test.md",
          ".cursor/skills/mflux-manual-testing/SKILL.md",
          ".cursor/skills/mflux-testing/SKILL.md",
          ".github/workflows/tests.yml",
          "src/mflux/models/common/training/state/training_spec.py"
        ],
        "docs": [
          "CHANGELOG.md",
          "LICENSE",
          "README.md",
          "src/mflux/cli/completions/README.md",
          "src/mflux/models/common/README.md",
          "src/mflux/models/depth_pro/README.md"
        ],
        "fileTypes": {
          ".md": 25,
          ".yml": 2,
          ".yaml": 1,
          ".toml": 2,
          ".py": 120,
          ".jpg": 30,
          ".png": 3,
          ".jpeg": 5,
          ".txt": 6,
          ".json": 1,
          ".pdf": 1
        }
      }
    },
    {
      "id": 1155553474,
      "name": "claudius",
      "displayName": "claudius",
      "description": "Agentic Development Environment",
      "summary": "The Problem\n\nMost devs using AI agents for code generation hit the same wall: clunky interfaces that ask you to paste prompts into random chat windows, zero context awareness, and a ton of manual setup. Want an agent that actually handles files, runs shell commands, and doesn't eat your config every update? Good luck. You end up hacking together scripts and praying nothing explodes.\n\nWhat This Does\n\nclaudius is a desktop app built for folks already using Claude Code. You just download it—no hunting for API keys or fighting with config files. The guts are in the .claude/agents/docs.md and .opencode/agent/docs.md files, which show off how agents interact natively with your project. The real magic is the Claude Agent SDK integration—think prompt caching, smarter context, and actual sandboxed execution (packages/web/src/assets/claudius-screenshot.png is proof, if you care about GUIs). You get native tools for editing, grepping, globs, bash—all handled in the agent, not some half-baked plugin.\n\nModes like Planning and Permission (documented in README.md) let you lock things down when you need to. Granular controls mean you don’t wake up to your agent nuking your repo. There’s a bunch of GitHub Actions (.github/actions/setup-bun/action.yml, .github/workflows/test.yml) for automating builds and checks, but the focus is on hands-off coding, not CI ceremony.\n\nReal-World Use\n\nSay you want to refactor a bunch of functions across files. Fire up Claudius, switch into build mode, and let the agent scan, edit, and write—using actual native tools, not some Python script duct-taped to a shell. Lock permissions if you’re paranoid, or go nuts and let it bash away. Example: drop a command via the agent to grep for async functions, rewrite them as sync, and commit. All handled without you touching a terminal.\n\nThe Bottom Line\n\nClaudius nails the desktop agent experience for people already using Claude Code. It’s fast, no nonsense, and doesn’t make you jump through setup hoops. If you’re looking for a toy chatbot, move on. If you want an agent that actually works with your codebase, this is worth the install. Not perfect for tiny projects—feels like overkill unless you’re serious about agentic workflows.",
      "url": "https://github.com/yebeai/claudius",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "crisogray/claudius",
        "url": "https://github.com/crisogray/claudius",
        "stars": 76
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 11, 2026",
      "updatedAt": "February 11, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".claude": 1,
          "(root)": 23,
          ".github": 19,
          ".husky": 1,
          ".opencode": 11,
          "packages": 145
        },
        "languages": {
          "Markdown": 27,
          "YAML": 17,
          "TypeScript": 29,
          "JSON": 6,
          "TOML": 3,
          "HTML": 2,
          "JavaScript": 2,
          "TSX": 66,
          "CSS": 1,
          "Rust": 1
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "cargo",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "packages/app/index.html",
          "packages/app/src/app.tsx",
          "packages/app/src/components/session/index.ts",
          "packages/app/src/index.ts",
          "packages/app/src/utils/index.ts",
          "packages/desktop/index.html"
        ],
        "configFiles": [
          "package.json",
          "packages/app/package.json",
          "packages/app/tsconfig.json",
          "packages/app/vite.config.ts",
          "packages/desktop/package.json",
          "packages/desktop/src-tauri/Cargo.toml"
        ],
        "dependencies": [
          "package.json",
          "packages/app/package.json",
          "packages/desktop/package.json",
          "packages/desktop/src-tauri/Cargo.toml"
        ],
        "testFiles": [
          ".github/workflows/test.yml",
          ".opencode/skill/test-skill/SKILL.md",
          "packages/app/src/addons/serialize.test.ts",
          "packages/app/src/context/layout-scroll.test.ts"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "STYLE_GUIDE.md",
          "packages/app/README.md",
          "packages/desktop/README.md",
          "packages/desktop/src-tauri/icons/README.md"
        ],
        "fileTypes": {
          ".md": 27,
          ".yml": 17,
          ".ts": 29,
          ".jsonc": 1,
          ".json": 6,
          ".txt": 1,
          ".lock": 2,
          ".toml": 3,
          ".html": 2,
          ".png": 22,
          ".ico": 1,
          ".js": 2,
          ".webmanifest": 1,
          ".tsx": 66,
          ".css": 1,
          ".plist": 2,
          ".bmp": 2,
          ".rs": 1,
          ".xml": 2
        }
      }
    },
    {
      "id": 1155539414,
      "name": "pgrok",
      "displayName": "pgrok",
      "description": "Personal ngrok alternative. Expose local ports to the internet with automatic HTTPS via SSH tunnels + Caddy.",
      "summary": "The Problem\n\nYou're running a local dev server, and you need to share it with others, test webhooks, or debug APIs. Sure, you could use ngrok or one of its clones, but most of them are either rate-limited, paid, or run on someone else's infrastructure. If you're already paying for a VPS, why rely on third-party services when you could just roll your own?\n\nWhat This Does\n\npgrok is like ngrok, except the infrastructure is yours. It uses SSH reverse tunnels and Caddy to expose local ports to the internet with automatic HTTPS. No weird proprietary protocols, no hidden servers—just good old SSH and a bit of clever scripting.\n\nThe server directory sets up your VPS. setup-vps.sh installs Caddy and some lightweight Python scripts (pgrok-ask and pgrok-tunnel) to dynamically manage routes and SSL certs. Meanwhile, the client directory, specifically the tui folder, gives you a slick terminal UI to monitor tunnels, inspect HTTP requests, and track connection stats in real-time. It's built on OpenTUI, and files like src/ui/connections.ts and src/ui/requests.ts handle the visuals like request logs and connection details. \n\nReal-World Use\n\nSay you're building a webhook for Stripe. You need a public HTTPS endpoint for testing, but you're sick of spinning up new ngrok instances every time. With pgrok, you'd just:\nInstall the client (setup.sh makes this ridiculously easy).\nRun pgrok stripe 3000.\nGet a custom HTTPS URL (e.g., https://stripe.yourdomain.com) that forwards traffic to your local localhost:3000.\n\nThe TUI dashboard shows live traffic in color-coded logs. Spot the 400 errors immediately, debug your handler, and call it a day. No subscription fees, no random subdomains, no BS.\n\nThe Bottom Line\n\npgrok is perfect if you’ve got a VPS gathering dust and want a no-nonsense, self-hosted tunnel solution. The TUI is a nice touch, and the setup script is straightforward. The trade-off? You’re in charge of maintenance—if your VPS goes down, so do your tunnels. If you're the type who doesn't mind a bit of DIY for full control, this is a solid tool. If not, stick with ngrok.",
      "url": "https://github.com/yebeai/pgrok",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "R44VC0RP/pgrok",
        "url": "https://github.com/R44VC0RP/pgrok",
        "stars": 794
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 11, 2026",
      "updatedAt": "February 11, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 26,
        "directories": {
          "(root)": 5,
          "client": 13,
          "server": 8
        },
        "languages": {
          "Markdown": 2,
          "TypeScript": 10,
          "JSON": 2,
          "Shell": 3,
          "YAML": 1
        },
        "frameworks": [
          "React",
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "client/tui/index.ts",
          "client/tui/src/app.ts"
        ],
        "configFiles": [
          "client/tui/package.json",
          "client/tui/tsconfig.json",
          "server/.env.example",
          "server/Dockerfile",
          "server/docker-compose.yml"
        ],
        "dependencies": [
          "client/tui/package.json"
        ],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".md": 2,
          ".example": 2,
          ".ts": 10,
          ".json": 2,
          ".sh": 3,
          ".yml": 1,
          ".service": 1
        }
      }
    },
    {
      "id": 1154731275,
      "name": "MemoryOS",
      "displayName": "MemoryOS",
      "description": "[EMNLP 2025 Oral] MemoryOS is designed to provide a memory operating system for personalized AI agents.",
      "summary": "MemoryOS: The Memory Management System AI Agents Deserve\n\nThe Problem\n\nAI agents are getting smarter, but their memory? Still goldfish-tier. Most Large Language Models (LLMs) either don’t remember past interactions or force you to hack together some janky custom solution for storing and retrieving context. If you’re building AI that needs to remember user preferences, ongoing projects, or long conversation histories, good luck. You’re stuck duct-taping vector databases, custom pipelines, and hope. MemoryOS says it’s here to fix all that.\n\nWhat This Does\n\nAt its core, MemoryOS is like an operating system for memory management in AI agents. It takes inspiration from how actual operating systems handle memory, splitting the problem into four key modules: Storage, Updating, Retrieval, and Generation. These modules are implemented in the memoryos-chromadb folder, with files like shortterm.py, longterm.py, and retriever.py doing the heavy lifting. For example, updater.py handles memory updates, while storageprovider.py integrates with vector databases (e.g., ChromaDB).\n\nThe architecture supports a hierarchical structure for handling short-term, mid-term, and long-term memory, which you can see in the eval/ directory. Scripts like shorttermmemory.py and longtermmemory.py evaluate these components using the LoCoMo benchmark (yeah, someone benchmarked memory for AIs now). Want to spin it up quickly? There’s a Dockerfile for deployment and a connector for ChromaDB.\n\nOh, and it’s not just for OpenAI models—you can plug in other LLMs like Qwen or Deepseek. There’s even a memoryos-mcp folder for managing workflows, though you’ll probably want to start with the docs (docs/docs.html) because the README assumes you’re psychic.\n\nReal-World Use\n\nSuppose you’re building a customer service bot. Instead of endlessly re-explaining your issue to the bot like a bad tech support loop, you could use MemoryOS to store conversations in shortterm.py, update user preferences with updater.py, and fetch relevant data using retriever.py. Here’s a quick (and dirty) example:\n\nfrom memoryoschromadb.retriever import Retriever\nretriever = Retriever(storagepath=\"./memorydb\")\nqueryresult = retriever.query(\"What was the user's last request?\")\nprint(query_result)\n\nThis setup would let the bot actually remember past interactions, instead of restarting at “Hi, how can I help you?” every time.\n\nThe Bottom Line\n\nMemoryOS has a clever design and strong modularity, but it’s not exactly plug-and-play unless you’re already comfortable with concepts like vector databases and custom memory pipelines. If you’re building a serious AI product that needs to remember stuff, it’s worth exploring. But for smaller projects, it might feel like bringing a bazooka to a water balloon fight. Also, no stars yet? Fork the original repo if you care about social proof.",
      "url": "https://github.com/yebeai/MemoryOS",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "BAI-LAB/MemoryOS",
        "url": "https://github.com/BAI-LAB/MemoryOS",
        "stars": 1206
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 10, 2026",
      "updatedAt": "February 10, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 73,
        "directories": {
          "(root)": 5,
          "docs": 4,
          "eval": 9,
          "memoryos-chromadb": 12,
          "memoryos-mcp": 16,
          "memoryos-playground": 16,
          "memoryos-pypi": 11
        },
        "languages": {
          "Markdown": 2,
          "HTML": 2,
          "Python": 52,
          "JSON": 4,
          "Shell": 1
        },
        "frameworks": [
          "Flask",
          "Docker"
        ],
        "packageManager": "pip",
        "hasDocker": true,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "memoryos-playground/memdemo/app.py",
          "memoryos-playground/memdemo/templates/index.html"
        ],
        "configFiles": [
          "Dockerfile",
          "memoryos-chromadb/requirements.txt",
          "memoryos-mcp/memoryos/requirements.txt",
          "memoryos-mcp/requirements.txt",
          "memoryos-playground/memdemo/requirements.txt",
          "memoryos-playground/requirements.txt",
          "memoryos-pypi/requirements.txt"
        ],
        "dependencies": [
          "memoryos-chromadb/requirements.txt",
          "memoryos-mcp/memoryos/requirements.txt",
          "memoryos-mcp/requirements.txt",
          "memoryos-playground/memdemo/requirements.txt",
          "memoryos-playground/requirements.txt",
          "memoryos-pypi/requirements.txt"
        ],
        "testFiles": [
          "memoryos-chromadb/comprehensive_test.py",
          "memoryos-mcp/memoryos/test.py",
          "memoryos-mcp/test_simple.py",
          "memoryos-playground/test.py",
          "memoryos-pypi/test.py"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "docs/docs.html",
          "docs/local1.png",
          "docs/local2.png",
          "docs/memoryos.png",
          "readme_cn.md"
        ],
        "fileTypes": {
          ".pdf": 1,
          ".md": 2,
          ".html": 2,
          ".png": 3,
          ".py": 52,
          ".json": 4,
          ".txt": 6,
          ".sh": 1
        }
      }
    },
    {
      "id": 1154564007,
      "name": "picoclaw",
      "displayName": "picoclaw",
      "description": "picoclaw",
      "summary": "The Problem\nEver tried running an AI assistant on a $10 device? Spoiler: It usually ends with a sad face emoji. Most AI solutions are memory-hungry beasts that demand top-notch hardware and a wallet to match. PicoClaw aims to squash that issue by fitting a capable AI assistant into a compact package that runs on less than 10MB of RAM. \n\nWhat This Does\nPicoClaw is built in Go and is reimagined to be lightweight and efficient. The core logic lives in the pkg/agent directory, where you'll find context.go and loop.go managing the AI's operations. It supports various channels like Discord and Telegram, thanks to files like pkg/channels/discord.go and pkg/channels/telegram.go. The whole thing is bundled into a single binary, making deployment a breeze across architectures like RISC-V, ARM, and x86.\n\nThe Makefile is your best friend here. Just run make build and you’re set to go. The included config.example.json gives you a blueprint for any necessary configurations without the headache of deciphering cryptic settings. \n\nReal-World Use\nImagine you're working on a low-budget IoT project. You fire up your PicoClaw on a $10 LicheeRV-Nano and set it up to manage your home automation. A quick glance at the cmd/picoclaw/main.go file shows how straightforward it is to kick off the assistant. Need it to log your daily tasks? Just tap into the logging functions in pkg/bus/bus.go. Voilà, you have a mini AI assistant keeping your life organized without breaking the bank.\n\nThe Bottom Line\nPicoClaw is a solid option for those who want to dip their toes into AI without shelling out for expensive hardware. It's fast, lightweight, and surprisingly capable for its size. On the downside, the features may feel limited if you’re coming from more established solutions like OpenClaw, but hey, for $10, what do you expect? If you’re a hobbyist or tinkerer looking to experiment, this could be your new best friend.",
      "url": "https://github.com/yebeai/picoclaw",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "sipeed/picoclaw",
        "url": "https://github.com/sipeed/picoclaw",
        "stars": 20763
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 10, 2026",
      "updatedAt": "February 10, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 58,
        "directories": {
          "(root)": 7,
          "assets": 11,
          "cmd": 1,
          "pkg": 32,
          "skills": 7
        },
        "languages": {
          "Markdown": 6,
          "Go": 33,
          "JSON": 1,
          "Shell": 2
        },
        "frameworks": [],
        "packageManager": "go modules",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "cmd/picoclaw/main.go"
        ],
        "configFiles": [
          "Makefile",
          "go.mod"
        ],
        "dependencies": [
          "go.mod"
        ],
        "testFiles": [
          "pkg/logger/logger_test.go"
        ],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".md": 6,
          ".jpg": 3,
          ".png": 2,
          ".gif": 5,
          ".mp4": 1,
          ".go": 33,
          ".json": 1,
          ".mod": 1,
          ".sum": 1,
          ".sh": 2
        }
      }
    },
    {
      "id": 1154378356,
      "name": "companion",
      "displayName": "companion",
      "description": "Web UI for Claude Code built on a reverse-engineered WebSocket protocol. Launch sessions, stream responses, approve tools.  All from your browser / mobile",
      "summary": "The Problem\n\nClaude Code is powerful, but let's be honest: running everything through a terminal is a pain. You get one session, so managing multiple tasks is a juggling act. Tool calls happen in the background without any real visibility. And if the CLI crashes, there goes your entire session history. It's like trying to write a novel on a typewriter while blindfolded. \n\nWhat This Does\n\nEnter companion—a Web UI for Claude Code that doesn't make you hate your life. It hooks into Claude Code via a reverse-engineered WebSocket protocol (WEBSOCKETPROTOCOLREVERSED.md has the receipts) and brings everything into your browser. \n\nThe backend lives in web/server/ and handles spinning up claude processes, managing WebSocket connections, and persisting sessions with session-store.ts. The frontend? Built with React 19 and Tailwind, running off web/index.html with components managed in web/dev.ts. It's simple, clean, and functional. \n\nWant to see every tool call? Done. Need to run a chain of sub-agents without losing your mind? Easy. You can even set up environment profiles in ~/.companion/envs/ for different projects, so you're not constantly copy-pasting API keys like a chump.\n\nReal-World Use\n\nImagine you're using Claude Code to write some gnarly automation scripts. You fire up bunx the-vibe-companion and open http://localhost:3456. From there:\nYou kick off a session with your prompt. \nA new claude process spins up, and you watch the response stream back token by token. \nThe agent decides to run a shell command. Instead of blindly executing it, the browser prompts you: approve or deny? You can even expand the command to see what it's doing.\nThe process dies. No problem. Relaunch with --resume, and you're back where you left off.\n\nMeanwhile, the session-store.ts persists everything, so you're not constantly starting from scratch. It's like having a debugger for your AI workflows.\n\nThe Bottom Line\n\ncompanion solves real headaches for Claude Code users. The reverse-engineered WebSocket protocol is slick, the UI is intuitive, and the session persistence is a lifesaver. That said, this isn't for hobbyists—if you're not already deep into Claude Code, this won't mean much to you. But for anyone running complex AI workflows, it's a no-brainer.",
      "url": "https://github.com/yebeai/companion",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "The-Vibe-Company/companion",
        "url": "https://github.com/The-Vibe-Company/companion",
        "stars": 2100
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 10, 2026",
      "updatedAt": "February 10, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 52,
        "directories": {
          ".claude": 1,
          "(root)": 13,
          ".github": 1,
          "scripts": 1,
          "web": 36
        },
        "languages": {
          "JSON": 6,
          "YAML": 1,
          "Markdown": 5,
          "Shell": 1,
          "TypeScript": 17,
          "HTML": 1,
          "TSX": 14,
          "CSS": 1
        },
        "frameworks": [
          "React"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "web/bin/cli.ts",
          "web/index.html",
          "web/server/index.ts",
          "web/src/App.tsx"
        ],
        "configFiles": [
          ".env.example",
          "Makefile",
          "package.json",
          "web/package.json",
          "web/tsconfig.json",
          "web/vite.config.ts"
        ],
        "dependencies": [
          "package.json",
          "web/package.json"
        ],
        "testFiles": [],
        "docs": [
          "CHANGELOG.md",
          "LICENSE",
          "README.md",
          "web/CHANGELOG.md"
        ],
        "fileTypes": {
          ".json": 6,
          ".example": 1,
          ".yml": 1,
          ".md": 5,
          ".lock": 1,
          ".png": 1,
          ".sh": 1,
          ".ts": 17,
          ".html": 1,
          ".tsx": 14,
          ".css": 1
        }
      }
    },
    {
      "id": 1154372145,
      "name": "django-unfold",
      "displayName": "django unfold",
      "description": "Modern Django admin theme",
      "summary": "The Problem\nDjango's default admin interface can be a design nightmare. If you’re tired of staring at bland forms and uninspired UI, you’re not alone. A modern, visually appealing admin can make a world of difference, both for developers and users.\n\nWhat This Does\nEnter django-unfold, a modern admin theme that spruces up your Django admin like a fresh coat of paint—if that paint was made with Tailwind CSS. The repo has a folder structure that’s pretty standard for any decent project: you’ve got your .github workflows for linting and testing in workflows, and the meat of the theme lives in docs/components. \n\nYou’ll find reusable UI components like buttons and cards in docs/components/button.md and docs/components/card.md. These components are designed to be easily plopped into your existing projects. Need advanced filters? Check out the docs/actions/index.md for a rundown on how to implement those.\n\nReal-World Use\nImagine you’re building an app for a client who’s all about aesthetics. You don’t want them to cringe every time they log in to manage their data. With django-unfold, you can customize the sidebar navigation and even toggle between light and dark modes. Here’s a quick snippet to get you started:\n\nfrom django.contrib import admin\nfrom unfold.admin import UnfoldModelAdmin\n\nclass MyModelAdmin(UnfoldModelAdmin):\n    listdisplay = ('name', 'createdat')\n    # Add any customizations here\n\nadmin.site.register(MyModel, MyModelAdmin)\n\nThis sets up a more visually appealing admin interface while keeping all the usual Django functionality.\n\nThe Bottom Line\ndjango-unfold is a solid choice if you’re looking to elevate your Django admin interface without reinventing the wheel. It’s particularly useful for projects where the admin UI matters—think SaaS applications or internal tools. Just be aware that if your project is small or the admin isn't heavily used, this might be overkill. But for those who need a polished look and feel, it’s worth a shot.",
      "url": "https://github.com/yebeai/django-unfold",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "unfoldadmin/django-unfold",
        "url": "https://github.com/unfoldadmin/django-unfold",
        "stars": 3232
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 10, 2026",
      "updatedAt": "February 10, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".github": 7,
          "(root)": 8,
          "docs": 82,
          "src": 103
        },
        "languages": {
          "Markdown": 87,
          "YAML": 6,
          "JSON": 2,
          "TOML": 1,
          "Python": 52,
          "HTML": 38,
          "CSS": 2,
          "JavaScript": 6
        },
        "frameworks": [
          "React",
          "Django"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          "package.json",
          "pyproject.toml"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json",
          "pyproject.toml"
        ],
        "testFiles": [
          ".github/workflows/test.yml"
        ],
        "docs": [
          "CHANGELOG.md",
          "LICENSE.md",
          "README.md",
          "docs/actions/action-form-example.md",
          "docs/actions/changeform-submitline.md",
          "docs/actions/changeform.md",
          "docs/actions/changelist-row.md",
          "docs/actions/changelist.md",
          "docs/actions/dropdown-actions.md",
          "docs/actions/index.md",
          "docs/actions/introduction.md",
          "docs/components/button.md",
          "docs/components/card.md",
          "docs/components/chart.md",
          "docs/components/cohort.md",
          "docs/components/component-class.md",
          "docs/components/index.md",
          "docs/components/introduction.md",
          "docs/components/layer.md",
          "docs/components/progress.md",
          "docs/components/table.md",
          "docs/components/tracker.md",
          "docs/configuration/command.md",
          "docs/configuration/conditional-fields.md",
          "docs/configuration/crispy-forms.md",
          "docs/configuration/custom-pages.md",
          "docs/configuration/custom-sites.md",
          "docs/configuration/dashboard.md",
          "docs/configuration/datasets.md",
          "docs/configuration/index.md",
          "docs/configuration/modeladmin.md",
          "docs/configuration/multi-language.md",
          "docs/configuration/paginator.md",
          "docs/configuration/sections.md",
          "docs/configuration/settings.md",
          "docs/configuration/site-dropdown.md",
          "docs/configuration/sortable-changelist.md",
          "docs/decorators/action.md",
          "docs/decorators/display.md",
          "docs/decorators/index.md",
          "docs/development/index.md",
          "docs/fields/autocomplete.md",
          "docs/fields/index.md",
          "docs/fields/json.md",
          "docs/filters/autocomplete.md",
          "docs/filters/checkbox-radio.md",
          "docs/filters/datetime.md",
          "docs/filters/dropdown.md",
          "docs/filters/horizontal.md",
          "docs/filters/index.md",
          "docs/filters/introduction.md",
          "docs/filters/numeric.md",
          "docs/filters/text.md",
          "docs/inlines/index.md",
          "docs/inlines/introduction.md",
          "docs/inlines/nonrelated.md",
          "docs/inlines/options.md",
          "docs/inlines/paginated.md",
          "docs/inlines/sortable.md",
          "docs/installation/auth.md",
          "docs/installation/index.md",
          "docs/installation/quickstart.md",
          "docs/integrations/django-celery-beat.md",
          "docs/integrations/django-constance.md",
          "docs/integrations/django-guardian.md",
          "docs/integrations/django-import-export.md",
          "docs/integrations/django-json-widget.md",
          "docs/integrations/django-location-field.md",
          "docs/integrations/django-modeltranslation.md",
          "docs/integrations/django-money.md",
          "docs/integrations/django-simple-history.md",
          "docs/integrations/djangoql.md",
          "docs/integrations/index.md",
          "docs/styles-scripts/customizing-tailwind.md",
          "docs/styles-scripts/index.md",
          "docs/styles-scripts/loading-files.md",
          "docs/tabs/changeform.md",
          "docs/tabs/changelist.md",
          "docs/tabs/dynamic.md",
          "docs/tabs/fieldsets.md",
          "docs/tabs/index.md",
          "docs/tabs/inline.md",
          "docs/widgets/array.md",
          "docs/widgets/index.md",
          "docs/widgets/wysiwyg.md",
          "src/unfold/contrib/filters/static/unfold/filters/css/nouislider/LICENSE",
          "src/unfold/contrib/filters/static/unfold/filters/js/nouislider/LICENSE",
          "src/unfold/contrib/filters/static/unfold/filters/js/wnumb/LICENSE",
          "src/unfold/contrib/forms/static/unfold/forms/css/trix/LICENSE",
          "src/unfold/contrib/forms/static/unfold/forms/js/trix/LICENSE"
        ],
        "fileTypes": {
          ".md": 87,
          ".yml": 5,
          ".yaml": 1,
          ".json": 2,
          ".toml": 1,
          ".py": 52,
          ".html": 38,
          ".css": 2,
          ".js": 6
        }
      }
    },
    {
      "id": 1154009932,
      "name": "worktrunk",
      "displayName": "worktrunk",
      "description": "Worktrunk is a CLI for Git worktree management, designed for parallel AI agent workflows",
      "summary": "Managing Git Worktrees with Worktrunk: A CLI for the Sane Developer\n\nThe Problem\n\nGit worktrees are amazing—when you’re juggling multiple branches or, as in this case, running a bunch of parallel AI agents, they save you from the nightmare of cloning a repo ten times. But here’s the catch: Git’s native worktree UX is trash. Even simple tasks like creating a new worktree or switching between them feel like a typing test for advanced keyboard masochists. And automating workflows? Yeah, good luck with that. \n\nWhat This Does\n\nWorktrunk makes git worktree as easy to use as git branch. Think of it as a modern, streamlined CLI wrapper that spares you from Git’s clunky syntax and injects much-needed developer sanity into your workflow. The repo is packed with features, but the core focus is on three commands: wt switch, wt remove, and wt list.\n\nThe wt switch command is the standout here. Need a new worktree for a feature? Just run wt switch -c feat and you’re off to the races. If you’re spinning up an AI agent alongside, add -x claude for instant integration. Want to clean up? wt remove takes care of deleting the worktree and the branch, sparing you from the usual multi-step dance of git worktree remove and git branch -d. Meanwhile, wt list gives you a readable, status-inclusive overview of all your active worktrees—none of that raw, path-only nonsense from git worktree list.\n\nThe repo isn’t just a CLI; it’s a full ecosystem. Check out the .claude-plugin/ directory for tight coupling with tools like Claude, including hooks (hooks.json) and skills (skills/worktrunk/SKILL.md) that automate workflows. There’s also a .config/wt.toml, which lets you define a path template for worktrees—no more hardcoding paths like a caveman. \n\nReal-World Use\n\nLet’s say you’re managing 5 AI agents, each working on a different feature. With native Git, you’d be running commands like:\n\ngit worktree add -b feat-1 ../repo.feat-1 && cd ../repo.feat-1 && agent\ngit worktree add -b feat-2 ../repo.feat-2 && cd ../repo.feat-2 && agent\n\nRepeat this for every agent, and hope you don’t typo yourself into a rage spiral. With Worktrunk:\n\nwt switch -c -x agent feat-1\nwt switch -c -x agent feat-2\n\nDone. Oh, and when you’re done? wt remove cleans up the entire mess for you.\n\nThe Bottom Line\n\nWorktrunk is a no-brainer if you’re using Git worktrees, especially if you’re working with AI agents or juggling multiple branches. The CLI is clean, the commands make sense, and it saves you from Git’s abysmal worktree ergonomics. That said, if you’re just hacking on one branch at a time, this might be overkill. But if you’re scaling workflows or automating tasks, you’ll never want to go back.",
      "url": "https://github.com/yebeai/worktrunk",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "max-sixty/worktrunk",
        "url": "https://github.com/max-sixty/worktrunk",
        "stars": 2343
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 9, 2026",
      "updatedAt": "February 9, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".cargo": 1,
          ".claude-plugin": 21,
          ".claude": 2,
          ".config": 4,
          ".github": 10,
          "(root)": 17,
          "benches": 4,
          "dev": 3,
          "docs": 71,
          "src": 67
        },
        "languages": {
          "TOML": 12,
          "Markdown": 44,
          "JSON": 4,
          "YAML": 12,
          "Rust": 70,
          "Python": 4,
          "Shell": 1,
          "SCSS": 1,
          "JavaScript": 3,
          "HTML": 9,
          "CSS": 3
        },
        "frameworks": [],
        "packageManager": "cargo",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "docs/demos/shared/fixtures/lib.rs",
          "docs/templates/index.html"
        ],
        "configFiles": [
          "Cargo.toml"
        ],
        "dependencies": [
          "Cargo.toml"
        ],
        "testFiles": [
          ".config/nextest.toml",
          "src/commands/list/spacing_test.rs",
          "src/commands/snapshots/wt__commands__configure_shell__tests__fish_completion_content.snap",
          "src/commands/snapshots/wt__commands__configure_shell__tests__fish_completion_content_custom_cmd.snap"
        ],
        "docs": [
          ".claude-plugin/README.md",
          ".claude-plugin/skills/worktrunk/reference/README.md",
          "CHANGELOG.md",
          "LICENSE",
          "README.md",
          "docs/.gitignore",
          "docs/CLAUDE.md",
          "docs/config.toml",
          "docs/content/_index.md",
          "docs/content/claude-code.md",
          "docs/content/config.md",
          "docs/content/faq.md",
          "docs/content/hook.md",
          "docs/content/list.md",
          "docs/content/llm-commits.md",
          "docs/content/merge.md",
          "docs/content/remove.md",
          "docs/content/step.md",
          "docs/content/switch.md",
          "docs/content/tips-patterns.md",
          "docs/content/worktrunk.md",
          "docs/demos/.gitignore",
          "docs/demos/CLAUDE.md",
          "docs/demos/build",
          "docs/demos/shared/__init__.py",
          "docs/demos/shared/fixtures/alpha-readme.md",
          "docs/demos/shared/fixtures/alpha-utils.rs",
          "docs/demos/shared/fixtures/gh-mock.sh",
          "docs/demos/shared/fixtures/lib-hooks.rs",
          "docs/demos/shared/fixtures/lib.rs",
          "docs/demos/shared/fixtures/starship.toml",
          "docs/demos/shared/lib.py",
          "docs/demos/shared/themes.py",
          "docs/demos/shared/validation.py",
          "docs/demos/snapshots/wt-commit.snap",
          "docs/demos/snapshots/wt-core.snap",
          "docs/demos/snapshots/wt-list.snap",
          "docs/demos/snapshots/wt-merge.snap",
          "docs/demos/tapes/shared-commands.tape",
          "docs/demos/tapes/shared-setup.tape",
          "docs/demos/tapes/wt-commit.tape",
          "docs/demos/tapes/wt-core.tape",
          "docs/demos/tapes/wt-devserver.tape",
          "docs/demos/tapes/wt-hooks.tape",
          "docs/demos/tapes/wt-list-remove.tape",
          "docs/demos/tapes/wt-list.tape",
          "docs/demos/tapes/wt-merge.tape",
          "docs/demos/tapes/wt-statusline.tape",
          "docs/demos/tapes/wt-switch-picker.tape",
          "docs/demos/tapes/wt-switch.tape",
          "docs/demos/tapes/wt-zellij-omnibus.tape",
          "docs/sass/custom.scss",
          "docs/static/apple-touch-icon.png",
          "docs/static/code-copy.js",
          "docs/static/demos/twitter/thread-preview.html",
          "docs/static/demos/twitter/thread.md",
          "docs/static/favicon-48.png",
          "docs/static/favicon.png",
          "docs/static/github-social-card.svg",
          "docs/static/logo.png",
          "docs/static/logo@2x.png",
          "docs/static/mobile-menu.js",
          "docs/static/normalize.css",
          "docs/static/robots.txt",
          "docs/static/search.js",
          "docs/static/social-card.svg",
          "docs/static/syntax-dark.css",
          "docs/static/syntax-light.css",
          "docs/templates/404.html",
          "docs/templates/_variables.html",
          "docs/templates/base.html",
          "docs/templates/index.html",
          "docs/templates/macros.html",
          "docs/templates/page.html",
          "docs/templates/shortcodes/rawcode.html",
          "docs/templates/shortcodes/terminal.html"
        ],
        "fileTypes": {
          ".toml": 12,
          ".md": 44,
          ".json": 4,
          ".yaml": 12,
          ".lock": 2,
          ".rs": 70,
          ".py": 4,
          ".sh": 1,
          ".snap": 6,
          ".tape": 13,
          ".scss": 1,
          ".png": 5,
          ".js": 3,
          ".html": 9,
          ".svg": 2,
          ".css": 3,
          ".txt": 1,
          ".nix": 1
        }
      }
    },
    {
      "id": 1154009614,
      "name": "maple-font",
      "displayName": "maple font",
      "description": "Maple Mono: Open source monospace font with round corner, ligatures and Nerd-Font icons for IDE and terminal, fine-grained customization options. 带连字和控制台图标的圆角等宽字体，中英文宽度完美2:1，细粒度的自定义选项",
      "summary": "The Problem\nTired of the same old boring monospace fonts? You know, the ones that make your code look like a jumbled mess? Especially when you're working with mixed languages like English and Chinese, it can be a nightmare to keep things aligned. Enter Maple Mono: a font designed to smooth out your coding experience while making your IDE and terminal look like a million bucks.\n\nWhat This Does\nMaple Mono isn't just another font; it's a thoughtfully crafted monospace font with features that actually matter. The build.py script automates the font generation, and the config.json allows for fine-tuning based on your preferences. You can toggle features on or off, making it customizable to suit your workflow. \n\nWant to see how it looks? Check out resources/showcase.png for a preview. The font supports a plethora of ligatures, detailed in source/features/README.md, which means less eye strain and more focus on your code. Plus, it comes with Nerd Font icons, so your terminal can actually look interesting instead of like a bland text dump.\n\nReal-World Use\nImagine you're coding a multilingual application and need a font that keeps everything aligned and readable. You can simply install Maple Mono via Scoop on Windows like this:\n\nscoop bucket add nerd-fonts\nscoop install Maple-Mono\n\nNow, you’ve got a font that ensures your Chinese and English characters are perfectly aligned in a 2:1 ratio. Perfect for those Markdown tables that usually look like they were formatted by a toddler.\n\nThe Bottom Line\nMaple Mono is a solid choice for developers looking to upgrade their font game without the hassle. It’s visually appealing and functional, especially for those juggling multiple languages. But if you’re just after a simple monospace font and don’t care about customization or aesthetics, you might find this overkill. For everyone else, it’s worth giving Maple Mono a try.",
      "url": "https://github.com/yebeai/maple-font",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "subframe7536/maple-font",
        "url": "https://github.com/subframe7536/maple-font",
        "stars": 24130
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 9, 2026",
      "updatedAt": "February 9, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 137,
        "directories": {
          "(root)": 14,
          ".github": 4,
          "resources": 5,
          "source": 112,
          "woff2": 2
        },
        "languages": {
          "YAML": 4,
          "Markdown": 9,
          "Python": 91,
          "JSON": 3,
          "TOML": 1
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": "pip",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          "Dockerfile",
          "pyproject.toml",
          "requirements.txt"
        ],
        "dependencies": [
          "pyproject.toml",
          "requirements.txt"
        ],
        "testFiles": [],
        "docs": [
          "README.md",
          "README_CN.md",
          "README_JA.md",
          "source/cn/README.md",
          "source/features/README.md",
          "source/features/README_CN.md",
          "source/py/feature/README.md",
          "source/py/task/merge_font/README.md"
        ],
        "fileTypes": {
          ".yml": 3,
          ".md": 9,
          ".txt": 3,
          ".py": 91,
          ".json": 3,
          ".toml": 1,
          ".png": 3,
          ".svg": 2,
          ".ttf": 5,
          ".glyphs": 2,
          ".vfc": 2,
          ".sha256": 1,
          ".yaml": 1,
          ".fea": 5,
          ".woff2": 2
        }
      }
    },
    {
      "id": 1154003465,
      "name": "kafka-training",
      "displayName": "kafka training",
      "description": " This repository contains labs, lectures, and reference material used to train developers and operations how to use Apache Kafka.",
      "summary": "The Problem\n\nGetting started with Apache Kafka is usually a headache: outdated blogs, cryptic docs, and a mess of half-baked tutorials that assume you’re already a distributed systems wizard. Most folks just want to spin up Kafka, poke around, and actually see what happens when you send a message or screw up a config—not read a whitepaper.\n\nWhat This Does\n\nThe kafka-training repo is basically a hands-on crash course for devs and ops folks who want to do things with Kafka, not just read about them. Each labs/LabXX* directory is a focused, self-contained unit. For example, labs/Lab01Setup/stepslocal.md hands you the exact steps to get Kafka running on your laptop, while labs/Lab03Messages/steps.md walks you through sending and consuming real messages.\n\nEvery lab comes with its own config (server.properties, log4j.properties) and questions so you can actually break stuff and learn. You’re not left guessing what to do next—the steps.md files are blunt and to the point. Need to see what happens when you mess with authentication? There’s even an LDAP lab (labs/Lab08LDAP/).\n\nReal-World Use\n\nSay you’ve got a new team member who’s never touched Kafka. Instead of hand-waving through a 60-slide deck, just point them to labs/Lab02Tools/steps.md. They’ll learn how to use Kafka’s CLI tools, spin up a broker, and send messages—all in a throwaway local environment. For example, the lab walks through commands like:\n\nbin/kafka-topics.sh --create --topic test --bootstrap-server localhost:9092\nbin/kafka-console-producer.sh --topic test --bootstrap-server localhost:9092\n\nThey’ll see exactly what happens and why, without taking down your prod cluster or getting lost in theory.\n\nThe Bottom Line\n\nIf you actually want to understand Kafka by pushing real buttons, this repo beats yet another documentation binge. The lab structure is old-school but effective—just follow the steps, break stuff, and learn. Great for onboarding or brushing up, but don’t expect fancy UIs or production-ready scripts. This is for people who learn by doing, not by sitting through another “Kafka 101” webinar.",
      "url": "https://github.com/yebeai/kafka-training",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "sassoftware/kafka-training",
        "url": "https://github.com/sassoftware/kafka-training",
        "stars": 121
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 9, 2026",
      "updatedAt": "February 9, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 42,
        "directories": {
          "(root)": 8,
          "assessments": 1,
          "labs": 33
        },
        "languages": {
          "Markdown": 20,
          "Java": 1,
          "Shell": 2
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [
          "labs/Lab08_LDAP/src/TestLDAP.java"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "labs/Lab01_Setup/README.md",
          "labs/Lab02_Tools/README.md",
          "labs/Lab03_Messages/README.md",
          "labs/Lab04_Topics/README.md",
          "labs/Lab08_LDAP/README.md",
          "labs/README.md"
        ],
        "fileTypes": {
          ".md": 20,
          ".txt": 1,
          ".properties": 14,
          ".ldif": 2,
          ".java": 1,
          ".sh": 2
        }
      }
    },
    {
      "id": 1154000837,
      "name": "echo-tts",
      "displayName": "echo tts",
      "description": "Echo-TTS inference codebase",
      "summary": "The Problem\n\nGenerating high-quality, multi-speaker text-to-speech (TTS) audio has always been a pain, especially when you need speaker-specific outputs. Most TTS models are either too generic, require massive compute, or don't provide much room to tweak and fine-tune the outputs. If you've ever struggled with unreliable speaker conditioning or models that butcher long-form text, you’ll appreciate what echo-tts brings to the table.\n\nWhat This Does\n\necho-tts is an inference pipeline for a multi-speaker TTS model that uses speaker reference conditioning. You feed it audio of a speaker, some text, and it spits out audio that sounds like that speaker saying the text. To get started, clone the repo, install the dependencies with requirements.txt, and fire up the Gradio interface using gradioapp.py. It’s all there in the README.md.\n\nThe heavy lifting happens in inference.py and the associated sampling functions, like samplepipeline. The model itself is pulled from Hugging Face (jordand/echo-tts-base), and it’s powered by a TPU-trained architecture with some fancy extras like \"blockwise generation\" (inferenceblockwise.py) for handling long sequences without burning through VRAM. \n\nWant to tweak things? Edit samplerpresets.json to customize the sampling behavior or adjust settings like FISHAEDTYPE in gradioapp.py to make it less of a VRAM hog.\n\nReal-World Use\n\nLet’s say you want your app to generate bedtime stories in your voice. Record a 10-second sample of yourself, save it as speaker.wav, and load it in your script with loadaudio. Use the samplepipeline function to generate audio, adjusting parameters like cfgscalespeaker to lock in your voice or tweak the output style. Run the script, and voilà, you now have a custom audio file (output.wav) of you narrating a story.\n\nIf you’re lazy (no judgment), just use the Gradio app (gradioapp.py). Upload your audio sample, type your text, hit \"Generate,\" and download the result.\n\nThe Bottom Line\n\necho-tts is solid if you want advanced TTS with speaker conditioning and are okay with some setup. It’s not plug-and-play for non-technical folks, and you’ll need decent hardware (8GB+ VRAM & a CUDA GPU). But if you’re a developer who loves tinkering with audio generation, this repo is worth a shot. Just don’t use it to fake Elon Musk interviews, okay?",
      "url": "https://github.com/yebeai/echo-tts",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "jordandare/echo-tts",
        "url": "https://github.com/jordandare/echo-tts",
        "stars": 126
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 9, 2026",
      "updatedAt": "February 9, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 18,
        "directories": {
          "(root)": 11,
          "audio_prompts": 7
        },
        "languages": {
          "Markdown": 1,
          "Python": 5,
          "JSON": 1
        },
        "frameworks": [
          "Flask",
          "Express"
        ],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [
          "requirements.txt"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md",
          "audio_prompts/LICENSE"
        ],
        "fileTypes": {
          ".md": 1,
          ".mp3": 6,
          ".py": 5,
          ".txt": 2,
          ".json": 1
        }
      }
    },
    {
      "id": 1153990980,
      "name": "PDF-Extract-Kit",
      "displayName": "PDF Extract Kit",
      "description": "A Comprehensive Toolkit for High-Quality PDF Content Extraction",
      "summary": "The Problem\nExtracting content from PDFs can feel like wrestling an octopus. You’ve got complex layouts, mixed media, and inconsistent formatting. Trying to get data out of these documents often leads to a frustrating experience where you’re left with half-baked results or, worse, nothing at all.\n\nWhat This Does\nPDF-Extract-Kit is a toolkit that tackles these issues head-on. It integrates various models for different extraction tasks, from layout detection to OCR. Want to identify tables in a financial report? Check out the assets/demo/layoutdetection folder, which hosts examples like financialreport.png. Need to convert formula images into LaTeX? The formularecognition folder has you covered with models like UniMERNet.\n\nThe modular design is a big plus; you can tweak configurations in config.yaml to mix and match functionalities. For example, if your PDF has tables and images, you can set up the toolkit to run both PaddleOCR+TableMaster and YOLO-v10ft without rewriting the wheel.\n\nReal-World Use\nImagine you receive a PDF report with a mix of text, images, and tables. You want to extract this data into a structured format for analysis. Simply point the toolkit to your PDF, configure your extraction settings in the config.yaml, and run the extraction script. The output could be a Markdown file, neatly organized and ready for whatever you need—be it analysis, translation, or just for sharing with your team.\n\npython extract.py --input myreport.pdf --output myreport.md --config config.yaml\n\nThe Bottom Line\nPDF-Extract-Kit isn’t perfect for every scenario—if you’re just extracting text from simple PDFs, it might be overkill. However, if you deal with complex documents regularly, this toolkit is a solid choice. It’s flexible, integrates well with existing models, and can save you a ton of time. Just be ready to invest some effort in configuration.",
      "url": "https://github.com/yebeai/PDF-Extract-Kit",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "opendatalab/PDF-Extract-Kit",
        "url": "https://github.com/opendatalab/PDF-Extract-Kit",
        "stars": 9406
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 9, 2026",
      "updatedAt": "February 9, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 5,
          ".vscode": 1,
          "assets": 25,
          "configs": 8,
          "docs": 161
        },
        "languages": {
          "YAML": 11,
          "JSON": 1,
          "Markdown": 9,
          "reStructuredText": 46,
          "Python": 2,
          "CSS": 2,
          "JavaScript": 6
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [
          "docs/en/Makefile",
          "docs/requirements.txt",
          "docs/zh_cn/Makefile"
        ],
        "dependencies": [
          "docs/requirements.txt"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE.md",
          "README.md",
          "README_zh-CN.md",
          "assets/readme/datalab_logo.png",
          "assets/readme/layout_example.png",
          "assets/readme/mfd_example.png",
          "assets/readme/modelscope_logo.png",
          "assets/readme/pdf-extract-kit_logo.png",
          "assets/readme/pipeline.png",
          "assets/readme/table_expamle.png",
          "assets/readme/unimernet_result.jpg",
          "docs/en/.readthedocs.yaml",
          "docs/en/Makefile",
          "docs/en/_static/image/logo.png",
          "docs/en/algorithm/formula_detection.rst",
          "docs/en/algorithm/formula_recognition.rst",
          "docs/en/algorithm/layout_detection.rst",
          "docs/en/algorithm/ocr.rst",
          "docs/en/algorithm/reading_order.rst",
          "docs/en/algorithm/table_recognition.rst",
          "docs/en/conf copy.py",
          "docs/en/conf.bak",
          "docs/en/conf.py",
          "docs/en/evaluation/formula_detection.rst",
          "docs/en/evaluation/formula_recognition.rst",
          "docs/en/evaluation/layout_detection.rst",
          "docs/en/evaluation/ocr.rst",
          "docs/en/evaluation/pdf_extract.rst",
          "docs/en/evaluation/reading_order.rst",
          "docs/en/evaluation/table_recognition.rst",
          "docs/en/get_started/installation.rst",
          "docs/en/get_started/pretrained_model.rst",
          "docs/en/get_started/quickstart.rst",
          "docs/en/index.rst",
          "docs/en/make.bat",
          "docs/en/models/supported.md",
          "docs/en/notes/changelog.md",
          "docs/en/project/doc_translate.rst",
          "docs/en/project/pdf_extract.rst",
          "docs/en/project/speed_up.rst",
          "docs/en/switch_language.md",
          "docs/en/task_extend/code.rst",
          "docs/en/task_extend/doc.rst",
          "docs/en/task_extend/evaluation.rst",
          "docs/requirements.txt",
          "docs/zh_cn/.readthedocs.yaml",
          "docs/zh_cn/Makefile",
          "docs/zh_cn/_build/doctrees/algorithm/formula_detection.doctree",
          "docs/zh_cn/_build/doctrees/algorithm/formula_recognition.doctree",
          "docs/zh_cn/_build/doctrees/algorithm/layout_detection.doctree",
          "docs/zh_cn/_build/doctrees/algorithm/ocr.doctree",
          "docs/zh_cn/_build/doctrees/algorithm/reading_order.doctree",
          "docs/zh_cn/_build/doctrees/algorithm/table_recognition.doctree",
          "docs/zh_cn/_build/doctrees/environment.pickle",
          "docs/zh_cn/_build/doctrees/evaluation/formula_detection.doctree",
          "docs/zh_cn/_build/doctrees/evaluation/formula_recognition.doctree",
          "docs/zh_cn/_build/doctrees/evaluation/layout_detection.doctree",
          "docs/zh_cn/_build/doctrees/evaluation/ocr.doctree",
          "docs/zh_cn/_build/doctrees/evaluation/pdf_extract.doctree",
          "docs/zh_cn/_build/doctrees/evaluation/reading_order.doctree",
          "docs/zh_cn/_build/doctrees/evaluation/table_recognition.doctree",
          "docs/zh_cn/_build/doctrees/get_started/installation.doctree",
          "docs/zh_cn/_build/doctrees/get_started/pretrained_model.doctree",
          "docs/zh_cn/_build/doctrees/get_started/quickstart.doctree",
          "docs/zh_cn/_build/doctrees/index.doctree",
          "docs/zh_cn/_build/doctrees/models/supported.doctree",
          "docs/zh_cn/_build/doctrees/notes/changelog.doctree",
          "docs/zh_cn/_build/doctrees/project/doc_translate.doctree",
          "docs/zh_cn/_build/doctrees/project/pdf_extract.doctree",
          "docs/zh_cn/_build/doctrees/project/speed_up.doctree",
          "docs/zh_cn/_build/doctrees/switch_language.doctree",
          "docs/zh_cn/_build/doctrees/task_extend/code.doctree",
          "docs/zh_cn/_build/doctrees/task_extend/doc.doctree",
          "docs/zh_cn/_build/doctrees/task_extend/evaluation.doctree",
          "docs/zh_cn/_build/html/.buildinfo",
          "docs/zh_cn/_build/html/_images/logo.png",
          "docs/zh_cn/_build/html/_sources/algorithm/formula_detection.rst",
          "docs/zh_cn/_build/html/_sources/algorithm/formula_recognition.rst",
          "docs/zh_cn/_build/html/_sources/algorithm/layout_detection.rst",
          "docs/zh_cn/_build/html/_sources/algorithm/ocr.rst",
          "docs/zh_cn/_build/html/_sources/algorithm/reading_order.rst",
          "docs/zh_cn/_build/html/_sources/algorithm/table_recognition.rst",
          "docs/zh_cn/_build/html/_sources/evaluation/formula_detection.rst",
          "docs/zh_cn/_build/html/_sources/evaluation/formula_recognition.rst",
          "docs/zh_cn/_build/html/_sources/evaluation/layout_detection.rst",
          "docs/zh_cn/_build/html/_sources/evaluation/ocr.rst",
          "docs/zh_cn/_build/html/_sources/evaluation/pdf_extract.rst",
          "docs/zh_cn/_build/html/_sources/evaluation/reading_order.rst",
          "docs/zh_cn/_build/html/_sources/evaluation/table_recognition.rst",
          "docs/zh_cn/_build/html/_sources/get_started/installation.rst",
          "docs/zh_cn/_build/html/_sources/get_started/pretrained_model.rst",
          "docs/zh_cn/_build/html/_sources/get_started/quickstart.rst",
          "docs/zh_cn/_build/html/_sources/index.rst",
          "docs/zh_cn/_build/html/_sources/models/supported.md",
          "docs/zh_cn/_build/html/_sources/notes/changelog.md",
          "docs/zh_cn/_build/html/_sources/project/doc_translate.rst",
          "docs/zh_cn/_build/html/_sources/project/pdf_extract.rst",
          "docs/zh_cn/_build/html/_sources/project/speed_up.rst",
          "docs/zh_cn/_build/html/_sources/switch_language.md",
          "docs/zh_cn/_build/html/_sources/task_extend/code.rst",
          "docs/zh_cn/_build/html/_sources/task_extend/doc.rst",
          "docs/zh_cn/_build/html/_sources/task_extend/evaluation.rst",
          "docs/zh_cn/_build/html/_static/basic.css",
          "docs/zh_cn/_build/html/_static/check-solid.svg",
          "docs/zh_cn/_build/html/_static/clipboard.min.js",
          "docs/zh_cn/_build/html/_static/copy-button.svg",
          "docs/zh_cn/_build/html/_static/copybutton.css",
          "docs/zh_cn/_build/html/_static/copybutton.js",
          "docs/zh_cn/_build/html/_static/copybutton_funcs.js",
          "docs/zh_cn/_build/html/_static/doctools.js",
          "docs/zh_cn/_build/html/_static/documentation_options.js",
          "docs/zh_cn/_build/html/_static/file.png",
          "docs/zh_cn/_build/html/_static/images/logo_binder.svg",
          "docs/zh_cn/_build/html/_static/images/logo_colab.png",
          "docs/zh_cn/_build/html/_static/images/logo_deepnote.svg",
          "docs/zh_cn/_build/html/_static/images/logo_jupyterhub.svg",
          "docs/zh_cn/_build/html/_static/language_data.js",
          "docs/zh_cn/_build/html/_static/locales/ar/LC_MESSAGES/booktheme.mo",
          "docs/zh_cn/_build/html/_static/locales/ar/LC_MESSAGES/booktheme.po",
          "docs/zh_cn/_build/html/_static/locales/bg/LC_MESSAGES/booktheme.mo",
          "docs/zh_cn/_build/html/_static/locales/bg/LC_MESSAGES/booktheme.po",
          "docs/zh_cn/_build/html/_static/locales/bn/LC_MESSAGES/booktheme.mo",
          "docs/zh_cn/_build/html/_static/locales/bn/LC_MESSAGES/booktheme.po",
          "docs/zh_cn/_build/html/_static/locales/ca/LC_MESSAGES/booktheme.mo",
          "docs/zh_cn/_build/html/_static/locales/ca/LC_MESSAGES/booktheme.po",
          "docs/zh_cn/_build/html/_static/locales/cs/LC_MESSAGES/booktheme.mo",
          "docs/zh_cn/_build/html/_static/locales/cs/LC_MESSAGES/booktheme.po",
          "docs/zh_cn/_build/html/_static/locales/da/LC_MESSAGES/booktheme.mo",
          "docs/zh_cn/_build/html/_static/locales/da/LC_MESSAGES/booktheme.po",
          "docs/zh_cn/_build/html/_static/locales/de/LC_MESSAGES/booktheme.mo",
          "docs/zh_cn/_build/html/_static/locales/de/LC_MESSAGES/booktheme.po",
          "docs/zh_cn/_build/html/_static/locales/el/LC_MESSAGES/booktheme.mo",
          "docs/zh_cn/_build/html/_static/locales/el/LC_MESSAGES/booktheme.po",
          "docs/zh_cn/_build/html/_static/locales/eo/LC_MESSAGES/booktheme.mo",
          "docs/zh_cn/_build/html/_static/locales/eo/LC_MESSAGES/booktheme.po",
          "docs/zh_cn/_build/html/_static/locales/es/LC_MESSAGES/booktheme.mo",
          "docs/zh_cn/_build/html/_static/locales/es/LC_MESSAGES/booktheme.po",
          "docs/zh_cn/_build/html/_static/locales/et/LC_MESSAGES/booktheme.mo",
          "docs/zh_cn/_build/html/_static/locales/et/LC_MESSAGES/booktheme.po",
          "docs/zh_cn/_build/html/_static/locales/fi/LC_MESSAGES/booktheme.mo",
          "docs/zh_cn/_build/html/_static/locales/fi/LC_MESSAGES/booktheme.po",
          "docs/zh_cn/_build/html/_static/locales/fr/LC_MESSAGES/booktheme.mo",
          "docs/zh_cn/_build/html/_static/locales/fr/LC_MESSAGES/booktheme.po",
          "docs/zh_cn/_build/html/_static/locales/hr/LC_MESSAGES/booktheme.mo",
          "docs/zh_cn/_build/html/_static/locales/hr/LC_MESSAGES/booktheme.po",
          "docs/zh_cn/_build/html/_static/locales/id/LC_MESSAGES/booktheme.mo",
          "docs/zh_cn/_build/html/_static/locales/id/LC_MESSAGES/booktheme.po",
          "docs/zh_cn/_build/html/_static/locales/it/LC_MESSAGES/booktheme.mo",
          "docs/zh_cn/_build/html/_static/locales/it/LC_MESSAGES/booktheme.po",
          "docs/zh_cn/_build/html/_static/locales/iw/LC_MESSAGES/booktheme.mo",
          "docs/zh_cn/_build/html/_static/locales/iw/LC_MESSAGES/booktheme.po",
          "docs/zh_cn/_build/html/_static/locales/ja/LC_MESSAGES/booktheme.mo",
          "docs/zh_cn/_build/html/_static/locales/ja/LC_MESSAGES/booktheme.po",
          "docs/zh_cn/_build/html/_static/locales/ko/LC_MESSAGES/booktheme.mo",
          "docs/zh_cn/_build/html/_static/locales/ko/LC_MESSAGES/booktheme.po",
          "docs/zh_cn/_build/html/_static/locales/lt/LC_MESSAGES/booktheme.mo",
          "docs/zh_cn/_build/html/_static/locales/lt/LC_MESSAGES/booktheme.po",
          "docs/zh_cn/_build/html/_static/locales/lv/LC_MESSAGES/booktheme.mo",
          "docs/zh_cn/_build/html/_static/locales/lv/LC_MESSAGES/booktheme.po",
          "docs/zh_cn/_build/html/_static/locales/ml/LC_MESSAGES/booktheme.mo",
          "docs/zh_cn/_build/html/_static/locales/ml/LC_MESSAGES/booktheme.po",
          "docs/zh_cn/_build/html/_static/locales/mr/LC_MESSAGES/booktheme.mo",
          "docs/zh_cn/_build/html/_static/locales/mr/LC_MESSAGES/booktheme.po",
          "docs/zh_cn/_build/html/_static/locales/ms/LC_MESSAGES/booktheme.mo",
          "docs/zh_cn/_build/html/_static/locales/ms/LC_MESSAGES/booktheme.po",
          "docs/zh_cn/_build/html/_static/locales/nl/LC_MESSAGES/booktheme.mo",
          "docs/zh_cn/_build/html/_static/locales/nl/LC_MESSAGES/booktheme.po",
          "docs/zh_cn/_build/html/_static/locales/no/LC_MESSAGES/booktheme.mo",
          "docs/zh_cn/_build/html/_static/locales/no/LC_MESSAGES/booktheme.po",
          "docs/zh_cn/_build/html/_static/locales/pl/LC_MESSAGES/booktheme.mo",
          "docs/zh_cn/_build/html/_static/locales/pl/LC_MESSAGES/booktheme.po",
          "docs/zh_cn/_build/html/_static/locales/pt/LC_MESSAGES/booktheme.mo"
        ],
        "fileTypes": {
          ".yaml": 11,
          ".json": 1,
          ".md": 9,
          ".pdf": 2,
          ".png": 26,
          ".jpg": 1,
          ".rst": 46,
          ".py": 2,
          ".bak": 1,
          ".bat": 1,
          ".txt": 1,
          ".doctree": 26,
          ".pickle": 1,
          ".css": 2,
          ".svg": 5,
          ".js": 6,
          ".mo": 28,
          ".po": 27
        }
      }
    },
    {
      "id": 1153990720,
      "name": "langextract",
      "displayName": "langextract",
      "description": "A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.",
      "summary": "The Problem\n\nExtracting structured data from messy text is a pain. You’re staring at a wall of clinical notes or some novel, and need actual fields—dates, names, relationships—mapped back to the original. Doing this reliably (and traceably) with LLMs is usually a hacky mess: outputs are inconsistent, source mapping is vague, and “visualization” means dumping JSON somewhere.\n\nWhat This Does\n\nlangextract is a Python library that lets you wrangle unstructured text into structured, source-grounded data using LLMs. The magic is in the way it ties each extracted entity to its exact spot in the text, so you can highlight and verify right in your browser. The README.md walks you through setting up extraction tasks with a prompt plus few-shot examples. The actual guts live in benchmarks/benchmark.py if you want to see how chunking and parallel processing work for big documents. You can plug in different models (cloud or local via Ollama) without rewriting everything. There’s a self-contained HTML visualization that shows thousands of entities in context—not some half-baked dashboard.\n\nReal-World Use\n\nSuppose you have a radiology report and need to pull out medications mentioned, mapped to their source sentences. You set up a prompt, give a few examples, and run:\n\nimport langextract as lx\n\nprompt = \"Extract all medications and their dosages from the report.\"\nexample = {\"medication\": \"Ibuprofen\", \"dosage\": \"200mg\"}\nresults = lx.extract(text, prompt, examples=[example], model=\"gemini-pro\")\nlx.visualize(results, output_file=\"medications.html\")\n\nNow you’ve got interactive highlighting in medications.html—not just a CSV dump.\n\nThe Bottom Line\n\nlangextract actually solves the traceability and schema headaches for LLM-based extraction. The source-grounding and visualization are genuinely useful; the parallel chunking is smart for big docs. Downsides: it’s overkill if you’re just scraping tweets, and LLM output is only as sane as your prompts/examples. If you care about reliability and auditability, especially on complex documents, this is worth your time.",
      "url": "https://github.com/yebeai/langextract",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "google/langextract",
        "url": "https://github.com/google/langextract",
        "stars": 33916
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 9, 2026",
      "updatedAt": "February 9, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 129,
        "directories": {
          ".github": 19,
          "(root)": 12,
          "benchmarks": 4,
          "docs": 9,
          "examples": 12,
          "langextract": 46,
          "scripts": 2,
          "tests": 25
        },
        "languages": {
          "Markdown": 14,
          "YAML": 14,
          "Shell": 4,
          "Python": 79,
          "TOML": 2
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          "Dockerfile",
          "examples/custom_provider_plugin/pyproject.toml",
          "examples/ollama/Dockerfile",
          "examples/ollama/docker-compose.yml",
          "pyproject.toml"
        ],
        "dependencies": [
          "examples/custom_provider_plugin/pyproject.toml",
          "pyproject.toml"
        ],
        "testFiles": [
          "examples/custom_provider_plugin/test_example_provider.py",
          "tests/.pylintrc",
          "tests/annotation_test.py",
          "tests/chunking_test.py",
          "tests/data_lib_test.py",
          "tests/extract_precedence_test.py",
          "tests/extract_schema_integration_test.py",
          "tests/factory_schema_test.py",
          "tests/factory_test.py",
          "tests/format_handler_test.py",
          "tests/inference_test.py",
          "tests/init_test.py",
          "tests/progress_test.py",
          "tests/prompt_validation_test.py",
          "tests/prompting_test.py",
          "tests/provider_plugin_test.py",
          "tests/provider_schema_test.py",
          "tests/registry_test.py",
          "tests/resolver_test.py",
          "tests/schema_test.py",
          "tests/test_gemini_batch_api.py",
          "tests/test_kwargs_passthrough.py",
          "tests/test_live_api.py",
          "tests/test_ollama_integration.py",
          "tests/tokenizer_test.py",
          "tests/visualization_test.py"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "docs/_static/logo.svg",
          "docs/_static/medication_entity.gif",
          "docs/_static/medication_entity_re.gif",
          "docs/_static/romeo_juliet_basic.gif",
          "docs/_static/romeo_juliet_full.gif",
          "docs/examples/batch_api_example.md",
          "docs/examples/japanese_extraction.md",
          "docs/examples/longer_text_example.md",
          "docs/examples/medication_examples.md",
          "examples/custom_provider_plugin/README.md",
          "examples/ollama/README.md",
          "langextract/_compat/README.md",
          "langextract/providers/README.md"
        ],
        "fileTypes": {
          ".md": 14,
          ".yml": 8,
          ".sh": 4,
          ".py": 79,
          ".yaml": 6,
          ".cff": 1,
          ".svg": 1,
          ".gif": 4,
          ".toml": 2,
          ".ipynb": 1,
          ".typed": 1,
          ".ini": 1
        }
      }
    },
    {
      "id": 1153977114,
      "name": "skills",
      "displayName": "skills",
      "description": "The open agent skills tool - npx skills",
      "summary": "The Open Agent Skills Tool: What Even Is This?\n\nThe Problem\n\nSo you've got your snazzy AI agent setup—maybe it's OpenAI, Claude, or some other fancy \"AI for everything\" tool. But here's the headache: building and managing skills (aka specific capabilities) for these agents is a mess. You end up hacking together scripts, duplicating code across projects, and wrestling with version control like it's 2005. What if you could just plug in skills from GitHub, GitLab, or even your local machine and have them \"just work\"? Yeah, that’s where npx skills comes in.\n\nWhat This Does\n\nAt its core, npx skills is a CLI tool for managing skills in the so-called \"open agent skills ecosystem.\" Fancy buzzwords aside, it’s a way to install, list, and manage skills for AI agents with a single command. The star here is the skills command, which you’ll find in bin/cli.mjs. This thing is the backbone of the tool, handling everything from parsing GitHub URLs (src/cli.ts) to slapping skills into the right project directories (src/add.ts).\n\nThe CLI supports a ton of source formats: GitHub shorthands like owner/repo, full URLs, GitLab links, raw git URLs, and even local paths. Want to install one skill? Cool. Want to install every skill in a repo to every agent you’re running? Sure, go nuts with --all. It’s brutally simple and surprisingly flexible. And the --list flag? Pure gold if you want to see what’s available without committing to anything.\n\nThe .github/ directory is packed with workflow automation (ci.yml, publish.yml) and issue templates for feature requests or bug reports. It’s clear this repo is designed for collaboration, even if the fork has zero stars. \n\nReal-World Use\n\nSay you’re building a chatbot with OpenAI’s API, and you want to slap in a skill for \"frontend-design\" from the vercel-labs/agent-skills repo. Here’s what you’d do:\n\nnpx skills add vercel-labs/agent-skills --skill frontend-design -a opencode\n\nDone. No manual cloning, no copy-pasting, no \"Wait, where do I put these files again?\" nonsense. If you’re running multiple agents, you can even target them individually (-a) or just YOLO it and install everything to everyone (--all).\n\nIt’s also CI/CD-friendly. Need to set up a workflow to add skills automatically? Pair the --yes flag with -g to install globally and skip all the annoying prompts.\n\nThe Bottom Line\n\nnpx skills is one of those tools that makes you wonder why it didn’t exist before. It’s not perfect (global installs aren’t always ideal, and the \"open agent skills ecosystem\" sounds like marketing fluff), but it’s a time-saver for anyone building modular AI agents. If you’re tired of duct-taping skills into your agents, give it a spin. Just don’t expect miracles—this is a pragmatic tool, not a magic wand.",
      "url": "https://github.com/yebeai/skills",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "vercel-labs/skills",
        "url": "https://github.com/vercel-labs/skills",
        "stars": 7299
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 9, 2026",
      "updatedAt": "February 9, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 67,
        "directories": {
          ".github": 8,
          "(root)": 9,
          ".husky": 1,
          "bin": 1,
          "scripts": 4,
          "skills": 1,
          "src": 31,
          "tests": 12
        },
        "languages": {
          "YAML": 8,
          "Markdown": 4,
          "JSON": 2,
          "TypeScript": 47
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "pnpm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "src/cli.ts",
          "src/providers/index.ts"
        ],
        "configFiles": [
          ".prettierrc",
          "package.json",
          "tsconfig.json"
        ],
        "dependencies": [
          "package.json"
        ],
        "testFiles": [
          "scripts/execute-tests.ts",
          "src/add-prompt.test.ts",
          "src/add.test.ts",
          "src/cli.test.ts",
          "src/init.test.ts",
          "src/list.test.ts",
          "src/remove.test.ts",
          "src/source-parser.test.ts",
          "src/test-utils.ts",
          "tests/cross-platform-paths.test.ts",
          "tests/dist.test.ts",
          "tests/full-depth-discovery.test.ts",
          "tests/installer-symlink.test.ts",
          "tests/list-installed.test.ts",
          "tests/plugin-manifest-discovery.test.ts",
          "tests/sanitize-name.test.ts",
          "tests/skill-matching.test.ts",
          "tests/skill-path.test.ts",
          "tests/source-parser.test.ts",
          "tests/wellknown-provider.test.ts",
          "tests/xdg-config-paths.test.ts"
        ],
        "docs": [
          "README.md",
          "scripts/generate-licenses.ts"
        ],
        "fileTypes": {
          ".yml": 7,
          ".md": 4,
          ".txt": 1,
          ".mjs": 2,
          ".json": 2,
          ".yaml": 1,
          ".ts": 47
        }
      }
    },
    {
      "id": 1153974469,
      "name": "MiniCPM-o",
      "displayName": "MiniCPM o",
      "description": "A Gemini 2.5 Flash Level MLLM for Vision, Speech, and Full-Duplex Multimodal Live Streaming on Your Phone",
      "summary": "The Problem\nEver tried using a voice assistant that stutters when you're streaming video? Or worse, when it stops responding mid-conversation? It's maddening. The issue lies in handling multiple streams—audio, video, and text—simultaneously without choking. Enter MiniCPM-o, which is designed to tackle this pain point head-on.\n\nWhat This Does\nMiniCPM-o is a multimodal large language model (MLLM) that can process images, text, audio, and video at the same time. It’s built on the MiniCPM framework, specifically the MiniCPM-o 4.5 model, which packs a punch with 9 billion parameters. Check out the README.md for an overview, but the real magic happens with its full-duplex streaming capabilities. \n\nTo get started, you'll find various issue templates in the .github/ISSUETEMPLATE directory, like bugreport.yaml and featurerequest.yaml, making it easy to report problems or suggest new features. Want to deploy it locally? There’s a guide in the demo/webdemo/WebRTCDemo/README.md that walks you through using Docker to set up a low-latency experience on your Mac.\n\nReal-World Use\nImagine you're at a café, engaging in a bilingual conversation while watching a live video. You can see the captions on-screen, hear the audio, and even get real-time translations—all without any hiccups. With MiniCPM-o, you could write a simple script to handle the input and output streams, like this:\n\nfrom minicpm import MiniCPM\n\nmodel = MiniCPM.load(\"MiniCPM-o-4.5\")\nresponse = model.process(inputvideo=\"path/to/video.mp4\", input_audio=\"path/to/audio.wav\")\nprint(response)\n\nThis code snippet illustrates how you can process video and audio inputs in one go. Just plug in your paths, and you're set.\n\nThe Bottom Line\nMiniCPM-o is powerful, but it’s probably overkill for simple apps. If you're building something that needs to juggle multiple media types in real-time, this is your go-to. Just be prepared for the learning curve, especially if you're new to MLLMs. For experienced developers, this is a fun playground with tons of potential.",
      "url": "https://github.com/yebeai/MiniCPM-o",
      "language": null,
      "stars": 1,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "OpenBMB/MiniCPM-o",
        "url": "https://github.com/OpenBMB/MiniCPM-o",
        "stars": 23949
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 9, 2026",
      "updatedAt": "February 9, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".github": 6,
          "(root)": 5,
          "assets": 132,
          "docs": 26,
          "eval_mm": 31
        },
        "languages": {
          "YAML": 6,
          "Markdown": 29,
          "HTML": 1,
          "Python": 26,
          "Shell": 1
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "eval_mm/vlmevalkit/setup.py"
        ],
        "configFiles": [
          "eval_mm/vlmevalkit/requirements.txt",
          "eval_mm/vlmevalkit/setup.py"
        ],
        "dependencies": [
          "eval_mm/vlmevalkit/requirements.txt"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md",
          "README_zh.md",
          "docs/MiniCPM_Llama3_V_25_technical_report.pdf",
          "docs/MiniCPM_V_4_5_Technical_Report.pdf",
          "docs/best_practice_summary.md",
          "docs/best_practice_summary_zh.md",
          "docs/compare_with_phi-3_vision.md",
          "docs/faqs.md",
          "docs/inference_on_multiple_gpus.md",
          "docs/llamafactory_train_and_infer.md",
          "docs/minicpm-llama-v-2-5_languages.md",
          "docs/minicpm_llama3_v2dot5.md",
          "docs/minicpm_o2dot6_en.md",
          "docs/minicpm_o2dot6_zh.md",
          "docs/minicpm_v1.md",
          "docs/minicpm_v2.md",
          "docs/minicpm_v2dot6.md",
          "docs/minicpm_v2dot6_en.md",
          "docs/minicpm_v2dot6_zh.md",
          "docs/minicpm_v4_en.md",
          "docs/minicpm_v4_zh.md",
          "docs/minicpm_v4dot5_en.md",
          "docs/minicpm_v4dot5_zh.md",
          "docs/omnilmm.md",
          "docs/omnilmm_en.md",
          "docs/swift_train_and_infer.md",
          "docs/wechat.md",
          "docs/xinference_infer.md",
          "eval_mm/README.md",
          "eval_mm/README_zh.md"
        ],
        "fileTypes": {
          ".yaml": 6,
          ".md": 29,
          ".png": 65,
          ".gif": 27,
          ".jpeg": 8,
          ".mp4": 6,
          ".jpg": 7,
          ".wav": 11,
          ".mp3": 1,
          ".html": 1,
          ".pdf": 4,
          ".svg": 1,
          ".webp": 1,
          ".py": 26,
          ".txt": 2,
          ".sh": 1
        }
      }
    },
    {
      "id": 1153904554,
      "name": "ComfyUI_FL-HeartMuLa",
      "displayName": "ComfyUI FL HeartMuLa",
      "description": "FL HeartMuLa - Multilingual AI music generation nodes for ComfyUI. Generate full songs with lyrics using HeartMuLa.",
      "summary": "The Problem\n\nMost AI music generators spit out generic instrumental tracks or mangle vocals so badly you’d think your headphones broke. If you want full songs—with actual lyrics, vocals, and control over genre, mood, and structure—you're out of luck. Especially if you want anything other than English.\n\nWhat This Does\n\nComfyUIFL-HeartMuLa drops a set of nodes into ComfyUI that actually spit out full songs with lyrics in five languages (English, Chinese, Japanese, Korean, Spanish). The flnodes/modelloader.py grabs and caches the HeartMuLa models for you, so no wrestling with weights. flnodes/conditioning.py turns your lyrics and tags into model input, handling those [Verse], [Chorus], etc. markers—finally, control over song sections.\n\nWant to tweak style? flnodes/tagsbuilder.py lets you pick genre, vocal type, mood, tempo, and instruments. The pipeline is modular: flnodes/sampler.py generates audio tokens (with CFG and temperature if you care), then flnodes/decode.py turns those tokens into actual waveforms using HeartCodec. There’s even a fl_nodes/transcribe.py for extracting lyrics from existing audio, which is surprisingly handy.\n\nReal-World Use\n\nLet’s say you want an energetic pop song with female vocals, in Japanese, about your cat. You toss your lyrics into the Conditioning node:\n\n[Verse]\nネコが窓辺で夢を見ている\n\n[Chorus]\n君と私、ずっと一緒\n\nAdd style tags: pop, female vocal, energetic. Connect Model Loader → Conditioning → Sampler → Decode → preview. The song structure markers actually matter—HeartMuLa pays attention, so you can force a real chorus and verse. You don’t need to fine-tune or mess with model weights. Models auto-download to ComfyUI/models/heartmula/ the first time you pick them.\n\nThe Bottom Line\n\nIf you want to crank out full songs with real lyrics and vocals—and not just generic background music—this is worth your time. The node system is modular but not bloated. VRAM requirements are hefty (12GB+), so laptop users are out of luck. Anyone building music workflows in ComfyUI and sick of half-baked instrumentals should try it.",
      "url": "https://github.com/yebeai/ComfyUI_FL-HeartMuLa",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "filliptm/ComfyUI_FL-HeartMuLa",
        "url": "https://github.com/filliptm/ComfyUI_FL-HeartMuLa",
        "stars": 116
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 9, 2026",
      "updatedAt": "February 9, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 32,
        "directories": {
          ".github": 1,
          "(root)": 5,
          "assets": 1,
          "fl_nodes": 7,
          "fl_utils": 4,
          "heartlib": 11,
          "web": 2,
          "workflow": 1
        },
        "languages": {
          "YAML": 1,
          "Markdown": 1,
          "Python": 23,
          "TOML": 1,
          "CSS": 1,
          "JavaScript": 1,
          "JSON": 1
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          "pyproject.toml",
          "requirements.txt"
        ],
        "dependencies": [
          "pyproject.toml",
          "requirements.txt"
        ],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".yml": 1,
          ".md": 1,
          ".py": 23,
          ".png": 1,
          ".toml": 1,
          ".txt": 1,
          ".css": 1,
          ".js": 1,
          ".json": 1
        }
      }
    },
    {
      "id": 1153672280,
      "name": "browser-operator-core",
      "displayName": "browser operator core",
      "description": "Browser Operator - The AI browser with built in Multi-Agent platform! Open source alternative to ChatGPT Atlas, Perplexity Comet, Dia and Microsoft CoPilot Edge Browser",
      "summary": "The Problem  \nBrowsers suck at doing more than... browsing. They’re not built for research, automation, or handling multiple tasks intelligently. You end up juggling 15 tabs, copying data between tools, and wishing your browser could just think. Sure, there are AI tools like ChatGPT Atlas and Perplexity Comet, but they’re either closed-source, tied to someone else’s server, or privacy nightmares.  \n\nWhat This Does  \nbrowser-operator-core turns your browser into an AI-powered Swiss Army knife for research, automation, and analysis. It’s open-source and runs locally, so your data stays your data. The magic happens thanks to integrations with 100+ AI models via platforms like OpenAI, LiteLLM, and OpenRouter.  \n\nThe structure is a bit intimidating at first glance (what’s with all the .gemini and .github/workflows files?), but it’s clean once you dive in. Key workflows like publish-to-npm-on-tag.yml make it clear this thing is built for continuous development. Configurable settings live in .env.example, and the .vscode folder includes helpful workspace setups for debugging and dev work. This isn’t spaghetti code—it’s built to scale.  \n\nThe standout feature? Multi-agent workflows. You can set up specialized AI agents to handle tasks like scraping data, summarizing research, or even auto-generating reports. It’s like Zapier, but for your browser, and way smarter.  \n\nReal-World Use  \nLet’s say you’re sourcing talent for a new project. You set up an agent to scour LinkedIn profiles, extract candidate data, and compile a list of potential hires into a CSV. You feed the agent some parameters: specific skills, experience levels, maybe a location filter. The AI handles the grunt work, and you get a polished output in minutes.  \n\nHere’s a simplified workflow you might use:  \n\n{\n  \"task\": \"find_candidates\",\n  \"parameters\": {\n    \"platform\": \"LinkedIn\",\n    \"keywords\": [\"React\", \"Node.js\"],\n    \"location\": \"remote\",\n    \"output\": \"candidates.csv\"\n  }\n}\n\nPair this with LiteLLM’s local models, and you’re not even sending sensitive queries to the cloud.  \n\nThe Bottom Line  \nbrowser-operator-core is ambitious and genuinely useful. It’s perfect for power users—think researchers, analysts, or anyone who’s sick of repetitive web tasks. The local-first approach is refreshing, but setup might intimidate casual users. If you’re looking for an open-source way to supercharge your browser, this is absolutely worth a look. Just don’t expect hand-holding.",
      "url": "https://github.com/yebeai/browser-operator-core",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "BrowserOperator/browser-operator-core",
        "url": "https://github.com/BrowserOperator/browser-operator-core",
        "stars": 460
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 9, 2026",
      "updatedAt": "February 9, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 31,
          ".gemini": 3,
          ".github": 6,
          ".vscode": 5,
          "agent-server": 23,
          "assets": 1,
          "build_overrides": 3,
          "config": 12,
          "docker": 7,
          "docs": 107,
          "extension-api": 2
        },
        "languages": {
          "TOML": 2,
          "YAML": 8,
          "JSON": 9,
          "Markdown": 64,
          "Python": 1,
          "JavaScript": 12,
          "TypeScript": 1
        },
        "frameworks": [
          "React",
          "Express",
          "Docker"
        ],
        "packageManager": "npm",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          ".env.example",
          "agent-server/.env.example",
          "agent-server/nodejs/.env.example",
          "agent-server/nodejs/package.json",
          "docker/Dockerfile",
          "docker/Makefile",
          "docker/docker-compose.lightweight.yml",
          "docker/docker-compose.yml"
        ],
        "dependencies": [
          "agent-server/nodejs/package-lock.json",
          "agent-server/nodejs/package.json"
        ],
        "testFiles": [
          "docs/images/debugging-e2e-tests-with-vscode.png",
          "docs/images/debugging-unit-tests-with-devtools.png",
          "docs/images/debugging-unit-tests-with-vscode.png",
          "docs/policy/images/devtools-gar-testing.png"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "agent-server/README.md",
          "agent-server/nodejs/README.md",
          "agent-server/nodejs/clients/README.md",
          "docker/README.md",
          "docs/OWNERS",
          "docs/README.md",
          "docs/architecture_of_devtools.md",
          "docs/architecture_of_devtools_lazy_loading_features.png",
          "docs/architecture_of_devtools_module_visibility_rules.png",
          "docs/checklist/README.md",
          "docs/checklist/images/checklist-application-trust-tokens.png",
          "docs/checklist/images/checklist-autocomplete-idl-attribute.png",
          "docs/checklist/images/checklist-css-properties.png",
          "docs/checklist/images/checklist-event-listener-breakpoints.png",
          "docs/checklist/images/checklist-network-trust-tokens.png",
          "docs/checklist/images/checklist-pseudo-classes.png",
          "docs/checklist/javascript.md",
          "docs/checklist/navbar.md",
          "docs/checklist/ui.md",
          "docs/checklist/webassembly.md",
          "docs/committers_policy.md",
          "docs/contributing/README.md",
          "docs/contributing/changes.md",
          "docs/contributing/design.md",
          "docs/contributing/images/design-guidelines.png",
          "docs/contributing/images/issues-nearestslo.png",
          "docs/contributing/images/issues-report-a-devtools-issue.png",
          "docs/contributing/images/issues-report-template.png",
          "docs/contributing/images/issues-slo-reports-settings.png",
          "docs/contributing/images/quickstart-gerrit-reviewers.png",
          "docs/contributing/images/quickstart-inception.png",
          "docs/contributing/images/quickstart-vscode-tsversion.png",
          "docs/contributing/infrastructure.md",
          "docs/contributing/issues.md",
          "docs/contributing/navbar.md",
          "docs/contributing/settings-experiments-features.md",
          "docs/contributing_changes.md",
          "docs/cookbook/README.md",
          "docs/cookbook/create_new_issues.md",
          "docs/cookbook/dependencies.md",
          "docs/cookbook/devtools_on_devtools.md",
          "docs/cookbook/images/devtools_on_devtools_automatic.png",
          "docs/cookbook/images/devtools_on_devtools_starter.png",
          "docs/cookbook/localization.md",
          "docs/cookbook/navbar.md",
          "docs/cookbook/release_management.md",
          "docs/cookbook/uma_metrics.md",
          "docs/dependencies.md",
          "docs/design_guidelines.md",
          "docs/devtools-protocol.md",
          "docs/ecosystem/README.md",
          "docs/ecosystem/automatic_workspace_folders.md",
          "docs/ecosystem/images/automatic_workspace_folders_flags.png",
          "docs/ecosystem/navbar.md",
          "docs/get_the_code.md",
          "docs/images/debugging-e2e-tests-with-vscode.png",
          "docs/images/debugging-unit-tests-with-devtools.png",
          "docs/images/debugging-unit-tests-with-vscode.png",
          "docs/images/gerrit-preview.png",
          "docs/l10n.md",
          "docs/language_extension_api.md",
          "docs/navbar.md",
          "docs/playbook.md",
          "docs/policy/README.md",
          "docs/policy/console-policy.md",
          "docs/policy/gar-page-zoom-policy.md",
          "docs/policy/images/console-policy1.png",
          "docs/policy/images/console-policy2.png",
          "docs/policy/images/console-policy3.png",
          "docs/policy/images/devtools-gar-testing.png",
          "docs/policy/images/docked-devtools.webp",
          "docs/policy/images/undocked-devtools.png",
          "docs/policy/slow-close.md",
          "docs/release_management.md",
          "docs/resource_management.md",
          "docs/styleguide/README.md",
          "docs/styleguide/markdown/markdown.md",
          "docs/styleguide/tsstyle/README.md",
          "docs/styleguide/ux/README.md",
          "docs/styleguide/ux/components.md",
          "docs/styleguide/ux/glossary.md",
          "docs/styleguide/ux/images/button-confirmation-dialog.png",
          "docs/styleguide/ux/images/button-icon-variations.png",
          "docs/styleguide/ux/images/button-multiple-primary.png",
          "docs/styleguide/ux/images/button-required-action.png",
          "docs/styleguide/ux/images/button-screenshot.png",
          "docs/styleguide/ux/images/button-text-variations.png",
          "docs/styleguide/ux/images/combo-box-variations.png",
          "docs/styleguide/ux/images/context-menu-example.png",
          "docs/styleguide/ux/images/glossary-labeled-bookmarks.jpg",
          "docs/styleguide/ux/images/glossary-panels.png",
          "docs/styleguide/ux/images/icon-dodonts.png",
          "docs/styleguide/ux/images/icons-header.png",
          "docs/styleguide/ux/images/outlined-buttons.png",
          "docs/styleguide/ux/images/outlined-dodonts.png",
          "docs/styleguide/ux/images/primary-buttons.png",
          "docs/styleguide/ux/images/primary-dodonts.png",
          "docs/styleguide/ux/images/radio-buttons-variations.png",
          "docs/styleguide/ux/images/sliders-variations.png",
          "docs/styleguide/ux/images/text-buttons.png",
          "docs/styleguide/ux/images/text-dodonts.png",
          "docs/styleguide/ux/images/tonal-buttons.png",
          "docs/styleguide/ux/images/tonal-dodonts.png",
          "docs/styleguide/ux/navbar.md",
          "docs/styleguide/ux/numbers.md",
          "docs/styleguide/ux/organizing.md",
          "docs/styleguide/ux/patterns.md",
          "docs/styleguide/ux/styleguide.md",
          "docs/styleguide/ux/styles.md",
          "docs/styleguide/ux/writing.md",
          "docs/ui_engineering.md"
        ],
        "fileTypes": {
          ".example": 3,
          ".toml": 2,
          ".yml": 7,
          ".yapf": 1,
          ".json": 9,
          ".gn": 3,
          ".md": 64,
          ".py": 1,
          ".yaml": 1,
          ".jsonl": 1,
          ".js": 12,
          ".png": 50,
          ".gni": 4,
          ".settings": 1,
          ".conf": 1,
          ".webp": 1,
          ".jpg": 1,
          ".mjs": 1,
          ".ts": 1
        }
      }
    },
    {
      "id": 1153514573,
      "name": "monty",
      "displayName": "monty",
      "description": "A minimal, secure Python interpreter written in Rust for use by AI",
      "summary": "The Problem\nEver tried executing Python code generated by an AI while keeping your system safe? Running untrusted code can be a nightmare—security holes, performance hits, and the dreaded container overhead. Monty solves this by providing a minimal environment for running Python code, making it quick and relatively secure without the container baggage.\n\nWhat This Does\nMonty is a Python interpreter written in Rust, specifically crafted for AI applications. It allows you to execute a subset of Python code with lightning-fast startup times—less than 1μs. You’ll find the core functionalities in crates/monty-cli/src/main.rs where the main execution logic resides.\n\nThe interpreter blocks access to the host environment, ensuring that the AI-generated code can’t wreak havoc. This is managed through function calls that you control. Want to limit memory consumption? Check out the resource tracking features that can cancel execution if limits are exceeded. The Cargo.toml file manages dependencies, while the .github/workflows/ci.yml sets up continuous integration to keep the project in check.\n\nReal-World Use\nImagine a scenario where an AI agent needs to execute code snippets on the fly—like parsing user input or generating simple reports. You can call Monty from Rust, Python, or JavaScript, making it flexible for various tech stacks. Here’s a snippet for calling Monty from Rust:\n\nuse monty::Interpreter;\n\nlet mut interpreter = Interpreter::new();\nlet result = interpreter.run(\"x = 10\\ny = x + 2\\nprint(y)\");\nprintln!(\"{}\", result); // Outputs: 12\n\nYou can collect outputs directly and control what the code can access, keeping your host environment secure.\n\nThe Bottom Line\nMonty is a solid pick if you’re looking to run AI-generated Python code without the usual overhead. The trade-off? It’s limited—no standard library except a few modules, and no third-party libraries. If you're okay with these restrictions and need a secure, fast execution environment for Python snippets, Monty might just fit the bill. Otherwise, you might be better off with a more traditional interpreter.",
      "url": "https://github.com/yebeai/monty",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "pydantic/monty",
        "url": "https://github.com/pydantic/monty",
        "stars": 5738
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 9, 2026",
      "updatedAt": "February 9, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".cargo": 1,
          ".claude": 3,
          "(root)": 13,
          ".github": 3,
          ".zed": 1,
          "crates": 179
        },
        "languages": {
          "TOML": 11,
          "JSON": 8,
          "Markdown": 11,
          "YAML": 5,
          "Rust": 87,
          "TypeScript": 13,
          "Shell": 1,
          "Python": 26
        },
        "frameworks": [
          "React",
          "Django",
          "Express"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "crates/monty-cli/src/main.rs",
          "crates/monty-js/src/lib.rs",
          "crates/monty-python/src/lib.rs",
          "crates/monty-type-checking/src/lib.rs",
          "crates/monty-type-checking/tests/main.rs",
          "crates/monty-typeshed/src/lib.rs",
          "crates/monty/benches/main.rs",
          "crates/monty/src/lib.rs"
        ],
        "configFiles": [
          "Cargo.toml",
          "Makefile",
          "crates/monty-cli/Cargo.toml",
          "crates/monty-js/Cargo.toml",
          "crates/monty-js/__test__/package.json",
          "crates/monty-js/package.json",
          "crates/monty-js/smoke-test/package.json",
          "crates/monty-js/smoke-test/tsconfig.json",
          "crates/monty-js/tsconfig.json",
          "crates/monty-python/Cargo.toml",
          "crates/monty-python/pyproject.toml",
          "crates/monty-type-checking/Cargo.toml",
          "crates/monty-typeshed/Cargo.toml",
          "crates/monty/Cargo.toml"
        ],
        "dependencies": [
          "Cargo.toml",
          "crates/monty-cli/Cargo.toml",
          "crates/monty-js/Cargo.toml",
          "crates/monty-js/__test__/package.json",
          "crates/monty-js/package-lock.json",
          "crates/monty-js/package.json",
          "crates/monty-js/smoke-test/package.json",
          "crates/monty-python/Cargo.toml",
          "crates/monty-python/pyproject.toml",
          "crates/monty-type-checking/Cargo.toml",
          "crates/monty-typeshed/Cargo.toml",
          "crates/monty/Cargo.toml"
        ],
        "testFiles": [
          "crates/monty-js/__test__/async.spec.ts",
          "crates/monty-js/__test__/basic.spec.ts",
          "crates/monty-js/__test__/exceptions.spec.ts",
          "crates/monty-js/__test__/external.spec.ts",
          "crates/monty-js/__test__/inputs.spec.ts",
          "crates/monty-js/__test__/limits.spec.ts",
          "crates/monty-js/__test__/package.json",
          "crates/monty-js/__test__/serialize.spec.ts",
          "crates/monty-js/__test__/start.spec.ts",
          "crates/monty-js/__test__/type_check.spec.ts",
          "crates/monty-js/__test__/types.spec.ts",
          "crates/monty-js/scripts/smoke-test.sh",
          "crates/monty-js/smoke-test/.gitignore",
          "crates/monty-js/smoke-test/package.json",
          "crates/monty-js/smoke-test/test.ts",
          "crates/monty-js/smoke-test/tsconfig.json",
          "crates/monty-python/tests/test_async.py",
          "crates/monty-python/tests/test_basic.py",
          "crates/monty-python/tests/test_dataclasses.py",
          "crates/monty-python/tests/test_exceptions.py",
          "crates/monty-python/tests/test_external.py",
          "crates/monty-python/tests/test_inputs.py",
          "crates/monty-python/tests/test_limits.py",
          "crates/monty-python/tests/test_os_access.py",
          "crates/monty-python/tests/test_os_access_compat.py",
          "crates/monty-python/tests/test_os_access_raw.py",
          "crates/monty-python/tests/test_os_calls.py",
          "crates/monty-python/tests/test_print.py",
          "crates/monty-python/tests/test_readme_examples.py",
          "crates/monty-python/tests/test_serialize.py",
          "crates/monty-python/tests/test_start.py",
          "crates/monty-python/tests/test_threading.py",
          "crates/monty-python/tests/test_type_check.py",
          "crates/monty-python/tests/test_types.py",
          "crates/monty-type-checking/tests/bad_types.py",
          "crates/monty-type-checking/tests/bad_types_output.txt",
          "crates/monty-type-checking/tests/good_types.py",
          "crates/monty-type-checking/tests/main.rs",
          "crates/monty-type-checking/tests/reveal_types.py",
          "crates/monty-type-checking/tests/reveal_types_output.txt"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "crates/monty-js/README.md",
          "crates/monty-python/README.md",
          "crates/monty-python/tests/test_readme_examples.py",
          "crates/monty-typeshed/README.md",
          "crates/monty-typeshed/custom/README.md",
          "crates/monty-typeshed/vendor/typeshed/stdlib/_typeshed/README.md"
        ],
        "fileTypes": {
          ".toml": 11,
          ".json": 8,
          ".md": 11,
          ".yml": 4,
          ".yaml": 1,
          ".lock": 1,
          ".rs": 87,
          ".ts": 13,
          ".sh": 1,
          ".py": 26,
          ".pyi": 24,
          ".typed": 1,
          ".txt": 3
        }
      }
    },
    {
      "id": 1153433491,
      "name": "hal-voice-assistant",
      "displayName": "hal voice assistant",
      "description": "A voice-activated AI assistant modeled after HAL 9000, built with Raspberry Pi and self-hosted services for speech-to-text, language generation, and text-to-speech.",
      "summary": "The Problem\nVoice-activated assistants are everywhere, but most rely on cloud services, which means privacy concerns and inconsistent performance. If you’re looking for a DIY solution that runs locally, giving you control over your data while channeling your inner HAL 9000, this project is for you.\n\nWhat This Does\nThe hal-voice-assistant repo provides a voice assistant using a Raspberry Pi Zero 2 W. It listens for the wake phrase “Hey HAL,” thanks to Porcupine in the models/porcupine folder. Once activated, it processes speech through a series of self-hosted services: Vosk for speech-to-text, Ollama for language generation, and Piper for text-to-speech. The brains of the operation is in app.py, where all the magic happens. \n\nYou’ll find your audio processing needs covered with requirements.txt managing dependencies. The drivers/apa102.py file handles LED controls, giving that authentic HAL vibe when your assistant is active. \n\nReal-World Use\nImagine this: you’re in the kitchen, hands full of flour, and you want to set a timer or ask for a recipe without touching your phone. Just say “Hey HAL,” and your voice assistant responds with the information you need, all while the Raspberry Pi handles everything locally. Here's a snippet to give you an idea of how the integration works in app.py:\n\ndef main():\n    while True:\n        if detectwakeword():\n            command = listen()\n            response = generate_response(command)\n            speak(response)\n\nThis loop runs indefinitely, keeping your assistant ready for action without any cloud dependency.\n\nThe Bottom Line\nThis project is a neat way to create a voice assistant while learning about hardware and software integration. If you’re comfortable with Python and want a fun DIY project, jump in. Just be aware that if you’re looking for something plug-and-play, this is overkill. For the tinkerers and hobbyists, though, it's a solid base to build your own digital companion.",
      "url": "https://github.com/yebeai/hal-voice-assistant",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "campwill/hal-voice-assistant",
        "url": "https://github.com/campwill/hal-voice-assistant",
        "stars": 50
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 9, 2026",
      "updatedAt": "February 9, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 18,
        "directories": {
          "(root)": 5,
          "assets": 10,
          "drivers": 1,
          "models": 2
        },
        "languages": {
          "Markdown": 1,
          "Python": 3
        },
        "frameworks": [
          "Flask"
        ],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "app.py"
        ],
        "configFiles": [
          "requirements.txt"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [],
        "docs": [
          "README.md",
          "models/porcupine/LICENSE.txt"
        ],
        "fileTypes": {
          ".md": 1,
          ".py": 3,
          ".jpg": 9,
          ".txt": 2,
          ".ppn": 1
        }
      }
    },
    {
      "id": 1153337154,
      "name": "natively-cluely-ai-assistant",
      "displayName": "natively cluely ai assistant",
      "description": "The Open Source Alternative to Cluely - A lightning-fast, privacy-first AI assistant that works seamlessly during meetings, interviews, and conversations without anyone knowing. Completely undetectable in video calls, screen shares, and recordings.",
      "summary": "The Problem\n\nYou’re in a meeting, interview, or live call and need instant help—summaries, context, follow-ups—without tipping anyone off that you’re using an AI. Most tools are either bulky, cloud-dependent, or straight-up violate your privacy. Screen shares and recordings make your “assistant” obvious, which is not ideal if you want to keep your edge (or just not look like a robot).\n\nWhat This Does\n\nnatively-cluely-ai-assistant is a desktop AI sidekick that stays invisible and runs locally. It hooks into your mic and screen using files like electron/audio/MicrophoneCapture.ts and electron/ScreenshotHelper.ts, grabs context, and feeds it to your chosen LLM (local via Ollama or BYOK for Gemini). Everything is handled on your machine—check out electron/LLMHelper.ts for the actual prompt/response magic, and electron/IntelligenceManager.ts for orchestration. Privacy isn’t just a checkbox; the repo literally won’t work without your own Google STT credentials (see .env.example). No telemetry, no shady uploads.\n\nThe UI is always-on-top but invisible during screen shares and recordings. That’s handled by electron/WindowHelper.ts and some clever window flagging. Global shortcuts (see electron/SettingsWindowHelper.ts) mean you can summon magic in any app—PowerPoint, Zoom, whatever.\n\nReal-World Use\n\nSay you’re in a technical interview on Zoom. You hit your shortcut, and Natively grabs your mic audio (MicrophoneCapture.ts), transcribes it locally (GoogleSTT.ts), and analyzes the question. Then it generates a succinct answer or a follow-up prompt using your local Ollama model (no cloud unless you opt-in). No one sees a floating window, no popups in your recording—just context-aware help piped straight to your clipboard or text box.\n\n// Example: Grab audio, transcribe, get reply\nconst audio = await MicrophoneCapture.start();\nconst transcript = await GoogleSTT.transcribe(audio);\nconst reply = await LLMHelper.generate(transcript, screenshotContext);\n\nThe Bottom Line\n\nIf you want privacy-first, instant AI help during calls—without exposing yourself or your data—this is what you’re looking for. Setup’s a bit annoying (Google Cloud keys, Rust for audio), but you’re trading convenience for actual privacy. Not for casual users, but if you care about local control and undetectable help, Natively delivers.",
      "url": "https://github.com/yebeai/natively-cluely-ai-assistant",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "evinjohnn/natively-cluely-ai-assistant",
        "url": "https://github.com/evinjohnn/natively-cluely-ai-assistant",
        "stars": 555
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 9, 2026",
      "updatedAt": "February 9, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 182,
        "directories": {
          "(root)": 17,
          ".vscode": 1,
          "assets": 13,
          "electron": 45,
          "native-module": 20,
          "renderer": 19,
          "src": 66,
          "worker-script": 1
        },
        "languages": {
          "JSON": 12,
          "Markdown": 2,
          "TypeScript": 55,
          "JavaScript": 5,
          "HTML": 2,
          "TOML": 2,
          "Rust": 13,
          "YAML": 1,
          "CSS": 3,
          "TSX": 36
        },
        "frameworks": [
          "React",
          "Tailwind"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "electron/llm/index.ts",
          "electron/main.ts",
          "electron/rag/index.ts",
          "index.html",
          "native-module/index.js",
          "native-module/src/lib.rs",
          "renderer/public/index.html",
          "renderer/src/App.tsx",
          "renderer/src/index.tsx",
          "src/App.tsx",
          "src/types/index.tsx",
          "worker-script/node/index.js"
        ],
        "configFiles": [
          ".env.example",
          "electron/tsconfig.json",
          "native-module/Cargo.toml",
          "native-module/package.json",
          "package.json",
          "renderer/package.json",
          "renderer/tsconfig.json",
          "tailwind.config.js",
          "tsconfig.json",
          "vite.config.mts"
        ],
        "dependencies": [
          "native-module/Cargo.toml",
          "native-module/package-lock.json",
          "native-module/package.json",
          "package-lock.json",
          "package.json",
          "renderer/package-lock.json",
          "renderer/package.json"
        ],
        "testFiles": [
          "electron/db/test-db.ts",
          "renderer/src/App.test.tsx",
          "renderer/src/setupTests.ts"
        ],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".example": 1,
          ".json": 12,
          ".md": 2,
          ".plist": 1,
          ".icns": 4,
          ".png": 34,
          ".gif": 1,
          ".ts": 55,
          ".js": 5,
          ".html": 2,
          ".toml": 2,
          ".lock": 1,
          ".rs": 13,
          ".yaml": 1,
          ".ico": 1,
          ".txt": 1,
          ".css": 3,
          ".tsx": 36,
          ".svg": 1,
          ".otf": 2,
          ".mts": 1
        }
      }
    },
    {
      "id": 1153308661,
      "name": "awesome-openclaw-usecases",
      "displayName": "awesome openclaw usecases",
      "description": "A community collection of OpenClaw use cases for making life easier.",
      "summary": "OpenClaw Use Cases: Stop Guessing, Start Building  \n\nAlright, let’s talk OpenClaw. If you’re here, you probably already know that OpenClaw (formerly ClawdBot, MoltBot—pick a name and stick to it, please) is one of those automation tools that can do everything... but figuring out what to actually do with it is the real headache.  \n\nThe repo, awesome-openclaw-usecases, is essentially a cheat sheet for real-world use cases. It’s crowdsourced, opinionated, and refreshingly light on the fluff. Instead of vague promises about \"transformative workflows\" (ugh), you get actionable examples with clear problem definitions and solutions that don’t make you want to rage-quit halfway through.  \n\nWhat’s Inside  \n\nThe repo is neatly organized into categories: Social Media, Productivity, Creative & Building, and Research & Learning. The use cases are Markdown files in the usecases/ folder, each with a structure that actually respects your time:  \nThe Problem: The pain point it solves.  \nWhat This Does: A breakdown of how it works, with references to specific files or relevant OpenClaw functions.  \nReal-World Use: Where the magic happens—actual scenarios or code snippets.  \nThe Bottom Line: Honest pros and cons. Spoiler: Some of these ideas are gold; others are meh.  \n\nExamples? Sure.  \n\nDaily Reddit Digest  \nThis one pulls highlights from your favorite subreddits and summarizes them into a customized daily email. It’s like having an intern filter Reddit for you (but less annoying). The setup is straightforward: configure subreddit preferences, schedule the digest, done. Perfect if you spend way too much time doomscrolling.  \n\nPersonal CRM  \nThis is my favorite. It scans your email and calendar to auto-build a contact database. You can query it in plain English—\"Who did I meet in August?\"—and get instant answers. The implementation is clean, but let’s be honest, if you work in sales or networking-heavy roles, this is a no-brainer. If you don’t, use it once and forget about it.  \n\nOvernight Mini-App Builder  \nThis one’s ambitious. Drop an idea into the system, and wake up to a ready-to-test micro-app. Cool, but feels like overkill unless you’re prototyping a lot. You’ll probably spend more time tweaking the output than if you just built the app yourself.  \n\nWhy This Repo Matters  \n\nOpenClaw’s biggest hurdle isn’t technical—it’s figuring out where it fits into your workflow without wasting a week tinkering with YAML files. This repo skips the BS and delivers practical ideas that actually work.  \n\nSome use cases are genuinely useful (Personal CRM, Inbox De-clutter), while others feel niche or experimental (YouTube Content Pipeline, X Account Analysis). But hey, that’s the beauty of it: pick what works for you, ignore the rest.  \n\nBottom line: If you’ve got OpenClaw installed and no clue what to do next, start here. It might just save you from a weekend of aimless Googling. Or it might make you realize OpenClaw isn’t for you—and that’s fine, too.",
      "url": "https://github.com/yebeai/awesome-openclaw-usecases",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "hesamsheikh/awesome-openclaw-usecases",
        "url": "https://github.com/hesamsheikh/awesome-openclaw-usecases",
        "stars": 11079
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 9, 2026",
      "updatedAt": "February 9, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 14,
        "directories": {
          ".github": 1,
          "(root)": 3,
          "usecases": 10
        },
        "languages": {
          "YAML": 1,
          "Markdown": 12
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".yml": 1,
          ".md": 12
        }
      }
    },
    {
      "id": 1153306528,
      "name": "tvscreener",
      "displayName": "tvscreener",
      "description": "TradingView Screener API - Stock, Crypto, Forex, Bond, Futures, Coin",
      "summary": "The Problem\nIf you’re knee-deep in trading data, you know the struggle of sifting through multiple APIs or scraping websites to get stock, crypto, or forex data. It’s tedious, error-prone, and often leads to outdated information. You want a single solution that can pull this data and serve it up neatly, but most solutions either cost an arm and a leg or simply don’t cut it.\n\nWhat This Does\nEnter the tvscreener library. This Python package acts as a middleman to fetch data from TradingView’s Screener. You can access various market types like stocks, crypto, bonds, and futures with a straightforward API. The project structure has a codegen directory that contains everything you need to build queries visually using Jupyter notebooks, specifically Generate FilterFields.ipynb and Generate.ipynb. It also generates the necessary Python code for you, so you don’t have to wrestle with constructing queries manually.\n\nYou’ll find a plethora of predefined fields in the .dev/codegen/data folder, covering everything from country.json to symbol type.json. These fields cover over 13,000 options, giving you the flexibility to refine your queries based on your unique needs.\n\nReal-World Use\nLet’s say you’re a trader looking for stocks with a price above $100 and a market cap between $1 billion and $50 billion. Here’s how you’d do it:\n\nfrom tvscreener import StockScreener, StockField\n\nss = StockScreener()\nss.where(StockField.PRICE > 100)\nss.where(StockField.MARKET_CAPITALIZATION.between(1e9, 50e9))\ndf = ss.get()\n\nThis code snippet pulls the relevant stock data into a Pandas DataFrame. You can then analyze, visualize, or export the data as needed. If you want to build queries visually, just fire up the Jupyter notebooks in the .dev/codegen folder.\n\nThe Bottom Line\ntvscreener is a solid choice for anyone dealing with trading data who wants to cut down on the manual work. It’s not perfect—some might find the learning curve steep if they’re not familiar with Python or Jupyter notebooks. Still, if you need to integrate market data into your applications efficiently, this library is worth a look. Just remember: it's unofficial, so use it at your own risk.",
      "url": "https://github.com/yebeai/tvscreener",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "deepentropy/tvscreener",
        "url": "https://github.com/deepentropy/tvscreener",
        "stars": 781
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 9, 2026",
      "updatedAt": "February 9, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 112,
        "directories": {
          ".dev": 23,
          ".github": 6,
          "(root)": 6,
          "app": 6,
          "docs": 30,
          "tests": 14,
          "tvscreener": 27
        },
        "languages": {
          "JSON": 13,
          "Python": 42,
          "YAML": 4,
          "Markdown": 25,
          "CSS": 2,
          "HTML": 1,
          "JavaScript": 3,
          "TOML": 1
        },
        "frameworks": [
          "Express"
        ],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "app/index.html",
          "app/js/app.js",
          "tvscreener/mcp/__main__.py",
          "tvscreener/mcp/server.py"
        ],
        "configFiles": [
          "pyproject.toml",
          "requirements.txt"
        ],
        "dependencies": [
          "pyproject.toml",
          "requirements.txt"
        ],
        "testFiles": [
          "tests/__init__.py",
          "tests/functional/__init__.py",
          "tests/functional/test_cryptoscreener.py",
          "tests/functional/test_forexscreener.py",
          "tests/functional/test_stockscreener.py",
          "tests/unit/__init__.py",
          "tests/unit/test_beauty.py",
          "tests/unit/test_columns.py",
          "tests/unit/test_field_conditions.py",
          "tests/unit/test_fields.py",
          "tests/unit/test_filters.py",
          "tests/unit/test_stream.py",
          "tests/unit/test_ta.py",
          "tests/unit/test_util.py"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "docs/api/enums.md",
          "docs/api/fields.md",
          "docs/api/filters.md",
          "docs/api/screeners.md",
          "docs/changelog.md",
          "docs/examples/crypto-strategies.md",
          "docs/examples/stock-screening.md",
          "docs/examples/technical-analysis.md",
          "docs/getting-started/code-generator.md",
          "docs/getting-started/installation.md",
          "docs/getting-started/quickstart.md",
          "docs/guide/filtering.md",
          "docs/guide/selecting-fields.md",
          "docs/guide/sorting-pagination.md",
          "docs/guide/streaming.md",
          "docs/guide/styled-output.md",
          "docs/guide/time-intervals.md",
          "docs/index.md",
          "docs/notebooks/01-quickstart.ipynb",
          "docs/notebooks/02-stocks.ipynb",
          "docs/notebooks/03-crypto.ipynb",
          "docs/notebooks/04-forex.ipynb",
          "docs/notebooks/05-bonds-futures.ipynb",
          "docs/screeners/bond.md",
          "docs/screeners/coin.md",
          "docs/screeners/crypto.md",
          "docs/screeners/forex.md",
          "docs/screeners/futures.md",
          "docs/screeners/stock.md",
          "docs/stylesheets/extra.css"
        ],
        "fileTypes": {
          ".ipynb": 7,
          ".generated": 7,
          ".json": 13,
          ".py": 42,
          ".png": 3,
          ".yml": 4,
          ".md": 25,
          ".css": 2,
          ".html": 1,
          ".js": 3,
          ".toml": 1,
          ".txt": 1,
          ".typed": 1
        }
      }
    },
    {
      "id": 1153304836,
      "name": "wg-easy",
      "displayName": "wg easy",
      "description": "The easiest way to run WireGuard VPN + Web-based Admin UI.",
      "summary": "The Problem\n\nSetting up WireGuard VPN is a pain. You’re stuck fiddling with config files, praying you typed the right CIDR, and then you realize you forgot to enable IP forwarding. Want a user-friendly admin UI? Good luck, because WireGuard doesn’t ship with one. Managing clients, handing out configs, and tracking connections is usually a mess—especially if you’re not a CLI junkie.\n\nWhat This Does\n\nwg-easy wraps WireGuard in a Docker container and slaps a web UI on top. You get everything in one place: VPN server, client management, QR codes for configs, stats, and even 2FA. The real magic sits in docker-compose.yml—spin it up and you’ve got a WireGuard server plus a web admin, no manual config hell required. The UI assets live in assets/screenshot.png and the docs hang out in docs/content/advanced/api.md if you want to dig deeper.\n\nNo need to touch /etc/wireguard or memorize systemd commands. Just run docker-compose up, pop open the browser, and manage clients like a sane person. It even handles “one-time links” for sharing configs securely (which, frankly, should be standard for VPN tools).\n\nReal-World Use\n\nLet’s say you want to give your friend VPN access. Fire up wg-easy with Docker Compose:\n\ndocker-compose up -d\n\nLog into the web UI, click “Add Client,” scan the QR code from your phone, and you’re done. Need to see who’s connected? The UI spits out client stats and usage charts. Want to revoke access? Click “Disable” or “Delete”—no SSH, no nano, just point and click. For nerds: you can automate stuff via the API documented in docs/content/advanced/api.md.\n\nThe Bottom Line\n\nwg-easy is what WireGuard should have shipped with. Installation is dead simple, and the web UI kills the need for manual config wrangling. If you’re running a VPN for family, work, or just want to avoid command-line headaches, use this. Downsides? If you hate Docker or need custom networking magic, you might hit a wall. Otherwise, it’s stupidly easy—and that’s a compliment.",
      "url": "https://github.com/yebeai/wg-easy",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "wg-easy/wg-easy",
        "url": "https://github.com/wg-easy/wg-easy",
        "stars": 24766
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 9, 2026",
      "updatedAt": "February 9, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 12,
          ".github": 14,
          ".vscode": 2,
          "assets": 2,
          "docs": 34,
          "scripts": 2,
          "src": 134
        },
        "languages": {
          "YAML": 16,
          "Markdown": 33,
          "JSON": 5,
          "Shell": 3,
          "Vue": 114,
          "TypeScript": 14,
          "JavaScript": 1
        },
        "frameworks": [
          "React",
          "Vue",
          "Docker"
        ],
        "packageManager": "pnpm",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "src/cli/index.ts"
        ],
        "configFiles": [
          "Dockerfile",
          "Dockerfile.dev",
          "docker-compose.dev.yml",
          "docker-compose.yml",
          "docs/.prettierrc.json",
          "docs/requirements.txt",
          "package.json",
          "src/.prettierrc.json"
        ],
        "dependencies": [
          "docs/requirements.txt",
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "CHANGELOG.md",
          "LICENSE",
          "README.md",
          "contributing.md",
          "docs/.prettierrc.json",
          "docs/content/advanced/api.md",
          "docs/content/advanced/config/amnezia.md",
          "docs/content/advanced/config/experimental-config.md",
          "docs/content/advanced/config/optional-config.md",
          "docs/content/advanced/config/unattended-setup.md",
          "docs/content/advanced/metrics/prometheus.md",
          "docs/content/advanced/migrate/from-14-to-15.md",
          "docs/content/advanced/migrate/index.md",
          "docs/content/assets/logo/favicon.png",
          "docs/content/assets/logo/logo.png",
          "docs/content/contributing/general.md",
          "docs/content/contributing/issues-and-pull-requests.md",
          "docs/content/contributing/translation.md",
          "docs/content/examples/tutorials/adguard.md",
          "docs/content/examples/tutorials/auto-updates.md",
          "docs/content/examples/tutorials/basic-installation.md",
          "docs/content/examples/tutorials/caddy.md",
          "docs/content/examples/tutorials/docker-run.md",
          "docs/content/examples/tutorials/dockerless.md",
          "docs/content/examples/tutorials/podman-nft.md",
          "docs/content/examples/tutorials/reverse-proxyless.md",
          "docs/content/examples/tutorials/routed.md",
          "docs/content/examples/tutorials/traefik.md",
          "docs/content/faq.md",
          "docs/content/getting-started.md",
          "docs/content/guides/2fa.md",
          "docs/content/guides/admin.md",
          "docs/content/guides/cli.md",
          "docs/content/guides/clients.md",
          "docs/content/guides/setup.md",
          "docs/content/index.md",
          "docs/mkdocs.yml",
          "docs/requirements.txt"
        ],
        "fileTypes": {
          ".yml": 15,
          ".md": 33,
          ".json": 5,
          ".dev": 1,
          ".png": 3,
          ".sketch": 1,
          ".txt": 1,
          ".yaml": 1,
          ".sh": 3,
          ".vue": 114,
          ".ts": 14,
          ".js": 1,
          ".mjs": 1
        }
      }
    },
    {
      "id": 1153074219,
      "name": "hestia-core",
      "displayName": "hestia core",
      "description": "A grid-based, modular dashboard built entirely from HTML, CSS, and JS with the ability to create your custom API integrations.",
      "summary": "Hestia-Core: A Zero-Backend Dashboard for Your Homelab\n\nThe Problem\n\nMost dashboards suck. Either they require a backend that you’ll spend hours babysitting, or they’re so limited in customization that you might as well just use sticky notes on your monitor. If you’re running a homelab, you probably want something lightweight, infinitely tweakable, and capable of integrating with your existing services without wrestling with CORS errors or spinning up an entire Kubernetes cluster.\n\nWhat This Does\n\nhestia-core is a modular, grid-based dashboard built with nothing but HTML, CSS, and JavaScript. No complicated backend. No bloated frameworks. Just good old vanilla code. The index.html is the heart of the project, and everything else branches off from there.\n\nThe CSS is modular and cleanly organized (css/base.css, css/layout.css, etc.), so you can tweak or rip out what you don’t like. There’s also full support for Base16 theming in css/variables.css, which is perfect if you want your dashboard to look like it’s straight out of a hacker movie.\n\nOn the JavaScript side, the js/apps/ folder is where all the magic happens. Each app (like clockApp.js or glancesApp.js) is self-contained, so you can easily add, remove, or hack them to your liking. For integrations with tools like Glances or Jellyfin, the included default.conf for Nginx handles CORS issues. No need to Google \"how to fix CORS\" for the 10th time this month.\n\nThe project uses localStorage and IndexedDB for persistence. No database to set up. No PHP to debug. Your configurations live right in your browser, and exporting/importing them is as simple as a JSON file. \n\nReal-World Use\n\nPicture this: You’ve got a homelab with a bunch of services—Glances for monitoring, Pi-hole for ad-blocking, Deluge for torrents, and Jellyfin for streaming. You want all this data in one place without juggling 20 browser tabs. Enter Hestia.\n\nPull the repo, edit default.conf to point to your local servers, and spin it up with Docker:\n\ndocker build -t hestia-core .\ndocker run -d -p 8080:80 --name hestia hestia-core\n\nGo to http://localhost:8080, drag-and-drop your widgets into place, and boom—your homelab has a sleek dashboard. Want to get fancy? Upload a custom theme, throw in some Markdown notes, or add a 3D pipes screensaver for that 90s nostalgia.\n\nThe Bottom Line\n\nhestia-core is a no-BS dashboard. It’s lightweight, customizable, and does exactly what it says on the tin. If you’re running a homelab or just want a slick DIY dashboard, it’s a solid choice. However, it’s not for everyone—if you’re not comfortable tweaking config files or customizing code, this might feel a little hands-on. For the tinkerers out there, though? It’s a goldmine.",
      "url": "https://github.com/yebeai/hestia-core",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "mult1v4c/hestia-core",
        "url": "https://github.com/mult1v4c/hestia-core",
        "stars": 650
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 8, 2026",
      "updatedAt": "February 8, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 67,
        "directories": {
          "(root)": 5,
          "assets": 2,
          "css": 7,
          "js": 53
        },
        "languages": {
          "Markdown": 1,
          "CSS": 7,
          "HTML": 1,
          "JavaScript": 53
        },
        "frameworks": [
          "Express",
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "index.html",
          "js/main.js"
        ],
        "configFiles": [
          "Dockerfile"
        ],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".md": 1,
          ".jpg": 1,
          ".gif": 1,
          ".css": 7,
          ".conf": 1,
          ".html": 1,
          ".js": 53
        }
      }
    },
    {
      "id": 1153067180,
      "name": "md-browse",
      "displayName": "md browse",
      "description": "Markdown Browser – See the web like an AI does",
      "summary": "The Problem\nNavigating the web can be a pain when you just want to read markdown content. Many pages are cluttered with ads, scripts, and other nonsense that distract from the actual information. Markdown is cleaner, easier to read, and most importantly, it’s what developers love. Enter md-browse, a browser that prioritizes markdown content over everything else.\n\nWhat This Does\nmd-browse fetches web pages with an Accept: text/markdown header to grab markdown content directly when available. If the server doesn’t play nice, it falls back on Turndown, which is a handy library located in src/shared/turndown.ts. It converts HTML to markdown, stripping out all the junk like scripts and styles. The app's structure, specifically the src/bun/index.ts file, handles the core functionality, including HTTP requests and navigation state management.\n\nYou'll find the UI in src/toolbar-svelte/, where the tab management and content display take place. Users can switch between raw markdown and a rendered preview, making it easy to see both the code and the formatted output. It’s designed for anyone who prefers a markdown-first browsing experience.\n\nReal-World Use\nImagine you’re researching a topic and land on a blog that’s a wall of text interspersed with ads and pop-ups. With md-browse, you type in the URL, and if the server sends back markdown, you get the clean content instantly. If not, Turndown kicks in, and you still get a readable version without the clutter. Here’s a quick snippet demonstrating fetching a URL:\n\nconst response = await fetch(url, { headers: { Accept: 'text/markdown' } });\nconst markdownContent = response.ok ? await response.text() : await turndown(htmlContent);\n\nThe Bottom Line\nmd-browse is a neat tool for markdown enthusiasts who can’t stand the web’s visual noise. It’s not for everyone—if you’re just browsing cat memes, you might be better off with your standard browser. But if you regularly read documentation or technical blogs, this could save you a lot of scrolling and squinting. Just keep in mind that it’s built for macOS and requires the Bun runtime, which might not be for the faint of heart.",
      "url": "https://github.com/yebeai/md-browse",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "needle-tools/md-browse",
        "url": "https://github.com/needle-tools/md-browse",
        "stars": 206
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 8, 2026",
      "updatedAt": "February 8, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 42,
        "directories": {
          "(root)": 7,
          "assets": 12,
          "scripts": 3,
          "src": 20
        },
        "languages": {
          "Markdown": 2,
          "TypeScript": 13,
          "JSON": 3,
          "Svelte": 1,
          "HTML": 1,
          "CSS": 1,
          "JavaScript": 1
        },
        "frameworks": [
          "React",
          "Svelte"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "src/bun/index.ts",
          "src/toolbar-svelte/index.html",
          "src/toolbar-svelte/main.ts"
        ],
        "configFiles": [
          "package.json",
          "src/toolbar-svelte/tsconfig.json",
          "src/toolbar-svelte/vite.config.mjs"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [
          "scripts/turndown-comparison.test.ts",
          "scripts/turndown.test.ts"
        ],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".md": 2,
          ".png": 11,
          ".svg": 2,
          ".lock": 1,
          ".ts": 13,
          ".json": 3,
          ".svelte": 1,
          ".ttf": 3,
          ".html": 1,
          ".css": 1,
          ".js": 1,
          ".mjs": 1
        }
      }
    },
    {
      "id": 1153066020,
      "name": "x-research-skill",
      "displayName": "x research skill",
      "description": "X/Twitter research skill for Claude Code and OpenClaw. Agentic search, thread following, deep-dives, sourced briefings.",
      "summary": "The Problem\n\nDigging through X/Twitter for actual signal is a nightmare. Search sucks, threads are scattered, and you waste time copy-pasting links for context. If you want sourced briefings or need to monitor accounts (for research, not stalking—hopefully), you’re either juggling APIs or praying Claude doesn’t hallucinate curl commands.\n\nWhat This Does\n\nx-research-skill turns Claude and OpenClaw into halfway decent X/Twitter research agents. The heart of it is x-search.ts, a Bun CLI that wraps the X API so you don’t have to mess with curl or raw endpoints. Need engagement-sorted results? It does that out of the box (--sort likes). Want to filter the noise? Retweets are auto-filtered, and you can nuke low-like tweets with --min-likes.\n\nThe lib/ folder handles the real work: api.ts talks to X, cache.ts saves money (and your sanity) by avoiding duplicate queries for 15 minutes, and format.ts spits out markdown or Telegram-friendly research docs. There’s also a watchlist system (data/watchlist.json and commands in the CLI) for keeping tabs on specific accounts without writing your own scripts.\n\nReal-World Use\n\nSay you want to know what X is chirping about Opus 4.6 trading, sorted by actual engagement—not just keywords. You run:\n\nbun run x-search.ts search \"Opus 4.6 trading\" --sort likes --min-likes 50 --limit 10 --markdown --save\n\nNow you get a markdown research doc (not garbage JSON), with sourced links, engagement stats, and thread context. You can also check what your watchlist accounts posted recently, or pull a full thread for context. No fiddling with curl, no API guesswork.\n\nThe Bottom Line\n\nIf you do any real research on X/Twitter, and you hate manual grunt work, this is solid. The CLI is fast, the cache saves API cost, and you actually get usable output. Downsides? X API costs are real, and the last-7-days limit is annoying. But for anyone building agent workflows or writing briefings, it beats scraping or rolling your own.",
      "url": "https://github.com/yebeai/x-research-skill",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "rohunvora/x-research-skill",
        "url": "https://github.com/rohunvora/x-research-skill",
        "stars": 860
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 8, 2026",
      "updatedAt": "February 8, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 12,
        "directories": {
          "(root)": 5,
          "data": 3,
          "lib": 3,
          "references": 1
        },
        "languages": {
          "Markdown": 4,
          "JSON": 1,
          "TypeScript": 4
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "CHANGELOG.md",
          "README.md"
        ],
        "fileTypes": {
          ".md": 4,
          ".json": 1,
          ".ts": 4
        }
      }
    },
    {
      "id": 1153061128,
      "name": "twelvedata-python",
      "displayName": "twelvedata python",
      "description": "Twelve Data Python Client - Financial data API & WebSocket",
      "summary": "Building Financial Apps with twelvedata-python\n\nThe Problem\n\nIf you've ever tried pulling financial data for stocks, crypto, or forex into your Python app, you know it's a pain. Most APIs either lock you behind convoluted pricing tiers or give you a JSON blob so raw you need a second library just to make sense of it. And if you want real-time WebSocket data? Good luck duct-taping that mess together.\n\nWhat This Does\n\nThe twelvedata-python library makes working with the Twelve Data API way less annoying. It's built around a clean TDClient object, which handles all the heavy lifting for making HTTP requests, parsing responses, and even working with WebSocket streams. \n\nDig into the src/twelvedata/ folder, and you'll find a well-structured client in client.py and some reusable context utilities in context.py. The library supports common financial data use cases: historical time series, technical indicators, company fundamentals, and even chart generation. You can output data in formats like pandas DataFrames, csv, or plain JSON—because not everyone dreams in DataFrames.\n\nThe best part? You can install it with optional dependencies. Want just basic API calls? Use pip install twelvedata. Need charting or WebSocket support? Add pandas, matplotlib, and websocket-client to the mix. No one-size-fits-all nonsense.\n\nReal-World Use\n\nLet’s say you’re building a dashboard to track Apple stock prices in real-time. First, install the package:\n\npip install twelvedata[pandas,websocket-client]\n\nThen, use the client to fetch data and set up a WebSocket listener:\n\nfrom twelvedata import TDClient\n\nInitialize the client\ntd = TDClient(apikey=\"yourapikeyhere\")\n\nFetch historical data\nts = td.timeseries(\n    symbol=\"AAPL\",\n    interval=\"1min\",\n    outputsize=10,\n).aspandas()\n\nprint(ts.head())\n\nSubscribe to real-time data\ndef onevent(event):\n    print(event)\n\ntd.websocket(symbols=\"AAPL\", onevent=onevent).listen()\n\nThis example gets you both historical data for Apple and a real-time stream of price updates. No extra JSON wrangling or reinventing the WebSocket wheel.\n\nThe Bottom Line\n\nTwelvedata-python is a solid library for anyone dealing with financial data—especially if you're already stuck using the Twelve Data API. It’s flexible, well-documented, and covers most common use cases. That said, it’s not magic. You’ll still need an API key, and if you’re working on a tiny hobby project, the free tier might not cut it. But for developers building anything from trading bots to market analytics dashboards, this is a no-brainer. Just don’t forget to read the docs—seriously.",
      "url": "https://github.com/yebeai/twelvedata-python",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "twelvedata/twelvedata-python",
        "url": "https://github.com/twelvedata/twelvedata-python",
        "stars": 650
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 8, 2026",
      "updatedAt": "February 8, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 40,
        "directories": {
          "(root)": 14,
          ".github": 5,
          "asset": 1,
          "docs": 7,
          "src": 11,
          "tests": 2
        },
        "languages": {
          "Markdown": 6,
          "YAML": 2,
          "reStructuredText": 6,
          "Python": 15,
          "TOML": 1
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "Travis CI",
        "entryPoints": [
          "setup.py"
        ],
        "configFiles": [
          "docs/Makefile",
          "pyproject.toml",
          "requirements.txt",
          "setup.cfg",
          "setup.py"
        ],
        "dependencies": [
          "Pipfile",
          "pyproject.toml",
          "requirements.txt"
        ],
        "testFiles": [
          "tests/conftest.py",
          "tests/test_client.py"
        ],
        "docs": [
          ".github/CONTRIBUTING.md",
          "CHANGELOG.rst",
          "LICENSE.txt",
          "README.md",
          "docs/Makefile",
          "docs/_static/.gitignore",
          "docs/authors.rst",
          "docs/changelog.rst",
          "docs/conf.py",
          "docs/index.rst",
          "docs/license.rst"
        ],
        "fileTypes": {
          ".md": 6,
          ".yml": 2,
          ".rst": 6,
          ".txt": 2,
          ".lock": 1,
          ".gif": 1,
          ".py": 15,
          ".toml": 1,
          ".cfg": 1
        }
      }
    },
    {
      "id": 1153059568,
      "name": "nanobot",
      "displayName": "nanobot",
      "description": "\"🐈 nanobot: The Ultra-Lightweight Clawdbot\"",
      "summary": "The Problem\nWe’ve all been there: drowning in bloated AI frameworks that promise the moon but leave your system gasping for breath. If you're looking for a personal AI assistant without the 400k lines of clutter, you’re in luck. Enter nanobot, the ultra-lightweight solution that strips away the fluff and gives you just what you need.\n\nWhat This Does\nnanobot packs a punch with about 4,000 lines of code. You can verify that by running bash coreagentlines.sh. Inside the nanobot directory, the real magic happens in files like agent/memory.py and agent/skills.py, which handle the core functionality of the agent. The bridge/src/server.ts file gives you a slick interface for integration, especially with messaging apps like WhatsApp. Want to add a new LLM provider? Just follow the two steps laid out in the README—no more convoluted setups.\n\nReal-World Use\nImagine you’re a developer needing a quick AI assistant for managing daily tasks. You clone the repo:\n\ngit clone https://github.com/HKUDS/nanobot.git\ncd nanobot\npip install -e .\n\nNext, you spin up the server using the server.ts file. You set it to run your daily schedule and even pull in market trends through its real-time analysis feature. With nanobot, you can automate your reminders, analyze data, and even write code snippets—without feeling like you’re wrestling a giant octopus of dependencies.\n\nThe Bottom Line\nnanobot is a solid choice for those who want a lightweight AI assistant that’s easy to deploy and modify. If you need a no-nonsense tool that gets the job done without unnecessary complexity, this is it. Just don’t expect it to handle every edge case under the sun—it's not a behemoth, and that’s kind of the point. Perfect for developers and researchers who want something straightforward without the weight of corporate jargon.",
      "url": "https://github.com/yebeai/nanobot",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "HKUDS/nanobot",
        "url": "https://github.com/HKUDS/nanobot",
        "stars": 26333
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 8, 2026",
      "updatedAt": "February 8, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 85,
        "directories": {
          "(root)": 11,
          "bridge": 6,
          "case": 4,
          "nanobot": 56,
          "tests": 2,
          "workspace": 6
        },
        "languages": {
          "Markdown": 16,
          "JSON": 2,
          "TypeScript": 4,
          "Shell": 4,
          "Python": 48,
          "TOML": 1
        },
        "frameworks": [
          "React",
          "Flask",
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "bridge/src/index.ts",
          "bridge/src/server.ts",
          "nanobot/__main__.py"
        ],
        "configFiles": [
          "Dockerfile",
          "bridge/package.json",
          "bridge/tsconfig.json",
          "pyproject.toml"
        ],
        "dependencies": [
          "bridge/package.json",
          "pyproject.toml"
        ],
        "testFiles": [
          "tests/test_docker.sh",
          "tests/test_tool_validation.py"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "nanobot/skills/README.md"
        ],
        "fileTypes": {
          ".md": 16,
          ".json": 2,
          ".ts": 4,
          ".gif": 4,
          ".sh": 4,
          ".py": 48,
          ".png": 2,
          ".toml": 1
        }
      }
    },
    {
      "id": 1153057758,
      "name": "chief",
      "displayName": "chief",
      "description": "Build big projects with Claude. Chief breaks your work into tasks and runs Claude Code in a loop until they're done.",
      "summary": "The Problem\n\nBuilding anything non-trivial with AI assistants usually falls apart after a few thousand tokens. Claude forgets, you hit context window limits, and your \"AI-powered\" project turns into a spaghetti mess of half-finished ideas and manual patching. You want clean commits, not AI-induced chaos.\n\nWhat Chief Does\n\nchief is a CLI tool that acts as a project manager for Claude Code. You define your big hairy project in a prd.json file under .chief/prds/, and Chief splits everything into tasks. Each loop, it runs Claude Code with a fresh context (see the \"Ralph Wiggum loop\" in the README), so you don’t blow the context window, but keeps track of task progress in files like .chief/prds/website-docs/progress.md. Git commits are made per task, giving you a history you can actually review.\n\nThe code is mostly Go—check out cmd/chief/main.go for the CLI entrypoint—and the TUI is built with Bubble Tea (see the love letter in docs/adr/0001-use-bubble-tea-for-tui.md). There’s a Makefile, a Homebrew formula, and even a VitePress-powered docs/ site if you like reading docs in dark mode.\n\nReal-World Use\n\nLet’s say you want to scaffold a docs site. You’d run:\n\nchief new\n\nDescribe your project and tasks in the prompt. Then launch the TUI:\n\nchief\n\nHit s to start. Chief will take each task, run Claude on it, and commit the results. You can track progress in .chief/prds/website-docs/progress.md and easily review each step in git log. When you need to tweak a prompt or restart, Chief doesn’t lose its mind—it just picks up where it left off.\n\nThe Bottom Line\n\nChief is for devs who want to wrangle Claude into doing actual work, not just spitting out toy scripts. Great for big refactors, scaffolding, or anything you’d break into tickets. Overkill if you just want to write a one-off script, but a lifesaver if you’re tired of AI forgetting what you asked two minutes ago. If you like tools that do one thing well (and don’t hide the sausage-making), give it a go.",
      "url": "https://github.com/yebeai/chief",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "MiniCodeMonkey/chief",
        "url": "https://github.com/MiniCodeMonkey/chief",
        "stars": 285
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 8, 2026",
      "updatedAt": "February 8, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 103,
        "directories": {
          ".chief": 3,
          ".github": 2,
          "(root)": 9,
          "Formula": 1,
          "cmd": 1,
          "docs": 37,
          "embed": 6,
          "internal": 40,
          "ralph": 4
        },
        "languages": {
          "JSON": 4,
          "Markdown": 28,
          "YAML": 3,
          "Ruby": 1,
          "Go": 42,
          "TypeScript": 2,
          "Vue": 8,
          "CSS": 1,
          "Shell": 1
        },
        "frameworks": [
          "React",
          "Vue"
        ],
        "packageManager": "go modules",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "cmd/chief/main.go",
          "docs/.vitepress/theme/index.ts",
          "internal/cmd/edit.go",
          "internal/cmd/edit_test.go",
          "internal/cmd/new.go",
          "internal/cmd/new_test.go",
          "internal/cmd/status.go",
          "internal/cmd/status_test.go"
        ],
        "configFiles": [
          "Makefile",
          "docs/package.json",
          "go.mod"
        ],
        "dependencies": [
          "docs/package-lock.json",
          "docs/package.json",
          "go.mod"
        ],
        "testFiles": [
          "CHIEF_TUI_SPEC.md",
          "embed/embed_test.go",
          "internal/cmd/edit_test.go",
          "internal/cmd/new_test.go",
          "internal/cmd/status_test.go",
          "internal/git/git_test.go",
          "internal/loop/loop_test.go",
          "internal/loop/manager_test.go",
          "internal/loop/parser_test.go",
          "internal/notify/sound_test.go",
          "internal/prd/generator_test.go",
          "internal/prd/prd_test.go",
          "internal/prd/watcher_test.go",
          "internal/tui/layout_test.go",
          "internal/tui/log_test.go",
          "internal/tui/state_test.go"
        ],
        "docs": [
          ".chief/prds/website-docs/prd.json",
          ".chief/prds/website-docs/prd.md",
          ".chief/prds/website-docs/progress.md",
          "CHANGELOG.md",
          "README.md",
          "docs/.vitepress/config.ts",
          "docs/.vitepress/theme/HomeLayout.vue",
          "docs/.vitepress/theme/components/AsciinemaPlaceholder.vue",
          "docs/.vitepress/theme/components/Features.vue",
          "docs/.vitepress/theme/components/Footer.vue",
          "docs/.vitepress/theme/components/Hero.vue",
          "docs/.vitepress/theme/components/HowItWorks.vue",
          "docs/.vitepress/theme/components/LlmActions.vue",
          "docs/.vitepress/theme/components/PlaceholderImage.vue",
          "docs/.vitepress/theme/index.ts",
          "docs/.vitepress/theme/tailwind.css",
          "docs/adr/0001-use-bubble-tea-for-tui.md",
          "docs/adr/0002-stream-json-parsing.md",
          "docs/adr/0003-parallel-prd-execution.md",
          "docs/adr/0004-embedded-prompts.md",
          "docs/adr/0005-prd-file-watching.md",
          "docs/adr/0006-audio-notifications.md",
          "docs/adr/README.md",
          "docs/concepts/chief-directory.md",
          "docs/concepts/how-it-works.md",
          "docs/concepts/prd-format.md",
          "docs/concepts/ralph-loop.md",
          "docs/guide/index.md",
          "docs/guide/installation.md",
          "docs/guide/quick-start.md",
          "docs/index.md",
          "docs/package-lock.json",
          "docs/package.json",
          "docs/public/favicon.ico",
          "docs/public/images/README.md",
          "docs/public/images/og-default.png",
          "docs/public/images/tui-screenshot.png",
          "docs/reference/cli.md",
          "docs/reference/configuration.md",
          "docs/reference/prd-schema.md",
          "docs/troubleshooting/common-issues.md",
          "docs/troubleshooting/faq.md"
        ],
        "fileTypes": {
          ".json": 4,
          ".md": 28,
          ".yml": 2,
          ".yaml": 1,
          ".rb": 1,
          ".go": 42,
          ".ts": 2,
          ".vue": 8,
          ".css": 1,
          ".ico": 1,
          ".png": 2,
          ".txt": 5,
          ".mod": 1,
          ".sum": 1,
          ".sh": 1,
          ".wav": 1
        }
      }
    },
    {
      "id": 1153051013,
      "name": "composio",
      "displayName": "composio",
      "description": "Composio equips your AI agents & LLMs with 100+ high-quality integrations via function calling",
      "summary": "The Problem\n\nAI agents are cool until you try to get them doing anything useful with real-world data or services. Then you're stuck cobbling together APIs, SDKs, and custom glue code for every integration—and maintaining it when APIs change. It's messy, repetitive, and a huge time sink. You want your agent solving problems, not wrangling APIs.\n\nWhat This Does\n\nComposio fixes that by giving your AI agents access to over 100 high-quality integrations out of the box. Think OpenAI, Google, LangChain, Cloudflare, and even niche players like HackerNews. The SDKs (Python and TypeScript) make it dead simple to set up agents with function calling and toolkits.  \n\nFor example, the @composio/core library (in the TypeScript SDK folder) provides a clean API for registering agents, fetching tools, and running workflows. The Python version (composio package) does the same for the Python crowd. If you dig into the .claude/skills/ directory, you’ll find guides for building agents with popular frameworks like Anthropic, LangChain, and OpenAI—practically a cookbook for getting started. Bonus points for the OpenAPI integration (fern/scripts/pull-openapi-spec.sh), which keeps API specs updated for building SDK docs.  \n\nReal-World Use\n\nLet’s say you want an agent that fetches the latest HackerNews posts and summarizes them. In TypeScript, you’d initialize the Composio client, fetch tools for the HACKERNEWS toolkit, and spin up an agent in a few lines:\n\nconst composio = new Composio({\n  provider: new OpenAIAgentsProvider(),\n});\n\nconst tools = await composio.tools.get(userId, { toolkits: ['HACKERNEWS'] });\n\nconst agent = new Agent({\n  name: 'Hackernews assistant',\n  tools: tools,\n});\n\nconst result = await run(agent, 'What is the latest hackernews post about?');\nconsole.log(result.finalOutput);\n\nThe Python version is just as straightforward. This is what you want AI integrations to look like. Simple, reusable, and scalable.\n\nThe Bottom Line\n\nComposio is a lifesaver if you're serious about building AI agents that interact with real-world services. It gets you up and running fast while offloading the boring API integration grind. But let’s be real—it’s probably overkill for simple toy projects. If you’re building anything production-grade, though, this is worth your time. Just don’t forget your API keys.",
      "url": "https://github.com/yebeai/composio",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "ComposioHQ/composio",
        "url": "https://github.com/ComposioHQ/composio",
        "stars": 27207
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 8, 2026",
      "updatedAt": "February 8, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 16,
          ".changeset": 2,
          ".claude": 18,
          ".github": 35,
          ".husky": 1,
          "docs": 128
        },
        "languages": {
          "Markdown": 37,
          "JSON": 7,
          "YAML": 29,
          "Shell": 1,
          "TSX": 42,
          "TypeScript": 8,
          "CSS": 1
        },
        "frameworks": [
          "React",
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "docs/components/quickstart/index.tsx"
        ],
        "configFiles": [
          ".prettierrc",
          "Dockerfile",
          "docs/.env.example"
        ],
        "dependencies": [],
        "testFiles": [
          ".claude/rules/bug-fix-testing.mdc",
          ".claude/skills/ephemeral-e2e-sdk-tests/SKILL.md",
          ".claude/skills/test-sdk-in-realworld/SKILL.md",
          ".github/workflows/cli.test-installation.yml",
          ".github/workflows/py.test.yml",
          ".github/workflows/ts.test-e2e.yml",
          ".github/workflows/ts.test.yml"
        ],
        "docs": [
          ".changeset/README.md",
          ".claude/commands/changelog.md",
          ".claude/skills/bug-fixing-guide/SKILL.md",
          ".github/workflows/docs.changelog-notification.yml",
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "docs/.claude/agents/docs-reviewer.md",
          "docs/.claude/context/api-reference.md",
          "docs/.claude/context/fumadocs.md",
          "docs/.claude/context/sdk-reference.md",
          "docs/.claude/context/twoslash.md",
          "docs/.claude/decisions/examples.md",
          "docs/.claude/decisions/feedback.md",
          "docs/.claude/decisions/toolkits.md",
          "docs/.claude/guides/changelog.md",
          "docs/.env.example",
          "docs/.gitignore",
          "docs/CLAUDE.md",
          "docs/README.md",
          "docs/app/(home)/docs/[[...slug]]/page.tsx",
          "docs/app/(home)/docs/changelog/[...slug]/page.tsx",
          "docs/app/(home)/docs/changelog/page.tsx",
          "docs/app/(home)/docs/layout.tsx",
          "docs/app/(home)/examples/[[...slug]]/page.tsx",
          "docs/app/(home)/examples/layout.tsx",
          "docs/app/(home)/layout.tsx",
          "docs/app/(home)/page.tsx",
          "docs/app/(home)/reference/[[...slug]]/page.tsx",
          "docs/app/(home)/reference/layout.tsx",
          "docs/app/(home)/toolkits/[[...slug]]/page.tsx",
          "docs/app/(home)/toolkits/layout.tsx",
          "docs/app/api/feedback/route.ts",
          "docs/app/api/proxy/route.ts",
          "docs/app/api/search/route.ts",
          "docs/app/api/tools/[slug]/route.ts",
          "docs/app/apple-icon.png",
          "docs/app/error.tsx",
          "docs/app/fonts/Flecha Font.otf",
          "docs/app/fonts/Inter Font.ttf",
          "docs/app/global-error.tsx",
          "docs/app/global.css",
          "docs/app/icon.png",
          "docs/app/layout.tsx",
          "docs/app/llms-full.txt/route.ts",
          "docs/app/llms.mdx/[[...slug]]/route.ts",
          "docs/app/llms.txt/route.ts",
          "docs/app/not-found.tsx",
          "docs/app/sitemap.ts",
          "docs/bun.lock",
          "docs/components.json",
          "docs/components/api-page.client.tsx",
          "docs/components/api-page.tsx",
          "docs/components/capability-card.tsx",
          "docs/components/copy-link.tsx",
          "docs/components/custom-schema-ui.tsx",
          "docs/components/decimal-widget.tsx",
          "docs/components/feedback.tsx",
          "docs/components/figure.tsx",
          "docs/components/nav-tabs.tsx",
          "docs/components/page-actions.tsx",
          "docs/components/posthog-provider.tsx",
          "docs/components/provider-card.tsx",
          "docs/components/quickstart/framework-selector.tsx",
          "docs/components/quickstart/index.tsx",
          "docs/components/quickstart/integration-tabs.tsx",
          "docs/components/quickstart/quickstart-flow.tsx",
          "docs/components/schema-generator.tsx",
          "docs/components/step-title.tsx",
          "docs/components/tool-type-selector.tsx",
          "docs/components/toolkits/auth-details-section.tsx",
          "docs/components/toolkits/toolkit-detail.tsx",
          "docs/components/toolkits/toolkits-landing.tsx",
          "docs/components/top-nav.tsx",
          "docs/components/ui/tabs.tsx",
          "docs/components/video.tsx",
          "docs/components/youtube.tsx",
          "docs/content/changelog/01-07-26.mdx",
          "docs/content/changelog/01-08-26-mcp-api-key-enforcement.mdx",
          "docs/content/changelog/01-09-26.mdx",
          "docs/content/changelog/01-12-26-tool-router-improvements.mdx",
          "docs/content/changelog/01-14-26-auth-config-patch-semantics.mdx",
          "docs/content/changelog/01-20-26-file-modifier-anyof-support.mdx",
          "docs/content/changelog/01-20-26-file-ttl.mdx",
          "docs/content/changelog/01-21-26-initiate-active-status-filter.mdx",
          "docs/content/changelog/01-22-26-experimental-assistive-prompts.mdx",
          "docs/content/changelog/01-29-26-sdk-major-update.mdx",
          "docs/content/changelog/01-30-26-simplified-optional-schemas.mdx",
          "docs/content/changelog/02-03-26.mdx",
          "docs/content/changelog/02-04-26-limit-prevents-important-auto-apply.mdx",
          "docs/content/changelog/02-06-26-webhook-subscriptions-api.mdx",
          "docs/content/changelog/09-15-25.mdx",
          "docs/content/changelog/09-16-25.mdx",
          "docs/content/changelog/09-26-25.mdx",
          "docs/content/changelog/10-22-25.mdx",
          "docs/content/changelog/11-05-25.mdx",
          "docs/content/changelog/11-10-25.mdx",
          "docs/content/changelog/11-13-25.mdx",
          "docs/content/changelog/12-03-25.mdx",
          "docs/content/changelog/12-09-25.mdx",
          "docs/content/changelog/12-10-25-labels-deprecation.mdx",
          "docs/content/changelog/12-10-25-masking.mdx",
          "docs/content/changelog/12-10-25.mdx",
          "docs/content/changelog/12-15-25.mdx",
          "docs/content/changelog/12-16-25.mdx",
          "docs/content/changelog/12-19-25.mdx",
          "docs/content/changelog/12-22-25.mdx",
          "docs/content/changelog/12-26-25.mdx",
          "docs/content/changelog/12-29-25.mdx",
          "docs/content/changelog/12-30-25-proxy-binary-data.mdx",
          "docs/content/changelog/12-30-25.mdx",
          "docs/content/changelog/12-31-25.mdx",
          "docs/content/docs/auth-configuration/connected-accounts.mdx",
          "docs/content/docs/auth-configuration/custom-auth-configs.mdx",
          "docs/content/docs/auth-configuration/custom-auth-params.mdx",
          "docs/content/docs/auth-configuration/meta.json",
          "docs/content/docs/auth-configuration/programmatic-auth-configs.mdx",
          "docs/content/docs/authenticating-users/in-chat-authentication.mdx",
          "docs/content/docs/authenticating-users/manually-authenticating.mdx",
          "docs/content/docs/authenticating-users/meta.json",
          "docs/content/docs/authentication.mdx",
          "docs/content/docs/cli.mdx",
          "docs/content/docs/configuring-sessions.mdx",
          "docs/content/docs/debugging-info.mdx",
          "docs/content/docs/index.mdx",
          "docs/content/docs/managing-multiple-connected-accounts.mdx",
          "docs/content/docs/meta.json",
          "docs/content/docs/migration-guide/index.mdx",
          "docs/content/docs/migration-guide/meta.json",
          "docs/content/docs/migration-guide/new-sdk.mdx",
          "docs/content/docs/migration-guide/tool-router-beta.mdx",
          "docs/content/docs/migration-guide/toolkit-versioning.mdx",
          "docs/content/docs/providers/anthropic.mdx",
          "docs/content/docs/providers/crewai.mdx",
          "docs/content/docs/providers/custom-providers/index.mdx"
        ],
        "fileTypes": {
          ".md": 37,
          ".json": 7,
          ".mdc": 1,
          ".yml": 28,
          ".sh": 1,
          ".yaml": 1,
          ".cjs": 1,
          ".example": 1,
          ".tsx": 42,
          ".ts": 8,
          ".png": 2,
          ".otf": 1,
          ".ttf": 1,
          ".css": 1,
          ".lock": 1,
          ".mdx": 54
        }
      }
    },
    {
      "id": 1152963873,
      "name": "awesome-ai-apps",
      "displayName": "awesome ai apps",
      "description": "A collection of projects showcasing RAG, agents, workflows, and other AI use cases",
      "summary": "Building Smarter Apps with awesome-ai-apps\n\nThe Problem\n\nAI is cool, but let’s face it—building anything beyond \"Hello, World\" is a pain. You’ve got a bazillion tools, libraries, and concepts like RAG (Retrieval Augmented Generation) and agents that sound fancy but leave you digging through mediocre docs and GitHub issues. If you’ve ever Googled \"AI agent tutorial\" and ended up with a 15-minute YouTube video that didn’t actually explain anything, this repo might save you.\n\nWhat This Does\n\nawesome-ai-apps is basically a buffet of AI projects, organized into categories like starteragents, memoryagents, and ragapplications. Think of it as a cookbook for AI apps: some recipes are simple, some are Michelin-star-level complicated. \n\nFor example, the advanceai_agents/ai-hedgefund folder is an actual use case—a hedge fund agent. It includes a docker-compose.yml to spin up services, config/company-mappings.json to map companies to tickers, and even sample output images (public/sample-output.png). It’s opinionated but complete enough to get you started or give you ideas for your own projects.\n\nThe .github/workflows/lint.yml file is a nice touch, ensuring your PRs stay clean. And if you’re into contributing, the CONTRIBUTING.md is one of the better ones I’ve seen, with actual guidelines instead of boilerplate fluff.\n\nReal-World Use\n\nLet’s say you want to build a \"smart\" trading bot. You could start with the ai-hedgefund example. Clone the repo, tweak the config/company-mappings.json to match your stocks, and customize the FinanceDataService.ts file in the services folder to pull your proprietary data. Then, use the docker-compose.yml to spin up your environment. Boom, you’ve got a basic prototype without needing to spend weeks piecing random libraries together.\n\n// Example from FinanceDataService.ts\nexport const getStockData = async (ticker: string): Promise<any> => {\n  const response = await fetch(https://api.example.com/stock/${ticker});\n  return response.json();\n};\n\nThis is the kind of scaffolding that saves you hours of Googling and debugging.\n\nThe Bottom Line\n\nawesome-ai-apps is a fork of a popular repo, so it has decent lineage. It’s perfect for anyone who wants to stop thinking about building AI apps and actually start doing it. That said, the \"awesome\" might be overselling it a bit—it’s not going to hold your hand, and some projects are more polished than others. If you’re a developer who knows what you’re doing and needs a jumpstart, it’s a solid resource. If you’re a total beginner, you’ll still need to Google stuff, but hey, that’s part of the job.",
      "url": "https://github.com/yebeai/awesome-ai-apps",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Arindam200/awesome-ai-apps",
        "url": "https://github.com/Arindam200/awesome-ai-apps",
        "stars": 9066
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 8, 2026",
      "updatedAt": "February 8, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".github": 8,
          "(root)": 6,
          "advance_ai_agents": 186
        },
        "languages": {
          "YAML": 11,
          "Markdown": 19,
          "JSON": 6,
          "TypeScript": 23,
          "TSX": 2,
          "Python": 60,
          "TOML": 11,
          "JavaScript": 1,
          "HTML": 2
        },
        "frameworks": [
          "React",
          "Flask",
          "Docker"
        ],
        "packageManager": "pip",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "advance_ai_agents/candidate_analyser/main.py",
          "advance_ai_agents/car_finder_agent/app.py",
          "advance_ai_agents/conference_agnositc_cfp_generator/main.py",
          "advance_ai_agents/content_team_agent/app.py",
          "advance_ai_agents/content_team_agent/main.py",
          "advance_ai_agents/deep_researcher_agent/app.py",
          "advance_ai_agents/deep_researcher_agent/server.py",
          "advance_ai_agents/finance_service_agent/app.py",
          "advance_ai_agents/job_finder_agent/app.py",
          "advance_ai_agents/meeting_assistant_agent/app.py",
          "advance_ai_agents/meeting_assistant_agent/main.py",
          "advance_ai_agents/price_monitoring_agent/app.py",
          "advance_ai_agents/smart_gtm_agent/app.py",
          "advance_ai_agents/startup_idea_validator_agent/app.py"
        ],
        "configFiles": [
          "advance_ai_agents/ai-hedgefund/Dockerfile",
          "advance_ai_agents/ai-hedgefund/docker-compose.yml",
          "advance_ai_agents/ai-hedgefund/package.json",
          "advance_ai_agents/ai-hedgefund/tsconfig.json",
          "advance_ai_agents/candidate_analyser/pyproject.toml",
          "advance_ai_agents/candidate_analyser/requirements.txt",
          "advance_ai_agents/car_finder_agent/pyproject.toml",
          "advance_ai_agents/car_finder_agent/requirements.txt",
          "advance_ai_agents/conference_agnositc_cfp_generator/.env.example",
          "advance_ai_agents/conference_agnositc_cfp_generator/docker-compose.yml",
          "advance_ai_agents/conference_agnositc_cfp_generator/pyproject.toml",
          "advance_ai_agents/conference_agnositc_cfp_generator/requirements.txt",
          "advance_ai_agents/content_team_agent/pyproject.toml",
          "advance_ai_agents/deep_researcher_agent/pyproject.toml",
          "advance_ai_agents/finance_service_agent/.env.example",
          "advance_ai_agents/finance_service_agent/Dockerfile",
          "advance_ai_agents/finance_service_agent/docker-compose.yml",
          "advance_ai_agents/finance_service_agent/pyproject.toml",
          "advance_ai_agents/finance_service_agent/requirements.txt",
          "advance_ai_agents/job_finder_agent/.env.example",
          "advance_ai_agents/job_finder_agent/pyproject.toml",
          "advance_ai_agents/job_finder_agent/requirements.txt",
          "advance_ai_agents/meeting_assistant_agent/.env.example",
          "advance_ai_agents/meeting_assistant_agent/pyproject.toml",
          "advance_ai_agents/price_monitoring_agent/pyproject.toml",
          "advance_ai_agents/smart_gtm_agent/pyproject.toml"
        ],
        "dependencies": [
          "advance_ai_agents/ai-hedgefund/package.json",
          "advance_ai_agents/candidate_analyser/pyproject.toml",
          "advance_ai_agents/candidate_analyser/requirements.txt",
          "advance_ai_agents/car_finder_agent/pyproject.toml",
          "advance_ai_agents/car_finder_agent/requirements.txt",
          "advance_ai_agents/conference_agnositc_cfp_generator/pyproject.toml",
          "advance_ai_agents/conference_agnositc_cfp_generator/requirements.txt",
          "advance_ai_agents/content_team_agent/pyproject.toml",
          "advance_ai_agents/deep_researcher_agent/pyproject.toml",
          "advance_ai_agents/finance_service_agent/pyproject.toml",
          "advance_ai_agents/finance_service_agent/requirements.txt",
          "advance_ai_agents/job_finder_agent/pyproject.toml",
          "advance_ai_agents/job_finder_agent/requirements.txt",
          "advance_ai_agents/meeting_assistant_agent/pyproject.toml",
          "advance_ai_agents/price_monitoring_agent/pyproject.toml",
          "advance_ai_agents/smart_gtm_agent/pyproject.toml"
        ],
        "testFiles": [
          "advance_ai_agents/conference_agnositc_cfp_generator/scripts/test_vector_search.py"
        ],
        "docs": [
          ".github/README_TEMPLATE.md",
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "advance_ai_agents/ai-hedgefund/README.md",
          "advance_ai_agents/candidate_analyser/README.md",
          "advance_ai_agents/car_finder_agent/README.md",
          "advance_ai_agents/conference_agnositc_cfp_generator/README.md",
          "advance_ai_agents/conference_talk_abstract_generator/README.md",
          "advance_ai_agents/content_team_agent/README.md",
          "advance_ai_agents/deep_researcher_agent/README.md",
          "advance_ai_agents/finance_service_agent/README.md",
          "advance_ai_agents/job_finder_agent/README.md",
          "advance_ai_agents/meeting_assistant_agent/README.md",
          "advance_ai_agents/price_monitoring_agent/README.md",
          "advance_ai_agents/smart_gtm_agent/README.md",
          "advance_ai_agents/startup_idea_validator_agent/README.md"
        ],
        "fileTypes": {
          ".yml": 10,
          ".md": 19,
          ".lock": 2,
          ".json": 6,
          ".example": 5,
          ".png": 28,
          ".ts": 23,
          ".tsx": 2,
          ".yaml": 1,
          ".py": 60,
          ".toml": 11,
          ".txt": 6,
          ".env": 2,
          ".gif": 7,
          ".js": 1,
          ".html": 2,
          ".db": 1
        }
      }
    },
    {
      "id": 1152918010,
      "name": "onionshare",
      "displayName": "onionshare",
      "description": "Securely and anonymously share files, host websites, and chat with friends using the Tor network",
      "summary": "The Problem\nIn a world where data privacy is a joke and sharing files can expose you to unwanted attention, OnionShare steps in to save the day. It lets you send files, host websites, and chat with friends all while keeping your identity under wraps using the Tor network. No more worrying about who’s snooping on your shared files.\n\nWhat This Does\nOnionShare is straightforward: you set it up, and it handles the heavy lifting of secure file sharing and anonymous communication. The main script, cli/onionsharecli/onionshare.py, is where the magic happens. It orchestrates everything from file transfers to creating hidden services on Tor. \n\nNeed to customize your setup? Check out cli/onionsharecli/modesettings.py for configuration options. If you want to dive deeper into the inner workings, cli/onionsharecli/censorship.py deals with bypassing restrictions—because sometimes you just can't trust your ISP.\n\nReal-World Use\nImagine you're sending sensitive documents to a colleague. Instead of using email (which is basically waving a red flag), you fire up OnionShare. Run a command like python onionshare.py /path/to/your/file, and it generates a Tor link. Your colleague opens it in their Tor browser, downloads the file, and you both breathe a sigh of relief knowing no one's eavesdropping. For chatting, resources/static/js/chat.js handles the real-time communication, making it feel like any other messaging app—but without the prying eyes.\n\nThe Bottom Line\nOnionShare is a solid tool for anyone serious about privacy. It’s not overkill if you frequently share files or need to communicate securely. However, if you're just sending the occasional meme, this might be more than you need. Overall, it’s a practical solution for those who value anonymity in their digital interactions. Just remember, you’re still responsible for what you share—Tor won’t save your hide if you’re careless.",
      "url": "https://github.com/yebeai/onionshare",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "onionshare/onionshare",
        "url": "https://github.com/onionshare/onionshare",
        "stars": 6893
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 8, 2026",
      "updatedAt": "February 8, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".github": 7,
          "(root)": 6,
          "cli": 56,
          "desktop": 131
        },
        "languages": {
          "Markdown": 8,
          "YAML": 3,
          "Shell": 1,
          "Python": 30,
          "CSS": 1,
          "JavaScript": 6,
          "HTML": 10,
          "TOML": 1,
          "JSON": 39
        },
        "frameworks": [
          "Django"
        ],
        "packageManager": "poetry",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "cli/setup.py",
          "desktop/onionshare/__main__.py"
        ],
        "configFiles": [
          "cli/pyproject.toml",
          "cli/setup.py"
        ],
        "dependencies": [
          "cli/poetry.lock",
          "cli/pyproject.toml"
        ],
        "testFiles": [
          ".github/workflows/tests.yml",
          "cli/tests/__init__.py",
          "cli/tests/conftest.py",
          "cli/tests/pytest.ini",
          "cli/tests/test_cli.py",
          "cli/tests/test_cli_common.py",
          "cli/tests/test_cli_settings.py",
          "cli/tests/test_cli_web.py",
          "cli/tests/test_range_request.py"
        ],
        "docs": [
          "CHANGELOG.md",
          "LICENSE.txt",
          "README.md",
          "cli/README.md",
          "desktop/README.md"
        ],
        "fileTypes": {
          ".md": 8,
          ".yml": 3,
          ".txt": 3,
          ".sh": 1,
          ".py": 30,
          ".css": 1,
          ".gif": 1,
          ".ico": 1,
          ".png": 88,
          ".js": 6,
          ".html": 10,
          ".lock": 1,
          ".toml": 1,
          ".ini": 1,
          ".json": 39
        }
      }
    },
    {
      "id": 1152917032,
      "name": "sheets-cli",
      "displayName": "sheets cli",
      "description": "Composable Google Sheets CLI for humans and agents. Read, write, update cells by key—with Agent Skills for Claude Code and OpenAI Codex.",
      "summary": "The Problem\n\nWrangling Google Sheets from the terminal sucks. You either hack together fragile scripts, babysit APIs, or click around the UI like a chump. Most CLI tools spit out CSVs, choke on OAuth, or assume you want to work with row indices (which break the second you add a new row). If you want to automate sheets or feed them to an AI agent, good luck.\n\nWhat This Does\n\nsheets-cli gives you a dead-simple CLI to read, write, and update Google Sheets—by key columns, not just row numbers. The src/cli.ts handles parsing arguments and maps them to the actual sheet ops in src/sheets.ts. Auth is not a disaster: src/auth.ts manages OAuth via a local redirect, so you don’t have to manually copy tokens. Everything outputs clean JSON; no weird CSV parsing.\n\nAgent integration is baked in. Drop the skill files from .claude/skills/sheets-cli.md into Claude or Codex, and AI agents can invoke the CLI directly. That means you can mention “spreadsheet” in a prompt, and the agent finds and uses sheets-cli without extra glue.\n\nReal-World Use\n\nSay you’re tracking projects and want to update the “Status” column for “Acme” to “Done”. No need to hunt for row numbers:\n\nsheets-cli update key --sheet \"Projects\" --key-col \"Name\" --key \"Acme\" --set '{\"Status\":\"Done\"}'\n\nWant to read the top 10 rows as structured JSON to feed your script or agent?\n\nsheets-cli read table --sheet \"Projects\" --limit 10\n\nOAuth is a one-liner: sheets-cli auth login --credentials ./client_secret.json opens the browser, grabs the token, done.\n\nThe Bottom Line\n\nIf you need to automate Google Sheets, especially for agent workflows, this gets out of your way and Just Works. Bun-only is a weird flex, but setup is quick. No fancy dashboards, no CSV hell—just CLI commands with sane output. Overkill for tiny scripts, but perfect if you want deterministic sheet ops or AI integration.",
      "url": "https://github.com/yebeai/sheets-cli",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "gmickel/sheets-cli",
        "url": "https://github.com/gmickel/sheets-cli",
        "stars": 45
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 8, 2026",
      "updatedAt": "February 8, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 31,
        "directories": {
          ".claude": 3,
          ".cursor": 3,
          ".github": 1,
          "(root)": 11,
          ".vscode": 1,
          "src": 12
        },
        "languages": {
          "Markdown": 7,
          "JSON": 5,
          "YAML": 2,
          "TypeScript": 12
        },
        "frameworks": [
          "React"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "src/cli.ts"
        ],
        "configFiles": [
          "package.json",
          "tsconfig.json"
        ],
        "dependencies": [
          "package.json"
        ],
        "testFiles": [
          "src/__tests__/auth.test.ts",
          "src/__tests__/cli.test.ts",
          "src/__tests__/output.test.ts",
          "src/__tests__/sheets.test.ts",
          "src/__tests__/skill-sync.test.ts",
          "src/__tests__/types.test.ts"
        ],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".md": 7,
          ".json": 5,
          ".mdc": 2,
          ".yml": 2,
          ".jsonc": 1,
          ".lock": 1,
          ".ts": 12
        }
      }
    },
    {
      "id": 1152877899,
      "name": "macrodata",
      "displayName": "macrodata",
      "description": "Give Claude Code and OpenCode persistent, self-refining memory and autonomous scheduling.",
      "summary": "Macrodata: Persistent Memory and Scheduling for Claude Code and OpenCode\n\nThe Problem\n\nAI agents are great at answering questions and coding, but they're goldfish when it comes to memory. Every session starts fresh, with zero context about who you are, what you're working on, or what you did last week. It's frustrating to repeat yourself, re-upload files, or re-explain your workflow every single time. If the agent could remember and refine its understanding of you, it would be way more useful — and way less annoying.\n\nWhat This Does\n\nmacrodata solves the memory problem with a local-first, layered architecture that tracks your identity, projects, and ongoing tasks. It stores everything in markdown and JSON files (identity.md, human.md, today.md, etc.), which are updated and referenced during each session. Need yesterday's notes or a decision you made last month? No problem — the journal system logs everything and lets you search across conversations using semantic indexing (plugins/macrodata/opencode/search.ts).\n\nThe scheduling feature is powered by a lightweight daemon (plugins/macrodata/bin/macrodata-daemon.ts) and uses cron jobs to trigger autonomous tasks. These include \"dream time\" reflections (macrodata-dreamtime/SKILL.md) and memory distillation (macrodata-distill/SKILL.md), which refine messy session data into structured knowledge files. Everything runs locally, respecting your existing security setup — no shady API calls or third-party nonsense.\n\nThe opencode/context.ts file handles context injection at the start of each session, pulling relevant state files to make the agent smarter about who you are and what you're working on. It's like giving your AI an actual brain — one that doesn't forget things every time you close the tab.\n\nReal-World Use\n\nSay you're working on a long-term project. At the start of your day, macrodata injects project context (workspace.md) and your daily priorities (today.md) into Claude Code or OpenCode. You ask for a feature idea, and the agent recalls your previous conversations about the same topic using semantic search. Overnight, dreamtime runs, analyzing patterns in your work and updating your state files with distilled insights. The next day, the agent is smarter — it remembers what worked, what didn't, and what you're trying to achieve long-term.\n\nHere's an example of the journal entry format (plugins/macrodata/opencode/journal.ts):\n\n2023-10-17\nObservations\nDebugged index-conversations.ts script. Issue was missing config parameter.\nDecisions\nUse macrodata-hook.sh to automate script deployment in the future.\n\nNow, when you hit a similar bug in two weeks, the agent can pull this entry and remind you what you did last time.\n\nThe Bottom Line\n\nIf you’re constantly annoyed by your AI’s short-term memory, macrodata is worth a look. It’s not set-and-forget — you’ll need to manage the markdown files and tweak the workflows. It’s also Linux/macOS-focused, so Windows users may struggle. But if you’re already using Claude Code or OpenCode and want your agent to feel less like a chatbot and more like an actual assistant, this is a smart solution. Just don’t expect polish — it’s experimental software, not a finished product.",
      "url": "https://github.com/yebeai/macrodata",
      "language": null,
      "stars": 1,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "ascorbic/macrodata",
        "url": "https://github.com/ascorbic/macrodata",
        "stars": 108
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 8, 2026",
      "updatedAt": "February 8, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 51,
        "directories": {
          ".changeset": 1,
          ".claude-plugin": 1,
          ".github": 2,
          "(root)": 6,
          "plans": 1,
          "plugins": 39,
          "scripts": 1
        },
        "languages": {
          "JSON": 6,
          "YAML": 3,
          "Markdown": 14,
          "Shell": 2,
          "TypeScript": 22
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "pnpm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "plugins/macrodata/opencode/index.ts",
          "plugins/macrodata/src/index.ts"
        ],
        "configFiles": [
          "package.json",
          "plugins/macrodata/package.json",
          "plugins/macrodata/tsconfig.json"
        ],
        "dependencies": [
          "package.json",
          "plugins/macrodata/package.json"
        ],
        "testFiles": [
          ".github/workflows/test.yml",
          "plugins/macrodata/test/config.test.ts",
          "plugins/macrodata/test/daemon.test.ts",
          "plugins/macrodata/test/helpers.ts",
          "plugins/macrodata/test/hook.test.ts",
          "plugins/macrodata/test/indexer.test.ts",
          "plugins/macrodata/test/reminders.test.ts"
        ],
        "docs": [
          "README.md",
          "plugins/macrodata/CHANGELOG.md",
          "plugins/macrodata/README.md"
        ],
        "fileTypes": {
          ".json": 6,
          ".yml": 2,
          ".md": 14,
          ".lock": 2,
          ".webp": 1,
          ".sh": 2,
          ".ts": 22,
          ".yaml": 1
        }
      }
    },
    {
      "id": 1152874229,
      "name": "CyberScraper-2077",
      "displayName": "CyberScraper 2077",
      "description": "A Powerful web scraper powered by LLM | OpenAI, Gemini & Ollama",
      "summary": "The Problem\nWeb scraping is a necessary evil for developers and data analysts, but traditional scrapers often get flagged by anti-bot measures. You need a tool that can pull data efficiently without raising alarms, especially when dealing with dynamic content or websites protected by CAPTCHAs. Enter CyberScraper 2077, which aims to mitigate these headaches.\n\nWhat This Does\nCyberScraper 2077 is built to scrape the web using AI models like OpenAI and Gemini. You’ll find its core functionality in src/scrapers/basescraper.py, which sets the foundation for various scraping methods. For example, the playwrightscraper.py utilizes Playwright for dynamic sites, while httpclient.py handles requests and responses, ensuring a smooth data extraction process.\n\nThe app structure includes app/streamlitwebscraperchat.py, which provides a sleek Streamlit interface for user interaction. You can easily export your scraped data in formats like JSON or CSV, thanks to the utility functions neatly tucked away in app/utils.py. Plus, with support for the Tor network and a stealth mode to bypass bot detection, you're covered on the anonymity front.\n\nReal-World Use\nImagine you’re tasked with scraping product prices from a competitor’s website. You fire up CyberScraper 2077, configure your environment with the required API keys, and run the scraper with a simple command. The main.py file orchestrates the entire process, so you don’t have to worry about the nitty-gritty. After the run, your data is exported to a CSV file with a single click, ready for analysis. If the site throws a CAPTCHA at you, just append -captcha to your URL, and let the scraper handle it.\n\nThe Bottom Line\nCyberScraper 2077 packs a punch for anyone serious about web scraping. It's feature-rich and designed to tackle modern anti-bot technologies. However, for small projects or simple tasks, it might feel like using a sledgehammer to crack a nut. If you’re scraping large datasets or need to bypass strict measures, this tool could save you a lot of headaches. Just keep in mind that setting it up requires a bit of legwork—especially if you’re not familiar with Docker or virtual environments.",
      "url": "https://github.com/yebeai/CyberScraper-2077",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "itsOwen/CyberScraper-2077",
        "url": "https://github.com/itsOwen/CyberScraper-2077",
        "stars": 2899
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 8, 2026",
      "updatedAt": "February 8, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 38,
        "directories": {
          "(root)": 11,
          ".github": 3,
          "app": 7,
          "src": 17
        },
        "languages": {
          "YAML": 1,
          "Markdown": 6,
          "Python": 22,
          "CSS": 1
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": "pip",
        "hasDocker": true,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "main.py"
        ],
        "configFiles": [
          "Dockerfile",
          "requirements.txt"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".yml": 1,
          ".md": 6,
          ".py": 22,
          ".png": 3,
          ".css": 1,
          ".txt": 1
        }
      }
    },
    {
      "id": 1152873511,
      "name": "input-overlay",
      "displayName": "input overlay",
      "description": "Show keyboard, gamepad and mouse input on stream",
      "summary": "The Problem\n\nEver watched a tutorial or a speedrun and thought, \"What the hell key did they just press?\" Yeah, me too. Viewers have no clue what’s happening on your keyboard, mouse, or gamepad unless you spell it out for them—painful for both sides. Streamers and content creators need an easy way to put their actual inputs on screen, in real time.\n\nWhat This Does\n\ninput-overlay is a plugin for OBS Studio that throws your keyboard, mouse, and gamepad inputs directly onto your stream. It’s available for Windows and Linux, and judging from the github/scripts mess, the build process is handled for you—just grab a release unless you like pain.\n\nThe config is all about flexibility. You’ll be mucking around with JSON files (see the Config creation tool), and the plugin pulls in heavy lifters like libuiohook for input capture and SDL2 for rendering, so you get low-level input tracking without rolling your own C++ horror show. The .github/actions and build scripts in scripts/ handle packaging, building, and code formatting, so if you do want to hack on it, you won’t lose your mind right away.\n\nReal-World Use\n\nLet’s say you’re streaming a rhythm game and want chat to stop accusing you of cheating. Install the plugin, drop the overlay source into OBS, and point it to your JSON config. Now, every time you bash your keyboard or flick your mouse, the audience sees it live. For bonus points, use the converter tool to migrate any old .ini configs. No more “what button was that?” in chat.\n\nThe Bottom Line\n\nIf you’re serious about streaming and want to show your inputs, input-overlay is hard to beat—unless you like duct-taping a webcam to your hands. The setup is way less annoying than rolling your own overlay, but if you’re allergic to JSON or OBS plugins, look elsewhere. For most streamers, though, it’s a no-brainer.",
      "url": "https://github.com/yebeai/input-overlay",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "univrsal/input-overlay",
        "url": "https://github.com/univrsal/input-overlay",
        "stars": 3881
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 8, 2026",
      "updatedAt": "February 8, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 9,
          ".github": 47,
          "build-aux": 12,
          "client": 13,
          "cmake": 31,
          "data": 20,
          "deps": 68
        },
        "languages": {
          "JSON": 3,
          "YAML": 12,
          "Markdown": 3,
          "Shell": 3,
          "C": 2,
          "C/C++ Header": 52,
          "C++": 7,
          "HTML": 3,
          "JavaScript": 7
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "data/overlay_render/js/main.js"
        ],
        "configFiles": [
          "CMakeLists.txt",
          "client/CMakeLists.txt",
          "deps/CMakeLists.txt"
        ],
        "dependencies": [],
        "testFiles": [
          "buildspec.json",
          "cmake/common/buildspec_common.cmake",
          "cmake/macos/buildspec.cmake",
          "cmake/windows/buildspec.cmake",
          "deps/sdl3/bin/x64/SDL3_test.lib",
          "deps/sdl3/bin/x86/SDL3_test.lib"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "client/README.md"
        ],
        "fileTypes": {
          ".json": 3,
          ".yml": 2,
          ".md": 3,
          ".yaml": 10,
          ".zsh": 3,
          ".ps1": 7,
          ".txt": 3,
          ".c": 2,
          ".h": 52,
          ".cpp": 7,
          ".hpp": 8,
          ".cmake": 24,
          ".in": 7,
          ".html": 3,
          ".ini": 9,
          ".js": 7,
          ".png": 1,
          ".dll": 2,
          ".lib": 4,
          ".pdb": 2
        }
      }
    },
    {
      "id": 1152873003,
      "name": "computer-science",
      "displayName": "computer science",
      "description": "🎓 Path to a free self-taught education in Computer Science!",
      "summary": "Free Computer Science Education: OSSU Fork Review  \n\nThe Problem  \nLearning computer science on your own is like trying to assemble IKEA furniture without the manual—possible, but painful. Most free online resources are scattered, incomplete, or just plain bad. If you want a structured, self-paced CS education that doesn’t cost a dime, you’re usually stuck cobbling together random YouTube tutorials and lecture notes. Enter OSSU: a curated, fully mapped-out curriculum that doesn’t waste your time.  \n\nWhat This Does  \nThis repo is a fork of ossu/computer-science, the OG free CS curriculum with over 200k stars. It provides a clear learning path that mimics a traditional undergrad CS degree, minus the fluff like \"Introduction to Philosophy.\" The curriculum is split into sections (Intro CS, Core CS, Advanced CS, and Final Project) and is backed by top-tier courses from places like MIT and Harvard.  \n\nFiles like CURRICULAR_GUIDELINES.md ensure the coursework aligns with ACM’s CS 2013 standards—aka, it’s legit. The coursepages folder is where you’ll find readmes guiding you through individual courses, with some projects (e.g., Project-1B-initial-xv6.md for OS concepts) to get your hands dirty. The extras/courses.md file lists other resources for those who want to go beyond the core curriculum.  \n\nThe repo also includes a ton of community-focused features: the FAQ.md answers common questions, CONTRIBUTING.md explains how to get involved, and HELP.md offers tips for when you inevitably get stuck. There’s even a delete-empty-issues.yml workflow in .github/workflows to auto-clean up spammy GitHub issues. Nice touch.  \n\nReal-World Use  \nLet’s say you’re tired of feeling like an impostor in technical meetings and want to level up. You could start with coursepages/intro-programming/README.md, which links to beginner-friendly courses like Harvard’s famous CS50. Once you’re comfortable with programming basics, you might move to coursepages/ostep/README.md for operating systems or tackle a project like Project-2A-processes-shell.md. By the end, you can complete the Final Project to showcase your skills to potential employers—or just brag to your friends.  \n\nThe Bottom Line  \nIf you’re serious about learning computer science but don’t want to fork over $50k for a degree, this repo (and its parent) is a goldmine. It’s well-organized, community-driven, and free. That said, it’s not for dabblers—the curriculum is challenging and requires real commitment. If you’re ready to put in the work, OSSU can take you from clueless beginner to someone who actually understands how a CPU scheduler works.",
      "url": "https://github.com/yebeai/computer-science",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "ossu/computer-science",
        "url": "https://github.com/ossu/computer-science",
        "stars": 201707
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 8, 2026",
      "updatedAt": "February 8, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 37,
        "directories": {
          ".github": 2,
          "(root)": 10,
          "_includes": 3,
          "_layouts": 1,
          "coursepages": 12,
          "extras": 4,
          "images": 5
        },
        "languages": {
          "Markdown": 20,
          "YAML": 2,
          "HTML": 4
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "CHANGELOG.md",
          "CONTRIBUTING.md",
          "CURRICULAR_GUIDELINES.md",
          "LICENSE",
          "README.md",
          "coursepages/intro-cs/README.md",
          "coursepages/intro-programming/README.md",
          "coursepages/ostep/README.md",
          "coursepages/spd/README.md"
        ],
        "fileTypes": {
          ".md": 20,
          ".yml": 2,
          ".html": 4,
          ".png": 4,
          ".ico": 1,
          ".svg": 1,
          ".webp": 2
        }
      }
    },
    {
      "id": 1152870275,
      "name": "verifiers",
      "displayName": "verifiers",
      "description": "Our library for RL environments + evals",
      "summary": "The Problem\nTraining and evaluating large language models (LLMs) can be a pain. You need to manage datasets, monitor performance, and create a structured environment for testing. It’s not just about throwing data at a model; without a well-defined setup, you risk a lot of wasted time and computing resources.\n\nWhat This Does\nEnter the verifiers repo, a library designed to create and manage environments for LLM reinforcement learning. Everything you need is in here: datasets, model harnesses, and reward functions. For instance, check out the .codex/environments/environment.toml file, which outlines the environment configuration. It’s straightforward and sets the stage for what your model will encounter during training.\n\nThe repo also includes various workflows located in the .github/workflows directory. Want automated testing? The test.yml file has you covered. Need to publish environments? Look at publish-envs.yml. These workflows mean you can focus on building and testing rather than worrying about deployment.\n\nReal-World Use\nImagine you’re building a new LLM capable of generating jokes (because why not?). You’ll want a specific environment to evaluate its humor. You’d start by running prime lab setup, which creates a local workspace and sets up the necessary files. Then you can modify configs/endpoints.py to connect to your model and define your evaluation criteria. Once that's in place, kick off training, and let the model learn from your dataset while you sip coffee.\n\nSet up your workspace\nprime lab setup\n\nStart training with your configured environment\nuv train --env myjokeenv\n\nThe Bottom Line\nThe verifiers library is a solid foundation for anyone serious about training LLMs. It’s well-structured, with clear workflows and configuration files that make setup a breeze. The downside? If you’re just tinkering or working on small projects, this might feel like overkill. But for serious development, especially in an academic or research context, it’s a useful toolkit that saves time and headaches.",
      "url": "https://github.com/yebeai/verifiers",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "PrimeIntellect-ai/verifiers",
        "url": "https://github.com/PrimeIntellect-ai/verifiers",
        "stars": 3866
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 8, 2026",
      "updatedAt": "February 8, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".codex": 1,
          ".cursor": 1,
          ".github": 8,
          "(root)": 8,
          "assets": 56,
          "configs": 24,
          "docs": 8,
          "environments": 94
        },
        "languages": {
          "TOML": 46,
          "Markdown": 75,
          "YAML": 11,
          "HTML": 1,
          "TypeScript": 6,
          "Shell": 10,
          "JSON": 7,
          "Python": 32
        },
        "frameworks": [
          "React",
          "Flask",
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "assets/rtd-redirect/index.html",
          "assets/templates/browserbase/cua/index.ts",
          "assets/templates/browserbase/cua/server.ts",
          "environments/openenv_echo/proj/server/app.py",
          "environments/openenv_textarena/proj/server/app.py"
        ],
        "configFiles": [
          "assets/templates/browserbase/cua/.env.example",
          "assets/templates/browserbase/cua/Dockerfile.build",
          "assets/templates/browserbase/cua/Dockerfile.runtime",
          "assets/templates/browserbase/cua/package.json",
          "assets/templates/browserbase/cua/tsconfig.json",
          "environments/alphabet_sort/pyproject.toml",
          "environments/browser_cua_example/pyproject.toml",
          "environments/browser_dom_example/pyproject.toml",
          "environments/continuation_quality/pyproject.toml",
          "environments/doublecheck/pyproject.toml",
          "environments/gem_wordle/pyproject.toml",
          "environments/gsm8k/pyproject.toml",
          "environments/math_group/pyproject.toml",
          "environments/math_python/pyproject.toml",
          "environments/mcp_search_env/pyproject.toml",
          "environments/mmmu/pyproject.toml",
          "environments/opencode_harbor/pyproject.toml",
          "environments/opencode_harbor/tasks/hello-world/environment/Dockerfile",
          "environments/openenv_echo/proj/pyproject.toml",
          "environments/openenv_echo/proj/server/Dockerfile",
          "environments/openenv_echo/pyproject.toml",
          "environments/openenv_textarena/proj/pyproject.toml",
          "environments/openenv_textarena/proj/server/Dockerfile",
          "environments/openenv_textarena/pyproject.toml",
          "environments/reasoning_gym_env/pyproject.toml",
          "environments/reverse_text/pyproject.toml",
          "environments/self_reward/pyproject.toml",
          "environments/sentence_repeater/pyproject.toml",
          "environments/terminus_harbor/pyproject.toml",
          "environments/terminus_harbor/tasks/hello-world/environment/Dockerfile"
        ],
        "dependencies": [
          "assets/templates/browserbase/cua/package.json",
          "environments/alphabet_sort/pyproject.toml",
          "environments/browser_cua_example/pyproject.toml",
          "environments/browser_dom_example/pyproject.toml",
          "environments/continuation_quality/pyproject.toml",
          "environments/doublecheck/pyproject.toml",
          "environments/gem_wordle/pyproject.toml",
          "environments/gsm8k/pyproject.toml",
          "environments/math_group/pyproject.toml",
          "environments/math_python/pyproject.toml",
          "environments/mcp_search_env/pyproject.toml",
          "environments/mmmu/pyproject.toml",
          "environments/opencode_harbor/pyproject.toml",
          "environments/openenv_echo/proj/pyproject.toml",
          "environments/openenv_echo/pyproject.toml",
          "environments/openenv_textarena/proj/pyproject.toml",
          "environments/openenv_textarena/pyproject.toml",
          "environments/reasoning_gym_env/pyproject.toml",
          "environments/reverse_text/pyproject.toml",
          "environments/self_reward/pyproject.toml",
          "environments/sentence_repeater/pyproject.toml",
          "environments/terminus_harbor/pyproject.toml"
        ],
        "testFiles": [
          ".github/workflows/test.yml",
          "environments/opencode_harbor/tasks/hello-world/tests/test.sh",
          "environments/opencode_harbor/tasks/hello-world/tests/test_state.py",
          "environments/terminus_harbor/tasks/hello-world/tests/test.sh"
        ],
        "docs": [
          ".github/workflows/README.md",
          "LICENSE",
          "README.md",
          "assets/lab/README.md",
          "assets/templates/browserbase/cua/README.md",
          "docs/development.md",
          "docs/environments.md",
          "docs/evaluation.md",
          "docs/faqs.md",
          "docs/mint.json",
          "docs/overview.md",
          "docs/reference.md",
          "docs/training.md",
          "environments/README.md",
          "environments/alphabet_sort/README.md",
          "environments/browser_cua_example/README.md",
          "environments/browser_dom_example/README.md",
          "environments/continuation_quality/README.md",
          "environments/doublecheck/README.md",
          "environments/gem_wordle/README.md",
          "environments/gsm8k/README.md",
          "environments/math_group/README.md",
          "environments/math_python/README.md",
          "environments/mcp_search_env/README.md",
          "environments/mmmu/README.md",
          "environments/opencode_harbor/README.md",
          "environments/openenv_echo/README.md",
          "environments/openenv_echo/proj/README.md",
          "environments/openenv_textarena/README.md",
          "environments/openenv_textarena/proj/README.md",
          "environments/reasoning_gym_env/README.md",
          "environments/reverse_text/README.md",
          "environments/self_reward/README.md",
          "environments/sentence_repeater/README.md",
          "environments/terminus_harbor/README.md"
        ],
        "fileTypes": {
          ".toml": 46,
          ".md": 75,
          ".yml": 6,
          ".yaml": 5,
          ".in": 1,
          ".html": 1,
          ".example": 1,
          ".build": 1,
          ".runtime": 1,
          ".ts": 6,
          ".sh": 10,
          ".json": 7,
          ".py": 32,
          ".txt": 1
        }
      }
    },
    {
      "id": 1152662479,
      "name": "GraphGen",
      "displayName": "GraphGen",
      "description": "GraphGen: Enhancing Supervised Fine-Tuning for LLMs with Knowledge-Driven Synthetic Data Generation",
      "summary": "GraphGen: Synthesizing Data to Fix LLM Blind Spots\n\nThe Problem  \nLarge Language Models (LLMs) are only as good as their training data. The problem? Real-world datasets are messy, incomplete, or just plain biased. LLMs often fail at niche knowledge or long-tail tasks—things like domain-specific QA or weird edge cases in reasoning. Sourcing and cleaning new data to patch these gaps is expensive, slow, and tedious. Enter GraphGen, which promises to generate synthetic, high-value training data with a side of knowledge graphs and style control. Neat.\n\nWhat This Does  \nGraphGen takes your raw text, builds a knowledge graph (think \"connect the dots\" for facts and relationships), and uses that graph to generate synthetic QA pairs. These aren't random trivia; they target high-value knowledge gaps in your LLM, identified through calibration error metrics. It's like handing your model a cheat sheet for the stuff it sucks at.\n\nThe repo structure is packed with features, but let me break it down. The magic starts in baselines/, where the BDS and EntiGraph modules handle baseline synthetic data generation. The assets/flow.png gives you an overview of how data flows through the pipeline. For deployment, the Dockerfile has you covered, and workflows like .github/workflows/push-to-hf.yml push your results to Hugging Face Spaces. The attention to automation is refreshing, even if the .github folder alone feels like overkill. (Do you really need six workflow configs for a repo with zero stars? I digress.)  \n\nPost-generation, you can fine-tune LLMs using tools like LLaMA-Factory or xtuner. The workflow is laid out in the README, though it assumes you're already comfortable with training pipelines.  \n\nReal-World Use  \nSay you're building a model to answer questions about botany, but your LLM keeps tripping over plant-specific terms. You'd feed your source texts into GraphGen, which builds a plant-specific knowledge graph and spits out QA pairs like:  \nQ: What are the optimal growing conditions for a Venus flytrap?  \nA: High humidity, bright indirect light, and nutrient-poor soil.  \n\nYou'd then take this synthetic data and mix it into your existing training set. Fine-tune your model, and boom—your LLM just graduated from \"plant clueless\" to \"botany nerd.\"\n\nThe Bottom Line  \nGraphGen is smart: it doesn’t just make more data—it makes targeted data. If you’re running serious fine-tuning for domain-specific LLMs, you’ll want to give this a try. That said, the setup assumes you’ve got some ML chops and a decent compute budget. For hobbyists or small projects, it’s overkill. For researchers and enterprise teams? This could be your secret weapon.",
      "url": "https://github.com/yebeai/GraphGen",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "InternScience/GraphGen",
        "url": "https://github.com/InternScience/GraphGen",
        "stars": 941
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 8, 2026",
      "updatedAt": "February 8, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 11,
          ".github": 13,
          "assets": 2,
          "baselines": 19,
          "examples": 86,
          "graphgen": 69
        },
        "languages": {
          "Markdown": 27,
          "YAML": 30,
          "Python": 82,
          "Shell": 28,
          "JSON": 6
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          ".env.example",
          "Dockerfile"
        ],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          ".github/contributing.md",
          "LICENSE",
          "README.md",
          "README_zh.md",
          "baselines/BDS/README.md",
          "baselines/EntiGraph/README.md",
          "baselines/Genie/README.md",
          "baselines/LongForm/README.md",
          "baselines/SELF-QA/README.md",
          "baselines/Wrap/README.md",
          "examples/extract/extract_schema_guided/README.md",
          "examples/extract/extract_schema_guided/extract_schema_guided.sh",
          "examples/extract/extract_schema_guided/schema_guided_extraction_config.yaml",
          "examples/generate/generate_aggregated_qa/README.md",
          "examples/generate/generate_atomic_qa/README.md",
          "examples/generate/generate_cot_qa/README.md",
          "examples/generate/generate_fill_in_blank_qa/README.md",
          "examples/generate/generate_multi_answer_qa/README.md",
          "examples/generate/generate_multi_choice_qa/README.md",
          "examples/generate/generate_multi_hop_qa/README.md",
          "examples/generate/generate_true_false_qa/README.md",
          "examples/generate/generate_vqa/README.md",
          "examples/output_examples/README.md",
          "examples/rephrase/rephrase_style_controlled/README.md",
          "examples/search/search_dna/README.md",
          "examples/search/search_protein/README.md",
          "examples/search/search_rna/README.md",
          "graphgen/models/extractor/schema_guided_extractor.py"
        ],
        "fileTypes": {
          ".example": 1,
          ".md": 27,
          ".yml": 10,
          ".yaml": 20,
          ".cff": 1,
          ".in": 1,
          ".png": 2,
          ".py": 82,
          ".sh": 28,
          ".csv": 1,
          ".txt": 2,
          ".graphml": 1,
          ".jpg": 6,
          ".json": 6,
          ".jsonl": 7,
          ".pdf": 1
        }
      }
    },
    {
      "id": 1152653913,
      "name": "core",
      "displayName": "core",
      "description": "Build your digital brain which can talk to your AI apps.",
      "summary": "The Problem\nAI apps often forget context. Every chat feels like a reset, requiring you to re-explain your preferences or insights. You’ve got critical information scattered across different tools, and they don’t communicate. It’s frustrating—and it’s a productivity killer.\n\nWhat This Does\nEnter CORE, your digital memory agent. It doesn’t just store data; it mimics human memory. The system organizes information into topics and associations, making it easier for you to retrieve what you need when you need it. Check out the file structure: the apps/webapp/app/bullmq/queues/index.ts manages job queues to handle memory requests, while apps/webapp/app/bullmq/start-workers.ts kicks off background processes to keep everything running smoothly. \n\nWant to integrate this into your workflow? The .github/workflows/build-docker-image.yml automates the Docker builds, so you can focus on building your app rather than worrying about deployment. \n\nReal-World Use\nImagine you’re working on a project and need to recall a past decision that shaped your current approach. With CORE, you’d simply query the memory agent rather than scrolling through endless chat logs. For example, you could call a function like retrieveMemory(topic) to fetch relevant insights, allowing you to make informed decisions without the guesswork.\n\nThe Bottom Line\nCORE is ambitious—maybe too ambitious for small projects. If you're drowning in context-switching and need a way to retain crucial insights across various AI applications, give it a shot. Just be prepared to invest some time in setup and integration. For developers who manage complex workflows, this could be a lifesaver; for solo devs or small teams, it might feel like overkill.",
      "url": "https://github.com/yebeai/core",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "RedPlanetHQ/core",
        "url": "https://github.com/RedPlanetHQ/core",
        "stars": 1375
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 8, 2026",
      "updatedAt": "February 8, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".claude-plugin": 1,
          ".configs": 1,
          "(root)": 8,
          ".github": 4,
          "apps": 186
        },
        "languages": {
          "JSON": 2,
          "YAML": 3,
          "Markdown": 4,
          "TypeScript": 30,
          "TSX": 149
        },
        "frameworks": [
          "React"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "apps/webapp/app/bullmq/queues/index.ts",
          "apps/webapp/app/bullmq/workers/index.ts",
          "apps/webapp/app/components/api/index.ts",
          "apps/webapp/app/components/conversation/index.ts",
          "apps/webapp/app/components/editor/skill-extension/index.ts",
          "apps/webapp/app/components/icon-picker/index.ts",
          "apps/webapp/app/components/icons/index.ts",
          "apps/webapp/app/components/logo/index.ts",
          "apps/webapp/app/components/logs/index.ts",
          "apps/webapp/app/components/onboarding/index.ts",
          "apps/webapp/app/components/ui/index.ts",
          "apps/webapp/app/components/virtualized-list/index.ts"
        ],
        "configFiles": [
          ".env.example",
          "apps/webapp/.eslintrc",
          "apps/webapp/.prettierrc"
        ],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md",
          "apps/webapp/README.md"
        ],
        "fileTypes": {
          ".json": 2,
          ".example": 1,
          ".yml": 3,
          ".md": 4,
          ".ts": 30,
          ".tsx": 149,
          ".svg": 1
        }
      }
    },
    {
      "id": 1152652352,
      "name": "VoxCPM",
      "displayName": "VoxCPM",
      "description": "VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning",
      "summary": "The Problem\n\nToken-based TTS models are stuck in their own little world—chopping up speech into discrete bits, losing all the nuance that makes a voice actually sound human. If you’ve ever tried to clone a voice and ended up with a robotic monotone or weird prosody, you know the pain. Context gets ignored, and \"zero-shot\" voice cloning is more like \"zero-personality\".\n\nWhat This Does\n\nVoxCPM ditches tokenization entirely and goes full end-to-end, generating continuous speech representations straight from text. The guts of it live in src/voxcpm/core.py and the model subfolder, where diffusion autoregressive modeling and a MiniCPM-4 backbone do the heavy lifting. Configuration is handled by YAML files in conf/voxcpmv1.5/ and conf/voxcpmv1/, letting you tweak fine-tuning setups (full-param or LoRA). Training, inference, and testing scripts are parked in scripts/, so you’re not left guessing how to run anything.\n\nVoice cloning is actually usable: throw in a short reference audio (see examples/example.wav), and it spits out speech that nails timbre, accent, emotion, and pacing. No more generic, flat outputs. And yes, it’s fast—RTF hovers around 0.15 on a 4090, so real-time apps aren’t a pipe dream.\n\nReal-World Use\n\nSay you want to clone your CEO’s voice for an internal chatbot (for better or worse). Grab the latest weights, chuck a sample audio into examples/, and use scripts/testvoxcpmlorainfer.py to run inference. Here’s a quick workflow:\n\nInference from CLI\n!voxcpm-cli --inputtext \"Quarterly profits are up!\" --referenceaudio examples/example.wav --output output.wav\n\nNeed more control? Edit conf/voxcpmv1.5/voxcpmfinetunelora.yaml for LoRA fine-tuning, then run scripts/trainvoxcpmfinetune.py with your own dataset (see examples/traindataexample.jsonl for format).\n\nThe Bottom Line\n\nVoxCPM finally makes TTS sound less like a robot reading Wikipedia. If you need context-aware, realistic voice cloning, and don’t mind fiddling with configs and scripts, this is worth your time. Overkill for tiny projects or simple IVRs, but if you care about vocal nuance—and have a GPU—it’s legit.",
      "url": "https://github.com/yebeai/VoxCPM",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "OpenBMB/VoxCPM",
        "url": "https://github.com/OpenBMB/VoxCPM",
        "stars": 5951
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 8, 2026",
      "updatedAt": "February 8, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 55,
        "directories": {
          ".github": 1,
          "(root)": 6,
          "assets": 5,
          "conf": 4,
          "docs": 4,
          "examples": 2,
          "scripts": 3,
          "src": 30
        },
        "languages": {
          "YAML": 5,
          "Markdown": 5,
          "Python": 35,
          "TOML": 1
        },
        "frameworks": [
          "Flask"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "app.py",
          "src/voxcpm/cli.py"
        ],
        "configFiles": [
          "pyproject.toml"
        ],
        "dependencies": [
          "pyproject.toml"
        ],
        "testFiles": [
          "scripts/test_voxcpm_ft_infer.py",
          "scripts/test_voxcpm_lora_infer.py"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "docs/finetune.md",
          "docs/performance.md",
          "docs/release_note.md",
          "docs/usage_guide.md"
        ],
        "fileTypes": {
          ".yml": 1,
          ".md": 5,
          ".py": 35,
          ".png": 5,
          ".yaml": 4,
          ".wav": 1,
          ".jsonl": 1,
          ".toml": 1
        }
      }
    },
    {
      "id": 1152645089,
      "name": "mlx-audio-swift",
      "displayName": "mlx audio swift",
      "description": "No description available",
      "summary": "MLX Audio Swift: Audio Processing with Apple Silicon and Swift\n\nThe Problem\n\nAudio processing with modern machine learning models is a mess on Apple platforms. Between clunky APIs, bloated frameworks, and the headache of integrating HuggingFace models, developers often waste hours just getting a basic TTS or STT workflow up and running. And if you’re targeting macOS or iOS, good luck finding something optimized for Apple Silicon.\n\nWhat This Does\n\nmlx-audio-swift is a modular Swift SDK for working with audio models on Apple platforms. It’s broken into logical modules like MLXAudioTTS (Text-to-Speech) and MLXAudioSTT (Speech-to-Text), so you only import what you actually need. For instance, the Sources/MLXAudioCodecs/DACVAE/DACVAE.swift file houses a VAE-based audio codec implementation, while the Examples/VoicesApp/Views directory contains pre-built SwiftUI components for building apps like a voice manager.\n\nThe repo also includes a working demo app under Examples/VoicesApp, which is basically a playground for managing voices and testing out TTS. It's got everything from TTSViewModel.swift for business logic to VoiceCollectionCard.swift for UI components. The modularity here is no joke—add models directly from HuggingFace using something like SopranoModel.fromPretrained() and you're good to go.\n\nReal-World Use\n\nLet’s say you’re building a macOS app that generates custom voiceovers. Using MLXAudioTTS, you can pull a model from HuggingFace, generate audio, and save it locally in just a few lines:\n\nlet model = try await SopranoModel.fromPretrained(\"mlx-community/Soprano-80M-bf16\")\nlet audio = try await model.generate(text: \"Hello from MLX Audio Swift!\")\ntry saveAudioArray(audio, sampleRate: Double(model.sampleRate), to: outputURL)\n\nWant to transcribe audio instead? Import MLXAudioSTT, load your audio file with loadAudioArray, and let the GLMASRModel do its thing. You can even stream generation if you’re working on a real-time TTS/chat app.\n\nThe Bottom Line\n\nmlx-audio-swift is a sharp tool, but like all sharp tools, it’s not for everyone. If you're building a quick-and-dirty app or don’t care about Apple Silicon performance, this might be overkill. But if you’re in the business of high-quality, ML-powered audio on macOS or iOS, this is worth a serious look. Just be ready to dig into the docs—this is a library for developers, not a plug-and-play solution.",
      "url": "https://github.com/yebeai/mlx-audio-swift",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Blaizzy/mlx-audio-swift",
        "url": "https://github.com/Blaizzy/mlx-audio-swift",
        "stars": 383
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 8, 2026",
      "updatedAt": "February 8, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 97,
        "directories": {
          ".github": 1,
          "(root)": 5,
          "Examples": 22,
          "Sources": 64,
          "Tests": 5
        },
        "languages": {
          "YAML": 1,
          "Swift": 77,
          "Markdown": 3
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [
          ".github/workflows/tests.yaml",
          "Tests/MLXAudioCodecsTests.swift",
          "Tests/MLXAudioSTTTests.swift",
          "Tests/MLXAudioTTSTests.swift",
          "Tests/media/conversational_a.wav",
          "Tests/media/intention.wav"
        ],
        "docs": [
          "Examples/VoicesApp/README.md",
          "LICENSE",
          "README.md",
          "Sources/MLXAudioTTS/Models/PocketTTS/README.md"
        ],
        "fileTypes": {
          ".yaml": 1,
          ".xcconfig": 3,
          ".template": 1,
          ".swift": 77,
          ".md": 3,
          ".pbxproj": 1,
          ".xcworkspacedata": 1,
          ".resolved": 2,
          ".xcuserstate": 1,
          ".xcbkptlist": 1,
          ".plist": 2,
          ".wav": 2
        }
      }
    },
    {
      "id": 1152043556,
      "name": "VisionClaw",
      "displayName": "VisionClaw",
      "description": "Real-time AI assistant for Meta Ray-Ban smart glasses -- voice + vision + agentic actions via Gemini Live and OpenClaw",
      "summary": "The Problem\n\nVoice assistants suck at context. Siri or Alexa can't see what you're looking at, can't handle your shopping list, and definitely can't send a WhatsApp message while you're walking around. If you've ever wished your smart glasses could actually act smart, VisionClaw is the fix.\n\nWhat This Does\n\nVisionClaw wires Meta Ray-Ban smart glasses to real-time AI via the Gemini Live API. The samples/CameraAccess/CameraAccess.xcodeproj is the iOS app—think camera stream + mic audio piped straight to Gemini, so the assistant knows what you see and hear. If you want actual actions (not just talking), plug in OpenClaw. That’s a local gateway (openclaw.json config) that exposes 56+ tools: messaging, web search, smart home, reminders.\n\nSetup is dead simple: clone, drop your Gemini API key into GeminiConfig.swift, and run. Want to test? Use your iPhone camera instead (no glasses needed). The pipeline is all here—audio, video, WebSocket to Gemini, and optional tool calls routed through OpenClaw.\n\nReal-World Use\n\nSay you’re in the kitchen, wearing your Ray-Bans. You tap the AI button and mumble, “Add milk to my shopping list.” The camera snaps a frame, the mic grabs your voice, everything zips to Gemini Live. Gemini figures out you want to update your shopping list, triggers OpenClaw, which then hits your app (maybe Todoist or Apple Reminders). You get confirmation spoken back—no hands, no phone, just glasses.\n\nHere's the setup in code:\n\n// samples/CameraAccess/CameraAccess/Gemini/GeminiConfig.swift\nstatic let apiKey = \"YOURGEMINIAPI_KEY\"\n\nThe Bottom Line\n\nVisionClaw finally makes smart glasses actually useful, as long as you’re comfortable fiddling with API keys and local gateways. The iOS app is straightforward, the OpenClaw integration is powerful but a bit much if you only want basic voice/vision. If you want real agentic AI—actions, not just answers—this is worth your time. If you’re just after “describe what I’m seeing,” stick with Gemini alone.",
      "url": "https://github.com/yebeai/VisionClaw",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "sseanliu/VisionClaw",
        "url": "https://github.com/sseanliu/VisionClaw",
        "stars": 1372
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 7, 2026",
      "updatedAt": "February 8, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 69,
        "directories": {
          "(root)": 6,
          "assets": 4,
          "samples": 59
        },
        "languages": {
          "Markdown": 5,
          "JSON": 12,
          "Swift": 32
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [
          "samples/CameraAccess/CameraAccessTests/Assets/plant.mp4",
          "samples/CameraAccess/CameraAccessTests/Assets/plant.png",
          "samples/CameraAccess/CameraAccessTests/CameraAccessTests.swift"
        ],
        "docs": [
          "CHANGELOG.md",
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "samples/CameraAccess/README.md"
        ],
        "fileTypes": {
          ".md": 5,
          ".png": 11,
          ".pbxproj": 1,
          ".xcscheme": 1,
          ".json": 12,
          ".jpeg": 1,
          ".entitlements": 1,
          ".swift": 32,
          ".plist": 1,
          ".mp4": 1
        }
      }
    },
    {
      "id": 1152642040,
      "name": "agents",
      "displayName": "agents",
      "description": "Trade autonomously on Polymarket using AI Agents",
      "summary": "The Problem\nTrading on Polymarket can feel like navigating a minefield, especially if you're doing it manually. Keeping track of market fluctuations, executing trades, and analyzing data can be overwhelming. Let’s face it: most of us have better things to do than refresh a browser all day, hoping to catch the perfect moment to place a bet.\n\nWhat This Does\nThe agents repo is your ticket to autonomous trading on Polymarket using AI agents. It integrates with the Polymarket API and provides a set of utilities to create your own trading agents. Check out files like agents/application/trade.py to see how you can execute trades, or agents/polymarket/polymarket.py for methods to interact with market data. You can set up your environment with a .env file to securely manage your API keys, allowing your agent to access the necessary data without hardcoding sensitive info.\n\nThe structure supports modular development. For example, the agents/connectors/chroma.py file lets you implement your own vector database for data sourcing. This means you can customize how your agent pulls in relevant information—be it from news articles or social media—tailoring it to your specific trading strategy.\n\nReal-World Use\nImagine you want to bet on an upcoming election. You could fire up python agents/application/trade.py and let your AI agent analyze real-time news and market sentiment. With the right setup, your agent can automatically place bets based on predefined conditions, reducing the manual workload and potentially increasing your profits. Want to see how your agent is performing? Use the command line interface with python scripts/python/cli.py to monitor its actions.\n\nThe Bottom Line\nThis repo is a solid starting point for anyone looking to automate trading on Polymarket. However, it's not for the faint of heart—setting up your environment requires some familiarity with Python and Docker. If you're a developer who enjoys building tools and has a penchant for betting markets, this could save you time and effort. But if you're just dabbling, it might feel like overkill.",
      "url": "https://github.com/yebeai/agents",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Polymarket/agents",
        "url": "https://github.com/Polymarket/agents",
        "stars": 2289
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 8, 2026",
      "updatedAt": "February 8, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 37,
        "directories": {
          "(root)": 8,
          ".github": 6,
          "agents": 12,
          "docs": 2,
          "scripts": 8,
          "tests": 1
        },
        "languages": {
          "Markdown": 6,
          "YAML": 5,
          "Python": 16,
          "Shell": 5
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": "pip",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "scripts/python/cli.py",
          "scripts/python/server.py",
          "scripts/python/setup.py"
        ],
        "configFiles": [
          ".env.example",
          "Dockerfile",
          "requirements.txt",
          "scripts/python/setup.py"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [
          "tests/test.py"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE.md",
          "README.md",
          "docs/EXAMPLE.md",
          "docs/images/cli.png"
        ],
        "fileTypes": {
          ".example": 1,
          ".md": 6,
          ".yml": 4,
          ".yaml": 1,
          ".py": 16,
          ".png": 1,
          ".txt": 1,
          ".sh": 5
        }
      }
    },
    {
      "id": 1152633202,
      "name": "BubbleLab",
      "displayName": "BubbleLab",
      "description": "Open source workflow automation platform built for developers - full observability and code exportability!",
      "summary": "The Problem\nYou know those no-code workflow tools (like n8n) that churn out ugly JSON and trap your logic inside a black box? You can't debug, version, or run anything outside their walled garden. If you're a developer and want to own your automation, you're out of luck.\n\nWhat This Does\nBubbleLab flips the script: you visually build workflows, but everything compiles down to TypeScript you actually control. The repo has a studio app (apps/bubble-studio) where you can edit flows and test them. Observability is baked in—think logs, token/cost tracking, and full execution tracing (not the usual \"something went wrong, good luck\"). If you want to use AI ops, Pearl (the assistant) sits in .claude/skills/, generating and amending workflows for you. The platform exports as real code, not proprietary junk, so you can plug workflows straight into your codebase or CI.\n\nReal-World Use\nSay you want to scrape Reddit and push new posts to Slack. You fire up BubbleLab, use the reddit-scraper template, and get a clean TypeScript file like this:\n\nimport { fetchRedditPosts, sendToSlack } from 'bubblelab-integrations';\n\nexport const redditNewsFlow = async () => {\n  const posts = await fetchRedditPosts('news');\n  for (const post of posts) {\n    await sendToSlack(post.title, post.url);\n  }\n};\n\nYou can run this in Node, debug with real logs, and tweak every line. No magic hidden nodes, no vendor lock-in.\n\nThe Bottom Line\nBubbleLab is for devs who hate being boxed in. If you want visual workflow editing but also demand transparency and exportability, this is worth a look. Setup is a bit rough (bring your own API keys), and it's probably overkill for tiny scripts, but if you're sick of fighting proprietary tools, grab it and own your automation.",
      "url": "https://github.com/yebeai/BubbleLab",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "bubblelabai/BubbleLab",
        "url": "https://github.com/bubblelabai/BubbleLab",
        "stars": 1051
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 8, 2026",
      "updatedAt": "February 8, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".claude": 3,
          ".cursor": 5,
          ".github": 5,
          "(root)": 12,
          ".husky": 1,
          "apps": 174
        },
        "languages": {
          "Shell": 1,
          "Markdown": 10,
          "YAML": 4,
          "JavaScript": 1,
          "HTML": 1,
          "JSON": 1,
          "TypeScript": 36,
          "CSS": 1,
          "TSX": 66
        },
        "frameworks": [
          "React",
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "apps/bubble-studio/index.html",
          "apps/bubble-studio/src/components/flow_visualizer/param-editors/index.ts"
        ],
        "configFiles": [
          ".prettierrc",
          "Dockerfile.api",
          "apps/bubble-studio/.env.example",
          "apps/bubble-studio/package.json"
        ],
        "dependencies": [
          "apps/bubble-studio/package.json"
        ],
        "testFiles": [
          "apps/bubble-studio/src/components/execution_logs/CodeRestoreModal.test.tsx",
          "apps/bubble-studio/src/components/execution_logs/ExecutionHistory.test.tsx",
          "apps/bubble-studio/src/components/execution_logs/JsonRenderer.test.tsx",
          "apps/bubble-studio/src/components/flow_visualizer/flowvisualizer.integration.test.ts"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE.txt",
          "README.md",
          "apps/bubble-studio/README.md",
          "apps/bubble-studio/src/components/flow_visualizer/README.md",
          "apps/bubble-studio/src/components/templates/template_codes/README.md"
        ],
        "fileTypes": {
          ".sh": 1,
          ".md": 10,
          ".mdc": 5,
          ".yml": 4,
          ".api": 1,
          ".txt": 2,
          ".png": 33,
          ".example": 1,
          ".js": 1,
          ".html": 1,
          ".json": 1,
          ".ico": 1,
          ".svg": 28,
          ".jpg": 1,
          ".ts": 36,
          ".css": 1,
          ".tsx": 66
        }
      }
    },
    {
      "id": 1152628911,
      "name": "quint-code",
      "displayName": "quint code",
      "description": "Structured reasoning framework for Claude Code, Gemini, Cursor, and Codex — hypothesis-driven decision making with auditable evidence trails",
      "summary": "Structured Reasoning for AI Coding Tools: A Look at quint-code\n\nThe Problem\n\nAI-assisted coding tools are great until they're not. You ask a question, get a decent answer, and then... forget why you made a decision two days later. Or worse, you’re left digging through an endless chat history trying to retrace your steps. AI feels like a black box, and decisions vanish into the void. \n\nWhat This Does\n\nquint-code forces both you and your AI to think clearly and document everything along the way. Using the First Principles Framework (FPF), it turns AI-assisted problem-solving into a structured process: generate hypotheses, verify logic, test with evidence, and document the lot in a .quint/ directory that lives in your repo. It's auditable, queryable, and—most importantly—yours.\n\nThe tool is built for AI coding assistants like Claude Code, Codex, Gemini, and Cursor. It hooks into these tools via commands you can initialize using quint-code init. For example, you get slash commands like /q1-hypothesize to generate ideas or /q2-verify to check logical constraints. These commands live in .claude/commands/*.md or their equivalents for other tools, and you can customize the setup with flags like --cursor or --codex.\n\nUnder the hood, the src/mcp folder houses the core logic, including an assurance engine (calculator.go) that handles evidence evaluation, and several commands defined in Markdown (q-hypothesize.md, q-verify.md, etc.) for extensibility.\n\nReal-World Use\n\nSay you're building a CI/CD pipeline and need to decide between self-hosted runners or a managed service. You can start with /q1-hypothesize to generate ideas, then refine them with /q2-verify to check constraints like cost and security. Finally, use /q3-test to gather evidence (e.g., benchmarks, team feedback). All decisions and their rationale are saved in .quint/, so you don't have to remember why you ruled out \"option #2\" three months later.\n\nThe docs/workflow_example/cicd-strategy.md file has a detailed walkthrough of this exact scenario. Or just hack into it yourself—the examples are nice, but it's faster to try it out.\n\nThe Bottom Line\n\nquint-code is like having an AI-powered project manager that documents everything. For large, complex projects with multiple AIs and stakeholders, it’s a no-brainer. For small, one-off tasks? Probably overkill. But if you've ever uttered the words, \"Why did we decide this again?\"—install it.",
      "url": "https://github.com/yebeai/quint-code",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "m0n0x41d/quint-code",
        "url": "https://github.com/m0n0x41d/quint-code",
        "stars": 1173
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 8, 2026",
      "updatedAt": "February 8, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 66,
        "directories": {
          ".githooks": 1,
          ".github": 2,
          "(root)": 10,
          "assets": 1,
          "docs": 7,
          "scripts": 1,
          "src": 44
        },
        "languages": {
          "YAML": 6,
          "Markdown": 24,
          "Shell": 2,
          "Go": 26,
          "SQL": 2
        },
        "frameworks": [],
        "packageManager": "go modules",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "src/mcp/cmd/commands.go",
          "src/mcp/cmd/commands/q-actualize.md",
          "src/mcp/cmd/commands/q-decay.md",
          "src/mcp/cmd/commands/q-query.md",
          "src/mcp/cmd/commands/q-reset.md",
          "src/mcp/cmd/commands/q-status.md",
          "src/mcp/cmd/commands/q0-init.md",
          "src/mcp/cmd/commands/q1-add.md",
          "src/mcp/cmd/commands/q1-hypothesize.md",
          "src/mcp/cmd/commands/q2-verify.md",
          "src/mcp/cmd/commands/q3-validate.md",
          "src/mcp/cmd/commands/q4-audit.md",
          "src/mcp/cmd/commands/q5-decide.md",
          "src/mcp/cmd/init.go",
          "src/mcp/cmd/root.go",
          "src/mcp/cmd/serve.go",
          "src/mcp/internal/fpf/server.go",
          "src/mcp/main.go"
        ],
        "configFiles": [
          "src/mcp/go.mod"
        ],
        "dependencies": [
          "src/mcp/go.mod"
        ],
        "testFiles": [
          "src/mcp/assurance/calculator_test.go",
          "src/mcp/db/migrations_test.go",
          "src/mcp/db/store_test.go",
          "src/mcp/internal/fpf/actualize_test.go",
          "src/mcp/internal/fpf/assurance_integration_test.go",
          "src/mcp/internal/fpf/fsm_test.go",
          "src/mcp/internal/fpf/integration_test.go",
          "src/mcp/internal/fpf/preconditions_test.go",
          "src/mcp/internal/fpf/projection_test.go",
          "src/mcp/internal/fpf/tools_test.go"
        ],
        "docs": [
          "CHANGELOG.md",
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "docs/advanced.md",
          "docs/architecture.md",
          "docs/evidence-freshness.md",
          "docs/fpf-engine.md",
          "docs/workflow_example/README.md",
          "docs/workflow_example/cicd-strategy.md",
          "docs/workflow_example/payment-webhooks.md"
        ],
        "fileTypes": {
          ".yml": 3,
          ".yaml": 3,
          ".md": 24,
          ".svg": 1,
          ".sh": 2,
          ".go": 26,
          ".mod": 1,
          ".sum": 1,
          ".sql": 2
        }
      }
    },
    {
      "id": 1152625843,
      "name": "rotki",
      "displayName": "rotki",
      "description": "A portfolio tracking, analytics, accounting and management application that protects your privacy",
      "summary": "The Problem\nManaging cryptocurrency portfolios can feel like herding cats. You’ve got wallets, exchanges, and blockchains, all spitting out data in different formats. Most tools out there are closed-source SaaS platforms where you’re basically handing over your wallet keys to a stranger. rotki aims to tackle this privacy disaster by letting you keep your data local and encrypted.\n\nWhat This Does\nrotki is an open-source, self-hosted portfolio manager that puts privacy first. You can track your balances across multiple platforms and exchanges without worrying about someone else snooping through your financials. The project structure is set up for easy development and contribution. For example, the .github/workflows directory contains multiple CI/CD workflows like rotkici.yml for continuous integration and rotkidocker_publish.yaml for pushing Docker images. These workflows automate testing and deployment, so you don’t have to manually babysit your code.\n\nThe README.md does a decent job laying out the features, like transaction decoding and graphical insights. The AGENTS.md file even provides details on how to set up your environment, which is a nice touch for those new to the project.\n\nReal-World Use\nImagine you’re a crypto trader who wants to analyze your performance over the past year. With rotki, you can set it up on your own machine, connect it to your wallets, and let it gather data. You can dive into detailed profit and loss reports, customize your UI, and visualize historical data with just a few clicks. If you want to tweak settings, just edit the .pylint.rc file for Python linting or the .bumpversion.cfg for versioning—no need to dig through endless menus.\n\nThe Bottom Line\nrotki is a solid choice for privacy-conscious users who want to manage their crypto portfolios without giving up control. It's not the most beginner-friendly option, and the self-hosting requirement can be a pain if you're not technically inclined. If you’re serious about keeping your financial data secure, though, rotki is worth a look—just don’t expect it to hold your hand.",
      "url": "https://github.com/yebeai/rotki",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "rotki/rotki",
        "url": "https://github.com/rotki/rotki",
        "stars": 3711
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 8, 2026",
      "updatedAt": "February 8, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 17,
          ".github": 19,
          "colibri": 36,
          "docs": 12,
          "frontend": 116
        },
        "languages": {
          "YAML": 14,
          "Markdown": 10,
          "Python": 2,
          "TOML": 2,
          "Rust": 32,
          "JSON": 4,
          "CSS": 1,
          "HTML": 3,
          "reStructuredText": 6,
          "TypeScript": 49,
          "JavaScript": 1
        },
        "frameworks": [
          "React",
          "Docker"
        ],
        "packageManager": "cargo",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "colibri/src/main.rs",
          "frontend/app/electron/main/index.ts",
          "frontend/app/electron/main/ipc-handlers/index.ts",
          "frontend/app/electron/preload/index.ts",
          "frontend/app/index.html"
        ],
        "configFiles": [
          "Dockerfile",
          "Makefile",
          "colibri/Cargo.toml",
          "docs/Makefile",
          "frontend/app/package.json"
        ],
        "dependencies": [
          "colibri/Cargo.toml",
          "frontend/app/package.json"
        ],
        "testFiles": [
          ".github/scripts/merge-latest.mjs",
          ".github/workflows/task_backend_tests.yml",
          ".github/workflows/task_e2e_tests.yml",
          ".github/workflows/task_fe_unit_tests.yml",
          "frontend/app/.env.test"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE.md",
          "README.md",
          "docs/Makefile",
          "docs/_static/rotkehlchen_docs.css",
          "docs/_templates/layout.html",
          "docs/api.rst",
          "docs/changelog.rst",
          "docs/conf.py",
          "docs/dev_changelog.rst",
          "docs/dev_guide.rst",
          "docs/files/rotki_generic_events.csv",
          "docs/files/rotki_generic_trades.csv",
          "docs/index.rst",
          "docs/websockets.rst",
          "frontend/app/electron/README.md"
        ],
        "fileTypes": {
          ".cfg": 1,
          ".yml": 11,
          ".ci": 1,
          ".md": 10,
          ".mjs": 1,
          ".py": 2,
          ".yaml": 3,
          ".rc": 1,
          ".toml": 2,
          ".lock": 1,
          ".rs": 32,
          ".json": 4,
          ".css": 1,
          ".html": 3,
          ".rst": 6,
          ".csv": 2,
          ".ts": 49,
          ".docker": 1,
          ".e2e": 1,
          ".test": 1,
          ".js": 1,
          ".svg": 25,
          ".png": 23
        }
      }
    },
    {
      "id": 1152624453,
      "name": "openagi",
      "displayName": "openagi",
      "description": "Paving the way for open agents and AGI for all.",
      "summary": "The Problem\n\nBuilding autonomous agents that actually do useful stuff is a pain. Most DIY agent frameworks are either half-baked, require gluing together a mess of APIs, or they assume you want to run everything through OpenAI like it's the only option. If you want something modular, hackable, and not stuck in someone's closed ecosystem, good luck.\n\nWhat This Does\n\nopenagi gives you a Python toolkit for making \"human-like\" agents. It's got a bunch of ready-to-use chunks: openagi.agent.Admin to wrangle multiple agents, openagi.planner.taskdecomposer.TaskPlanner for breaking up tasks, and actions like openagi.actions.tools.ddgsearch.DuckDuckGoSearch for web scraping. You wire it up in a few lines—no 2000-line YAML configs or 14 microservices. The code lives in plain Python files, so you can actually read it. If you want to see how an agent works, you just look at the example in the README or poke at the openagi/worker.py file.\n\nReal-World Use\n\nSay you want a trip planner bot. You set up your LLM (OpenAI or Gemini), slap on a search action, and plug it into a Worker with some instructions. Then, use Admin to run it against a user query, like \"Give me total 3 Days Trip to San francisco Bay area\". The agent will break down the task, search the web, and spit out an itinerary. If you want to get fancy, make it fully autonomous, drop the workers, and have it hunt down cricket scores or whatever. It's dead simple, and the example code actually works without hunting through docs.\n\nThe Bottom Line\n\nopenagi is for devs who want to build multi-agent LLM bots without drowning in abstraction hell. The parts are modular, the examples are clear, and you don't need a PhD in prompt engineering. If you need something production-grade or super customizable, you'll hit limits fast—but for prototyping and hacking, it's solid.",
      "url": "https://github.com/yebeai/openagi",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "aiplanethub/openagi",
        "url": "https://github.com/aiplanethub/openagi",
        "stars": 561
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 8, 2026",
      "updatedAt": "February 8, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 10,
          ".gitbook": 40,
          ".github": 1,
          "assets": 1,
          "cookbook": 7,
          "docs": 76,
          "example": 13,
          "src": 52
        },
        "languages": {
          "YAML": 1,
          "Markdown": 26,
          "Python": 65,
          "TOML": 1
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "src/openagi/cli.py"
        ],
        "configFiles": [
          ".env.example",
          "pyproject.toml",
          "requirements.txt"
        ],
        "dependencies": [
          "poetry.lock",
          "pyproject.toml",
          "requirements.txt"
        ],
        "testFiles": [
          "docs/acknowledgment/special-mentions.md"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "docs/.gitbook/assets/1.png",
          "docs/.gitbook/assets/2.png",
          "docs/.gitbook/assets/3.png",
          "docs/.gitbook/assets/Agents.png",
          "docs/.gitbook/assets/Screenshot 2024-08-22 at 15.51.33.png",
          "docs/.gitbook/assets/image (1) (1).png",
          "docs/.gitbook/assets/image (1).png",
          "docs/.gitbook/assets/image (10).png",
          "docs/.gitbook/assets/image (11).png",
          "docs/.gitbook/assets/image (12).png",
          "docs/.gitbook/assets/image (13).png",
          "docs/.gitbook/assets/image (14).png",
          "docs/.gitbook/assets/image (15).png",
          "docs/.gitbook/assets/image (16).png",
          "docs/.gitbook/assets/image (17).png",
          "docs/.gitbook/assets/image (18).png",
          "docs/.gitbook/assets/image (19).png",
          "docs/.gitbook/assets/image (2) (1).png",
          "docs/.gitbook/assets/image (2).png",
          "docs/.gitbook/assets/image (20).png",
          "docs/.gitbook/assets/image (21).png",
          "docs/.gitbook/assets/image (22).png",
          "docs/.gitbook/assets/image (23).png",
          "docs/.gitbook/assets/image (24).png",
          "docs/.gitbook/assets/image (25).png",
          "docs/.gitbook/assets/image (26).png",
          "docs/.gitbook/assets/image (27).png",
          "docs/.gitbook/assets/image (28).png",
          "docs/.gitbook/assets/image (29).png",
          "docs/.gitbook/assets/image (3) (1).png",
          "docs/.gitbook/assets/image (3).png",
          "docs/.gitbook/assets/image (30).png",
          "docs/.gitbook/assets/image (31).png",
          "docs/.gitbook/assets/image (32).png",
          "docs/.gitbook/assets/image (33).png",
          "docs/.gitbook/assets/image (34).png",
          "docs/.gitbook/assets/image (35).png",
          "docs/.gitbook/assets/image (36).png",
          "docs/.gitbook/assets/image (37).png",
          "docs/.gitbook/assets/image (38).png",
          "docs/.gitbook/assets/image (39).png",
          "docs/.gitbook/assets/image (4).png",
          "docs/.gitbook/assets/image (40).png",
          "docs/.gitbook/assets/image (41).png",
          "docs/.gitbook/assets/image (42).png",
          "docs/.gitbook/assets/image (43).png",
          "docs/.gitbook/assets/image (44).png",
          "docs/.gitbook/assets/image (45).png",
          "docs/.gitbook/assets/image (5).png",
          "docs/.gitbook/assets/image (6).png",
          "docs/.gitbook/assets/image (7).png",
          "docs/.gitbook/assets/image (8).png",
          "docs/.gitbook/assets/image (9).png",
          "docs/.gitbook/assets/image.png",
          "docs/README.md",
          "docs/SUMMARY.md",
          "docs/acknowledgment/special-mentions.md",
          "docs/components/action/README.md",
          "docs/components/action/tools.md",
          "docs/components/admin.md",
          "docs/components/aiagent/README.md",
          "docs/components/aiagent/agent-configuration.md",
          "docs/components/llm.md",
          "docs/components/memory.md",
          "docs/components/planner.md",
          "docs/components/vectorstore/README.md",
          "docs/components/vectorstore/chromastorage.md",
          "docs/components/workers.md",
          "docs/contact-us.md",
          "docs/getting-started/installation.md",
          "docs/getting-started/quickstart.md",
          "docs/use-cases/blog-writing-agent.md",
          "docs/use-cases/github-agent.md",
          "docs/use-cases/jobsearch-agent.md",
          "docs/use-cases/market-agent.md",
          "docs/use-cases/movie-recommender-agent.md",
          "src/Readme.md"
        ],
        "fileTypes": {
          ".example": 1,
          ".png": 95,
          ".yml": 1,
          ".md": 26,
          ".py": 65,
          ".ipynb": 7,
          ".lock": 1,
          ".toml": 1,
          ".txt": 1
        }
      }
    },
    {
      "id": 1152364673,
      "name": "echolon",
      "displayName": "echolon",
      "description": "A powerful, local-first API client with Git integration, offline support, and multi-protocol capabilities. Open source alternative to Postman.",
      "summary": "The Problem\n\nPostman is great—until it’s not. If you’ve ever been annoyed by its sluggishness, forced login, or bloated UI, you’re not alone. And let’s not even get started on the lack of version control for team workflows unless you fork over cash. API testing should be fast, local, and Git-friendly without requiring a cloud-based account or a multi-step onboarding process. That’s what echolon solves.\n\nWhat This Does\n\nEcholon is a local-first API client with Git integration, built with Electron and React. It’s essentially your API workspace, but smarter. No accounts, no data leaving your machine (unless you use the optional cloud features), and full control over versioning via Git baked right into the app.\n\nThe project lives in the core folder, which houses the Electron app. You’ve got everything you’d expect: core/main/httpRequest.ts handles sending API requests, core/main/git.ts manages Git operations, and core/main/mockServer.ts lets you mock APIs locally or via a cloud proxy. The core/assets/app-icon directory is where you’ll find the slick branding (props for the clean design). \n\nIt’s not just a tool for one-off API calls—it supports collections, folders, and environment variables like Postman, but with more control. You can even export requests as cURL commands, which is great for command-line junkies. And yes, you can import your Postman collections or OpenAPI specs to make switching painless.\n\nReal-World Use\n\nImagine you’re building a microservices-based app and want to test APIs without dealing with Postman’s constant updates or login prompts. You clone your repo, fire up Echolon, and start creating collections for each service. You commit your API workspace (requests, collections, etc.) to Git right from the app using core/main/git.ts. Need to test a new auth flow? Build requests in Echolon, mock responses using core/main/mockServer.ts, and refine your workflow—all offline.\n\nSwitching to a production environment? Just swap out your variables in the environment manager. Everything stays local unless you explicitly push it to GitHub via the integrated Git client.\n\nThe Bottom Line\n\nEcholon is like Postman for people who hate Postman. It’s fast, private, and developer-first. The Git integration is killer for teams, and the local-first approach makes it ideal for privacy-conscious devs. That said, it’s an Electron app, so if you’re a purist who hates anything heavier than a CLI, this might not be your jam. But for everyone else? Highly recommend giving it a spin, especially if you’re already using Git in your workflow.",
      "url": "https://github.com/yebeai/echolon",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "echolon-app/echolon",
        "url": "https://github.com/echolon-app/echolon",
        "stars": 41
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 7, 2026",
      "updatedAt": "February 7, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 4,
          "core": 196
        },
        "languages": {
          "JSON": 4,
          "Markdown": 1,
          "YAML": 2,
          "TypeScript": 63,
          "HTML": 1,
          "TSX": 61,
          "CSS": 57
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "core/index.html",
          "core/main/index.ts",
          "core/renderer/App.tsx",
          "core/renderer/components/layout/BottomBar/index.ts",
          "core/renderer/components/layout/LeftSidebar/index.ts",
          "core/renderer/components/layout/MainLayout/index.ts",
          "core/renderer/components/layout/TopBar/index.ts",
          "core/renderer/components/layout/index.ts",
          "core/renderer/components/modals/FunctionConfigModal/index.ts",
          "core/renderer/components/modals/GitCommitModal/index.ts",
          "core/renderer/components/modals/GitHubConnectModal/index.ts",
          "core/renderer/components/modals/GlobalSearchModal/index.ts",
          "core/renderer/components/modals/ImportModal/index.ts",
          "core/renderer/components/modals/MoveCollectionModal/index.ts",
          "core/renderer/components/modals/NewCollectionModal/index.ts",
          "core/renderer/components/modals/NewEnvironmentModal/index.ts",
          "core/renderer/components/modals/OnboardingTour/index.ts",
          "core/renderer/components/modals/RequestHistoryModal/index.ts",
          "core/renderer/components/modals/SettingsModal/index.ts",
          "core/renderer/components/modals/ShortcutsModal/index.ts",
          "core/renderer/components/modals/UpdateModal/index.ts",
          "core/renderer/components/modals/index.ts",
          "core/renderer/components/panels/APIReferencePanel/index.ts",
          "core/renderer/components/panels/CenterPanel/index.ts",
          "core/renderer/components/panels/CodePanel/index.ts",
          "core/renderer/components/panels/ConsolePanel/index.ts",
          "core/renderer/components/panels/DiffViewer/index.ts",
          "core/renderer/components/panels/GitPanel/index.ts",
          "core/renderer/components/panels/LeftPanel/index.ts",
          "core/renderer/components/panels/MockingPanel/index.ts",
          "core/renderer/components/panels/RightPanel/index.ts",
          "core/renderer/components/panels/index.ts",
          "core/renderer/components/ui/AutoComplete/index.ts",
          "core/renderer/components/ui/Badge/index.ts",
          "core/renderer/components/ui/Button/index.ts",
          "core/renderer/components/ui/CodeEditor/index.ts",
          "core/renderer/components/ui/CollapsibleList/index.ts",
          "core/renderer/components/ui/ColorEmojiPicker/index.ts",
          "core/renderer/components/ui/ContextMenu/index.ts",
          "core/renderer/components/ui/DiffViewer/index.ts",
          "core/renderer/components/ui/DragDropUpload/index.ts",
          "core/renderer/components/ui/Dropdown/index.ts",
          "core/renderer/components/ui/EditableTable/index.ts",
          "core/renderer/components/ui/Input/index.ts",
          "core/renderer/components/ui/Modal/index.ts",
          "core/renderer/components/ui/NumericInput/index.ts",
          "core/renderer/components/ui/ProgressBar/index.ts",
          "core/renderer/components/ui/ResizablePanel/index.ts",
          "core/renderer/components/ui/SearchInput/index.ts",
          "core/renderer/components/ui/SimpleInput/index.ts",
          "core/renderer/components/ui/StorageBanner/index.ts",
          "core/renderer/components/ui/Switch/index.ts"
        ],
        "configFiles": [
          ".eslintrc.json",
          "core/package.json"
        ],
        "dependencies": [
          "core/package-lock.json",
          "core/package.json"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md",
          "core/changelog.json"
        ],
        "fileTypes": {
          ".json": 4,
          ".md": 1,
          ".zip": 1,
          ".webp": 1,
          ".ico": 1,
          ".svg": 1,
          ".png": 2,
          ".plist": 1,
          ".yml": 2,
          ".ts": 63,
          ".html": 1,
          ".txt": 1,
          ".tsx": 61,
          ".css": 57
        }
      }
    },
    {
      "id": 1152348004,
      "name": "lumentis",
      "displayName": "lumentis",
      "description": "AI powered one-click comprehensive docs from transcripts and text.",
      "summary": "The Problem\nWe’ve all been there—staring at a mountain of meeting transcripts or sprawling notes, wondering how to turn that chaos into something remotely useful. The pain of manually sifting through and structuring information is real, especially when you're on a tight deadline. You need a solution that cuts through the noise without sacrificing quality.\n\nWhat This Does\nEnter Lumentis. This tool generates documentation from your transcripts or unstructured text with a single command. After running npx lumentis, you're prompted to provide your content. The magic happens in the src/page-generator.ts, where it transforms your input into a structured outline based on themes and audience. You can also switch between models using the functions defined in src/prompts.ts, allowing you to customize the output based on your needs.\n\nThe project is built using TypeScript, as indicated by the presence of tsconfig.json and .npmignore. It’s lightweight, with the main logic encapsulated in the src directory. You only need to care about a few files, making it straightforward to dive in.\n\nReal-World Use\nImagine you just wrapped up a crucial product meeting. You have a 2-hour video transcript and a pile of notes. You run npx lumentis, feed it the transcript, answer a few prompts about your audience, and wait. In mere moments, you have a polished document ready to be deployed to Vercel. Here’s how your command might look:\n\nnpx lumentis\n\nThen just provide the transcript when prompted, and let Lumentis do the heavy lifting. \n\nThe Bottom Line\nLumentis is a practical tool for anyone drowning in documentation tasks. It’s not perfect—there's a known issue with the cache that requires you to clear it if you've used it before—but once you get past that, it’s a time-saver. If you’re regularly converting transcripts to docs, this is worth a shot. Otherwise, you might find it overkill for small projects. Just be prepared to manage your caching issues.",
      "url": "https://github.com/yebeai/lumentis",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "hrishioa/lumentis",
        "url": "https://github.com/hrishioa/lumentis",
        "stars": 1696
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 7, 2026",
      "updatedAt": "February 7, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 18,
        "directories": {
          "(root)": 9,
          ".vscode": 1,
          "assets": 1,
          "src": 7
        },
        "languages": {
          "JSON": 4,
          "Markdown": 2,
          "TypeScript": 7,
          "JavaScript": 1
        },
        "frameworks": [
          "React"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "src/app.ts"
        ],
        "configFiles": [
          "package.json",
          "tsconfig.json"
        ],
        "dependencies": [
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".json": 4,
          ".md": 2,
          ".png": 1,
          ".ts": 7,
          ".js": 1
        }
      }
    },
    {
      "id": 1152344773,
      "name": "toad",
      "displayName": "toad",
      "description": "A unified interface for AI in your terminal.",
      "summary": "The Problem\n\nTalking to AI agents from the terminal sucks. You get half-baked wrappers that can't remember your shell state, mangle anything more complex than plain text, and break the moment you try something interactive. Forget about switching between agents, editing prompts with any decency, or doing anything that feels like modern software. It's like gluing ChatGPT to cat and calling it a day.\n\nWhat This Does\n\ntoad gives you a real terminal UI for AI agents—Claude, Gemini, Codex, OpenHand, whatever—without the usual hacky nonsense. The guts live in src/toad/, with things like acp/agent.py and acp/api.py handling connections via Agent Client Protocol. The shell itself isn't just a wrapper—it actually runs a legit shell, so your state sticks around (src/toad/main.py and _loop.py are key here). You get a Markdown editor for prompts, file picker with fuzzy search, and diff viewer with syntax highlighting. All those \"nice to have\" bits people usually skip in CLI tools? They're here.\n\nReal-World Use\n\nSay you want to refactor a Python file and ask Claude for help. Fire up toad in your terminal, hit @ to attach the file using the picker (not some garbage path autocomplete), write your prompt in the Markdown editor, and get a color-coded diff back. Your shell history, environment, and working directory persist like you'd expect. You can swap agents or install new ones through the \"app store\" (see acp/agent.py for integration). No more copy-pasting garbage or losing context between commands.\n\nThe Bottom Line\n\ntoad fixes the mess most AI terminal interfaces make. It's overkill if you're just slapping together one-off prompts, but if you actually work with code and want sane workflows, it's the first CLI that feels like someone gave a damn about UX. Still early days—expect quirks—but it's the only one I'd bother with for serious dev work. If you want a terminal AI sidekick that doesn't feel like a toy, try it.",
      "url": "https://github.com/yebeai/toad",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "batrachianai/toad",
        "url": "https://github.com/batrachianai/toad",
        "stars": 2429
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 7, 2026",
      "updatedAt": "February 7, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 137,
        "directories": {
          ".github": 4,
          "(root)": 9,
          "project": 2,
          "src": 120,
          "tools": 2
        },
        "languages": {
          "YAML": 3,
          "Markdown": 5,
          "Python": 100,
          "TOML": 16
        },
        "frameworks": [
          "Django",
          "Flask"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "src/toad/__main__.py",
          "src/toad/app.py",
          "src/toad/cli.py",
          "src/toad/screens/main.py"
        ],
        "configFiles": [
          "Makefile",
          "pyproject.toml"
        ],
        "dependencies": [
          "pyproject.toml"
        ],
        "testFiles": [],
        "docs": [
          "CHANGELOG.md",
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".yml": 3,
          ".md": 5,
          ".py": 100,
          ".tcss": 6,
          ".toml": 16,
          ".png": 1,
          ".wav": 2
        }
      }
    },
    {
      "id": 1152343788,
      "name": "dexter",
      "displayName": "dexter",
      "description": "An autonomous agent for deep financial research",
      "summary": "The Problem\n\nFinancial research is a dumpster fire of complexity. It's tedious, time-consuming, and full of manual work—digging through balance sheets, income statements, and APIs that feel like they were designed in 1997. Worse, when you're done, you're left wondering if you missed something critical. There's no structure, no automation, and definitely no self-checking. Enter: dexter.\n\nWhat This Does\n\ndexter is essentially an LLM-powered intern for financial research, but unlike your usual intern, it doesn’t need two weeks of onboarding and definitely won’t forget to double-check its work. It breaks down complex financial questions into clear, actionable steps and executes them autonomously. It’s all in the code—start in src/agent/ to see how the agent plans tasks (agent.ts), generates prompts (prompts.ts), and tracks progress with a scratchpad (scratchpad.ts).\n\nThe project is built on the Bun runtime (if you’re still using Node.js, maybe it’s time to modernize), and it integrates with APIs like OpenAI, financial datasets, and Exa for web search. The src/components/ folder handles the interactive UI, with parts like AgentEventView.tsx for task logs and ModelSelector.tsx for picking your LLM poison. There's also an evaluation suite (src/evals/) that lets you test dexter with real-world financial questions. Bonus: it even logs results to LangSmith for tracking accuracy.\n\nReal-World Use\n\nSay you’re asked, “What’s Tesla’s current debt-to-equity ratio, and how does it compare to Ford’s over the last five years?” Instead of manually scraping financial statements and Googling for hours, you fire up dexter:\n\nbun start\n\nYou input the question, and dexter does the rest: fetching Tesla and Ford's financials, calculating ratios, and presenting the results in an organized format. It even self-checks its calculations using the token-counter.ts utility to avoid hallucinations. Debugging along the way? Check the scratchpad logs for every tool call—it’s all there.\n\nThe Bottom Line\n\ndexter is impressive for automating tedious financial research, especially if you already live in a world of LLMs and APIs. It’s not a plug-and-play toy, though—you’ll need API keys, some familiarity with Bun, and probably a few hours to tweak .env configs. If you’re a finance nerd or a quant looking to save time, it’s worth trying. For casual users? Probably overkill.",
      "url": "https://github.com/yebeai/dexter",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "virattt/dexter",
        "url": "https://github.com/virattt/dexter",
        "stars": 16649
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 7, 2026",
      "updatedAt": "February 7, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 98,
        "directories": {
          ".github": 1,
          "(root)": 8,
          "scripts": 1,
          "src": 88
        },
        "languages": {
          "YAML": 1,
          "Markdown": 4,
          "JavaScript": 1,
          "JSON": 2,
          "Shell": 1,
          "TypeScript": 68,
          "TSX": 17
        },
        "frameworks": [
          "React"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "src/agent/index.ts",
          "src/components/index.ts",
          "src/evals/components/index.ts",
          "src/index.tsx",
          "src/skills/index.ts",
          "src/tools/browser/index.ts",
          "src/tools/descriptions/index.ts",
          "src/tools/finance/index.ts",
          "src/tools/index.ts",
          "src/tools/search/index.ts",
          "src/utils/index.ts"
        ],
        "configFiles": [
          "jest.config.js",
          "package.json",
          "tsconfig.json"
        ],
        "dependencies": [
          "package.json"
        ],
        "testFiles": [
          "src/utils/cache.test.ts"
        ],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".yml": 1,
          ".md": 4,
          ".lock": 1,
          ".example": 1,
          ".js": 1,
          ".json": 2,
          ".sh": 1,
          ".ts": 68,
          ".tsx": 17,
          ".csv": 1
        }
      }
    },
    {
      "id": 1152153309,
      "name": "awesome-homelab",
      "displayName": "awesome homelab",
      "description": "Curating Top Open Source Apps for Homelab Enthusiasts",
      "summary": "The Problem\n\nBuilding and managing a homelab is like assembling IKEA furniture without a manual—frustrating, time-consuming, and filled with bad decisions you'll regret later. Sure, there are hundreds of open-source apps to choose from, but good luck figuring out which ones are actually worth your time. Nobody has the energy to sift through GitHub repos with 3 stars and last commits from 2018.\n\nWhat This Does\n\nawesome-homelab is basically your cheat sheet for home server apps. It's a curated list of open-source tools, organized into YAML files under the data/ directory, like data/ai.yaml, data/backup.yaml, and data/infra-management.yaml. Each file lists apps in that category, along with metadata like GitHub stars and descriptions.\n\nThe main entry point is the README.md, which pulls all this data together into a clean table format. It's not some over-engineered database—just YAML files and a markdown table. Simple and effective. The assets/logo.svg and .github/workflows/build.yaml suggest there's some automation here, likely to ensure the README stays fresh. (If not, someone should add that—manual updates are a nightmare.)\n\nReal-World Use\n\nSay you’re setting up a homelab and need a backup solution. Instead of wasting hours Googling \"best open source backup tools\" and ending up on page six of Reddit threads, you can just check the data/backup.yaml. There, you’ll find curated options with details like GitHub stars and descriptions to help you decide.\n\nFor example, maybe you find BorgBackup listed. You click the link, skim the repo, and decide it’s perfect. You install it, configure it, and boom—your data is now safe. You didn’t have to sort through 15 abandoned projects first.\n\nThe Bottom Line\n\nawesome-homelab is a solid resource if you’re serious about building a homelab without wasting time. The YAML-and-markdown approach is lightweight and easy to contribute to. That said, with 0 stars and no original content (it’s a fork), this repo currently brings nothing new to the table. If you’re already familiar with the original repo (miantiao-me/awesome-homelab), skip this one. Otherwise, it’s a good starting point for homelab enthusiasts. Just don’t expect magic.",
      "url": "https://github.com/yebeai/awesome-homelab",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "miantiao-me/awesome-homelab",
        "url": "https://github.com/miantiao-me/awesome-homelab",
        "stars": 1715
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 7, 2026",
      "updatedAt": "February 7, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 49,
        "directories": {
          "(root)": 7,
          ".github": 1,
          ".vscode": 1,
          "assets": 1,
          "data": 35,
          "script": 3,
          "tmpl": 1
        },
        "languages": {
          "YAML": 37,
          "JSON": 2,
          "Markdown": 2,
          "JavaScript": 4
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "pnpm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "script/index.js"
        ],
        "configFiles": [
          "package.json"
        ],
        "dependencies": [
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "README.md",
          "tmpl/README.md"
        ],
        "fileTypes": {
          ".yaml": 37,
          ".json": 2,
          ".md": 2,
          ".svg": 1,
          ".js": 4
        }
      }
    },
    {
      "id": 1152119403,
      "name": "repo_posts",
      "displayName": "repo posts",
      "description": "No description available",
      "summary": "The Problem  \nManaging posts for a static site can get messy fast. You’ve got content updates, related links, RSS feeds, and embedding calculations. Doing all this manually is a nightmare, especially when you want it to stay consistent and automated. Enter repoposts, which tries to turn a Jekyll-based blog into a hands-free operation.  \n\nWhat This Does  \nAt its core, this repo is a Jekyll site with a bunch of automation sprinkled on top. The posts are stored in docs/posts/, with layout overrides in docs/layouts/default.html and images living in docs/assets/. Nothing groundbreaking there.  \n\nWhat actually makes this useful is the automation in .github/workflows/. For example:  \ngenerate-related-min.yml calculates \"related posts\" based on embeddings stored in docs/data/embeddings.npz.  \nrss-smoke.yml verifies your RSS feed doesn’t break after every update.  \nimage-compress.yml ensures that images in docs/assets/ don’t wreck your page load times.  \n\nEvery push to main triggers a rebuild and deploys the updated site to GitHub Pages. If your data changes (embeddings, related links, etc.), the workflows handle those updates without you lifting a finger.  \n\nReal-World Use  \nSay you’re running a blog with dozens of posts. You add a new post to docs/posts/ and push to main. The generate-related-min.yml workflow kicks in, calculating similar posts using embeddings. These related links are updated in docs/data/related.json and reflected in your live site automatically. Meanwhile, the rss-smoke.yml workflow makes sure your RSS feed doesn’t implode after the update.  \n\nAnd if you didn’t compress your latest image upload? No problem. image-compress.yml will optimize it in the background.  \n\nThe Bottom Line  \nIf you're running a Jekyll blog with some complexity—frequent content updates, related post linking, and RSS feeds—this repo does a solid job of keeping things automated. The workflows are well-organized, but they might be overkill for smaller projects or sites with infrequent updates.  \n\nThe lack of documentation (seriously, \"No description\"?) makes onboarding annoying, but if you’re comfortable with GitHub Actions and Jekyll, you’ll get the hang of it. For hands-free site management, it’s worth a look.",
      "url": "https://github.com/yebeai/repo_posts",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "tom-doerr/repo_posts",
        "url": "https://github.com/tom-doerr/repo_posts",
        "stars": 237
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 7, 2026",
      "updatedAt": "February 7, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".github": 8,
          "(root)": 7,
          "docs": 185
        },
        "languages": {
          "YAML": 9,
          "Markdown": 172,
          "JSON": 3,
          "HTML": 9
        },
        "frameworks": [
          "React",
          "Rails"
        ],
        "packageManager": "bundler",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          "Makefile",
          "docs/Gemfile.lock"
        ],
        "dependencies": [],
        "testFiles": [
          "docs/_posts/2025-02-17-oldmoe-litestack.md"
        ],
        "docs": [
          "CONTENT-LICENSE.md",
          "LICENSE",
          "README.md",
          "docs/.touch",
          "docs/Gemfile.lock",
          "docs/README.md",
          "docs/_config.yml",
          "docs/_data/embeddings.npz",
          "docs/_data/image_dims.json",
          "docs/_data/related.json",
          "docs/_data/status.json",
          "docs/_includes/analytics.html",
          "docs/_includes/dummy",
          "docs/_includes/header.html",
          "docs/_includes/img_abs_url.html",
          "docs/_includes/meta-description.html",
          "docs/_includes/post_card.html",
          "docs/_includes/post_snippet.html",
          "docs/_includes/related_item.html",
          "docs/_includes/schema-software.html",
          "docs/_layouts/default.html",
          "docs/_posts/2025-02-17-BasedHardware-omi.md",
          "docs/_posts/2025-02-17-FunAudioLLM-InspireMusic.md",
          "docs/_posts/2025-02-17-JosefAlbers-VimLM.md",
          "docs/_posts/2025-02-17-Kong-kong.md",
          "docs/_posts/2025-02-17-LeaVerou-style-observer.md",
          "docs/_posts/2025-02-17-MinishLab-semhash.md",
          "docs/_posts/2025-02-17-OpenSignLabs-OpenSign.md",
          "docs/_posts/2025-02-17-SonyResearch-micro_diffusion.md",
          "docs/_posts/2025-02-17-TermoraDev-termora.md",
          "docs/_posts/2025-02-17-ZGGSONG-STranslate.md",
          "docs/_posts/2025-02-17-apache-airflow.md",
          "docs/_posts/2025-02-17-cocktailpeanut-fluxgym.md",
          "docs/_posts/2025-02-17-commaai-openpilot.md",
          "docs/_posts/2025-02-17-dexie-Dexie.js.md",
          "docs/_posts/2025-02-17-dmayboroda-minima.md",
          "docs/_posts/2025-02-17-egoist-sitefetch.md",
          "docs/_posts/2025-02-17-facebookresearch-Kats.md",
          "docs/_posts/2025-02-17-flame-engine-flame.md",
          "docs/_posts/2025-02-17-fleetdm-fleet.md",
          "docs/_posts/2025-02-17-ggml-org-llama.cpp.md",
          "docs/_posts/2025-02-17-henrythe9th-AI-Crash-Course.md",
          "docs/_posts/2025-02-17-hhhuang-CAG.md",
          "docs/_posts/2025-02-17-hristo2612-SQLNoir.md",
          "docs/_posts/2025-02-17-lowlighter-mizu.md",
          "docs/_posts/2025-02-17-microsoft-MarS.md",
          "docs/_posts/2025-02-17-mishushakov-llm-scraper.md",
          "docs/_posts/2025-02-17-mylinuxforwork-dotfiles.md",
          "docs/_posts/2025-02-17-neigebaie-shadcn-ui-tree-view.md",
          "docs/_posts/2025-02-17-oldmoe-litestack.md",
          "docs/_posts/2025-02-17-ouch-org-ouch.md",
          "docs/_posts/2025-02-17-piebro-factorio-blueprint-visualizer.md",
          "docs/_posts/2025-02-17-rectorphp-rector.md",
          "docs/_posts/2025-02-17-seal-rg-recurrent-pretraining.md",
          "docs/_posts/2025-02-17-simonask-werk.md",
          "docs/_posts/2025-02-17-tesserato-CodeWeaver.md",
          "docs/_posts/2025-02-17-tillywork-tillywork.md",
          "docs/_posts/2025-02-17-vernu-vps-audit.md",
          "docs/_posts/2025-02-18-0xPlaygrounds-rig.md",
          "docs/_posts/2025-02-18-ErlichLiu-DeepClaude.md",
          "docs/_posts/2025-02-18-Eugeny-tabby.md",
          "docs/_posts/2025-02-18-HeavyHorst-remco.md",
          "docs/_posts/2025-02-18-Huanshere-VideoLingo.md",
          "docs/_posts/2025-02-18-PatrickJS-awesome-cursorrules.md",
          "docs/_posts/2025-02-18-RocketChat-Rocket.Chat.md",
          "docs/_posts/2025-02-18-TEN-framework-TEN-Agent.md",
          "docs/_posts/2025-02-18-automatisch-automatisch.md",
          "docs/_posts/2025-02-18-binwiederhier-ntfy.md",
          "docs/_posts/2025-02-18-browserbase-stagehand.md",
          "docs/_posts/2025-02-18-browserless-browserless.md",
          "docs/_posts/2025-02-18-cameron314-concurrentqueue.md",
          "docs/_posts/2025-02-18-comet-ml-opik.md",
          "docs/_posts/2025-02-18-deepseek-ai-DeepSeek-Coder.md",
          "docs/_posts/2025-02-18-fabriziosalmi-caddy-waf.md",
          "docs/_posts/2025-02-18-gaogaotiantian-viztracer.md",
          "docs/_posts/2025-02-18-getmaxun-maxun.md",
          "docs/_posts/2025-02-18-keephq-keep.md",
          "docs/_posts/2025-02-18-leonboe1-GoogleFindMyTools.md",
          "docs/_posts/2025-02-18-linuxmint-timeshift.md",
          "docs/_posts/2025-02-18-mediar-ai-screenpipe.md",
          "docs/_posts/2025-02-18-meta-llama-llama-stack.md",
          "docs/_posts/2025-02-18-nbonamy-witsy.md",
          "docs/_posts/2025-02-18-opendatalab-PDF-Extract-Kit.md",
          "docs/_posts/2025-02-18-openstatusHQ-data-table-filters.md",
          "docs/_posts/2025-02-18-pages-cms-pages-cms.md",
          "docs/_posts/2025-02-18-pydantic-pydantic-ai.md",
          "docs/_posts/2025-02-18-serengil-deepface.md",
          "docs/_posts/2025-02-18-siyuan-note-siyuan.md",
          "docs/_posts/2025-02-18-thiswillbeyourgithub-AnkiAIUtils.md",
          "docs/_posts/2025-02-18-unclecode-crawl4ai.md",
          "docs/_posts/2025-02-18-viccon-sturdyc.md",
          "docs/_posts/2025-02-18-yorukot-superfile.md",
          "docs/_posts/2025-02-19-AlexxIT-go2rtc.md",
          "docs/_posts/2025-02-19-All-Hands-AI-OpenHands.md",
          "docs/_posts/2025-02-19-Bin-Huang-chatbox.md",
          "docs/_posts/2025-02-19-Byaidu-PDFMathTranslate.md",
          "docs/_posts/2025-02-19-DioxusLabs-dioxus.md",
          "docs/_posts/2025-02-19-Dokploy-dokploy.md",
          "docs/_posts/2025-02-19-ItzCrazyKns-Perplexica.md",
          "docs/_posts/2025-02-19-ManimCommunity-manim.md",
          "docs/_posts/2025-02-19-QwenLM-Qwen-Agent.md",
          "docs/_posts/2025-02-19-QwenLM-Qwen2.5-Coder.md",
          "docs/_posts/2025-02-19-Skyvern-AI-skyvern.md",
          "docs/_posts/2025-02-19-Tencent-HunyuanVideo.md",
          "docs/_posts/2025-02-19-Zipstack-unstract.md",
          "docs/_posts/2025-02-19-aidenybai-react-scan.md",
          "docs/_posts/2025-02-19-al1abb-invoify.md",
          "docs/_posts/2025-02-19-anthropics-anthropic-cookbook.md",
          "docs/_posts/2025-02-19-awslabs-multi-agent-orchestrator.md",
          "docs/_posts/2025-02-19-black-forest-labs-flux.md",
          "docs/_posts/2025-02-19-bluewave-labs-Checkmate.md",
          "docs/_posts/2025-02-19-cyclotruc-gitingest.md",
          "docs/_posts/2025-02-19-deskflow-deskflow.md",
          "docs/_posts/2025-02-19-fishaudio-fish-speech.md",
          "docs/_posts/2025-02-19-freqtrade-freqtrade.md",
          "docs/_posts/2025-02-19-gitroomhq-postiz-app.md",
          "docs/_posts/2025-02-19-google-gemini-cookbook.md",
          "docs/_posts/2025-02-19-hcengineering-platform.md",
          "docs/_posts/2025-02-19-hengyoush-kyanos.md",
          "docs/_posts/2025-02-19-hoarder-app-hoarder.md",
          "docs/_posts/2025-02-19-khoj-ai-khoj.md",
          "docs/_posts/2025-02-19-leaningtech-webvm.md",
          "docs/_posts/2025-02-19-livekit-agents.md",
          "docs/_posts/2025-02-19-loco-rs-loco.md",
          "docs/_posts/2025-02-19-marimo-team-marimo.md",
          "docs/_posts/2025-02-19-microsoft-TinyTroupe.md",
          "docs/_posts/2025-02-19-mudler-LocalAI.md",
          "docs/_posts/2025-02-19-open-mmlab-Amphion.md",
          "docs/_posts/2025-02-19-pathwaycom-llm-app.md",
          "docs/_posts/2025-02-19-payloadcms-payload.md",
          "docs/_posts/2025-02-19-serafimcloud-21st.md",
          "docs/_posts/2025-02-19-soxoj-maigret.md",
          "docs/_posts/2025-02-19-stackblitz-bolt.new.md",
          "docs/_posts/2025-02-19-stackblitz-labs-bolt.diy.md",
          "docs/_posts/2025-02-19-stanford-oval-storm.md",
          "docs/_posts/2025-02-19-steel-dev-steel-browser.md",
          "docs/_posts/2025-02-19-stepfun-ai-Step-Audio.md",
          "docs/_posts/2025-02-20-BerriAI-litellm.md",
          "docs/_posts/2025-02-20-Melkeydev-go-blueprint.md",
          "docs/_posts/2025-02-20-NVIDIA-garak.md",
          "docs/_posts/2025-02-20-NVlabs-VILA.md",
          "docs/_posts/2025-02-20-NeverCease-uchu.md",
          "docs/_posts/2025-02-20-NovaSky-AI-SkyThought.md",
          "docs/_posts/2025-02-20-Open-Magic-Video-Magic-1-For-1.md",
          "docs/_posts/2025-02-20-SWivid-F5-TTS.md",
          "docs/_posts/2025-02-20-SeekStorm-SeekStorm.md",
          "docs/_posts/2025-02-20-ant-design-x.md",
          "docs/_posts/2025-02-20-antfu-shiki-stream.md",
          "docs/_posts/2025-02-20-blacklanternsecurity-bbot.md",
          "docs/_posts/2025-02-20-chaitin-SafeLine.md",
          "docs/_posts/2025-02-20-chonkie-ai-chonkie.md",
          "docs/_posts/2025-02-20-dhealy05-frames_of_mind.md",
          "docs/_posts/2025-02-20-dvershinin-gixy.md",
          "docs/_posts/2025-02-20-fuma-nama-fumadocs.md",
          "docs/_posts/2025-02-20-haydenbleasel-next-forge.md",
          "docs/_posts/2025-02-20-iBotPeaches-Apktool.md",
          "docs/_posts/2025-02-20-kunkunsh-kunkun.md",
          "docs/_posts/2025-02-20-langchain-ai-open-canvas.md",
          "docs/_posts/2025-02-20-lmnr-ai-flow.md",
          "docs/_posts/2025-02-20-loft-sh-vcluster.md",
          "docs/_posts/2025-02-20-luckjiawei-frpc-desktop.md",
          "docs/_posts/2025-02-20-mainmatter-100-exercises-to-learn-rust.md",
          "docs/_posts/2025-02-20-meshtastic-firmware.md",
          "docs/_posts/2025-02-20-microsoft-BitNet.md",
          "docs/_posts/2025-02-20-microsoft-ai-agents-for-beginners.md",
          "docs/_posts/2025-02-20-microsoft-graphrag.md",
          "docs/_posts/2025-02-20-motiondivision-motion.md",
          "docs/_posts/2025-02-20-nexus-xyz-nexus-zkvm.md",
          "docs/_posts/2025-02-20-opendatalab-MinerU.md",
          "docs/_posts/2025-02-20-outerbase-studio.md",
          "docs/_posts/2025-02-20-pixelfed-pixelfed.md",
          "docs/_posts/2025-02-20-projectdiscovery-nuclei.md",
          "docs/_posts/2025-02-20-rivet-gg-actor-core.md",
          "docs/_posts/2025-02-20-ruilisi-fortune-sheet.md",
          "docs/_posts/2025-02-20-soGeneri-awesome-launch.md",
          "docs/_posts/2025-02-20-spf13-cobra.md",
          "docs/_posts/2025-02-20-stepfun-ai-Step-Video-T2V.md",
          "docs/_posts/2025-02-20-taishikato-supavec.md",
          "docs/_posts/2025-02-20-teamhanko-hanko.md",
          "docs/_posts/2025-02-20-timescale-pgai.md",
          "docs/_posts/2025-02-20-trailbaseio-trailbase.md",
          "docs/_posts/2025-02-20-tursodatabase-libsql.md",
          "docs/_posts/2025-02-20-udecode-plate.md",
          "docs/_posts/2025-02-20-zcaceres-markdownify-mcp.md",
          "docs/_posts/2025-02-21-Azure-Azure-Sentinel.md",
          "docs/_posts/2025-02-21-Caldis-Mos.md",
          "docs/_posts/2025-02-21-FoundationVision-FlashVideo.md",
          "docs/_posts/2025-02-21-Gen-Verse-ReasonFlux.md"
        ],
        "fileTypes": {
          ".yml": 9,
          ".md": 172,
          ".lock": 1,
          ".npz": 1,
          ".json": 3,
          ".html": 9
        }
      }
    },
    {
      "id": 1152074677,
      "name": "babyagi3",
      "displayName": "babyagi3",
      "description": "No description available",
      "summary": "The Problem\nManaging tasks and automating interactions can be a real pain, especially when juggling multiple tools and workflows. You end up spending more time configuring systems than actually getting things done. BabyAGI 3 steps in to solve this by acting as a centralized AI agent that can remember things, send emails, and schedule tasks—all controlled through natural language.\n\nWhat This Does\nBabyAGI 3 is a minimal AI agent that simplifies your life. You kick it off by cloning the repo and running python main.py, and you’re good to go. The config.yaml file handles your API keys and user settings, while main.py orchestrates the entire operation. When you fire it up, BabyAGI checks for necessary configurations like OWNERNAME and OWNEREMAIL. If those are missing, it guides you through a setup dialogue, so you don’t need to fumble through a manual.\n\nThe project structure includes directories like listeners and memory, which manage interactions and data storage, respectively. For instance, listeners/email.py takes care of sending emails, while memory/context.py manages what the agent remembers. The whole system is designed to be a single loop: input -> LLM -> action -> execute -> output. \n\nReal-World Use\nImagine you’re swamped with tasks: research a topic, send follow-up emails, and schedule meetings. Instead of switching between tools, just tell BabyAGI: \"Research AI trends,\" or \"Send an email to my colleague.\" It’ll handle those requests as background tasks, keeping track of everything in memory/models.py. You can even ask it to \"remember that I have a meeting next Tuesday at 3 PM,\" and it’ll store that info for future reference.\n\nThe Bottom Line\nBabyAGI 3 is a handy tool if you’re drowning in tasks and want a digital assistant that actually remembers things. It’s straightforward to set up but can get pricey if you start running a lot of automations or using premium models. If you’re a solo developer or a small team looking to automate mundane tasks, give it a shot—but keep an eye on those costs if you scale up. Just be warned: if you’re looking for a silver bullet for team collaboration, this might be overkill.",
      "url": "https://github.com/yebeai/babyagi3",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "yoheinakajima/babyagi3",
        "url": "https://github.com/yoheinakajima/babyagi3",
        "stars": 114
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 7, 2026",
      "updatedAt": "February 7, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 107,
        "directories": {
          ".github": 1,
          "(root)": 19,
          "attached_assets": 1,
          "listeners": 6,
          "memory": 12,
          "metrics": 6,
          "senders": 5,
          "tests": 17,
          "tools": 34,
          "utils": 6
        },
        "languages": {
          "YAML": 2,
          "Markdown": 11,
          "Python": 88,
          "TOML": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "listeners/cli.py",
          "main.py",
          "senders/cli.py",
          "server.py"
        ],
        "configFiles": [
          "pyproject.toml"
        ],
        "dependencies": [
          "pyproject.toml"
        ],
        "testFiles": [
          "tests/__init__.py",
          "tests/conftest.py",
          "tests/test_agent.py",
          "tests/test_config.py",
          "tests/test_llm_config.py",
          "tests/test_memory_models.py",
          "tests/test_metrics_collector.py",
          "tests/test_metrics_costs.py",
          "tests/test_metrics_models.py",
          "tests/test_optional_tools.py",
          "tests/test_scheduler.py",
          "tests/test_secrets_optional_keys.py",
          "tests/test_senders.py",
          "tests/test_server.py",
          "tests/test_testing.py",
          "tests/test_tools_init.py",
          "tests/test_utils.py",
          "tools/testing.py"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "listeners/README.md",
          "memory/README.md",
          "metrics/README.md",
          "senders/README.md",
          "tools/README.md",
          "utils/README.md"
        ],
        "fileTypes": {
          ".yml": 1,
          ".md": 11,
          ".py": 88,
          ".txt": 1,
          ".yaml": 1,
          ".toml": 1,
          ".lock": 1
        }
      }
    },
    {
      "id": 1152066468,
      "name": "vibe-cv-resume",
      "displayName": "vibe cv resume",
      "description": "No description available",
      "summary": "The Problem\n\nTweaking your CV for every job is a nightmare. You copy-paste bullet points, try to shoehorn keywords, mess with layouts, and pray nothing breaks in LaTeX. Then you lose track of which version went where. It’s a manual, error-prone grind that feels stuck in 2010.\n\nWhat This Does\n\nThis repo treats your CV like code. The v1/master.tex file is your single source of truth. Each job gets its own folder (v1/canva/ or whatever), with a tailored main.tex and a jobdesc.md for the target job description. The prompts/jobdescmatch.md is basically your agent cheat sheet—feed this to Claude or GPT-4 and it’ll rewrite your CV bullets to fit the job posting.\n\nEverything runs inside a Docker dev container (.devcontainer/devcontainer.json), so you don’t have to fight with TeX Live installs. Versioning and branching happen in Git, meaning you can track edits, roll back garbage changes, and tag what you sent to recruiters. If you want to swap layouts, change the template and keep your content untouched.\n\nReal-World Use\n\nSay you’re applying to Canva. Drop their job description in v1/canva/jobdesc.md. Copy your base CV from v1/master.tex to v1/canva/main.tex. Fire up your agent, feed it the prompt from prompts/jobdescmatch.md, and let it churn out keyword-optimized bullets. Commit the changes, branch if needed, and you’re ready—no more guessing if your CV matches the posting.\n\nExample: generate a job-specific CV\ncp v1/master.tex v1/canva/main.tex\nPaste job description into v1/canva/jobdesc.md\nUse your agent with prompts/jobdesc_match.md to update main.tex\ngit add v1/canva/main.tex\ngit commit -m \"Optimized CV for Canva PM role\"\n\nThe Bottom Line\n\nIf you’re sick of manually hacking CVs and you already pay for AI tools, this setup is worth it. The folder structure makes sense, prompts are tested, and Docker saves you from LaTeX hell. Not for people who want to click around Word templates, but if you treat your CV like code, you’ll have more control and less headache.",
      "url": "https://github.com/yebeai/vibe-cv-resume",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "madnanrizqu/vibe-cv-resume",
        "url": "https://github.com/madnanrizqu/vibe-cv-resume",
        "stars": 67
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 7, 2026",
      "updatedAt": "February 7, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 8,
        "directories": {
          ".devcontainer": 1,
          "(root)": 3,
          "prompts": 1,
          "v1": 3
        },
        "languages": {
          "JSON": 1,
          "Markdown": 3
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".json": 1,
          ".md": 3,
          ".mp4": 1,
          ".tex": 2
        }
      }
    },
    {
      "id": 1152065926,
      "name": "llamacoder",
      "displayName": "llamacoder",
      "description": "Open source Claude Artifacts – built with Llama 3.1 405B",
      "summary": "LlamaCoder: Generate Small Apps from a Single Prompt\n\nThe Problem\n\nBuilding small apps is annoying when you're staring at a blank VSCode window. You either waste time setting up boilerplate, cobbling together dependencies, or trying to remember the exact syntax for setting up a Next.js app (again). Even worse, if you're not a developer, the barrier to entry is massive. You just want to throw in an idea and get something usable without wading through code hell.\n\nWhat This Does\n\nLlamaCoder is an open-source project that uses Meta's Llama 3.1 405B model and Together AI's inference API to generate app code based on a single prompt. You type what you want, and BAM—out comes a working app. Think ChatGPT’s code generation but tailored for quick app prototyping.\n\nThe core functionality lives in app/api/create-chat/route.ts, where it handles the prompt, talks to the Together AI API, and generates the app's structure. It even integrates with Sandpack (app/(main)/chats/[id]/code-viewer.tsx) to let you preview and play with the generated app right in the browser. The app/(main)/chats/[id]/chat-log.tsx handles the chat interface, while app/(main)/chats/[id]/code-viewer-layout.tsx gives you a clean layout to switch between code and chat.\n\nThe stack includes Tailwind (for styling), Prisma with PostgreSQL (for database stuff), and Helicone (to track API usage). It’s not throwing anything crazy at you—just solid, modern tools.\n\nReal-World Use\n\nLet’s say you want a simple app that tracks tasks. Drop a prompt like:  \n\"Build a task tracker app with a list of tasks, a checkbox to mark them as done, and a way to delete tasks.\"\n\nLlamaCoder generates the app, spins up the code, and drops it into a browser-based preview with Sandpack. You can tweak the code directly in code-viewer.tsx or download the project and run it locally with npm run dev. \n\nNeed to share your masterpiece? The app/(main)/chats/[id]/share.tsx creates a sharable link for your generated app, so you can wow your team or pretend you did all the work yourself.\n\nThe Bottom Line\n\nLlamaCoder is great for prototyping and demoing ideas. If you're a developer, it saves you from the boilerplate grind. If you're not, it lowers the barrier to building apps. That said, it's not magic—you'll still need to know how to debug the output. Great for hackathons and quick experiments, but don’t expect it to replace your day job. Yet.",
      "url": "https://github.com/yebeai/llamacoder",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Nutlope/llamacoder",
        "url": "https://github.com/Nutlope/llamacoder",
        "stars": 6878
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 7, 2026",
      "updatedAt": "February 7, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 118,
        "directories": {
          "(root)": 16,
          "app": 27,
          "components": 30,
          "hooks": 3,
          "lib": 23,
          "prisma": 5,
          "public": 14
        },
        "languages": {
          "JSON": 9,
          "Markdown": 3,
          "TypeScript": 18,
          "TSX": 58,
          "CSS": 1,
          "YAML": 1,
          "SQL": 3,
          "TOML": 1
        },
        "frameworks": [
          "React",
          "Next.js",
          "Tailwind"
        ],
        "packageManager": "pnpm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "lib/shadcn-docs/index.ts"
        ],
        "configFiles": [
          ".eslintrc.json",
          ".prettierrc",
          "next.config.ts",
          "package.json",
          "tailwind.config.ts",
          "tsconfig.json"
        ],
        "dependencies": [
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "lib/shadcn-docs/avatar.tsx",
          "lib/shadcn-docs/button.tsx",
          "lib/shadcn-docs/card.tsx",
          "lib/shadcn-docs/checkbox.tsx",
          "lib/shadcn-docs/index.ts",
          "lib/shadcn-docs/input.tsx",
          "lib/shadcn-docs/label.tsx",
          "lib/shadcn-docs/radio-group.tsx",
          "lib/shadcn-docs/select.tsx",
          "lib/shadcn-docs/textarea.tsx"
        ],
        "fileTypes": {
          ".json": 9,
          ".env": 1,
          ".md": 3,
          ".ts": 18,
          ".tsx": 58,
          ".ico": 1,
          ".css": 1,
          ".png": 8,
          ".txt": 1,
          ".yaml": 1,
          ".mjs": 1,
          ".sql": 3,
          ".toml": 1,
          ".prisma": 1,
          ".ttf": 3,
          ".otf": 3,
          ".svg": 1
        }
      }
    },
    {
      "id": 1152063101,
      "name": "VoiceInk",
      "displayName": "VoiceInk",
      "description": "Voice-to-text app for macOS to transcribe what you say to text almost instantly",
      "summary": "The Problem\nTranscribing voice to text can be a hassle. Most solutions either require an internet connection, compromising your privacy, or are just plain slow. VoiceInk tackles this issue head-on for macOS users, offering a fast, offline transcription solution that keeps your data where it belongs: on your device.\n\nWhat This Does\nVoiceInk is a native macOS app that utilizes local AI models to deliver almost instantaneous transcription with 99% accuracy. You can dive into the core logic behind the app in VoiceInk/AppDelegate.swift, where the application lifecycle is managed. The app's ability to recognize context and adapt on the fly is handled in VoiceInk/AppIntents/AppShortcuts.swift, making it feel smart without needing a permanent internet connection.\n\nWant to build it yourself? Check out BUILDING.md for the nitty-gritty on compiling the app. The Makefile is there to streamline your build process, though if you just want it to work, install it via Homebrew with brew install --cask voiceink. \n\nReal-World Use\nImagine you're drafting an email but don't want to stop typing to jot down ideas. With VoiceInk, you can set up global shortcuts for quick voice recording. Just hit your configured key combo, dictate your thoughts, and watch them appear in your email client without missing a beat. Using the Personal Dictionary feature, you can train the app to understand niche terminology, making it invaluable for professionals in specialized fields. \n\nThe Bottom Line\nVoiceInk is a solid choice for anyone needing a reliable voice-to-text solution on macOS. It’s fast, respects your privacy, and offers useful features like global shortcuts and a personal dictionary. However, it’s still in the early stages with 0 stars on GitHub, so expect some rough edges. If you’re a developer or a power user looking to contribute, this could be your playground. Just remember: it’s open-source, but don’t expect a polished corporate experience.",
      "url": "https://github.com/yebeai/VoiceInk",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Beingpax/VoiceInk",
        "url": "https://github.com/Beingpax/VoiceInk",
        "stars": 3993
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 7, 2026",
      "updatedAt": "February 7, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".github": 3,
          "(root)": 7,
          "VoiceInk.xcodeproj": 4,
          "VoiceInk": 186
        },
        "languages": {
          "Markdown": 7,
          "Swift": 156,
          "JSON": 5
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [
          "Makefile"
        ],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "VoiceInk/Models/LicenseViewModel.swift",
          "VoiceInk/Services/LicenseManager.swift",
          "VoiceInk/Views/LicenseManagementView.swift",
          "VoiceInk/Views/LicenseView.swift"
        ],
        "fileTypes": {
          ".md": 7,
          ".pbxproj": 1,
          ".xcworkspacedata": 1,
          ".xcsettings": 1,
          ".resolved": 1,
          ".swift": 156,
          ".json": 5,
          ".png": 8,
          ".plist": 1,
          ".wav": 1,
          ".mp3": 3,
          ".scpt": 11,
          ".bin": 1
        }
      }
    },
    {
      "id": 1151941627,
      "name": "VoiceAI",
      "displayName": "VoiceAI",
      "description": "Local voice assistant that learns new abilities via auto-discovered n8n workflows exposed as tools via MCP",
      "summary": "Building a Smarter Voice Assistant with VoiceAI\n\nThe Problem\n\nSo, you've got a voice assistant, but it either relies too much on the cloud, leaks your data to who-knows-where, or is about as useful as a paperweight when it comes to customization. You want local control, real privacy, and the ability to expand functionality without writing custom code for every small feature. That’s where VoiceAI steps in.\n\nWhat This Does\n\nVoiceAI is a local-first voice assistant, but the real magic is in how it integrates with n8n workflows. Any workflow you create in n8n can become a tool that the assistant uses, thanks to the MCP (Multi-Context Processing, if you care about acronyms). This isn't just a dumb wake-word bot—it can grow smarter on the fly, without over-complicated setups.\n\nThe project is Dockerized (see the Dockerfile and docker-compose.yaml files), so spinning it up is a 5-minute job. The .env.example file is where you set up your LAN IP and other configurations. For GPU-heavy tasks like STT (speech-to-text) or TTS (text-to-speech), it uses Ollama and Kokoro. Don’t have a GPU? No problem—just switch to the CPU mode with Groq and Piper by using docker-compose.cpu.yaml.\n\nThere are specific deployment setups too, like the Apple Silicon variant (docs/APPLE-SILICON.md) and a distributed deployment option (docs/DISTRIBUTED-DEPLOYMENT.md). The structure is well-thought-out, and the entrypoint.sh script ensures everything initializes smoothly.\n\nReal-World Use\n\nLet’s say you’ve got Home Assistant managing your smart home, but you want to automate more niche tasks. Maybe you want your assistant to order groceries when the fridge is low on milk. You set up an n8n workflow that triggers a grocery API when a \"milk low\" event is detected. Expose this workflow as a tool in VoiceAI using a simple webhook, and boom—your assistant now knows how to replenish the fridge.\n\nHere’s how you’d enable the CPU mode to test it out:\n\ngit clone https://github.com/CoreWorxLab/caal.git\ncd caal\ncp .env.example .env\nnano .env  # Set CAALHOSTIP to your local IP\ndocker compose -f docker-compose.cpu.yaml up -d\n\nOnce running, open up the web interface at http://YOURSERVERIP:3000, complete the setup wizard, and add your custom workflows.\n\nThe Bottom Line\n\nVoiceAI is like Jarvis for your smart home, but without Iron Man's budget—or his data security issues. It’s perfect for tinkerers, privacy nerds, and anyone tired of Alexa or Google Assistant’s limitations. But fair warning: if you’re allergic to Docker or don’t want to touch .env files, this might not be your jam. Still, for anyone who wants a truly customizable, local-first voice assistant, it’s a killer project. Get hacking.",
      "url": "https://github.com/yebeai/VoiceAI",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "CoreWorxLab/CAAL",
        "url": "https://github.com/CoreWorxLab/CAAL",
        "stars": 342
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 7, 2026",
      "updatedAt": "February 7, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 21,
          ".github": 4,
          "docs": 5,
          "frontend": 144,
          "mobile": 26
        },
        "languages": {
          "Markdown": 15,
          "YAML": 13,
          "Shell": 1,
          "JSON": 9,
          "TypeScript": 45,
          "TSX": 54,
          "CSS": 1,
          "Kotlin": 1
        },
        "frameworks": [
          "React",
          "Next.js",
          "Docker"
        ],
        "packageManager": "gradle",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "frontend/components/app/app.tsx",
          "frontend/components/setup/index.ts",
          "frontend/components/tools/index.ts"
        ],
        "configFiles": [
          ".env.example",
          "Dockerfile",
          "docker-compose.apple.yaml",
          "docker-compose.cpu.yaml",
          "docker-compose.dev.yml",
          "docker-compose.distributed.yml",
          "docker-compose.yaml",
          "frontend/.env.example",
          "frontend/.eslintrc.json",
          "frontend/.prettierrc",
          "frontend/Dockerfile",
          "frontend/next.config.ts",
          "frontend/package.json",
          "frontend/tsconfig.json",
          "mobile/.env.example",
          "mobile/android/app/build.gradle",
          "mobile/android/build.gradle"
        ],
        "dependencies": [
          "frontend/package.json",
          "mobile/android/app/build.gradle",
          "mobile/android/build.gradle"
        ],
        "testFiles": [
          "frontend/.github/workflows/build-and-test.yaml",
          "frontend/app/api/setup/test-groq/route.ts",
          "frontend/app/api/setup/test-hass/route.ts",
          "frontend/app/api/setup/test-n8n/route.ts",
          "frontend/app/api/setup/test-ollama/route.ts",
          "frontend/lib/__tests__/workflow-sanitizer.test.ts"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "docs/APPLE-SILICON.md",
          "docs/DISTRIBUTED-DEPLOYMENT.md",
          "docs/HOME-ASSISTANT.md",
          "docs/I18N.md",
          "docs/N8N-WORKFLOWS.md",
          "frontend/.github/assets/readme-hero.webp",
          "frontend/LICENSE",
          "frontend/README.md",
          "mobile/LICENSE",
          "mobile/README.md"
        ],
        "fileTypes": {
          ".example": 4,
          ".md": 15,
          ".yml": 3,
          ".yaml": 10,
          ".sh": 1,
          ".json": 9,
          ".webp": 5,
          ".svg": 5,
          ".ts": 45,
          ".tsx": 54,
          ".ico": 1,
          ".mjs": 2,
          ".otf": 4,
          ".woff": 2,
          ".png": 8,
          ".ppn": 1,
          ".pv": 1,
          ".css": 1,
          ".template": 1,
          ".gradle": 3,
          ".xml": 7,
          ".kt": 1,
          ".properties": 2,
          ".plist": 1
        }
      }
    },
    {
      "id": 1151940886,
      "name": "semantica",
      "displayName": "semantica",
      "description": "Semantica🧠: Open-Source Semantic Layer & Knowledge Engineering Framework for building Explainable, Auditable, and Trustworthy AI Systems — beyond Text Similarity",
      "summary": "The Problem\nAI systems often operate as black boxes, making it tough to trust their outputs. In high-stakes scenarios like healthcare or finance, this lack of transparency can lead to disastrous outcomes. You need a way to ensure that your AI isn’t just spitting out answers but is also explainable, auditable, and trustworthy.\n\nWhat This Does\nSemantica is designed to bridge that semantic gap. It’s not just another run-of-the-mill framework; it focuses on creating a semantic intelligence layer. The semanticextract module contains the NERExtractor, which helps you extract entities from text, while the kg module's GraphBuilder constructs knowledge graphs that keep track of these entities and their relationships.\n\nThe project's structure is solid. You’ve got .github folders for issues and discussions, which means the maintainers are serious about community engagement. The CHANGELOG.md helps you keep track of updates, while CONTRIBUTING.md outlines how to get involved if you're feeling generous with your time.\n\nReal-World Use\nImagine you're building a healthcare application. You need to analyze patient records and ensure that your AI can explain its decisions. You'd start with:\n\nfrom semantica.semanticextract import NERExtractor\nfrom semantica.kg import GraphBuilder\n\nner = NERExtractor(method=\"ml\", model=\"encoreweb_sm\")\nentities = ner.extract(\"Patient John Doe was diagnosed with diabetes.\")\nkg = GraphBuilder().build({\"entities\": entities, \"relationships\": []})\n\nprint(f\"Built KG with {len(kg.get('entities', []))} entities\")\n\nThis snippet fetches relevant entities and builds a knowledge graph, allowing you to trace decisions back to their origins. It’s not just about what the AI says, but why it says it.\n\nThe Bottom Line\nSemantica is a solid choice if you need to build trustworthy AI systems, especially in high-stakes domains. It's not for small projects or those who are just dabbling in AI; this is for serious applications where accountability matters. The integration with other frameworks like LangChain is a nice touch, but it comes with a learning curve. If you need transparency and auditability, give Semantica a look.",
      "url": "https://github.com/yebeai/semantica",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Hawksight-AI/semantica",
        "url": "https://github.com/Hawksight-AI/semantica",
        "stars": 711
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 7, 2026",
      "updatedAt": "February 7, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 16,
          ".github": 18,
          "cookbook": 136,
          "docs": 30
        },
        "languages": {
          "Markdown": 47,
          "YAML": 11,
          "Python": 1,
          "JSON": 15,
          "HTML": 1,
          "CSS": 1,
          "TOML": 1
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          "docker-compose.yml"
        ],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "CHANGELOG.md",
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "cookbook/use_cases/advanced_rag/expert_guide.txt",
          "cookbook/use_cases/advanced_rag/expert_skincare_guide.txt",
          "docs/CodeExamples.md",
          "docs/DOCS_README.md",
          "docs/LIBS_README.md",
          "docs/architecture.md",
          "docs/arrow_exporter.md",
          "docs/assets/img/Semantica Logo.png",
          "docs/citation.md",
          "docs/community-projects.md",
          "docs/community.md",
          "docs/concepts.md",
          "docs/contributing.md",
          "docs/cookbook.md",
          "docs/css/custom.css",
          "docs/deep-dive.md",
          "docs/examples.md",
          "docs/faq.md",
          "docs/getting-started.md",
          "docs/glossary.md",
          "docs/governance.md",
          "docs/index.md",
          "docs/installation.md",
          "docs/integrations/docling.md",
          "docs/integrations/snowflake.md",
          "docs/learning-more.md",
          "docs/license.md",
          "docs/modules.md",
          "docs/netlify.toml",
          "docs/quickstart.md",
          "docs/reference/change_management.md",
          "docs/reference/conflicts.md"
        ],
        "fileTypes": {
          ".md": 47,
          ".yml": 8,
          ".yaml": 3,
          ".png": 2,
          ".ipynb": 47,
          ".ttl": 4,
          ".py": 1,
          ".txt": 41,
          ".graphml": 12,
          ".json": 15,
          ".dot": 1,
          ".gexf": 1,
          ".html": 1,
          ".csv": 11,
          ".css": 1,
          ".toml": 1
        }
      }
    },
    {
      "id": 1151939786,
      "name": "compasso",
      "displayName": "compasso",
      "description": "A finance tracking app that parses bank PDF ledgers, categorizes transactions with smart suggestions, and displays data in an interactive dashboard.",
      "summary": "The Problem\n\nBank statements are a nightmare—PDFs full of cryptic transactions, impossible to categorize, and nowhere near anything you'd call “insightful.” Most finance apps choke on local privacy or force you to hand over credentials. If you want to track spending without selling your soul (or your data), you’re stuck with spreadsheets and rage.\n\nWhat This Does\n\ncompasso takes those ugly bank PDFs (Novo Banco and CGD supported out of the box) and turns them into actual, usable data. The backend (apps/api/src/parsers/cgd.ts) parses PDF ledgers, extracting every transaction into a local SQLite database—no cloud nonsense, just data on your machine. Smart categorization happens via pattern matching in the backend, with suggestions you can override. The frontend (apps/web) gives you charts, dashboards, and reports that don’t look like they were made in 2005.\n\nMulti-user and multi-workspace are baked in. You get authentication (apps/api/src/middleware/auth.ts), session management, and granular roles—owners, editors, viewers. Collaboration is a real thing: invite people by email or username, and back up or restore workspaces if you screw something up.\n\nReal-World Use\n\nLet’s say you’ve got a stack of PDFs from CGD. Drag one into the Upload page, the parser (parsers/cgd.ts) does its thing, and you get a categorized list of transactions. Maybe the parser suggests \"Groceries\" for “LIDL*”. You can tweak categories, add custom patterns (“Pizza Hut” goes to “Takeout”—obviously). Want a monthly report? Click around—charts update instantly, pulled from the local SQLite DB.\n\nExample:  \n\n// apps/api/src/parsers/cgd.ts\nconst transactions = parseCGDPdf(buffer);\ndb.insertTransactions(transactions, workspaceId);\n\nNo external API calls. No account linking. Your data stays put.\n\nThe Bottom Line\n\nIf you want finance tracking without cloud drama or privacy trade-offs, compasso is legit. Setup is easy, the UI doesn’t suck, and the PDF parser actually works. Downsides: only a couple banks supported, and it’s not for people afraid of a terminal. For devs and privacy nerds, it’s a breath of fresh air. For everyone else—stick to Mint and pray they don’t get hacked again.",
      "url": "https://github.com/yebeai/compasso",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "s3rgiosan/compasso",
        "url": "https://github.com/s3rgiosan/compasso",
        "stars": 9
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 7, 2026",
      "updatedAt": "February 7, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 179,
        "directories": {
          "(root)": 14,
          ".github": 2,
          "apps": 157,
          "packages": 6
        },
        "languages": {
          "JSON": 13,
          "Markdown": 3,
          "YAML": 2,
          "TypeScript": 107,
          "HTML": 1,
          "JavaScript": 2,
          "TSX": 41,
          "CSS": 1
        },
        "frameworks": [
          "React",
          "Tailwind",
          "Docker"
        ],
        "packageManager": "npm",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "apps/api/src/index.ts",
          "apps/api/src/routes/index.ts",
          "apps/web/index.html",
          "apps/web/src/App.tsx",
          "apps/web/src/i18n/index.ts",
          "apps/web/src/services/api/index.ts",
          "packages/shared/src/index.ts"
        ],
        "configFiles": [
          ".env.example",
          ".eslintrc.json",
          ".prettierrc",
          "Dockerfile",
          "apps/api/package.json",
          "apps/api/tsconfig.json",
          "apps/web/package.json",
          "apps/web/tailwind.config.js",
          "apps/web/tsconfig.json",
          "apps/web/vite.config.ts",
          "docker-compose.yml",
          "package.json",
          "packages/shared/package.json",
          "packages/shared/tsconfig.json",
          "tsconfig.json"
        ],
        "dependencies": [
          "apps/api/package.json",
          "apps/web/package.json",
          "package-lock.json",
          "package.json",
          "packages/shared/package.json"
        ],
        "testFiles": [
          "apps/api/src/db/seed.test.ts",
          "apps/api/src/errors.test.ts",
          "apps/api/src/middleware/auth.test.ts",
          "apps/api/src/middleware/errorHandler.test.ts",
          "apps/api/src/middleware/validate.test.ts",
          "apps/api/src/parsers/cgd.test.ts",
          "apps/api/src/parsers/novo-banco.test.ts",
          "apps/api/src/routes/auth.test.ts",
          "apps/api/src/routes/backup.test.ts",
          "apps/api/src/routes/categories.test.ts",
          "apps/api/src/routes/dashboard.test.ts",
          "apps/api/src/routes/invitations.test.ts",
          "apps/api/src/routes/recurring.test.ts",
          "apps/api/src/routes/reports.test.ts",
          "apps/api/src/routes/test-helpers.ts",
          "apps/api/src/routes/transactions.test.ts",
          "apps/api/src/routes/upload.test.ts",
          "apps/api/src/routes/workspaces.test.ts",
          "apps/api/src/services/authService.test.ts",
          "apps/api/src/services/backupService.test.ts",
          "apps/api/src/services/categoryMatcher.test.ts",
          "apps/api/src/services/categoryService.test.ts",
          "apps/api/src/services/dashboardService.test.ts",
          "apps/api/src/services/emailService.test.ts",
          "apps/api/src/services/memberService.test.ts",
          "apps/api/src/services/passwordResetService.test.ts",
          "apps/api/src/services/recategorizer.test.ts",
          "apps/api/src/services/recurringDetector.test.ts",
          "apps/api/src/services/reportsService.test.ts",
          "apps/api/src/services/transactionService.test.ts",
          "apps/api/src/services/uploadService.test.ts",
          "apps/api/src/services/workspaceManagementService.test.ts",
          "apps/api/src/services/workspaceService.test.ts",
          "apps/api/src/utils/queryHelpers.test.ts",
          "apps/api/vitest.config.ts"
        ],
        "docs": [
          ".github/BANK_PARSER_GUIDE.md",
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".example": 1,
          ".json": 13,
          ".md": 3,
          ".yml": 2,
          ".ts": 107,
          ".html": 1,
          ".js": 2,
          ".svg": 1,
          ".tsx": 41,
          ".css": 1
        }
      }
    },
    {
      "id": 1151728663,
      "name": "awesome-llm-apps",
      "displayName": "awesome llm apps",
      "description": "Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.",
      "summary": "The Problem\nBuilding intelligent applications that harness the power of large language models (LLMs) can be a hassle. You’ve got to wrangle various models, configure them correctly, and then figure out how to make them work together. It’s a lot of effort for something that should be straightforward.\n\nWhat This Does\nThe awesome-llm-apps repository is like a buffet of LLM-powered applications, offering a collection of projects that utilize models from OpenAI, Anthropic, Google’s Gemini, and more. You’ll find everything from autonomous game-playing agents in the advancedaiagents/autonomousgameplayingagentapps/ directory, to multi-agent teams in advancedaiagents/multiagentapps/. Each project comes with a README.md, which is your guide to understanding how to set it up and what dependencies are required, often listed in the requirements.txt files. \n\nFor instance, if you dive into aichessagent/aichessagent.py, you’ll see how this agent plays chess using a combination of LLMs and custom logic. Want to build a finance bot? Check out aifinanceagentteam/financeagentteam.py, where you can see how to set it up for financial analysis.\n\nReal-World Use\nImagine you’re tasked with creating a simple AI chess app. You clone the repo, navigate to advancedaiagents/autonomousgameplayingagentapps/aichessagent/, and run the provided requirements.txt with pip install -r requirements.txt. You tweak aichess_agent.py to fit your needs, maybe integrating it with a web app using Flask to expose an API for your chess game. Before you know it, you’ve got a working prototype up and running.\n\nThe Bottom Line\nThis repo is a solid starting point for anyone looking to play around with LLMs and AI agents, especially for those with a bit of coding know-how. It’s not a one-size-fits-all solution—some projects might feel overly complex for simple tasks. But if you’re in the market for inspiration or a quick jumpstart on an LLM app, it’s worth a look. Just remember, you’re still going to need to roll up your sleeves and do some coding.",
      "url": "https://github.com/yebeai/awesome-llm-apps",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Shubhamsaboo/awesome-llm-apps",
        "url": "https://github.com/Shubhamsaboo/awesome-llm-apps",
        "stars": 97661
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 6, 2026",
      "updatedAt": "February 6, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".github": 1,
          "(root)": 2,
          "advanced_ai_agents": 197
        },
        "languages": {
          "YAML": 2,
          "Markdown": 29,
          "Python": 84,
          "Shell": 1,
          "SQL": 6,
          "TOML": 2,
          "TypeScript": 11,
          "TSX": 26,
          "CSS": 1,
          "JSON": 3
        },
        "frameworks": [
          "React",
          "Next.js",
          "Flask",
          "Docker"
        ],
        "packageManager": "pip",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "advanced_ai_agents/autonomous_game_playing_agent_apps/ai_tic_tac_toe_agent/app.py",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/backend/api/app.py",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/backend/main.py"
        ],
        "configFiles": [
          "advanced_ai_agents/autonomous_game_playing_agent_apps/ai_3dpygame_r1/requirements.txt",
          "advanced_ai_agents/autonomous_game_playing_agent_apps/ai_chess_agent/requirements.txt",
          "advanced_ai_agents/autonomous_game_playing_agent_apps/ai_tic_tac_toe_agent/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_competitor_intelligence_agent_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_finance_agent_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_game_design_agent_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_legal_agent_team/local_ai_legal_agent_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_legal_agent_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_real_estate_agent_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_recruitment_agent_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_sales_intelligence_agent_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_seo_audit_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_services_agency/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_teaching_agent_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/backend/.env.example",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/backend/Dockerfile",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/backend/pyproject.toml",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/client/.env.example",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/client/next.config.ts",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/client/package.json",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/client/tsconfig.json",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_vc_due_diligence_agent_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_coding_agent_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_design_agent_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_uiux_feedback_agent_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/ai_Self-Evolving_agent/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/ai_aqi_analysis_agent/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/ai_domain_deep_research_agent/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/ai_email_gtm_outreach_agent/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/ai_financial_coach_agent/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/ai_home_renovation_agent/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/ai_mental_wellbeing_agent/requirements.txt"
        ],
        "dependencies": [
          "advanced_ai_agents/autonomous_game_playing_agent_apps/ai_3dpygame_r1/requirements.txt",
          "advanced_ai_agents/autonomous_game_playing_agent_apps/ai_chess_agent/requirements.txt",
          "advanced_ai_agents/autonomous_game_playing_agent_apps/ai_tic_tac_toe_agent/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_competitor_intelligence_agent_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_finance_agent_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_game_design_agent_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_legal_agent_team/local_ai_legal_agent_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_legal_agent_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_real_estate_agent_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_recruitment_agent_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_sales_intelligence_agent_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_seo_audit_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_services_agency/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_teaching_agent_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/backend/pyproject.toml",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/client/package.json",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_vc_due_diligence_agent_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_coding_agent_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_design_agent_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_uiux_feedback_agent_team/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/ai_Self-Evolving_agent/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/ai_aqi_analysis_agent/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/ai_domain_deep_research_agent/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/ai_email_gtm_outreach_agent/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/ai_financial_coach_agent/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/ai_home_renovation_agent/requirements.txt",
          "advanced_ai_agents/multi_agent_apps/ai_mental_wellbeing_agent/requirements.txt"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md",
          "advanced_ai_agents/autonomous_game_playing_agent_apps/ai_3dpygame_r1/README.md",
          "advanced_ai_agents/autonomous_game_playing_agent_apps/ai_chess_agent/README.md",
          "advanced_ai_agents/autonomous_game_playing_agent_apps/ai_tic_tac_toe_agent/README.md",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_competitor_intelligence_agent_team/README.md",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_finance_agent_team/README.md",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_game_design_agent_team/README.md",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_legal_agent_team/README.md",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_legal_agent_team/local_ai_legal_agent_team/README.md",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_real_estate_agent_team/README.md",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_recruitment_agent_team/README.md",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_sales_intelligence_agent_team/README.md",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_seo_audit_team/README.md",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_services_agency/README.md",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_teaching_agent_team/README.md",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/README.md",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/backend/agents/README.md",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/client/README.md",
          "advanced_ai_agents/multi_agent_apps/agent_teams/ai_vc_due_diligence_agent_team/README.md",
          "advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_coding_agent_team/README.md",
          "advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_design_agent_team/README.md",
          "advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_uiux_feedback_agent_team/README.md",
          "advanced_ai_agents/multi_agent_apps/ai_Self-Evolving_agent/README.md",
          "advanced_ai_agents/multi_agent_apps/ai_aqi_analysis_agent/README.md",
          "advanced_ai_agents/multi_agent_apps/ai_domain_deep_research_agent/README.md",
          "advanced_ai_agents/multi_agent_apps/ai_email_gtm_outreach_agent/README.md",
          "advanced_ai_agents/multi_agent_apps/ai_financial_coach_agent/README.md",
          "advanced_ai_agents/multi_agent_apps/ai_home_renovation_agent/README.md",
          "advanced_ai_agents/multi_agent_apps/ai_mental_wellbeing_agent/README.md"
        ],
        "fileTypes": {
          ".yml": 1,
          ".md": 29,
          ".py": 84,
          ".txt": 25,
          ".example": 2,
          ".sh": 1,
          ".sql": 6,
          ".toml": 2,
          ".lock": 1,
          ".ts": 11,
          ".tsx": 26,
          ".ico": 1,
          ".css": 1,
          ".json": 3,
          ".mjs": 2,
          ".yaml": 1,
          ".prisma": 1
        }
      }
    },
    {
      "id": 1151727435,
      "name": "agentql",
      "displayName": "agentql",
      "description": "AgentQL is a suite of tools for connecting your AI to the web. Featuring a query language and Playwright integrations for interacting with elements and extracting data quickly, precisely, and at scale. Includes REST API, Python and JavaScript SDKs, browser debugger.",
      "summary": "The Problem\nWeb scraping is a pain. Websites change their structure all the time, and if you're not careful, your carefully crafted scraping scripts break faster than you can say “HTTP error.” Plus, dealing with authentication and dynamic content can make the whole process feel like pulling teeth. If you've ever spent hours tweaking your selectors just to get a single data point, you know what I mean.\n\nWhat This Does\nEnter AgentQL. This suite of tools lets you connect your AI to web data without losing your sanity. It provides a natural language query language to extract data from live sites, even if they’re behind a login or dynamic content. The README.md does a decent job of laying out the features, but the real magic happens in the examples folder, which contains Jupyter notebooks that demonstrate various use cases, like logging into sites and collecting paginated data.\n\nThe integration with Playwright is a standout feature. You can easily run automation scripts using the Python SDK or JavaScript SDK, both of which have their respective installation guides linked in the README. The templates/python/templatesync.py gives you a solid starting point to build your own queries, while the examples/googlecolab directory provides practical scenarios to get you up and running with minimal fuss.\n\nReal-World Use\nImagine you need to scrape product prices from a competitor's site that requires login and has infinite scroll. With AgentQL, you can define a natural language query to pull that data, and the built-in resilience means it won't break as the site updates. Here's a quick snippet to illustrate:\n\nfrom agentql import AgentQL\n\nquery = AgentQL(\"Get all product prices from the electronics section\")\ndata = query.run(url=\"https://competitorsite.com/electronics\", loginrequired=True)\nprint(data)\n\nThis lets you focus on extracting the data you need rather than wrestling with HTML selectors.\n\nThe Bottom Line\nAgentQL is a solid tool for developers looking to scrape data from the web without the usual headaches. It's not for small projects since it brings in some complexity and overhead. But if you're regularly scraping data or automating workflows, this could save you a lot of time. Just be prepared to dig into the docs if you want to get the most out of it.",
      "url": "https://github.com/yebeai/agentql",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "tinyfish-io/agentql",
        "url": "https://github.com/tinyfish-io/agentql",
        "stars": 1255
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 6, 2026",
      "updatedAt": "February 6, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 142,
        "directories": {
          "(root)": 8,
          ".github": 6,
          ".templates": 4,
          ".vscode": 3,
          "examples": 121
        },
        "languages": {
          "YAML": 5,
          "JSON": 6,
          "JavaScript": 27,
          "Markdown": 51,
          "Python": 27,
          "TOML": 2
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "poetry",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "examples/js/close-cookie-dialog/main.js",
          "examples/js/close-popup/main.js",
          "examples/js/collect-paginated-ecommerce-data/main.js",
          "examples/js/collect-paginated-news-headlines/main.js",
          "examples/js/collect-pricing-data/main.js",
          "examples/js/collect-youtube-comments/main.js",
          "examples/js/compare-product-prices/main.js",
          "examples/js/first-steps/main.js",
          "examples/js/get-by-prompt/main.js",
          "examples/js/humanlike-antibot/main.js",
          "examples/js/infinite-scroll/main.js",
          "examples/js/list-query-usage/main.js",
          "examples/js/log-into-sites/main.js",
          "examples/js/maps_scraper/main.js",
          "examples/js/news-aggregator/main.js",
          "examples/js/perform-sentiment-analysis/main.js",
          "examples/js/run-script-in-headless-browser/main.js",
          "examples/js/save-and-load-authenticated-session/main.js",
          "examples/js/stealth-mode/main.js",
          "examples/js/submit-form/main.js",
          "examples/js/use-existing-browser/main.js",
          "examples/js/use-remote-browser/main.js",
          "examples/js/wait-for-entire-page-load/main.js",
          "examples/js/xpath/main.js",
          "examples/python/close_cookie_dialog/main.py",
          "examples/python/close_popup/main.py",
          "examples/python/collect_ecommerce_pricing_data/main.py",
          "examples/python/collect_paginated_ecommerce_listing_data/main.py",
          "examples/python/collect_paginated_news_headlines/main.py",
          "examples/python/compare_product_prices/main.py",
          "examples/python/first_steps/main.py",
          "examples/python/get_by_prompt/main.py",
          "examples/python/humanlike-antibot/main.py",
          "examples/python/infinite_scroll/main.py",
          "examples/python/list_query_usage/main.py",
          "examples/python/log_into_sites/main.py",
          "examples/python/maps_scraper/main.py",
          "examples/python/news-aggregator/main.py",
          "examples/python/perform_sentiment_analysis/main.py",
          "examples/python/run_script_in_headless_browser/main.py",
          "examples/python/save_and_load_authenticated_session/main.py",
          "examples/python/stealth_mode/main.py",
          "examples/python/submit_form/main.py",
          "examples/python/use_existing_browser/main.py",
          "examples/python/use_remote_browser/main.py",
          "examples/python/wait_for_entire_page_load/main.py",
          "examples/python/xpath/main.py"
        ],
        "configFiles": [
          "Makefile",
          "examples/js/.eslintrc.js",
          "examples/js/.prettierrc.js",
          "examples/js/package.json",
          "examples/python/pyproject.toml"
        ],
        "dependencies": [
          "examples/js/package-lock.json",
          "examples/js/package.json",
          "examples/python/poetry.lock",
          "examples/python/pyproject.toml"
        ],
        "testFiles": [],
        "docs": [
          ".templates/python/README.md",
          "LICENSE",
          "README.md",
          "examples/js/close-cookie-dialog/README.md",
          "examples/js/close-popup/README.md",
          "examples/js/collect-paginated-ecommerce-data/README.md",
          "examples/js/collect-paginated-news-headlines/README.md",
          "examples/js/collect-pricing-data/README.md",
          "examples/js/collect-youtube-comments/README.md",
          "examples/js/compare-product-prices/README.md",
          "examples/js/first-steps/README.md",
          "examples/js/get-by-prompt/README.md",
          "examples/js/humanlike-antibot/README.md",
          "examples/js/infinite-scroll/README.md",
          "examples/js/list-query-usage/README.md",
          "examples/js/log-into-sites/README.md",
          "examples/js/maps_scraper/README.md",
          "examples/js/news-aggregator/README.md",
          "examples/js/perform-sentiment-analysis/README.md",
          "examples/js/run-script-in-headless-browser/README.md",
          "examples/js/save-and-load-authenticated-session/README.md",
          "examples/js/stealth-mode/README.md",
          "examples/js/submit-form/README.md",
          "examples/js/use-existing-browser/README.md",
          "examples/js/use-remote-browser/README.md",
          "examples/js/wait-for-entire-page-load/README.md",
          "examples/js/xpath/README.md",
          "examples/python/close_cookie_dialog/README.md",
          "examples/python/close_popup/README.md",
          "examples/python/collect_ecommerce_pricing_data/README.md",
          "examples/python/collect_paginated_ecommerce_listing_data/README.md",
          "examples/python/collect_paginated_news_headlines/README.md",
          "examples/python/compare_product_prices/README.md",
          "examples/python/first_steps/README.md",
          "examples/python/get_by_prompt/README.md",
          "examples/python/humanlike-antibot/README.md",
          "examples/python/infinite_scroll/README.md",
          "examples/python/list_query_usage/README.md",
          "examples/python/log_into_sites/README.md",
          "examples/python/maps_scraper/README.md",
          "examples/python/news-aggregator/README.md",
          "examples/python/perform_sentiment_analysis/README.md",
          "examples/python/run_script_in_headless_browser/README.md",
          "examples/python/run_script_online_in_google_colab/README.md",
          "examples/python/save_and_load_authenticated_session/README.md",
          "examples/python/stealth_mode/README.md",
          "examples/python/submit_form/README.md",
          "examples/python/use_existing_browser/README.md",
          "examples/python/use_remote_browser/README.md",
          "examples/python/wait_for_entire_page_load/README.md",
          "examples/python/xpath/README.md"
        ],
        "fileTypes": {
          ".yaml": 1,
          ".yml": 4,
          ".json": 6,
          ".js": 27,
          ".md": 51,
          ".py": 27,
          ".ipynb": 11,
          ".csv": 3,
          ".lock": 1,
          ".toml": 2
        }
      }
    },
    {
      "id": 1151722325,
      "name": "call-center-ai",
      "displayName": "call center ai",
      "description": "Send a phone call from AI agent, in an API call. Or, directly call the bot from the configured phone number!",
      "summary": "The Problem\nCall centers are often bogged down by repetitive inquiries and lengthy wait times. Customers get frustrated, agents get overwhelmed, and the whole experience is a mess. You need a way to handle calls efficiently without adding more human resources to the mix.\n\nWhat This Does\nThe call-center-ai repo lets you send calls from an AI agent via a simple API call. Just look at the app/helpers/callllm.py file for the logic behind the AI's call handling. It uses Azure and OpenAI's GPT to manage conversations intelligently, and it can handle low to medium complexity calls without breaking a sweat.\n\nYou can customize the AI’s responses and behavior by tweaking files in the app/helpers/configmodels/ directory. Want to change how the bot interacts based on the type of inquiry? Just update the relevant model. The bot even stores conversation history for future reference, which is handy for improving accuracy over time.\n\nReal-World Use\nImagine you run an IT support call center. A user calls in needing help with a software issue. You send a POST request to the /call endpoint, passing in the required details like phonenumber, task, and claim attributes. Here's how that looks:\n\ndata='{\n  \"botcompany\": \"Contoso\",\n  \"botname\": \"Amélie\",\n  \"phonenumber\": \"+11234567890\",\n  \"task\": \"Help the customer with their software issue.\",\n  \"agentphonenumber\": \"+33612345678\",\n  \"claim\": [\n    {\n      \"name\": \"issue_description\",\n      \"type\": \"text\"\n    }\n  ]\n}'\n\ncurl --header 'Content-Type: application/json' --request POST --url https://xxx/call --data $data\n\nThe bot interacts with the customer, gathers the necessary information, and even creates a to-do list for follow-up—all while you kick back with your coffee.\n\nThe Bottom Line\nThis repo is a solid choice for medium to large call centers looking to reduce workload and improve customer experience. The AI's ability to handle calls is impressive, but it might be overkill for smaller operations. If you're in a high-volume environment and want a customizable solution, give this a shot. Just keep an eye on Azure costs; they can creep up on you.",
      "url": "https://github.com/yebeai/call-center-ai",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "microsoft/call-center-ai",
        "url": "https://github.com/microsoft/call-center-ai",
        "stars": 6345
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 6, 2026",
      "updatedAt": "February 6, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 102,
        "directories": {
          ".devcontainer": 1,
          "(root)": 14,
          ".github": 3,
          ".vscode": 2,
          "app": 64,
          "cicd": 3,
          "docs": 3,
          "examples": 2,
          "public": 2,
          "tests": 8
        },
        "languages": {
          "JSON": 4,
          "YAML": 7,
          "Markdown": 2,
          "Python": 64,
          "TOML": 1
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "app/main.py"
        ],
        "configFiles": [
          ".env.example",
          "Makefile",
          "cicd/Dockerfile",
          "pyproject.toml"
        ],
        "dependencies": [
          "pyproject.toml"
        ],
        "testFiles": [
          "tests/__init__.py",
          "tests/cache.py",
          "tests/conftest.py",
          "tests/conversations.yaml",
          "tests/llm.py",
          "tests/local.py",
          "tests/search.py",
          "tests/store.py"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "app/resources/tiktoken/README.md",
          "docs/demo.json",
          "docs/demo.mp4",
          "docs/user_report.png"
        ],
        "fileTypes": {
          ".json": 4,
          ".example": 1,
          ".yml": 2,
          ".yaml": 5,
          ".config": 1,
          ".md": 2,
          ".py": 64,
          ".jinja": 4,
          ".bicep": 2,
          ".mp4": 1,
          ".png": 1,
          ".csv": 1,
          ".ipynb": 1,
          ".xml": 1,
          ".wav": 1,
          ".toml": 1,
          ".lock": 1
        }
      }
    },
    {
      "id": 1151697939,
      "name": "tview",
      "displayName": "tview",
      "description": "Terminal UI library with rich, interactive widgets — written in Golang",
      "summary": "The Problem\nBuilding terminal UIs can be a pain in the neck. You often end up reinventing the wheel with basic components like buttons, checkboxes, or even layouts. If you’ve ever spent hours fighting with ASCII art to align elements on the screen, you know exactly what I mean.\n\nWhat This Does\nEnter tview, a Go package that gives you interactive widgets for terminal-based user interfaces. It’s like someone took all the common UI elements you need and wrapped them up in a neat little package. You can find everything from checkboxes in checkbox.go to buttons in button.go. The application.go file is the real MVP here—it sets up your app's main loop and manages the UI components.\n\nWant to create a simple box with a title? Check out the Hello World example in README.md. Just whip up a few lines of code, and you’ve got a bordered box titled “Hello, world!” without breaking a sweat. The demos folder is packed with examples to get you started—pick any of the main.go files, run them, and watch your terminal come alive.\n\nReal-World Use\nLet’s say you’re building a CLI tool to manage server configurations. Instead of crafting your own UI components, you can use tview to create a user-friendly interface. For instance, use tview.NewForm() to gather user inputs effortlessly, making it easy to get values for different configuration parameters. Your users will appreciate not having to remember command-line flags when they can just check a box or fill out a field.\n\nHere’s a snippet that shows how you might set up a form:\n\nform := tview.NewForm().\n    AddInputField(\"Host\", \"\", 20, nil).\n    AddInputField(\"Port\", \"\", 5, nil).\n    AddButton(\"Save\", func() {\n        // Handle saving logic\n    })\n\nThe Bottom Line\ntview is a solid choice if you need to whip up a terminal UI quickly without dealing with the grunt work of layout management. It’s feature-rich and has a decent number of demo applications to get your creative juices flowing. However, if your project is small and straightforward, this might feel like overkill. Save it for times when you need a polished interface that doesn’t look like it was designed in the ‘80s.",
      "url": "https://github.com/yebeai/tview",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "rivo/tview",
        "url": "https://github.com/rivo/tview",
        "stars": 13608
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 6, 2026",
      "updatedAt": "February 6, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 119,
        "directories": {
          ".github": 1,
          "(root)": 32,
          "demos": 86
        },
        "languages": {
          "YAML": 1,
          "Markdown": 23,
          "Go": 64
        },
        "frameworks": [],
        "packageManager": "go modules",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "demos/box/main.go",
          "demos/button/main.go",
          "demos/checkbox/main.go",
          "demos/dropdown/main.go",
          "demos/flex/main.go",
          "demos/form/main.go",
          "demos/frame/main.go",
          "demos/grid/main.go",
          "demos/image/main.go",
          "demos/inputfield/autocomplete/main.go",
          "demos/inputfield/autocompleteasync/main.go",
          "demos/inputfield/main.go",
          "demos/list/main.go",
          "demos/modal/main.go",
          "demos/pages/main.go",
          "demos/presentation/main.go",
          "demos/primitive/main.go",
          "demos/table/main.go",
          "demos/table/virtualtable/main.go",
          "demos/textarea/main.go",
          "demos/textview/chat/main.go",
          "demos/textview/main.go",
          "demos/treeview/main.go",
          "demos/unicode/main.go"
        ],
        "configFiles": [
          "go.mod"
        ],
        "dependencies": [
          "go.mod"
        ],
        "testFiles": [],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE.txt",
          "README.md",
          "demos/box/README.md",
          "demos/button/README.md",
          "demos/checkbox/README.md",
          "demos/dropdown/README.md",
          "demos/flex/README.md",
          "demos/form/README.md",
          "demos/frame/README.md",
          "demos/grid/README.md",
          "demos/image/README.md",
          "demos/inputfield/README.md",
          "demos/list/README.md",
          "demos/modal/README.md",
          "demos/pages/README.md",
          "demos/primitive/README.md",
          "demos/table/README.md",
          "demos/table/virtualtable/README.md",
          "demos/textarea/README.md",
          "demos/textview/README.md",
          "demos/textview/chat/README.md",
          "demos/treeview/README.md",
          "demos/unicode/README.md"
        ],
        "fileTypes": {
          ".yml": 1,
          ".md": 23,
          ".txt": 2,
          ".go": 64,
          ".png": 25,
          ".jpg": 1,
          ".mod": 1,
          ".sum": 1,
          ".gif": 1
        }
      }
    },
    {
      "id": 1151407364,
      "name": "knowledge_graph",
      "displayName": "knowledge graph",
      "description": "Convert any text to a graph of knowledge. This can be used for Graph Augmented Generation or Knowledge Graph based QnA",
      "summary": "The Problem\nText is a messy beast, especially when you want to pull out meaningful relationships and insights. Traditional methods of extracting knowledge often fall flat, leaving you with a jumble of data that’s hard to interpret. If you’ve ever wished for a way to visualize connections between concepts in a straightforward manner, you’re not alone.\n\nWhat This Does\nThe knowledgegraph repository offers a no-nonsense approach to transforming text into a knowledge graph. It breaks down your text corpus into digestible chunks, processes them, and spits out a graph that represents the relationships between different concepts. The magic happens in extractgraph.ipynb, where you chunk your text, extract concepts, and determine their relationships based on co-occurrences. \n\nYou can find your input files in the datainput folder—like cureus-0015-00000040274.txt—and after processing, the output lives in dataoutput/cureus/graph.csv. This is where you’ll find your neatly organized graph data, ready for exploration. The whole setup runs locally, which means you’re not at the mercy of any API limits or costs. \n\nReal-World Use\nImagine you have a research paper and want to analyze its key concepts and their interrelations. Pull your text into the pipeline by placing it in datainput. Then, fire up extractgraph.ipynb, tweak the parameters as needed, and watch as it processes your text to populate dataoutput/cureus/graph.csv. You’ll end up with a CSV file that neatly outlines the relationships, which can then be visualized using any graph library of your choice—no special tools required.\n\nimport pandas as pd\ngraphdata = pd.readcsv('dataoutput/cureus/graph.csv')\nNow visualize or analyze your graphdata as needed\n\nThe Bottom Line\nThis repository is solid if you need a straightforward way to create knowledge graphs from text. It's not for every use case, especially if you’re working with small datasets or need complex natural language processing. However, if you’re delving into larger bodies of work and want to visualize connections, this tool is worth a look. Just be prepared to roll up your sleeves and tweak the extractgraph.ipynb notebook to suit your needs.",
      "url": "https://github.com/yebeai/knowledge_graph",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "rahulnyk/knowledge_graph",
        "url": "https://github.com/rahulnyk/knowledge_graph",
        "stars": 3002
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 6, 2026",
      "updatedAt": "February 6, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 42,
        "directories": {
          ".github": 1,
          "(root)": 8,
          "assets": 9,
          "data_input": 2,
          "data_output": 11,
          "docs": 2,
          "helpers": 3,
          "old_notebooks": 4,
          "ollama": 2
        },
        "languages": {
          "YAML": 2,
          "Markdown": 1,
          "HTML": 2,
          "Python": 4,
          "TOML": 1
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": "poetry",
        "hasDocker": true,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "docs/index.html"
        ],
        "configFiles": [
          "dockerfile",
          "pyproject.toml"
        ],
        "dependencies": [
          "poetry.lock",
          "pyproject.toml"
        ],
        "testFiles": [],
        "docs": [
          "README.md",
          "docs/graph.html",
          "docs/index.html"
        ],
        "fileTypes": {
          ".yml": 2,
          ".md": 1,
          ".bkp": 3,
          ".png": 4,
          ".pdf": 2,
          ".drawio": 1,
          ".txt": 1,
          ".csv": 11,
          ".html": 2,
          ".ipynb": 6,
          ".py": 4,
          ".lock": 1,
          ".toml": 1
        }
      }
    },
    {
      "id": 1151344423,
      "name": "sokuji",
      "displayName": "sokuji",
      "description": "Live speech translation application built with Electron 34 and React, using OpenAI's Realtime API.",
      "summary": "The Problem\nLanguage barriers can be a serious pain in the neck, especially in real-time settings like meetings or conferences. You can’t just throw a translator at the problem and expect smooth communication. Misunderstandings can lead to awkward moments or even major blunders. That's where a tool like Sokuji comes in, aiming to tackle this head-on.\n\nWhat This Does\nSokuji is a live speech translation app built with Electron 34 and React, utilizing OpenAI's Realtime API, Google Gemini, and Palabra.ai. It captures audio input, translates it on the fly, and feeds back the translated output, making conversations feel more natural. You’ll find the core logic in the src folder, where the magic of handling audio streams happens.\n\nThe build-pkg.sh script helps package the app for different platforms, so you can run it on Windows, macOS, or Linux without a hitch. For developers interested in contributing, the .github/ISSUE_TEMPLATE folder contains templates for bug reports and feature requests, which shows they’re serious about managing feedback.\n\nReal-World Use\nImagine you’re in a meeting with international clients. You fire up Sokuji, and as they speak in their native language, the app captures the audio, translates it, and displays the text in real-time on your screen. You can even integrate it with Google Meet or Microsoft Teams via the browser extension. Just follow the straightforward steps in the README to load the extension in developer mode and you’re good to go.\n\nExample command to build the application\nbash build-pkg.sh\n\nThe Bottom Line\nSokuji is a solid choice for anyone needing real-time translation without the usual hassle. It’s not the simplest tool out there, and setting it up might require some tinkering, especially if you're not used to working with Electron apps. Still, for teams working in multilingual environments, it’s a lifesaver. Just be prepared for a bit of a learning curve if you're diving into the code. If you're looking for a straightforward solution, this might be overkill; stick to simpler tools.",
      "url": "https://github.com/yebeai/sokuji",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "kizuna-ai-lab/sokuji",
        "url": "https://github.com/kizuna-ai-lab/sokuji",
        "stars": 841
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 6, 2026",
      "updatedAt": "February 6, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 11,
          ".github": 5,
          "assets": 7,
          "docs": 77,
          "electron": 10,
          "evals": 28,
          "extension": 62
        },
        "languages": {
          "JavaScript": 15,
          "Markdown": 40,
          "YAML": 4,
          "Shell": 1,
          "HTML": 20,
          "JSON": 64,
          "TypeScript": 14
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "docs/index.html",
          "electron/main.js",
          "evals/runner/cli.ts",
          "evals/runner/index.ts"
        ],
        "configFiles": [
          ".env.example",
          "electron/tsconfig.json",
          "evals/runner/tsconfig.json"
        ],
        "dependencies": [],
        "testFiles": [
          "docs/tutorials/realtime-api-tester.html",
          "evals/runner/core/TestCaseLoader.ts",
          "evals/runner/core/TestExecutor.ts",
          "evals/runner/core/TestRunner.ts",
          "evals/schemas/test-case.schema.json",
          "evals/schemas/test-result.schema.json",
          "evals/test-cases/ja-en-realtime.json",
          "evals/test-cases/regression-direct-question-en-audio.json",
          "evals/test-cases/regression-direct-question-zh-audio.json",
          "evals/test-cases/regression-meta-commentary-zh-en-audio.json",
          "evals/test-cases/regression-meta-commentary-zh-en.json"
        ],
        "docs": [
          ".github/CONTRIBUTING.md",
          "CHANGELOG.md",
          "LICENSE",
          "README.ja.md",
          "README.md",
          "docs/ANALYTICS_EVENTS.md",
          "docs/GITHUB_SECRETS_SETUP.md",
          "docs/INDEX.md",
          "docs/KIZUNA_AI_INTEGRATION.md",
          "docs/PROFILE-OPTIMIZATION.md",
          "docs/README.md",
          "docs/SYSTEM_AUDIO_CAPTURE.md",
          "docs/TODO-AUTH-INTEGRATION.md",
          "docs/app/README.md",
          "docs/app/app-analytics-events.md",
          "docs/app/app-analytics-integration.md",
          "docs/app/app-audio-device-switching.md",
          "docs/audio-analysis/README.md",
          "docs/audio-analysis/audio-flow-analysis.md",
          "docs/build/macos-installer-guide.md",
          "docs/extension/README.md",
          "docs/extension/chrome_web_store_response.md",
          "docs/extension/extension-audio-profile-notification.md",
          "docs/extension/extension-gather-town-integration.md",
          "docs/extension/extension-popup-analytics.md",
          "docs/extension/extension-posthog-distinct-id.md",
          "docs/github-issues/README.md",
          "docs/github-issues/issue-55-comment.md",
          "docs/guides/README.md",
          "docs/guides/onboarding-guide.md",
          "docs/index.html",
          "docs/privacy-policy.html",
          "docs/sokuji_promo_1280x800.png",
          "docs/store/README.md",
          "docs/store/chrome_web_store_response.md",
          "docs/supported-ai-providers.html",
          "docs/supported-sites.html",
          "docs/tutorials/cometapi-setup.html",
          "docs/tutorials/discord.html",
          "docs/tutorials/gather.html",
          "docs/tutorials/gemini-setup.html",
          "docs/tutorials/google-meet.html",
          "docs/tutorials/google-meet/1.png",
          "docs/tutorials/google-meet/2.png",
          "docs/tutorials/google-meet/3.png",
          "docs/tutorials/google-meet/4.png",
          "docs/tutorials/google-meet/5.png",
          "docs/tutorials/linux-install.html",
          "docs/tutorials/macos-install.html",
          "docs/tutorials/microsoft-teams.html",
          "docs/tutorials/openai-setup.html",
          "docs/tutorials/openai-setup/1.png",
          "docs/tutorials/openai-setup/2.png",
          "docs/tutorials/openai-setup/3.png",
          "docs/tutorials/openai-setup/4.png",
          "docs/tutorials/openai-setup/5.png",
          "docs/tutorials/openai-setup/6.png",
          "docs/tutorials/openai-setup/7.png",
          "docs/tutorials/openai-setup/budget.png",
          "docs/tutorials/openai-setup/credit-balance.png",
          "docs/tutorials/openai-setup/rate-limits.png",
          "docs/tutorials/palabraai-setup.html",
          "docs/tutorials/realtime-api-tester.html",
          "docs/tutorials/slack.html",
          "docs/tutorials/whereby.html",
          "docs/tutorials/windows-install.html",
          "docs/tutorials/windows-install/1.png",
          "docs/tutorials/windows-install/2.png",
          "docs/tutorials/windows-install/3.5.jpg",
          "docs/tutorials/windows-install/3.png",
          "docs/tutorials/windows-install/4.png",
          "docs/tutorials/windows-install/5.png",
          "docs/tutorials/windows-install/6.png",
          "docs/tutorials/windows-install/7.png",
          "docs/tutorials/zoom.html",
          "docs/tutorials/zoom/1.png",
          "docs/tutorials/zoom/2.png",
          "docs/tutorials/zoom/3.png",
          "docs/tutorials/zoom/4.png",
          "docs/tutorials/zoom/5.png",
          "docs/tutorials/zoom/6.png",
          "docs/uninstall_feedback.html",
          "evals/README.md",
          "extension/README.md"
        ],
        "fileTypes": {
          ".js": 15,
          ".example": 1,
          ".md": 40,
          ".yml": 4,
          ".png": 32,
          ".svg": 2,
          ".icns": 1,
          ".ico": 1,
          ".sh": 1,
          ".html": 20,
          ".jpg": 1,
          ".json": 64,
          ".ts": 14
        }
      }
    },
    {
      "id": 1151266970,
      "name": "voxtral.c",
      "displayName": "voxtral.c",
      "description": "Pure C inference of Mistral Voxtral Realtime 4B speech to text model",
      "summary": "The Problem\nTranscribing audio is a pain, especially when you need a solution that doesn't demand an entire tech stack. Most speech-to-text services are either tied to cloud APIs or come with a ton of dependencies. Enter voxtral.c, a pure C implementation of Mistral's Voxtral Real-time 4B model, which cuts the bloat and keeps it simple.\n\nWhat This Does\nThe repo offers a straightforward inference pipeline for the Voxtral model with zero external dependencies, aside from the C standard library. You can build it for Apple Silicon or Intel using the Makefile, and it even supports MPS for some nice GPU acceleration. The audio processing is handled in voxtralaudio.c, which uses a chunked encoder to manage memory efficiently, regardless of how long your audio is. Want to transcribe a file? Just run ./voxtral -d voxtral-model -i audio.wav and watch the tokens stream to stdout.\n\nNeed to pipe audio from ffmpeg? That’s easy too. Use the --stdin flag for real-time transcription. The voxstreamt API lets you feed audio incrementally, which is a pretty slick feature for those who need continuous input.\n\nReal-World Use\nImagine you have a podcast episode in .wav format and want to transcribe it without the hassle of setting up a Python environment or worrying about cloud costs. Just download the model using ./downloadmodel.sh, then run:\n\nffmpeg -i podcast.mp3 -f s16le -ar 16000 -ac 1 - 2>/dev/null | \\\n    ./voxtral -d voxtral-model --stdin\n\nYou’ll get a steady stream of transcription tokens printed out as the audio plays. It’s efficient, doesn’t drown you in dependencies, and just works.\n\nThe Bottom Line\nvoxtral.c is a no-nonsense solution for real-time speech-to-text transcription. It’s lightweight and efficient, perfect for developers who want a straightforward implementation without the corporate fluff. Just keep in mind, the project still needs more testing for production use, especially with longer audio. If you’re tired of the usual overhead, give this a shot.",
      "url": "https://github.com/yebeai/voxtral.c",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "antirez/voxtral.c",
        "url": "https://github.com/antirez/voxtral.c",
        "stars": 1440
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 6, 2026",
      "updatedAt": "February 6, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 29,
        "directories": {
          "(root)": 25,
          "samples": 4
        },
        "languages": {
          "Markdown": 3,
          "Shell": 1,
          "C": 9,
          "Python": 1,
          "C/C++ Header": 6
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "main.c"
        ],
        "configFiles": [
          "Makefile"
        ],
        "dependencies": [],
        "testFiles": [
          "inspect_weights.c",
          "samples/test_speech.wav"
        ],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".md": 3,
          ".sh": 1,
          ".c": 9,
          ".py": 1,
          ".ogg": 1,
          ".gif": 1,
          ".wav": 2,
          ".h": 6,
          ".m": 1,
          ".metal": 1
        }
      }
    },
    {
      "id": 1151251666,
      "name": "fastapi-voyager",
      "displayName": "fastapi voyager",
      "description": "Visualize your API endpoints and explore them interactively, also support Django ninja & Litestar",
      "summary": "The Problem\n\nEver felt like you're spelunking through someone else's API just to figure out what routes exist and where they lead? Sure, Swagger UI helps, but it’s a glorified list of endpoints—zero context about how your code modules are organized. If you’re working on a FastAPI, Django Ninja, or Litestar project, you probably want more than just \"here’s a GET endpoint.\" You want a bird’s-eye view of your API structure, tied to the actual code, not just the HTTP layer. Enter fastapi-voyager.\n\nWhat This Does\n\nfastapi-voyager gives you an interactive visualization of your API endpoints, mapped to modules in your codebase. It’s not just for FastAPI—it also supports Django Ninja and Litestar. The heavy lifting happens in src/fastapivoyager/adapters/, with framework-specific adapters like djangoninjaadapter.py and fastapiadapter.py. The core functionality is exposed through the createvoyager function in src/fastapivoyager/init.py. \n\nYou mount the Voyager UI as a sub-application (e.g., /voyager), and it shows you all your endpoints, module color-coding, and even links back to your repo for source browsing. If you’re feeling fancy, you can configure options like modulecolor to differentiate code modules visually, or swaggerurl for quick access to your Swagger docs. The CLI (src/fastapivoyager/cli.py) also lets you spin up Voyager without embedding it into a larger application—perfect for debugging.\n\nReal-World Use\n\nLet’s say you’ve inherited a sprawling FastAPI app with routes scattered across multiple modules. First, install fastapi-voyager:\n\npip install fastapi-voyager\n\nAdd Voyager to your app:\n\nfrom fastapi import FastAPI\nfrom fastapivoyager import createvoyager\n\napp = FastAPI()\n\napp.mount('/voyager', createvoyager(app, module_color={'src.services': 'tomato'}))\n\nRun your app, and hit http://localhost:8000/voyager. Now, you’ve got a visual map of your endpoints, organized by code module. Bonus: link it to your repo URL and click directly into the source code for each route. For Django Ninja or Litestar, the setup is similar—just swap the adapter.\n\nThe Bottom Line\n\nIf you’re working on mid-to-large projects with messy endpoint sprawl, fastapi-voyager is worth a look. It’s not perfect—sub-applications are unsupported, and it feels very early-stage (Pydantic v2-only, no stars yet). But for dev teams needing better API clarity, it’s a solid documentation tool. For solo devs on small projects? Probably overkill.",
      "url": "https://github.com/yebeai/fastapi-voyager",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "allmonday/fastapi-voyager",
        "url": "https://github.com/allmonday/fastapi-voyager",
        "stars": 433
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 6, 2026",
      "updatedAt": "February 6, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 112,
        "directories": {
          ".githooks": 2,
          ".github": 3,
          "(root)": 16,
          "docs": 3,
          "src": 57,
          "tests": 31
        },
        "languages": {
          "Markdown": 10,
          "YAML": 1,
          "JSON": 1,
          "TOML": 1,
          "Shell": 4,
          "Python": 55,
          "JavaScript": 9,
          "CSS": 2,
          "HTML": 1
        },
        "frameworks": [
          "Django",
          "FastAPI"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "src/fastapi_voyager/cli.py",
          "src/fastapi_voyager/server.py",
          "src/fastapi_voyager/web/index.html"
        ],
        "configFiles": [
          ".prettierrc",
          "pyproject.toml"
        ],
        "dependencies": [
          "package-lock.json",
          "pyproject.toml"
        ],
        "testFiles": [
          "setup-litestar.sh",
          "src/fastapi_voyager/adapters/litestar_adapter.py",
          "src/fastapi_voyager/introspectors/__init__.py",
          "src/fastapi_voyager/introspectors/base.py",
          "src/fastapi_voyager/introspectors/detector.py",
          "src/fastapi_voyager/introspectors/django_ninja.py",
          "src/fastapi_voyager/introspectors/fastapi.py",
          "src/fastapi_voyager/introspectors/litestar.py",
          "tests/README.md",
          "tests/__init__.py",
          "tests/django_ninja/__init__.py",
          "tests/django_ninja/demo.py",
          "tests/django_ninja/embedding.py",
          "tests/django_ninja/settings.py",
          "tests/django_ninja/urls.py",
          "tests/embedding_test_utils.py",
          "tests/fastapi/__init__.py",
          "tests/fastapi/demo.py",
          "tests/fastapi/demo_anno.py",
          "tests/fastapi/embedding.py",
          "tests/litestar/__init__.py",
          "tests/litestar/demo.py",
          "tests/litestar/embedding.py",
          "tests/service/__init__.py",
          "tests/service/schema/__init__.py",
          "tests/service/schema/base_entity.py",
          "tests/service/schema/extra.py",
          "tests/service/schema/schema.py",
          "tests/test_adapter_interface.py",
          "tests/test_analysis.py",
          "tests/test_embedding_django_ninja.py",
          "tests/test_embedding_fastapi.py",
          "tests/test_embedding_litestar.py",
          "tests/test_filter.py",
          "tests/test_generic.py",
          "tests/test_import.py",
          "tests/test_module.py",
          "tests/test_resolve_util_impl.py",
          "tests/test_type_helper.py"
        ],
        "docs": [
          ".githooks/README.md",
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "docs/changelog.md",
          "docs/claude/0_REFACTORING_RENDER_NOTES.md",
          "docs/idea.md",
          "tests/README.md"
        ],
        "fileTypes": {
          ".md": 10,
          ".yml": 1,
          ".json": 1,
          ".toml": 1,
          ".sh": 4,
          ".py": 55,
          ".j2": 13,
          ".js": 9,
          ".css": 2,
          ".png": 5,
          ".ico": 1,
          ".webmanifest": 1,
          ".html": 1,
          ".lock": 1,
          ".jpg": 1
        }
      }
    },
    {
      "id": 1151223529,
      "name": "beautiful-mermaid",
      "displayName": "beautiful mermaid",
      "description": "No description available",
      "summary": "The Problem\nMermaid diagrams are cool, but the default renderer is about as appealing as a root canal. If you want your diagrams to look professional, customizing them often means wrestling with CSS classes that feel like they were designed by someone who hates developers. Plus, if you're working in a terminal, good luck rendering anything useful without a massive dependency hell.\n\nWhat This Does\nEnter beautiful-mermaid. This repo turns your plain text Mermaid diagrams into sleek SVGs or ASCII art without the bloat. You can find the main rendering functions in index.ts: renderMermaid for SVG output and renderMermaidAscii for terminal-friendly ASCII. The README.md gives you a quick start guide, so you can go from text to visuals faster than you can say “dependency injection.”\n\nThe theming system is solid. It’s based on just two colors—background and foreground—defined in your render call. This setup is found in src/tests/styles.test.ts, which ensures your diagrams can look good without diving into complex CSS. You can also find workflow files in .github/workflows, which automate CI and publishing, keeping your repo tidy.\n\nReal-World Use\nImagine you’re documenting an API and need to visualize the flow of data. You whip out renderMermaid and create a flowchart, like so:\n\nconst svg = await renderMermaid(\n  graph TD\n    A[Start] --> B{Decision}\n    B -->|Yes| C[Action]\n    B -->|No| D[End]\n)\n\nIn seconds, you have a clean SVG ready for your documentation. Or, if you're in a terminal, flip it to ASCII with:\n\nconst ascii = renderMermaidAscii(graph LR; A --> B --> C)\n\n┌───┐     ┌───┐     ┌───┐\n│   │     │   │     │   │\n│ A │────►│ B │────►│ C │\n│   │     │   │     │   │\n└───┘     └───┘     └───┘\n\nThe Bottom Line\nbeautiful-mermaid is a solid tool for anyone needing good-looking diagrams fast. It’s especially useful if you're working on CLI tools or need SVGs without a heap of dependencies. However, if you're just doodling for a one-off project, this might be overkill. Overall, it's a win for developers who want their diagrams to not suck.",
      "url": "https://github.com/yebeai/beautiful-mermaid",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "lukilabs/beautiful-mermaid",
        "url": "https://github.com/lukilabs/beautiful-mermaid",
        "stars": 7878
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 6, 2026",
      "updatedAt": "February 6, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 161,
        "directories": {
          ".github": 2,
          "(root)": 12,
          "public": 4,
          "src": 143
        },
        "languages": {
          "YAML": 2,
          "Markdown": 1,
          "TypeScript": 51,
          "JSON": 2
        },
        "frameworks": [
          "React"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "index.ts",
          "src/ascii/index.ts",
          "src/index.ts"
        ],
        "configFiles": [
          "package.json",
          "tsconfig.json"
        ],
        "dependencies": [
          "package.json"
        ],
        "testFiles": [
          "src/__tests__/ascii.test.ts",
          "src/__tests__/class-arrow-directions.test.ts",
          "src/__tests__/class-integration.test.ts",
          "src/__tests__/class-parser.test.ts",
          "src/__tests__/dagre-adapter.test.ts",
          "src/__tests__/er-integration.test.ts",
          "src/__tests__/er-parser.test.ts",
          "src/__tests__/integration.test.ts",
          "src/__tests__/parser.test.ts",
          "src/__tests__/renderer.test.ts",
          "src/__tests__/sequence-integration.test.ts",
          "src/__tests__/sequence-layout.test.ts",
          "src/__tests__/sequence-parser.test.ts",
          "src/__tests__/styles.test.ts",
          "src/__tests__/testdata/ascii/ampersand_lhs.txt",
          "src/__tests__/testdata/ascii/ampersand_lhs_and_rhs.txt",
          "src/__tests__/testdata/ascii/ampersand_rhs.txt",
          "src/__tests__/testdata/ascii/ampersand_without_edge.txt",
          "src/__tests__/testdata/ascii/back_reference_from_child.txt",
          "src/__tests__/testdata/ascii/backlink_from_bottom.txt",
          "src/__tests__/testdata/ascii/backlink_from_top.txt",
          "src/__tests__/testdata/ascii/backlink_with_short_y_padding.txt",
          "src/__tests__/testdata/ascii/cls_all_relationships.txt",
          "src/__tests__/testdata/ascii/cls_annotation.txt",
          "src/__tests__/testdata/ascii/cls_association.txt",
          "src/__tests__/testdata/ascii/cls_basic.txt",
          "src/__tests__/testdata/ascii/cls_dependency.txt",
          "src/__tests__/testdata/ascii/cls_inheritance.txt",
          "src/__tests__/testdata/ascii/cls_methods.txt",
          "src/__tests__/testdata/ascii/comments.txt",
          "src/__tests__/testdata/ascii/custom_padding.txt",
          "src/__tests__/testdata/ascii/duplicate_labels.txt",
          "src/__tests__/testdata/ascii/er_attributes.txt",
          "src/__tests__/testdata/ascii/er_basic.txt",
          "src/__tests__/testdata/ascii/er_identifying.txt",
          "src/__tests__/testdata/ascii/flowchart_tb_simple.txt",
          "src/__tests__/testdata/ascii/graph_bt_direction.txt",
          "src/__tests__/testdata/ascii/graph_tb_direction.txt",
          "src/__tests__/testdata/ascii/nested_subgraphs_with_labels.txt",
          "src/__tests__/testdata/ascii/preserve_order_of_definition.txt",
          "src/__tests__/testdata/ascii/self_reference.txt",
          "src/__tests__/testdata/ascii/self_reference_with_edge.txt",
          "src/__tests__/testdata/ascii/seq_basic.txt",
          "src/__tests__/testdata/ascii/seq_multiple_messages.txt",
          "src/__tests__/testdata/ascii/seq_self_message.txt",
          "src/__tests__/testdata/ascii/single_node.txt",
          "src/__tests__/testdata/ascii/single_node_longer_name.txt",
          "src/__tests__/testdata/ascii/subgraph_complex_mixed.txt",
          "src/__tests__/testdata/ascii/subgraph_complex_nested.txt",
          "src/__tests__/testdata/ascii/subgraph_empty.txt",
          "src/__tests__/testdata/ascii/subgraph_mixed_nodes.txt",
          "src/__tests__/testdata/ascii/subgraph_mixed_nodes_td.txt",
          "src/__tests__/testdata/ascii/subgraph_multiple_edges.txt",
          "src/__tests__/testdata/ascii/subgraph_multiple_nodes.txt",
          "src/__tests__/testdata/ascii/subgraph_nested.txt",
          "src/__tests__/testdata/ascii/subgraph_nested_with_external.txt",
          "src/__tests__/testdata/ascii/subgraph_node_outside_lr.txt",
          "src/__tests__/testdata/ascii/subgraph_single_node.txt",
          "src/__tests__/testdata/ascii/subgraph_td_direction.txt",
          "src/__tests__/testdata/ascii/subgraph_td_multiple.txt",
          "src/__tests__/testdata/ascii/subgraph_td_multiple_paddingy.txt",
          "src/__tests__/testdata/ascii/subgraph_three_levels_nested.txt",
          "src/__tests__/testdata/ascii/subgraph_three_separate.txt",
          "src/__tests__/testdata/ascii/subgraph_two_separate.txt",
          "src/__tests__/testdata/ascii/subgraph_with_labels.txt",
          "src/__tests__/testdata/ascii/three_nodes.txt",
          "src/__tests__/testdata/ascii/three_nodes_single_line.txt",
          "src/__tests__/testdata/ascii/two_layer_single_graph.txt",
          "src/__tests__/testdata/ascii/two_layer_single_graph_longer_names.txt",
          "src/__tests__/testdata/ascii/two_nodes_linked.txt",
          "src/__tests__/testdata/ascii/two_nodes_longer_names.txt",
          "src/__tests__/testdata/ascii/two_root_nodes.txt",
          "src/__tests__/testdata/ascii/two_root_nodes_longer_names.txt",
          "src/__tests__/testdata/ascii/two_single_root_nodes.txt",
          "src/__tests__/testdata/unicode/ampersand_lhs.txt",
          "src/__tests__/testdata/unicode/ampersand_lhs_and_rhs.txt",
          "src/__tests__/testdata/unicode/ampersand_rhs.txt",
          "src/__tests__/testdata/unicode/ampersand_without_edge.txt",
          "src/__tests__/testdata/unicode/back_reference_from_child.txt",
          "src/__tests__/testdata/unicode/backlink_from_bottom.txt",
          "src/__tests__/testdata/unicode/backlink_from_top.txt",
          "src/__tests__/testdata/unicode/cls_all_relationships.txt",
          "src/__tests__/testdata/unicode/cls_annotation.txt",
          "src/__tests__/testdata/unicode/cls_association.txt",
          "src/__tests__/testdata/unicode/cls_basic.txt",
          "src/__tests__/testdata/unicode/cls_dependency.txt",
          "src/__tests__/testdata/unicode/cls_inheritance.txt",
          "src/__tests__/testdata/unicode/cls_methods.txt",
          "src/__tests__/testdata/unicode/comments.txt",
          "src/__tests__/testdata/unicode/duplicate_labels.txt",
          "src/__tests__/testdata/unicode/er_attributes.txt",
          "src/__tests__/testdata/unicode/er_basic.txt",
          "src/__tests__/testdata/unicode/er_identifying.txt",
          "src/__tests__/testdata/unicode/graph_bt_direction.txt",
          "src/__tests__/testdata/unicode/preserve_order_of_definition.txt",
          "src/__tests__/testdata/unicode/self_reference.txt",
          "src/__tests__/testdata/unicode/self_reference_with_edge.txt",
          "src/__tests__/testdata/unicode/seq_basic.txt",
          "src/__tests__/testdata/unicode/seq_multiple_messages.txt",
          "src/__tests__/testdata/unicode/seq_self_message.txt",
          "src/__tests__/testdata/unicode/single_node.txt",
          "src/__tests__/testdata/unicode/single_node_longer_name.txt",
          "src/__tests__/testdata/unicode/three_nodes.txt",
          "src/__tests__/testdata/unicode/three_nodes_single_line.txt",
          "src/__tests__/testdata/unicode/two_layer_single_graph.txt",
          "src/__tests__/testdata/unicode/two_layer_single_graph_longer_names.txt",
          "src/__tests__/testdata/unicode/two_nodes_linked.txt",
          "src/__tests__/testdata/unicode/two_nodes_longer_names.txt",
          "src/__tests__/testdata/unicode/two_root_nodes.txt",
          "src/__tests__/testdata/unicode/two_root_nodes_longer_names.txt",
          "src/__tests__/testdata/unicode/two_single_root_nodes.txt"
        ],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".yml": 2,
          ".md": 1,
          ".ts": 51,
          ".lock": 1,
          ".png": 3,
          ".json": 2,
          ".ico": 1,
          ".svg": 1,
          ".txt": 97
        }
      }
    },
    {
      "id": 1151170355,
      "name": "dash",
      "displayName": "dash",
      "description": "Self-learning data agent that grounds its answers in 6 layers of context. Inspired by OpenAI's in-house implementation.",
      "summary": "Data-driven decision-making is often hampered by the complexity of translating human questions into actionable insights. Traditional text-to-SQL pipelines, while promising in theory, frequently fall short in practice due to a lack of context, brittle SQL generation, and the inability to learn from mistakes. Enter Dash, a self-learning data agent inspired by OpenAI's in-house implementation, designed to overcome these limitations by grounding its responses in six distinct layers of context and continuously improving its performance over time. For teams grappling with messy, schema-heavy datasets and the need for rapid, reliable insights, Dash offers a compelling solution.\n\nAt its core, Dash is more than just another text-to-SQL tool. It combines schema introspection, curated knowledge, and adaptive learning to deliver meaningful, context-aware answers. While most SQL agents treat database schemas as static, opaque structures, Dash integrates multiple dimensions of context: annotated business rules, query patterns that have proven successful, institutional knowledge from external sources, and even runtime schema changes. This means that when you ask a question like \"How many races has Lewis Hamilton won?\", Dash doesn't just query a database—it understands the intent behind the question and enriches its response with interpretive insights. The self-learning loop, powered by its \"Learning Machine,\" eliminates repetitive errors by diagnosing and saving fixes, ensuring that mistakes aren't repeated and the system grows smarter with every query.\n\nA closer look at Dash's file structure reveals a meticulously designed architecture that supports its ambitious goals. Core logic resides in the dash package, with dash/agents.py orchestrating the retrieval of context and SQL generation. The dash/context subdirectory houses essential modules like businessrules.py and semanticmodel.py, responsible for encoding human annotations and semantic understanding. Meanwhile, the dash/knowledge directory contains pre-curated datasets, including JSON files for business metrics and race results, as well as reusable SQL snippets in commonqueries.sql. This structured knowledge base is critical to Dash's ability to ground its SQL generation in patterns that have been validated to work. The dash/evals package, including components like grader.py and runevals.py, provides the framework for testing and refining the agent’s outputs, ensuring continuous improvement. Additionally, the inclusion of a Dockerfile and compose.yaml emphasizes the project's focus on ease of deployment, while the validate.yml GitHub Action underscores a commitment to maintainable, production-grade code.\n\nDevelopers stand to benefit from Dash in several real-world scenarios. For example, a data analyst working with a complex relational database—such as a Formula 1 dataset tracking race results, driver stats, and team performance—can bypass the steep SQL learning curve and instead rely on Dash to generate insights. Questions like \"Compare Ferrari vs Mercedes points from 2015 to 2020\" are answered succinctly, with added interpretation and business context. Similarly, teams managing rapidly evolving data models can leverage Dash’s runtime schema introspection to adapt queries on the fly without manual intervention. Finally, organizations with large, distributed knowledge bases—spanning wikis, documentation, and tribal knowledge—can integrate these resources into Dash’s institutional knowledge layer, ensuring that even unstructured data becomes actionable.\n\nUltimately, Dash represents a significant step forward in how we interact with data. By addressing the fundamental shortcomings of text-to-SQL systems and embedding a self-learning mechanism, it goes beyond merely executing queries to deliver actionable insights. For developers and organizations striving to make sense of their data in a fast-paced environment, Dash offers a scalable, intelligent assistant that learns alongside your team. It’s not just about answering questions—it’s about answering them better, every time.",
      "url": "https://github.com/yebeai/dash",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "agno-agi/dash",
        "url": "https://github.com/agno-agi/dash",
        "stars": 1725
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 6, 2026",
      "updatedAt": "February 6, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 49,
        "directories": {
          "(root)": 11,
          ".github": 1,
          "app": 3,
          "dash": 24,
          "db": 3,
          "scripts": 7
        },
        "languages": {
          "YAML": 3,
          "Markdown": 2,
          "Python": 22,
          "JSON": 7,
          "SQL": 1,
          "TOML": 1,
          "Shell": 7
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": "pip",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "app/main.py",
          "dash/__main__.py"
        ],
        "configFiles": [
          "Dockerfile",
          "pyproject.toml",
          "requirements.txt"
        ],
        "dependencies": [
          "pyproject.toml",
          "requirements.txt"
        ],
        "testFiles": [
          "dash/evals/test_cases.py",
          "dash/knowledge/tables/fastest_laps.json",
          "dash/tools/introspect.py"
        ],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".yml": 1,
          ".md": 2,
          ".py": 22,
          ".yaml": 2,
          ".json": 7,
          ".sql": 1,
          ".env": 1,
          ".toml": 1,
          ".txt": 1,
          ".sh": 7
        }
      }
    },
    {
      "id": 1151009743,
      "name": "gh-aw",
      "displayName": "gh aw",
      "description": "GitHub Agentic Workflows",
      "summary": "In the fast-paced world of software development, repetitive tasks can drain a team's productivity and creativity. Developers often find themselves bogged down by routine operations, such as managing issues or updating documentation, rather than focusing on critical features and innovative solutions. This is where GitHub Agentic Workflows (gh-aw) comes into play, offering a transformative approach. By allowing developers to create workflows using natural language markdown, it eliminates the need for complex scripting while leveraging AI to automate mundane tasks.\n\nGitHub Agentic Workflows is designed to empower developers by combining the power of GitHub Actions with AI-driven agents. Its unique proposition lies in the ability to write agentic workflows in markdown, which are then interpreted and executed by AI agents such as Copilot, Claude, and Codex. This abstraction not only democratizes the process of creating workflows but also enhances accessibility for teams with varying levels of programming expertise. The project emphasizes safety through its architecture, which includes default read-only permissions and a suite of security features such as sandboxed execution and input sanitization, ensuring that even non-technical users can utilize AI without compromising on security.\n\nDelving into the architecture, the project employs a modular file structure that promotes clarity and maintainability. The .changeset directory is an interesting aspect, featuring markdown files like patch-bump-codex-sandbox-runtime.md and patch-log-gh-cli-version.md, which indicate a robust versioning and change management strategy. The .devcontainer folder suggests containerization for consistent development environments, streamlining the onboarding process for new contributors. Furthermore, the .github/actions directory contains YAML files defining GitHub Actions for performance improvement and testing, showing a commitment to continuous integration and delivery. The presence of comprehensive documentation is notable, particularly in files like create-agentic-workflow.md, which guides users through creating their workflows, embodying the project's focus on ease of use.\n\nThe potential use cases for GitHub Agentic Workflows are compelling. For instance, a team managing a large open-source project can automate issue reporting and updates by defining a daily status report workflow in markdown. This not only keeps stakeholders informed but also fosters transparency in project progress. Another scenario could involve automating the generation of release notes based on merged pull requests, effectively saving time during release cycles. Additionally, teams can benefit from using agentic workflows to automate routine code reviews, where AI agents can analyze code changes and provide preliminary feedback, allowing human reviewers to focus on more complex issues.\n\nUltimately, GitHub Agentic Workflows represents a significant shift in how developers can interact with their tools. By merging natural language processing with automation, it not only enhances productivity but also empowers teams to harness AI in a safe and effective manner. As software development continues to evolve, projects like gh-aw are crucial in pushing the boundaries of what can be achieved, making AI-driven automation accessible and secure for all developers. This is not merely about reducing repetitive tasks; it’s about rethinking how we work and enabling teams to focus on innovation rather than routine.",
      "url": "https://github.com/yebeai/gh-aw",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "github/gh-aw",
        "url": "https://github.com/github/gh-aw",
        "stars": 3662
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 6, 2026",
      "updatedAt": "February 6, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".changeset": 10,
          ".devcontainer": 3,
          "(root)": 1,
          ".github": 186
        },
        "languages": {
          "Markdown": 107,
          "JSON": 4,
          "Shell": 1,
          "YAML": 82
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          ".devcontainer/Dockerfile"
        ],
        "dependencies": [],
        "testFiles": [
          ".github/actions/daily-test-improver/coverage-steps/action.yml",
          ".github/agents/w3c-specification-writer.agent.md",
          ".github/aw/test-dispatcher.md",
          ".github/workflows/codex-github-remote-mcp-test.lock.yml",
          ".github/workflows/codex-github-remote-mcp-test.md",
          ".github/workflows/daily-choice-test.lock.yml",
          ".github/workflows/daily-choice-test.md",
          ".github/workflows/daily-multi-device-docs-tester.lock.yml",
          ".github/workflows/daily-multi-device-docs-tester.md",
          ".github/workflows/daily-testify-uber-super-expert.lock.yml",
          ".github/workflows/daily-testify-uber-super-expert.md",
          ".github/workflows/docs-noob-tester.lock.yml",
          ".github/workflows/docs-noob-tester.md"
        ],
        "docs": [
          ".changeset/README",
          ".github/aw/runbooks/README.md"
        ],
        "fileTypes": {
          ".md": 107,
          ".json": 4,
          ".sh": 1,
          ".yml": 82
        }
      }
    },
    {
      "id": 847620283,
      "name": "ycombinator-job-scraper",
      "displayName": "ycombinator job scraper",
      "description": "Y Combinator Job Scraper  This repository houses an automated job scraping tool designed to streamline the job search process for tech professionals. Focused on Y Combinator's job board, this project aims to provide timely, relevant job listings to aid in career advancement.  Key Features: • Automated Scraping: Daily scraping of Y Combinator's jobs",
      "summary": "For anyone navigating the modern tech job market, staying ahead of new opportunities is often a daily challenge. The process quickly becomes overwhelming: job boards refresh constantly, positions disappear in hours, and keeping tabs on high-value sources like Y Combinator’s job board can turn into a full-time job itself. The ycombinator-job-scraper project on GitHub speaks directly to this pain point, offering an automated way to scrape fresh job listings and deliver instant alerts, streamlining what is typically an exhausting manual search.\n\nThe uniqueness of ycombinator-job-scraper lies not just in its automation but in its targeted focus and delivery mechanism. While plenty of generic web scrapers exist, few are tailored specifically to the fast-moving startup ecosystem fostered by Y Combinator, and fewer still offer direct, actionable notifications via WhatsApp. This integration means you’re not just aggregating jobs—you’re getting a curated feed of high-quality opportunities pushed straight to your phone, precisely when they become available. The project is designed to run daily at 10am East African Time, ensuring a reliable cadence that matches the urgency with which these roles are posted and filled.\n\nUnder the hood, the architecture is clean and modular, adhering to best practices for maintainability and extensibility. The src directory encapsulates the core logic, with scraper.py handling the intricacies of web scraping—likely leveraging Selenium or a similar browser automation tool, as evidenced by the inclusion of chromedriver.exe in assets/chromedriver-win64. Database operations, abstracted in database.py, suggest that scraped jobs are stored for deduplication or historical tracking, which is essential for avoiding redundant alerts. Messaging.py is responsible for integrating with Twilio’s API, sending out WhatsApp notifications; environmental variables such as TWILIOACCOUNTSID and YOURPHONENUMBER must be configured for authentication and targeting. The main.py file serves as the orchestrator, bootstrapping the workflow. The presence of a .github/workflows/scraper.yml GitHub Actions file signals a commitment to automation and CI/CD, likely enabling scheduled runs or facilitating test deployments. Rigorous testing is evident in the tests/ directory, covering core modules to help ensure robust, predictable behavior—a critical requirement for any automation that interacts with external APIs and systems.\n\nThis tool would be particularly valuable for three types of users. First, solo developers actively seeking their next role can use it to stay on top of new openings without constant manual checking, freeing up time for more strategic job search activities. Second, tech recruiters focused on startups can leverage the scraper to quickly identify new talent needs as soon as they’re posted, giving them a competitive edge. Third, career coaches or bootcamp organizers could integrate this tool into their workflow to keep cohorts informed about fresh opportunities in the YC network, adding tangible value to their guidance and services.\n\nUltimately, ycombinator-job-scraper is more than just a utilitarian script—it’s a blueprint for how open source automation can transform an inefficient process into a strategic advantage. By combining modular Python code, robust testing, and seamless integration with real-time messaging, it demonstrates what’s possible when targeted automation meets real-world needs. For developers, this project is a reminder that thoughtful engineering can turn pain points into productivity gains, especially when the stakes are as high as landing the next big job.",
      "url": "https://github.com/yebeai/ycombinator-job-scraper",
      "language": "Python",
      "stars": 4,
      "forks": 1,
      "topics": [],
      "parent": null,
      "type": "original",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "August 26, 2024",
      "updatedAt": "February 5, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 20,
        "directories": {
          ".github": 1,
          "(root)": 6,
          "assets": 3,
          "src": 6,
          "tests": 4
        },
        "languages": {
          "YAML": 1,
          "Markdown": 1,
          "Python": 10
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "src/main.py"
        ],
        "configFiles": [
          "requirements.txt"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [
          "tests/__init__.py",
          "tests/test_database.py",
          "tests/test_messaging.py",
          "tests/test_scraper.py"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "assets/chromedriver-win64/LICENSE.chromedriver"
        ],
        "fileTypes": {
          ".yml": 1,
          ".md": 1,
          ".chromedriver": 2,
          ".exe": 1,
          ".txt": 2,
          ".py": 10,
          ".code-workspace": 1
        }
      }
    },
    {
      "id": 1150967487,
      "name": "libredesk",
      "displayName": "libredesk",
      "description": "Modern, open source, self-hosted customer support desk. Single binary app.",
      "summary": "The Problem\n\nWrangling customer support with shared inboxes, random Gmail filters, and a dozen browser tabs is a nightmare. Toss in the privacy headache of SaaS helpdesks and you’ve got a mess that’s neither secure nor fun to manage. You want something self-hosted, modern, and not a weekend-long Docker Compose puzzle.\n\nWhat This Does\n\nlibredesk gives you a single binary that spins up a full-featured, open source support desk. Everything lives in one codebase—no “microservices” rabbit hole. Actual features are mapped to real files: automation logic is in cmd/automation.go, AI rewrite magic is hiding in cmd/ai.go, and you get granular permission controls straight from cmd/auth.go. The Dockerfile and sample config.sample.toml make deployment almost idiot-proof.\n\nThe project structure is dead simple. Backend commands are all in cmd/, and you manage installs or DB upgrades with CLI flags like --install or --upgrade (see the README’s binary section). No “run this Node script, then this Python script, then...”—just copy the config, run the binary, and you’re off. There’s even a ready-to-go Docker Compose setup for people who want to be lazy (read: sane).\n\nReal-World Use\n\nLet’s say you want to run your own support desk for a SaaS you actually care about not leaking data. You drop docker-compose.yml and config.sample.toml into a VM, tweak config.toml for your Postgres credentials, and fire up docker compose up -d. After that, you set the system user password:\n\ndocker exec -it libredesk_app ./libredesk --set-system-user-password\n\nNow you’ve got a web UI at http://localhost:9000 with multiple shared inboxes, custom roles, automation rules, and even AI-powered reply rewriting—without paying Zendesk $99/month for the privilege.\n\nThe Bottom Line\n\nlibredesk is for devs and teams who want a real support desk they can actually control, not another SaaS subscription. The install story is refreshingly painless and the features aren’t just marketing bullet points—they exist as actual code. If you’re running a small to medium outfit, or just hate bloated SaaS, give it a shot. If you need Salesforce-level “enterprise integrations,” look elsewhere.",
      "url": "https://github.com/yebeai/libredesk",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "abhinavxd/libredesk",
        "url": "https://github.com/abhinavxd/libredesk",
        "stars": 2329
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 5, 2026",
      "updatedAt": "February 5, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 12,
          ".github": 6,
          "cmd": 42,
          "frontend": 140
        },
        "languages": {
          "Markdown": 6,
          "YAML": 7,
          "Go": 42,
          "TOML": 1,
          "JSON": 6,
          "JavaScript": 28,
          "HTML": 2,
          "Vue": 94,
          "SCSS": 1
        },
        "frameworks": [
          "React",
          "Vue",
          "Docker"
        ],
        "packageManager": "pnpm",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "cmd/actvity_log.go",
          "cmd/agent_import.go",
          "cmd/ai.go",
          "cmd/auth.go",
          "cmd/automation.go",
          "cmd/business_hours.go",
          "cmd/config.go",
          "cmd/contacts.go",
          "cmd/conversation.go",
          "cmd/csat.go",
          "cmd/custom_attributes.go",
          "cmd/draft.go",
          "cmd/handlers.go",
          "cmd/i18n.go",
          "cmd/inboxes.go",
          "cmd/init.go",
          "cmd/install.go",
          "cmd/login.go",
          "cmd/macro.go",
          "cmd/main.go",
          "cmd/media.go",
          "cmd/messages.go",
          "cmd/middlewares.go",
          "cmd/oauth.go",
          "cmd/oidc.go",
          "cmd/priorities.go",
          "cmd/report.go",
          "cmd/roles.go",
          "cmd/search.go",
          "cmd/settings.go",
          "cmd/sla.go",
          "cmd/statuses.go",
          "cmd/tags.go",
          "cmd/teams.go",
          "cmd/templates.go",
          "cmd/updates.go",
          "cmd/upgrade.go",
          "cmd/user_notifications.go",
          "cmd/users.go",
          "cmd/views.go",
          "cmd/webhooks.go",
          "cmd/websocket.go",
          "frontend/index.html",
          "frontend/src/api/index.js",
          "frontend/src/components/ui/accordion/index.js",
          "frontend/src/components/ui/alert-dialog/index.js",
          "frontend/src/components/ui/alert/index.js",
          "frontend/src/components/ui/auto-form/index.js",
          "frontend/src/components/ui/avatar/index.js",
          "frontend/src/components/ui/badge/index.js",
          "frontend/src/components/ui/breadcrumb/index.js",
          "frontend/src/components/ui/button/index.js",
          "frontend/src/components/ui/calendar/index.js",
          "frontend/src/components/ui/card/index.js",
          "frontend/src/components/ui/chart-bar/index.js",
          "frontend/src/components/ui/chart-line/index.js",
          "frontend/src/components/ui/chart/index.js",
          "frontend/src/components/ui/checkbox/index.js",
          "frontend/src/components/ui/collapsible/index.js"
        ],
        "configFiles": [
          "Dockerfile",
          "Makefile",
          "docker-compose.yml",
          "frontend/.eslintrc.cjs",
          "frontend/.prettierrc.json",
          "frontend/package.json"
        ],
        "dependencies": [
          "frontend/package.json"
        ],
        "testFiles": [
          "frontend/cypress/e2e/testLogin.cy.js"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "frontend/README.md"
        ],
        "fileTypes": {
          ".md": 6,
          ".yml": 5,
          ".yaml": 2,
          ".go": 42,
          ".toml": 1,
          ".cjs": 1,
          ".json": 6,
          ".js": 28,
          ".html": 2,
          ".ico": 1,
          ".png": 1,
          ".svg": 2,
          ".vue": 94,
          ".scss": 1
        }
      }
    },
    {
      "id": 1150915450,
      "name": "Shannon",
      "displayName": "Shannon",
      "description": "A production-oriented multi-agent orchestration framework.",
      "summary": "The Problem\n\nBuilding production-grade AI agents sucks. They're expensive, unpredictable, and half the time, you have no clue why they failed. Maybe your API calls timed out, maybe the LLM hallucinated itself into oblivion. Either way, debugging is a nightmare, and every time you scale, you end up rewriting half your architecture. Oh, and let's not forget the security dumpster fire that is running user-defined code.\n\nWhat This Does\n\nShannon tackles these issues head-on with a framework designed for real-world production use. At its core, it orchestrates multi-agent workflows and gives you tools to stop the chaos before it starts. The big wins here:\nTemporal workflows for step-by-step debugging. If your agent freaks out, you can replay the exact execution chain to figure out what went wrong (clients/python/examples/sessioncontinuity.py hints at how this works).  \nCost control baked in. Every agent/task gets a hard token budget, and Shannon auto-falls back to cheaper models if needed. No runaway bills.  \nReal-time monitoring via dashboards, Prometheus metrics, and OpenTelemetry tracing. Check out .github/workflows/ci.yml and ROADMAP.md for the scope of what's planned.  \nSecurity that doesn’t suck: WASI sandboxing, Open Policy Agent (OPA) policies, and multi-tenant isolation.  \n\nFile-wise, the Python SDK (clients/python/) is your bread and butter for integrating this into apps. The examples/ folder is loaded with code snippets for workflows, streaming, approvals, and more.  \n\nReal-World Use\n\nLet’s say you need an agent to process customer support tickets. You could spin up Shannon, use the REST API or Python SDK (pip install shannon-sdk), and connect it to your existing pipeline. Here's a quick Python example:  \n\nfrom shannon import ShannonClient\n\nwith ShannonClient(baseurl=\"http://localhost:8080\") as client:\n    # Submit a task\n    task = client.submittask(query=\"Summarize this ticket: [customer issue here]\")\n    \n    # Monitor status and stream events\n    for event in client.streamevents(task.workflowid):\n        print(event)  # Real-time updates\n\n    # Get final result\n    result = client.gettaskresult(task.taskid)\n    print(\"Summary:\", result.data)\n\nNeed approvals for some steps? Use the streamingwithapprovals.py example. Want workflows routed based on complexity? Check out workflow_routing.py. It's flexible enough to fit most production setups.\n\nThe Bottom Line\n\nShannon is legit if you're building serious AI systems at scale. The debugging tools, cost management, and security features are clutch for production use. That said, it’s probably overkill for hobby projects or one-off experiments. If you're a startup or a team tired of duct-taping together agent workflows, Shannon might save your sanity. Just be ready to dive into the docs—it’s powerful, but not exactly plug-and-play.",
      "url": "https://github.com/yebeai/Shannon",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Kocoro-lab/Shannon",
        "url": "https://github.com/Kocoro-lab/Shannon",
        "stars": 1095
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 5, 2026",
      "updatedAt": "February 5, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 10,
          ".github": 4,
          "clients": 29,
          "config": 45,
          "deploy": 11,
          "desktop": 101
        },
        "languages": {
          "YAML": 29,
          "Markdown": 24,
          "Python": 21,
          "TOML": 2,
          "JSON": 7,
          "Shell": 1,
          "TSX": 43,
          "CSS": 1,
          "TypeScript": 14,
          "Rust": 1
        },
        "frameworks": [
          "React",
          "Next.js",
          "Docker"
        ],
        "packageManager": "npm",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "clients/python/src/shannon/cli.py",
          "desktop/components/radar/index.ts"
        ],
        "configFiles": [
          ".env.example",
          "Makefile",
          "clients/python/Makefile",
          "clients/python/pyproject.toml",
          "deploy/compose/docker-compose.override.example.yml",
          "deploy/compose/docker-compose.release.yml",
          "deploy/compose/docker-compose.yml",
          "deploy/compose/grafana/docker-compose-grafana-prometheus.yml",
          "desktop/next.config.ts",
          "desktop/package.json",
          "desktop/src-tauri/Cargo.toml"
        ],
        "dependencies": [
          "clients/python/pyproject.toml",
          "desktop/package-lock.json",
          "desktop/package.json",
          "desktop/src-tauri/Cargo.toml"
        ],
        "testFiles": [
          "clients/python/TEST_RESULTS_V0.4.0.md",
          "clients/python/tests/integration/__init__.py",
          "clients/python/tests/integration/test_control_signals.py",
          "clients/python/tests/integration/test_control_simple.py",
          "clients/python/tests/test_core.py",
          "clients/python/tests/test_http_errors.py",
          "clients/python/tests/test_model_params.py",
          "clients/python/tests/test_v030_comprehensive.py",
          "clients/python/tests/test_v030_features.py",
          "config/openapi_specs/.gitkeep",
          "config/shannon-policy-test.yaml",
          "config/shannon-test.yaml",
          "config/skills/core/test-driven-dev.md",
          "config/templates/synthesis/test_bullet_summary.tmpl"
        ],
        "docs": [
          "CHANGELOG.md",
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "clients/python/CHANGELOG.md",
          "clients/python/README.md",
          "config/README.md",
          "config/opa/README.md",
          "config/otel/README.md",
          "config/skills/README.md",
          "config/templates/synthesis/README.md",
          "config/workflows/user/README.md",
          "deploy/compose/grafana/README.md",
          "desktop/README.md",
          "desktop/desktop-app-build-guide.md"
        ],
        "fileTypes": {
          ".example": 2,
          ".yml": 10,
          ".md": 24,
          ".in": 1,
          ".py": 21,
          ".toml": 2,
          ".yaml": 19,
          ".rego": 5,
          ".tmpl": 7,
          ".ini": 1,
          ".json": 7,
          ".sh": 1,
          ".tsx": 43,
          ".ico": 2,
          ".css": 1,
          ".ts": 14,
          ".mjs": 2,
          ".png": 19,
          ".svg": 5,
          ".rs": 1,
          ".xml": 1
        }
      }
    },
    {
      "id": 1150904723,
      "name": "GDevelop",
      "displayName": "GDevelop",
      "description": "🎮 Open-source, cross-platform 2D/3D/multiplayer game engine designed for everyone.",
      "summary": "Game development has historically been an intimidating venture, often requiring mastery of complex programming languages, graphics APIs, and intricate build processes. For indie creators, educators, and even seasoned engineers wanting rapid prototyping, the friction of setup and technical hurdles can stifle creativity before it even begins. The challenge isn’t just building a game; it’s building a game engine that empowers rather than impedes. This is where GDevelop stands out in the open-source ecosystem, offering a solution that radically lowers the barrier to entry without sacrificing depth or extensibility.\n\nAt its core, GDevelop is a full-featured, open-source game engine designed for everyone—those who want to make 2D, 3D, or multiplayer games for mobile, desktop, or web platforms. Unlike many open-source engines, GDevelop’s focus isn’t just on code; it’s on accessibility. The project’s event-based system allows creators to build logic visually, avoiding traditional code entirely if they choose, while still supporting modular behaviors and code-driven extensions for those who want to dig deeper. The inclusion of AI-assisted creation and modular asset workflows demonstrates a commitment to both ease of use and power. What makes GDevelop unique isn’t simply the breadth of platforms it supports, but how it manages to remain approachable to beginners while scalable for professionals.\n\nExamining the repository’s file structure reveals a mature architecture built for both collaboration and cross-platform deployment. The presence of multiple CI/CD configurations—.circleci/config.yml, .travis.yml, .semaphore/semaphore.yml, .github/workflows, and .gitpod.yml—shows that GDevelop is committed to continuous integration and rapid iteration. The .devcontainer/devcontainer.json file points to a standardized development environment, facilitating onboarding and consistency for contributors regardless of their local setup. The use of .clang-tidy, .clangformat, and .clangcomplete indicates rigorous code quality and style enforcement, particularly for C++ components, while .vscode and .github directories provide tailored developer tooling and issue templates. This isn’t just a codebase; it’s an ecosystem engineered for maintainability, community growth, and modular extensibility. The layered architecture implied by paths like newIDE/README.md and asset store submission templates suggests clear separation between editor, engine, and marketplace components, making it easier for developers to contribute to or extend specific parts of the system.\n\nThere are several practical scenarios where GDevelop shines. For educators, it’s a ready-to-use teaching tool for game logic and design, with no need to wrangle compilers or dependencies—students can focus on creative problem-solving. Indie developers can leverage the event system and asset store to quickly prototype ideas, iterate, and deploy to multiple platforms without rewriting code for each. Teams building commercial games benefit from the open-source nature, allowing deep customization, integration with their own CI/CD pipelines, and the ability to contribute upstream. Even seasoned engineers can use GDevelop as a rapid prototyping engine: the tight integration of VSCode tooling, linting, and containerized development makes it possible to spin up a feature branch, test a new mechanic, and merge with confidence.\n\nThe real insight here is how GDevelop embodies the best practices of modern open-source development while solving real-world problems for a diverse range of creators. Its architecture, attention to tooling, and community-driven processes are not just technical conveniences—they’re strategic enablers for innovation and inclusivity in game development. In an industry where proprietary engines often dominate and lock out experimentation, GDevelop demonstrates that open-source can deliver both accessibility and professional-grade capabilities. It’s a blueprint for how to build software that welcomes newcomers, empowers experts, and evolves through collaborative stewardship.",
      "url": "https://github.com/yebeai/GDevelop",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "4ian/GDevelop",
        "url": "https://github.com/4ian/GDevelop",
        "stars": 20842
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 5, 2026",
      "updatedAt": "February 5, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".circleci": 1,
          "(root)": 8,
          ".devcontainer": 1,
          ".github": 14,
          ".semaphore": 1,
          ".vscode": 6,
          "Binaries": 1,
          "Core": 168
        },
        "languages": {
          "YAML": 15,
          "JSON": 6,
          "Markdown": 3,
          "C/C++ Header": 78,
          "C++": 88
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "Travis CI",
        "entryPoints": [],
        "configFiles": [
          "CMakeLists.txt",
          "Core/CMakeLists.txt"
        ],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "Binaries/README.md"
        ],
        "fileTypes": {
          ".yml": 15,
          ".json": 6,
          ".md": 3,
          ".code-snippets": 1,
          ".txt": 2,
          ".h": 78,
          ".cpp": 88,
          ".inl": 1
        }
      }
    },
    {
      "id": 1150849553,
      "name": "slidev",
      "displayName": "slidev",
      "description": "Presentation Slides for Developers",
      "summary": "Creating engaging and effective presentation slides is often a tedious process for developers. Traditional tools like PowerPoint or Google Slides lack the flexibility developers expect, especially when it comes to integrating code snippets, customizing themes, or leveraging modern tooling. Developers frequently find themselves jumping between their favorite text editor and slide-building software, sacrificing productivity and creative control. This gap between presentation tools and developer workflows is precisely where Slidev steps in.\n\nSlidev, forked from the highly popular repository slidevjs/slidev, offers a unique take on presentation slide creation, designed specifically for developers. Unlike conventional slide builders, Slidev is Markdown-based, allowing developers to create slides directly from their preferred text editor, such as VSCode. This approach not only reduces friction but also introduces a \"code-first\" philosophy that aligns seamlessly with developer habits. With built-in features like syntax highlighting, live coding, and Vue.js component integration, Slidev bridges the gap between presentation creation and software development. Its focus on customizability and interactivity sets it apart, making it a powerful tool for technical presentations, coding workshops, or even live demos.\n\nThe technical architecture of Slidev is a testament to its developer-centric design principles. The file structure emphasizes modularity and automation, evident from the robust .github/workflows directory. For instance, the autofix.yml and test.yml workflows suggest a commitment to maintaining code quality and reliability through automated linting and testing. The inclusion of release.yml and smoke.yml workflows further showcases a mature CI/CD pipeline, ensuring smooth releases and stability. The .vscode folder, containing configurations like extensions.json and settings.json, underscores Slidev's integration with VSCode, enabling developers to optimize their workflow with relevant extensions and settings preconfigured. The project's commitment to community contribution is evident in files like CONTRIBUTING.md and CODEOFCONDUCT.md, fostering an inclusive and collaborative environment.\n\nThe use cases for Slidev are extensive, particularly for developers who value efficiency and customization. For example, it’s an ideal tool for software engineers hosting technical talks or workshops. The ability to embed live code snippets and execute them during presentations elevates the experience, making concepts more tangible and engaging for the audience. Similarly, educators and trainers in STEM fields can leverage Slidev’s built-in support for LaTeX, diagrams via Mermaid.js, and drawing tools to present complex ideas visually without switching between multiple applications. Another compelling scenario is product demos, where developers can utilize Slidev’s presenter mode to control slides seamlessly across devices while highlighting technical features in real-time.\n\nSlidev is more than just a slide-building tool; it’s a paradigm shift in how developers approach presentations. By blending the power of modern web technologies like Vue.js and Vite with a Markdown-based workflow, Slidev redefines what it means to create developer-centric presentations. Its modular structure, automation capabilities, and rich feature set empower developers to focus on content rather than tooling. At its core, Slidev embodies the ethos of developer productivity—leveraging automation, customization, and code-first principles to deliver impactful presentations. Whether you're a conference speaker, a coding instructor, or a product engineer, Slidev is a tool that deserves a place in your workflow.",
      "url": "https://github.com/yebeai/slidev",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "slidevjs/slidev",
        "url": "https://github.com/slidevjs/slidev",
        "stars": 44529
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 5, 2026",
      "updatedAt": "February 5, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".github": 10,
          "(root)": 6,
          ".vscode": 3,
          "assets": 26,
          "cypress": 13,
          "demo": 25,
          "docs": 117
        },
        "languages": {
          "YAML": 8,
          "Markdown": 93,
          "JSON": 8,
          "TypeScript": 21,
          "Vue": 35,
          "HTML": 1,
          "CSS": 4
        },
        "frameworks": [
          "React",
          "Vue"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "demo/composable-vue/index.html",
          "docs/.vitepress/theme/index.ts"
        ],
        "configFiles": [
          "cypress/fixtures/basic/package.json",
          "cypress/fixtures/basic/vite.config.ts",
          "cypress/tsconfig.json",
          "demo/composable-vue/package.json",
          "demo/starter/package.json",
          "demo/starter/vite.config.ts",
          "demo/vue-runner/package.json"
        ],
        "dependencies": [
          "cypress/fixtures/basic/package.json",
          "demo/composable-vue/package.json",
          "demo/starter/package.json",
          "demo/vue-runner/package.json"
        ],
        "testFiles": [
          ".github/workflows/test.yml",
          "cypress/e2e/examples/basic.spec.ts",
          "cypress/e2e/examples/smoke.spec.ts"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "demo/README.md",
          "demo/starter/README.md",
          "docs/.gitignore",
          "docs/.npmrc",
          "docs/.vitepress/addons.ts",
          "docs/.vitepress/config.ts",
          "docs/.vitepress/customizations.ts",
          "docs/.vitepress/pages.ts",
          "docs/.vitepress/showcases.ts",
          "docs/.vitepress/sidebar-gen.ts",
          "docs/.vitepress/theme/components/AddonGallery.vue",
          "docs/.vitepress/theme/components/AddonInfo.vue",
          "docs/.vitepress/theme/components/Demo.vue",
          "docs/.vitepress/theme/components/DemoEditor.vue",
          "docs/.vitepress/theme/components/DemoSlide.vue",
          "docs/.vitepress/theme/components/Environment.vue",
          "docs/.vitepress/theme/components/FeatureTag.vue",
          "docs/.vitepress/theme/components/FeaturesAnimation.vue",
          "docs/.vitepress/theme/components/FeaturesAnimationInner.vue",
          "docs/.vitepress/theme/components/FeaturesOverview.vue",
          "docs/.vitepress/theme/components/LandingPage.vue",
          "docs/.vitepress/theme/components/Layout.vue",
          "docs/.vitepress/theme/components/LinkCard.vue",
          "docs/.vitepress/theme/components/LinkInline.vue",
          "docs/.vitepress/theme/components/SeeAlso.vue",
          "docs/.vitepress/theme/components/ShowCaseInfo.vue",
          "docs/.vitepress/theme/components/ShowCases.vue",
          "docs/.vitepress/theme/components/SlideContainer.vue",
          "docs/.vitepress/theme/components/TheTweet.vue",
          "docs/.vitepress/theme/components/ThemeGallery.vue",
          "docs/.vitepress/theme/components/ThemeInfo.vue",
          "docs/.vitepress/theme/composables/dark.ts",
          "docs/.vitepress/theme/index.ts",
          "docs/.vitepress/theme/styles/custom.css",
          "docs/.vitepress/theme/styles/demo.css",
          "docs/.vitepress/theme/styles/vars.css",
          "docs/.vitepress/themes.ts",
          "docs/.vitepress/utils.ts",
          "docs/README.md",
          "docs/builtin/cli.md",
          "docs/builtin/components.md",
          "docs/builtin/layouts.md",
          "docs/components.d.ts",
          "docs/custom/config-code-runners.md",
          "docs/custom/config-context-menu.md",
          "docs/custom/config-fonts.md",
          "docs/custom/config-highlighter.md",
          "docs/custom/config-katex.md",
          "docs/custom/config-mermaid.md",
          "docs/custom/config-monaco.md",
          "docs/custom/config-parser.md",
          "docs/custom/config-routes.md",
          "docs/custom/config-shortcuts.md",
          "docs/custom/config-transformers.md",
          "docs/custom/config-unocss.md",
          "docs/custom/config-vite.md",
          "docs/custom/config-vue.md",
          "docs/custom/directory-structure.md",
          "docs/custom/index.md",
          "docs/features/block-frontmatter.md",
          "docs/features/build-with-pdf.md",
          "docs/features/bundle-remote-assets.md",
          "docs/features/canvas-size.md",
          "docs/features/click-marker.md",
          "docs/features/code-block-line-numbers.md",
          "docs/features/code-block-max-height.md",
          "docs/features/code-groups.md",
          "docs/features/direction-variant.md",
          "docs/features/draggable.md",
          "docs/features/drawing.md",
          "docs/features/eject-theme.md",
          "docs/features/frontmatter-merging.md",
          "docs/features/global-layers.md",
          "docs/features/icons.md",
          "docs/features/import-snippet.md",
          "docs/features/importing-slides.md",
          "docs/features/index.data.ts",
          "docs/features/index.md",
          "docs/features/latex.md",
          "docs/features/line-highlighting.md",
          "docs/features/mdc.md",
          "docs/features/mermaid.md",
          "docs/features/monaco-editor.md",
          "docs/features/monaco-run.md",
          "docs/features/monaco-write.md",
          "docs/features/notes-auto-ruby.md",
          "docs/features/og-image.md",
          "docs/features/plantuml.md",
          "docs/features/prettier-plugin.md",
          "docs/features/recording.md",
          "docs/features/remote-access.md",
          "docs/features/rough-marker.md",
          "docs/features/seo-meta.md",
          "docs/features/shiki-magic-move.md",
          "docs/features/side-editor.md",
          "docs/features/slide-hook.md",
          "docs/features/slide-scope-style.md",
          "docs/features/slot-sugar.md",
          "docs/features/timer.md",
          "docs/features/transform-component.md",
          "docs/features/twoslash.md",
          "docs/features/vscode-extension.md",
          "docs/features/zoom-slide.md",
          "docs/guide/animations.md",
          "docs/guide/component.md",
          "docs/guide/exporting.md",
          "docs/guide/faq.md",
          "docs/guide/global-context.md",
          "docs/guide/hosting.md",
          "docs/guide/index.md",
          "docs/guide/layout.md",
          "docs/guide/syntax.md",
          "docs/guide/theme-addon.md",
          "docs/guide/ui.md",
          "docs/guide/why.md",
          "docs/guide/work-with-ai.md",
          "docs/guide/write-addon.md",
          "docs/guide/write-layout.md",
          "docs/guide/write-theme.md"
        ],
        "fileTypes": {
          ".yml": 8,
          ".md": 93,
          ".json": 8,
          ".svg": 4,
          ".png": 22,
          ".ts": 21,
          ".vue": 35,
          ".html": 1,
          ".css": 4
        }
      }
    },
    {
      "id": 1149826102,
      "name": "invoicerr",
      "displayName": "invoicerr",
      "description": "Invoicerr is a freelance-focused invoicing app that lets you create quotes, generate invoices, track payments, and collect secure signatures.",
      "summary": "The Problem\nFreelancers often juggle multiple clients, invoices, and payment statuses, which can turn into a chaotic mess. Managing quotes and invoices without a centralized tool leads to lost payments and missed deadlines. Enter Invoicerr—the antidote to your invoicing headache.\n\nWhat This Does\nInvoicerr simplifies the invoicing process with a clean interface and useful features. You can create and manage invoices and quotes in one place, track their statuses, and even send them off via email. The backend/docker-compose.local.yml file makes it easy to spin up the whole app with Docker, which is a huge win for local development. You get to define your environment variables right in the docker-compose.yml, including DATABASEURL for your PostgreSQL connection string and SMTPHOST for email sending.\n\nThe app is built with a modern stack: React for the frontend, NestJS for the backend, and Prisma for database interactions. You’ll find backend/prisma/config.ts for your database schema, which is also where you can manage migrations, like those found in backend/prisma/migrations/.\n\nReal-World Use\nImagine you just completed a project for a client and need to send an invoice. With Invoicerr, you can quickly create an invoice from a quote you already sent, track when the client opens it, and even see if they've signed it. If they have questions, you can customize email templates using the SMTP_* environment variables to ensure your correspondence looks professional. No more juggling spreadsheets or missed payments—just straightforward invoicing.\n\nThe Bottom Line\nInvoicerr is a solid choice for freelancers tired of the invoicing chaos. The Docker setup makes it easy to deploy, but if you’re working on a small project or just starting out, this might feel like overkill. Still, if you're managing multiple clients and need a reliable tool, Invoicerr could be your new best friend. Just make sure you have your environment variables sorted, or you'll be in for a surprise.",
      "url": "https://github.com/yebeai/invoicerr",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "invoicerr-app/invoicerr",
        "url": "https://github.com/invoicerr-app/invoicerr",
        "stars": 646
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 4, 2026",
      "updatedAt": "February 4, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 9,
          ".github": 7,
          "backend": 150,
          "e2e": 19,
          "frontend": 15
        },
        "languages": {
          "YAML": 7,
          "Markdown": 6,
          "JavaScript": 2,
          "JSON": 19,
          "TypeScript": 120,
          "SQL": 21,
          "TOML": 1,
          "Shell": 1,
          "HTML": 1,
          "TSX": 4
        },
        "frameworks": [
          "React",
          "NestJS",
          "Docker"
        ],
        "packageManager": "npm",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "backend/src/main.ts",
          "backend/src/plugins/index.ts",
          "frontend/index.html"
        ],
        "configFiles": [
          "Dockerfile",
          "backend/.env.example",
          "backend/.eslintrc.js",
          "backend/.prettierrc",
          "backend/docker-compose.local.yml",
          "backend/package.json",
          "backend/src/plugins/signing/providers/documenso/tsconfig.json",
          "backend/src/plugins/storage/providers/s3/tsconfig.json",
          "backend/tsconfig.json",
          "docker-compose.yml",
          "e2e/package.json",
          "e2e/tsconfig.json",
          "frontend/.env.example",
          "frontend/package.json"
        ],
        "dependencies": [
          "backend/package-lock.json",
          "backend/package.json",
          "e2e/package-lock.json",
          "e2e/package.json",
          "frontend/package-lock.json",
          "frontend/package.json"
        ],
        "testFiles": [
          "backend/.env.test",
          "backend/prisma/reset-db.test.ts",
          "backend/src/app.controller.spec.ts",
          "backend/test/app.e2e-spec.ts",
          "backend/test/jest-e2e.json",
          "e2e/E2E_TEST_PLAN.md",
          "frontend/.env.test"
        ],
        "docs": [
          "LICENSE",
          "LICENSE.COMMERCIAL.md",
          "README.md",
          "backend/README.md"
        ],
        "fileTypes": {
          ".yml": 7,
          ".md": 6,
          ".webp": 1,
          ".example": 2,
          ".test": 2,
          ".js": 2,
          ".json": 19,
          ".ts": 120,
          ".sql": 21,
          ".toml": 1,
          ".prisma": 1,
          ".sh": 1,
          ".html": 1,
          ".png": 1,
          ".svg": 2,
          ".tsx": 4
        }
      }
    },
    {
      "id": 1149245380,
      "name": "agent-device",
      "displayName": "agent device",
      "description": "CLI to control iOS and Android devices for AI agents",
      "summary": "Controlling mobile devices with precision from the command line has long been a challenge for developers and researchers building AI agents that interact with real-world apps. Most existing solutions are either platform-specific, rely on clunky GUIs, or demand heavy dependencies and complex setups. Imagine you’re developing an AI agent that needs to navigate a mobile app, trigger alerts, or capture screenshots — all without manual intervention or fragile scripting. This is the gap agent-device aims to bridge: providing seamless, low-dependency device automation for both iOS and Android, directly from the CLI, as a foundation for higher-level agent workflows.\n\nAgent-device distinguishes itself by focusing on minimalism and universality. Inspired by Vercel’s agent-browser, but tailored for mobile platforms, this project exposes a unified command suite covering both iOS and Android, with direct Node.js execution — no transpilation or build step required. The commands are ergonomically designed: you can open apps, simulate interactions like presses or typing, inspect UI accessibility trees, and even manipulate device settings like Wi-Fi or airplane mode. What’s compelling is the deliberate avoidance of heavy frameworks; everything is driven via platform tooling like adb for Android and simctl/devicectl for iOS, with rich snapshot and inspection features that are usually missing from open-source mobile automation tools.\n\nArchitecturally, agent-device leverages a hybrid approach to device interaction, evident from its file structure. The CLI entrypoint, bin/agent-device.mjs, is written in TypeScript and executed directly on Node 22+, which is a strategic choice for speed and maintainability. On the iOS side, you’ll find a native Swift runner (ios-runner/AgentDeviceRunner) and an AXSnapshot module — the latter exposing accessibility tree snapshots via AX and XCTest backends. The hybrid snapshot logic described in the README is implemented by first querying AX (fast but sometimes incomplete) and then supplementing with scoped XCTest queries, yielding a more reliable UI tree. The iOS runner is built as an Xcode project, including test suites (AgentDeviceRunnerUITests/RunnerTests.swift) and asset catalogs; this modularity allows for easy extension and debugging, a design pattern rarely seen in cross-platform CLI tools. Meanwhile, Android interactions are orchestrated via adb, with all device commands abstracted behind the CLI. The documentation (docs/ios-automation.md, docs/ios-runner-protocol.md) clarifies the protocol and integration points, which will be useful for contributors or those extending the tool.\n\nDevelopers working on AI agents that need to interact with real devices (or simulators/emulators) will immediately see the value in agent-device. For instance, you might be building a reinforcement learning agent that adapts its strategy based on app state — the snapshot command gives you a stable, semantic map of the UI, and actions like click or type can be targeted by accessibility refs rather than brittle coordinates. Another scenario: automated regression testing workflows can use agent-device to script end-to-end flows across both Android and iOS, including capturing screenshots or toggling settings, all from a single CLI. And for those prototyping new app features, the ability to quickly open, interact, and inspect apps in diverse device contexts — without wrestling with Appium or platform-specific wrappers — is a productivity boon.\n\nThe significance of agent-device goes beyond convenience; it’s about enabling robust, agent-driven automation for mobile apps, lowering the barrier to experimentation, and facilitating reproducible interactions. The project’s modular architecture, minimalist dependency footprint, and thoughtful abstraction of platform quirks signal a new direction for open-source device tooling. As AI agents increasingly move from browser automation to mobile, having a reliable, scriptable bridge is crucial — and agent-device, even in its experimental stage, is poised to become a foundational piece in this ecosystem. Developers seeking to automate, test, or research mobile UI flows should keep a close eye on its evolution.",
      "url": "https://github.com/yebeai/agent-device",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "callstackincubator/agent-device",
        "url": "https://github.com/callstackincubator/agent-device",
        "stars": 854
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 3, 2026",
      "updatedAt": "February 3, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 62,
        "directories": {
          ".codex": 1,
          "(root)": 10,
          "bin": 1,
          "docs": 2,
          "ios-runner": 17,
          "skills": 6,
          "src": 21,
          "test": 4
        },
        "languages": {
          "TOML": 1,
          "Markdown": 12,
          "Swift": 5,
          "JSON": 8,
          "YAML": 1,
          "TypeScript": 26
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "pnpm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "src/cli.ts",
          "src/platforms/android/index.ts",
          "src/platforms/ios/index.ts"
        ],
        "configFiles": [
          "package.json",
          "tsconfig.json"
        ],
        "dependencies": [
          "package.json"
        ],
        "testFiles": [
          "ios-runner/AgentDeviceRunner/AgentDeviceRunnerUITests/RunnerTests.swift",
          "test/integration/android.test.ts",
          "test/integration/ios.test.ts",
          "test/smoke/cli.test.ts",
          "test/smoke/retry.test.ts"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "docs/ios-automation.md",
          "docs/ios-runner-protocol.md",
          "ios-runner/README.md"
        ],
        "fileTypes": {
          ".toml": 1,
          ".md": 12,
          ".mjs": 1,
          ".swift": 5,
          ".pbxproj": 1,
          ".xcworkspacedata": 1,
          ".xcscheme": 1,
          ".json": 8,
          ".jpg": 2,
          ".png": 1,
          ".yaml": 1,
          ".ts": 26
        }
      }
    },
    {
      "id": 1149242405,
      "name": "lamb",
      "displayName": "lamb",
      "description": "Tiny Pure Functional Programming Language in C",
      "summary": "Functional programming has long been a cornerstone of academic computer science, but its real-world applications are becoming increasingly relevant. As we shift towards concurrency, immutability, and mathematical rigor in software engineering, functional programming languages like Haskell, Lisp, and Scala are gaining traction. Yet, these languages often come with a steep learning curve and a heavy runtime. Enter \"Lamb,\" a tiny, pure functional programming language implemented in C. Lamb offers a lightweight, minimalist approach to functional programming with a focus on the untyped lambda calculus and normal-order reduction. It’s not designed to compete with industrial-grade languages, but rather to serve as a tool for learning, experimentation, or embedding functional paradigms into C-based systems.\n\nAt its core, Lamb is a language interpreter written in a single C file, lamb.c. It is designed around the principles of the untyped lambda calculus, the theoretical foundation upon which modern functional programming is built. Unlike most functional languages that come with extensive standard libraries and complex ecosystems, Lamb is stripped down to its essence. It provides just enough syntax to express functions, variables, and applications, allowing developers to explore the purity of the lambda calculus without distractions. What makes Lamb particularly unique is its focus on normal-order reduction, a reduction strategy that evaluates the outermost function first and delays computation until absolutely necessary. This feature differentiates it from eager evaluation strategies like those in C, making it an ideal playground for those wanting to experiment with lazy evaluation.\n\nThe project’s simplicity is reflected in its file structure. The entire interpreter is encapsulated in lamb.c, which makes it approachable for developers who want to understand the inner mechanics of a language runtime. The accompanying std.lamb acts as a standard library, providing reusable constructs and patterns for functional programming. The use of std.lamb demonstrates a critical principle of functional programming: building abstractions from first principles. Meanwhile, the repository also includes a few .png files in the assets directory, which are used for branding and serve no functional purpose in the codebase. The README.md is well-documented and doubles as a learning resource, walking users through the syntax, evaluation strategy, and even debugging aids like the #trace magic. This thoughtful documentation makes Lamb not just a tool but an educational asset for developers looking to understand the lambda calculus or build their first interpreter.\n\nLamb finds its niche in several interesting use cases. First, it is an excellent teaching tool. Computer science educators can use Lamb to introduce students to the lambda calculus in a hands-on manner. By writing small programs in Lamb, students can directly see how higher-order functions and currying work. Second, Lamb is a great way for developers to experiment with embedding functional programming into C-based systems. For example, someone building an application in C could use Lamb as an embedded scripting language for user-defined behaviors or domain-specific logic. Finally, Lamb could serve as an inspiration or a starting point for developers interested in designing their own programming languages. By studying its minimal architecture, one can glean insights into how language interpreters handle syntax parsing, evaluation, and reduction strategies.\n\nIn a world where software complexity is constantly increasing, Lamb serves as a refreshing reminder of the power of simplicity. By stripping functional programming down to its theoretical roots, it allows developers to focus on the core ideas without being overwhelmed by extraneous features. Moreover, the choice to implement it in C provides a direct line to the underlying system, offering performance and control that high-level languages abstract away. While it may not be the tool for production-grade software, Lamb’s value lies in its ability to educate, enable experimentation, and inspire. For anyone interested in functional programming or language design, this tiny project is worth exploring.",
      "url": "https://github.com/yebeai/lamb",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "tsoding/lamb",
        "url": "https://github.com/tsoding/lamb",
        "stars": 187
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1531482615713-2afd69097998?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 3, 2026",
      "updatedAt": "February 3, 2026",
      "readTime": 4,
      "knowledgeGraph": {
        "totalFiles": 8,
        "directories": {
          "(root)": 5,
          "assets": 3
        },
        "languages": {
          "Markdown": 1,
          "C": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".md": 1,
          ".png": 3,
          ".c": 1,
          ".lamb": 1
        }
      }
    },
    {
      "id": 1149237245,
      "name": "elasticsearch-skill",
      "displayName": "elasticsearch skill",
      "description": "Claude Code skill for interacting with Elasticsearch REST API — Query DSL, aggregations, cluster ops, ILM, ES|QL, and more",
      "summary": "The Problem\n\nElasticsearch's REST API is a beast. The docs are a maze, the client libraries are bloated, and half the time you just want a working curl without 200 lines of boilerplate. If you're wrangling logs, metrics, or search features and hate fighting with \"official\" SDKs, you know exactly what I'm talking about.\n\nWhat This Does\n\nelasticsearch-skill is a markdown kit for Claude Code that teaches it how to talk to Elasticsearch using raw REST calls, not some magic black-box client. Everything lives in plain text: SKILL.md covers auth, search, CRUD, bulk ops, index management, cluster health, ILM, ES|QL, and ingest pipelines. The references/ folder breaks down the gnarly stuff—query-dsl.md for search queries, aggregations.md for metrics and leaderboards, and APIs for documents, clusters, and Kibana. No servers to run, no dependencies to install, no Docker circus.\n\nSetup is dead simple—clone, copy to ~/.claude/skills/elasticsearch, set your ESURL and ESAPI_KEY as env vars. Claude Code then loads the skill and knows how to craft every API call as needed. The docs even call out why you shouldn't bother with MCP servers unless you like burning tokens and maintaining extra junk.\n\nReal-World Use\n\nSay you need to grab the top 10 error rates per service for the last 24 hours. Using Claude Code with this skill, you just ask for the right curl (with a query from aggregations.md), paste it into your terminal, and you're done. No SDK, no codegen, no waiting for JavaScript dependencies to finish installing. You can also automate bulk imports, tweak ILM policies, or check cluster health—all with copy-pasteable commands straight from markdown.\n\nThe Bottom Line\n\nIf you want Claude Code to actually do stuff with Elasticsearch instead of just hallucinating API calls, this is the way. No bloat, no server, no protocol translation—just markdown and working curl examples. Great for folks who already get Elasticsearch and want less friction; probably overkill if you're fine staying inside Kibana or just need simple search. But if you care about speed and clarity, this beats any bloated SDK.",
      "url": "https://github.com/yebeai/elasticsearch-skill",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "davidgeorgehope/elasticsearch-skill",
        "url": "https://github.com/davidgeorgehope/elasticsearch-skill",
        "stars": 23
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 3, 2026",
      "updatedAt": "February 3, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 12,
        "directories": {
          "(root)": 2,
          "references": 10
        },
        "languages": {
          "Markdown": 12
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".md": 12
        }
      }
    },
    {
      "id": 1149234360,
      "name": "opcode",
      "displayName": "opcode",
      "description": "A powerful GUI app and Toolkit for Claude Code - Create custom agents, manage interactive Claude Code sessions, run secure background agents, and more.",
      "summary": "Managing complex AI workflows with tools like Claude Code is often a balancing act between power and usability. Developers get sophisticated capabilities at the command line, but as projects grow—tracking sessions, customizing agent behavior, and monitoring usage—these tasks can become unwieldy and error-prone. The lack of a central, visual hub means missed context, lost productivity, and opaque analytics. This is where opcode comes in, offering a desktop GUI that bridges these gaps and turns Claude Code into a truly developer-friendly platform.\n\nAt its core, opcode is a toolkit and GUI application designed to enhance how developers interact with Claude Code. Unlike minimal wrappers or thin dashboards, opcode is architected for extensibility and depth. It doesn’t just display data—it enables workflows: custom agent creation, interactive session management, secure background execution, and real-time analytics. The project’s independence from Anthropic and its focus on open developer tooling distinguishes it from commercial alternatives. By leveraging Tauri 2, opcode delivers a performant cross-platform desktop app without the bloat of Electron, and it’s built to integrate seamlessly with the file-based ecosystem Claude Code users already rely on.\n\nLooking at the file structure, several architectural choices stand out. The presence of src-tauri/Cargo.toml and src-tauri/Info.plist signals a Rust/Tauri backend, meaning tight OS integration and resource efficiency. The src-tauri/build.rs and src-tauri/capabilities/default.json files suggest custom build steps and modular capability management—likely enabling plugin-like extensibility for new agent types or session features. The ccagents/ directory contains JSON specs like git-commit-bot.opcode.json and security-scanner.opcode.json, indicating a declarative approach to agent configuration. This pattern enables reproducible, auditable agent definitions, allowing teams to share and version agent behaviors as code. The inclusion of workflows under .github/workflows/build-linux.yml and build-macos.yml points to robust CI/CD, simplifying cross-platform builds and distribution. Meanwhile, bun.lock and package.json hint at a modern JavaScript/TypeScript frontend, suggesting a responsive UI and potential for rapid feature iteration.\n\nOpcode shines in scenarios where AI-driven development needs structure and transparency. For example, a team working on a large codebase can use the Project Browser to navigate sessions, resume context-rich conversations, and track their progress visually, rather than relying on scattered CLI logs. When automating repetitive tasks—like running unit tests or scanning for vulnerabilities—developers can define custom agents in ccagents/, then launch them as secure background processes, freeing up the main UI and providing detailed execution logs. In another case, solo developers or teams can monitor Claude API usage and costs through the integrated analytics dashboard, making budgeting and optimization actionable rather than guesswork. Each feature is designed to solve a tangible pain point in the AI coding workflow.\n\nThe significance of opcode is its ability to operationalize AI coding—turning it from a series of disconnected CLI commands into an integrated, auditable, and extensible system. This matters because as AI assistants become central to the software development lifecycle, the need for visibility, control, and customization grows. Opcode offers not just a nicer interface, but a foundation for scaling AI-powered development, enabling teams to build, track, and iterate on agent workflows with the same rigor as any other part of their stack. For developers invested in Claude Code, opcode is more than a convenience: it’s a strategic tool for unlocking the full potential of AI-assisted engineering.",
      "url": "https://github.com/yebeai/opcode",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "winfunc/opcode",
        "url": "https://github.com/winfunc/opcode",
        "stars": 20701
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1607799279861-4dd421887fb3?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 3, 2026",
      "updatedAt": "February 3, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".cargo": 1,
          ".github": 7,
          "(root)": 11,
          "cc_agents": 4,
          "scripts": 1,
          "src-tauri": 79,
          "src": 97
        },
        "languages": {
          "TOML": 2,
          "YAML": 7,
          "Markdown": 5,
          "JSON": 7,
          "HTML": 1,
          "Shell": 1,
          "Rust": 20,
          "TSX": 87,
          "CSS": 1,
          "TypeScript": 6
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "cargo",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "index.html",
          "src-tauri/src/lib.rs",
          "src-tauri/src/main.rs",
          "src/App.tsx",
          "src/components/index.ts",
          "src/components/widgets/index.ts",
          "src/hooks/index.ts"
        ],
        "configFiles": [
          "package.json",
          "src-tauri/Cargo.toml"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json",
          "src-tauri/Cargo.toml"
        ],
        "testFiles": [
          ".github/workflows/build-test.yml",
          "cc_agents/unit-tests-bot.opcode.json",
          "src-tauri/tests/TESTS_COMPLETE.md",
          "src-tauri/tests/TESTS_TASK.md"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "cc_agents/README.md"
        ],
        "fileTypes": {
          ".toml": 2,
          ".yml": 7,
          ".md": 5,
          ".lock": 2,
          ".lockb": 1,
          ".json": 7,
          ".html": 1,
          ".sh": 1,
          ".nix": 1,
          ".plist": 2,
          ".rs": 20,
          ".png": 49,
          ".icns": 1,
          ".ico": 1,
          ".tsx": 87,
          ".ttf": 1,
          ".ogg": 1,
          ".css": 1,
          ".ts": 6
        }
      }
    },
    {
      "id": 1149228029,
      "name": "hyprnote",
      "displayName": "hyprnote",
      "description": "Local-first AI Notepad for Private Meetings",
      "summary": "Taking notes during meetings often feels like an exercise in futility. You're trying to stay engaged in the conversation while simultaneously capturing key points, action items, and follow-ups. For many professionals, this balancing act leads to incomplete notes, forgotten ideas, and missed opportunities for collaboration. And for organizations that deal with sensitive information, relying on cloud-based AI tools often raises privacy concerns. Hyprnote, a local-first AI notepad, aims to address these pain points by offering a unique solution tailored for private meetings and offline environments.\n\nHyprnote is an AI-powered meeting assistant designed to make note-taking seamless while respecting user privacy. What sets it apart is its local-first architecture, enabling users to transcribe, summarize, and organize meeting notes without relying on external cloud services. Unlike many AI-enabled productivity tools that require internet connectivity and often involve sending sensitive data to third-party servers, Hyprnote runs entirely on your local machine. By leveraging tools like LM Studio and Ollama, it allows users to incorporate their own large language models (LLMs), ensuring complete control over their data. Moreover, its ability to craft personalized summaries based on your memos—and even generate high-quality summaries without any input—makes it a standout option for professionals juggling multiple meetings daily.\n\nFrom a technical perspective, the repository provides intriguing insights into how Hyprnote is architected. The file structure suggests a modular, extensible design. For example, the .cursor/commands directory includes Markdown documentation for CLI commands like add-analytics.md, update-seed.md, and web-designer.md, hinting at a robust command-line interface for managing plugins, analytics, and branch diffs. These capabilities suggest that Hyprnote is built with scalability and developer customization in mind. Additionally, the .github/actions directory contains numerous YAML configurations for GitHub Actions, such as argmaxsdksetup, generate_checksums, and desktop-e2e-linux. This reveals a focus on automating development workflows, CI/CD pipelines, and cross-platform support. The inclusion of .cargo/config.toml also indicates that parts of Hyprnote may be written in Rust, a language known for its memory safety and performance, making it well-suited for local-first applications. The architecture reflects a thoughtful balance between user-facing features and developer-centric flexibility.\n\nHyprnote introduces compelling use cases for developers and teams. First, imagine a remote software engineering team conducting daily stand-ups. With Hyprnote running locally, the team can transcribe discussions and generate summaries without relying on external transcription services, ensuring sensitive project details remain secure. Second, consider a legal team preparing for a case. They can leverage Hyprnote's offline capabilities to transcribe depositions or client meetings without risking exposure to cloud-based platforms. Finally, academic researchers attending lectures or brainstorming sessions can use Hyprnote to organize their notes, create summaries, and even query their notes via AI chat for follow-ups like \"What were the key findings from this session?\" The ability to customize templates and integrate with tools like Obsidian further enhances its utility for diverse workflows.\n\nHyprnote matters because it challenges the status quo of AI-powered productivity tools. By prioritizing privacy, local-first operation, and developer extensibility, it addresses critical concerns around data security and compliance, particularly in industries with strict regulatory requirements. Its modular design and support for user-defined LLMs empower developers to tailor the tool to their specific needs, making it far more versatile than one-size-fits-all solutions. For professionals and organizations seeking a secure, customizable, and efficient way to manage meeting notes, Hyprnote offers a glimpse into the future of privacy-conscious AI tooling.",
      "url": "https://github.com/yebeai/hyprnote",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "fastrepl/char",
        "url": "https://github.com/fastrepl/char",
        "stars": 7807
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 3, 2026",
      "updatedAt": "February 3, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".cargo": 1,
          ".cursor": 8,
          "(root)": 15,
          ".drizzle": 1,
          ".github": 72,
          ".grit": 2,
          ".vscode": 2,
          ".zed": 1,
          "apps": 98
        },
        "languages": {
          "TOML": 6,
          "JSON": 14,
          "Markdown": 14,
          "YAML": 74,
          "Rust": 3,
          "TypeScript": 53,
          "JavaScript": 1,
          "HTML": 1
        },
        "frameworks": [
          "React",
          "Docker"
        ],
        "packageManager": "cargo",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "apps/ai/src/main.rs",
          "apps/api/src/index.ts",
          "apps/api/src/integration/index.ts",
          "apps/api/src/middleware/index.ts",
          "apps/api/src/observability/index.ts",
          "apps/api/src/routes/index.ts",
          "apps/bot/src/devin/index.ts",
          "apps/bot/src/features/index.ts",
          "apps/bot/src/index.ts",
          "apps/bot/src/server.ts",
          "apps/desktop/index.html"
        ],
        "configFiles": [
          ".prettierrc",
          "Cargo.toml",
          "apps/ai/Cargo.toml",
          "apps/ai/Dockerfile",
          "apps/api/Dockerfile",
          "apps/api/package.json",
          "apps/api/tsconfig.json",
          "apps/bot/Dockerfile",
          "apps/bot/package.json",
          "apps/bot/tsconfig.json",
          "apps/desktop/package.json"
        ],
        "dependencies": [
          "Cargo.toml",
          "apps/ai/Cargo.toml",
          "apps/api/package.json",
          "apps/bot/package.json",
          "apps/desktop/package.json"
        ],
        "testFiles": [
          "apps/api/src/middleware/load-test-auth.ts",
          "apps/bot/test/fixtures/issues.opened.json",
          "apps/bot/test/fixtures/mock-cert.pem",
          "apps/bot/test/fixtures/pull_request.opened.json",
          "apps/bot/test/setup-env.ts",
          "apps/bot/vitest.config.ts"
        ],
        "docs": [
          ".cursor/commands/new-changelog.md",
          ".github/workflows/changelog.yaml",
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".toml": 6,
          ".json": 14,
          ".md": 14,
          ".yml": 12,
          ".yaml": 62,
          ".mjs": 2,
          ".jsonc": 1,
          ".lock": 1,
          ".rs": 3,
          ".ts": 53,
          ".js": 1,
          ".pem": 1,
          ".desktop": 1,
          ".xml": 1,
          ".html": 1,
          ".gif": 2,
          ".jpeg": 2,
          ".png": 6,
          ".svg": 1,
          ".otf": 1
        }
      }
    },
    {
      "id": 1149226521,
      "name": "tgterm",
      "displayName": "tgterm",
      "description": "Control your MacOS terminals via Telegram, for fun coding agents interaction and profit",
      "summary": "As developers become increasingly reliant on agile workflows and remote collaboration, the need for efficient terminal access has never been more pressing. Imagine a scenario where you are away from your desk, yet you need to manage your development environment, run scripts, or troubleshoot an issue—all while not being physically present at your machine. Traditional methods like SSH tunneling or VPNs can often be cumbersome and require significant setup, particularly when dealing with graphical outputs or needing to juggle multiple terminal sessions. This is where tgterm comes into play, offering an innovative solution that leverages Telegram as a medium for terminal control.\n\ntgterm is an open-source project designed to control macOS terminal sessions via a Telegram bot. It abstracts away the complexities of SSH tunneling and multiplexing tools like tmux, allowing developers to interact with their terminals through a simple chat interface. The key differentiator here is the integration with Telegram, a platform that many users are already familiar with, thereby reducing the learning curve and setup time. The project's README highlights its motivations and the user-centric design, emphasizing that it is tailored for scenarios where instant access to terminal commands is crucial, especially for modern coding agents powered by AI.\n\nDiving into the architecture, tgterm is structured around a C programming core, with a clear separation of concerns evident in its file hierarchy. The bot.c file handles the main functionalities related to the Telegram bot communication, while botlib.c and botlib.h encapsulate reusable components for bot operations. The use of cJSON.c and cJSON.h suggests a JSON-centric approach to data handling, which is critical for parsing commands and responses between the Telegram API and the terminal. The presence of files like sqlite_wrap.c indicates that the project may leverage SQLite for any state management or logging needs, while qrcodegen.c facilitates the TOTP setup, ensuring secure access to the bot. This modular design not only adheres to good programming practices but also makes it easier for future contributors to understand and extend the functionality.\n\nThe potential use cases for tgterm are extensive. First, consider a developer who is working on a long-running machine learning model that requires occasional monitoring and adjustments. With tgterm, they could receive terminal screenshots and send commands to modify parameters without needing to configure complicated remote access setups. Secondly, for teams collaborating on a project where multiple terminal sessions need to be monitored or controlled, tgterm allows team members to quickly switch contexts and interact with various sessions through simple commands sent via Telegram. Finally, for debugging graphical applications, where direct SSH access may not suffice, tgterm allows developers to view terminal output in real-time and interact with the application seamlessly.\n\nIn conclusion, tgterm embodies a forward-thinking approach to terminal management for macOS users, challenging conventional methods that often hinder productivity. Its design leverages existing tools like Telegram to create a more streamlined interaction model, making it easier for developers to stay connected with their work regardless of their physical location. As we continue to adopt more remote and hybrid work environments, projects like tgterm are invaluable in enhancing our ability to manage and control our development workflows effectively. The implications of such innovative solutions are clear: they not only simplify processes but also empower developers to focus on what truly matters—building and innovating.",
      "url": "https://github.com/yebeai/tgterm",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "antirez/tgterm",
        "url": "https://github.com/antirez/tgterm",
        "stars": 205
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 3, 2026",
      "updatedAt": "February 3, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 23,
        "directories": {
          "(root)": 23
        },
        "languages": {
          "Markdown": 3,
          "C": 8,
          "C/C++ Header": 8
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [
          "Makefile"
        ],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".md": 3,
          ".c": 8,
          ".h": 8,
          ".png": 1
        }
      }
    },
    {
      "id": 1149213593,
      "name": "tsl-node-editor",
      "displayName": "tsl node editor",
      "description": "No description available",
      "summary": "The Problem\n\nBuilding custom shaders in Three.js is a pain. Writing raw GLSL is tedious, error-prone, and debugging it feels like trying to read hieroglyphs. Tools like ShaderGraph exist, but they don't always play nicely with exporting to a format you can reuse in your app. If you've ever wanted a visual node editor for Three.js shaders with WebGPU support, but without needing a PhD in graphics programming, that's where this repo comes in.\n\nWhat This Does\n\ntsl-node-editor is a visual editor for creating Three.js shaders (TSL) with a WebGPU-based live preview. The main work happens in src/viewer.ts and src/tslGltfExporter.ts. The former handles the WebGPU-powered shader/material preview, while the latter deals with exporting your creations to TSL, GLTF, or even app-ready JavaScript/TypeScript.\n\nThe UI lives in src/App.tsx and uses a React-based front end. You can drag and drop nodes, connect them, and tweak parameters in real time. The exported build is served via Vite (vite.config.ts) with some static assets in public/. For a quick test, open the viewer.html file directly in your browser, though you'll need WebGPU support (Chrome 113+ or Edge 113+).\n\nReal-World Use\n\nLet’s say you’re working on a custom Three.js-based WebGPU project and need a shader that blends textures based on a noise function. Instead of writing raw GLSL, you fire up this editor (npm run dev), connect a few nodes (like a texture node, a noise function node, and a blend node), and preview the output directly in the app. Once it looks good, export the result using the tools in src/tslGltfExporter.ts. Copy the exported code into your project, and you're done. No cryptic shader errors, no guesswork.\n\nimport { MyCustomMaterial } from './exportedMaterial.js';\nconst material = new MyCustomMaterial();\nconst mesh = new THREE.Mesh(geometry, material);\nscene.add(mesh);\n\nThe Bottom Line\n\nIf you're building custom shaders with Three.js and want a more visual approach, this is a solid tool to experiment with. The WebGPU live preview is slick, and the TSL export is a nice touch if you’re already in the Three.js ecosystem. That said, it’s experimental, unpolished, and definitely not production-ready (seriously, \"vibe-coding\"?). But if you’re hacking on side projects or learning WebGPU, it’s worth a couple of hours to play with. Just don’t expect hand-holding or documentation beyond the basics.",
      "url": "https://github.com/yebeai/tsl-node-editor",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "takahirox/tsl-node-editor",
        "url": "https://github.com/takahirox/tsl-node-editor",
        "stars": 21
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 3, 2026",
      "updatedAt": "February 3, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 23,
        "directories": {
          ".github": 1,
          "(root)": 12,
          "public": 3,
          "src": 7
        },
        "languages": {
          "YAML": 1,
          "Markdown": 1,
          "JavaScript": 2,
          "HTML": 2,
          "JSON": 5,
          "CSS": 2,
          "TSX": 2,
          "TypeScript": 3
        },
        "frameworks": [
          "React",
          "Express"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "index.html",
          "src/App.tsx"
        ],
        "configFiles": [
          "package.json",
          "tsconfig.json",
          "vite.config.ts"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".yml": 1,
          ".md": 1,
          ".js": 2,
          ".html": 2,
          ".json": 5,
          ".wasm": 1,
          ".svg": 2,
          ".css": 2,
          ".tsx": 2,
          ".ts": 3
        }
      }
    },
    {
      "id": 1149213280,
      "name": "videosos",
      "displayName": "videosos",
      "description": "Enable AI models for video production in the browser",
      "summary": "The Problem\nVideo production has traditionally been a resource-intensive task, often requiring hefty software and cloud services, leading to privacy concerns and high costs. For many creators, the lack of a straightforward, browser-based solution that handles AI video generation and editing is a major pain point.\n\nWhat This Does\nEnter VideoSOS, an open-source video editor designed to run entirely in your browser. The project leverages AI models for text-to-video, image generation, and audio creation without the hassle of uploads or privacy invasions. The core of the app relies on FFmpeg.wasm and Remotion, found in the Makefile and various scripts, to handle video rendering locally.\n\nThe README.md outlines how to get started, while INSTALL-PORTABLE.txt gives you the lowdown on setting up your environment. Want to track project costs? The VIDEOMODELSPARAMETERS.md file ensures you know how much you're spending on each media item. \n\nReal-World Use\nImagine you're a content creator needing to whip up a quick promotional video. You open VideoSOS, select a text-to-video model like Google Veo 3.1, and type in your script. The timeline editor lets you drag and drop elements, adjust audio tracks, and fine-tune visuals—all while keeping an eye on your budget with the cost tracking feature. You export your project directly in the browser, avoiding the waiting game of cloud processing.\n\nHere's a simple snippet to kick off a new project:\n\nconst videoProject = new VideoProject();\nvideoProject.addClip('intro.mp4');\nvideoProject.addAudio('background-music.mp3');\nvideoProject.render();\n\nThe Bottom Line\nVideoSOS is a solid pick for anyone looking to produce videos without the bloat of traditional software. It's especially useful for small to medium projects where privacy and cost efficiency are priorities. Just be aware that if you're working on large-scale productions, the local-only processing might not cut it—this isn't Adobe Premiere. Still, for quick edits and experimentation, it’s a no-brainer.",
      "url": "https://github.com/yebeai/videosos",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "timoncool/videosos",
        "url": "https://github.com/timoncool/videosos",
        "stars": 1123
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 3, 2026",
      "updatedAt": "February 3, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 30,
          ".github": 8,
          ".husky": 1,
          "data": 2,
          "docker": 2,
          "docs": 79,
          "messages": 2,
          "public": 4,
          "scripts": 7,
          "src": 65
        },
        "languages": {
          "JSON": 8,
          "Markdown": 92,
          "YAML": 7,
          "Shell": 1,
          "TypeScript": 12,
          "Python": 1,
          "TSX": 56,
          "CSS": 1
        },
        "frameworks": [
          "React",
          "Next.js",
          "Docker"
        ],
        "packageManager": "npm",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          ".env.example",
          ".eslintrc.json",
          "Makefile",
          "docker-compose.yml",
          "docker/node/Dockerfile",
          "next.config.mjs",
          "package.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [
          "src/components/aspect-ratio.tsx"
        ],
        "docs": [
          ".github/CONTRIBUTING.md",
          "CONTRIBUTING.md",
          "LICENSE",
          "README-Portable.txt",
          "README.md",
          "README.ru.md",
          "data/README.md",
          "docker/README.md",
          "docs/README.md",
          "docs/fal/TOC.md",
          "docs/fal/models/fal-top-models.md",
          "docs/fal/pages/authentication.md",
          "docs/fal/pages/authentication/github.md",
          "docs/fal/pages/authentication/key-based.md",
          "docs/fal/pages/client.md",
          "docs/fal/pages/errors.md",
          "docs/fal/pages/faq.md",
          "docs/fal/pages/fast-flux.md",
          "docs/fal/pages/fast-sdxl.md",
          "docs/fal/pages/guides/convert-speech-to-text.md",
          "docs/fal/pages/guides/custom-workflow-ui.md",
          "docs/fal/pages/guides/generate-images-from-text.md",
          "docs/fal/pages/guides/generate-videos-from-image.md",
          "docs/fal/pages/guides/n8n.md",
          "docs/fal/pages/guides/use-llms.md",
          "docs/fal/pages/index.md",
          "docs/fal/pages/integrations/nextjs.md",
          "docs/fal/pages/integrations/vercel.md",
          "docs/fal/pages/mcp.md",
          "docs/fal/pages/model-endpoints.md",
          "docs/fal/pages/model-endpoints/queue.md",
          "docs/fal/pages/model-endpoints/server-side.md",
          "docs/fal/pages/model-endpoints/synchronous-requests.md",
          "docs/fal/pages/model-endpoints/webhooks.md",
          "docs/fal/pages/model-endpoints/websockets.md",
          "docs/fal/pages/model-endpoints/workflows.md",
          "docs/fal/pages/quickstart.md",
          "docs/fal/pages/real-time.md",
          "docs/fal/pages/real-time/quickstart.md",
          "docs/fal/pages/real-time/secrets.md",
          "docs/fal/pages/support.md",
          "docs/runware/TOC.md",
          "docs/runware/models/runware-top-models.md",
          "docs/runware/pages/audio-inference/api-reference.md",
          "docs/runware/pages/audio-inference/introduction.md",
          "docs/runware/pages/getting-started/how-to-connect.md",
          "docs/runware/pages/getting-started/introduction.md",
          "docs/runware/pages/image-inference/api-reference.md",
          "docs/runware/pages/image-inference/flux-tools.md",
          "docs/runware/pages/image-inference/image-to-image.md",
          "docs/runware/pages/image-inference/inpainting.md",
          "docs/runware/pages/image-inference/introduction.md",
          "docs/runware/pages/image-inference/model-upload.md",
          "docs/runware/pages/image-inference/models.md",
          "docs/runware/pages/image-inference/outpainting.md",
          "docs/runware/pages/image-inference/photomaker.md",
          "docs/runware/pages/image-inference/schedulers.md",
          "docs/runware/pages/image-inference/text-to-image.md",
          "docs/runware/pages/libraries/comfyui.md",
          "docs/runware/pages/libraries/javascript.md",
          "docs/runware/pages/libraries/python.md",
          "docs/runware/pages/libraries/vercel-ai.md",
          "docs/runware/pages/providers/bfl.md",
          "docs/runware/pages/providers/bria.md",
          "docs/runware/pages/providers/bytedance.md",
          "docs/runware/pages/providers/google.md",
          "docs/runware/pages/providers/ideogram.md",
          "docs/runware/pages/providers/introduction.md",
          "docs/runware/pages/providers/klingai.md",
          "docs/runware/pages/providers/lightricks.md",
          "docs/runware/pages/providers/minimax.md",
          "docs/runware/pages/providers/openai.md",
          "docs/runware/pages/providers/pixverse.md",
          "docs/runware/pages/providers/sourceful.md",
          "docs/runware/pages/providers/vidu.md",
          "docs/runware/pages/tools/caption.md",
          "docs/runware/pages/tools/controlnet-preprocess.md",
          "docs/runware/pages/tools/image-masking.md",
          "docs/runware/pages/tools/prompt-enhancer.md",
          "docs/runware/pages/tools/remove-background.md",
          "docs/runware/pages/tools/upscale.md",
          "docs/runware/pages/utilities/account-management.md",
          "docs/runware/pages/utilities/image-upload.md",
          "docs/runware/pages/utilities/model-search.md",
          "docs/runware/pages/utilities/task-responses.md",
          "docs/runware/pages/video-inference/api-reference.md",
          "docs/runware/pages/video-inference/introduction.md"
        ],
        "fileTypes": {
          ".example": 1,
          ".json": 8,
          ".md": 92,
          ".yml": 7,
          ".txt": 2,
          ".bat": 2,
          ".sh": 1,
          ".ts": 12,
          ".mjs": 2,
          ".png": 4,
          ".webp": 1,
          ".py": 1,
          ".tsx": 56,
          ".ico": 1,
          ".woff": 2,
          ".css": 1
        }
      }
    },
    {
      "id": 1149211983,
      "name": "FlyingCarpet",
      "displayName": "FlyingCarpet",
      "description": "Cross-platform AirDrop. File transfer between Android, iOS, Linux, macOS, and Windows over ad hoc WiFi. No network infrastructure required, just two devices with WiFi chips (and optionally Bluetooth) in close range.",
      "summary": "In an increasingly mobile world, the need for seamless and efficient file transfers between diverse platforms cannot be overstated. Imagine a scenario where you need to transfer a large file from your Android device to a laptop running Linux while both devices are disconnected from the internet. Traditional methods such as USB drives or cloud services become cumbersome and time-consuming. Furthermore, in environments with strict network security policies, accessing external networks may not be feasible. This is where FlyingCarpet comes into play, providing an innovative solution for cross-platform file transfer without the need for any network infrastructure.\n\nFlyingCarpet is a cross-platform application that allows users to send and receive files between Android, iOS, Linux, macOS, and Windows devices over ad hoc WiFi. Its key differentiator lies in its ability to perform file transfers without requiring a shared network or cellular connection, merely leveraging the WiFi chips present in the devices. The project builds upon the success of its predecessor, which has garnered significant attention on GitHub with nearly 5,000 stars. With features like Bluetooth integration for transfer negotiation and a focus on simplicity and accessibility, FlyingCarpet addresses a crucial gap in the file transfer landscape.\n\nDelving into the architecture of FlyingCarpet, the project employs Rust as its core programming language, promoting performance and memory safety. This is evident in the presence of the Cargo.toml file, which indicates a Rust-based environment. The project structure is organized into platform-specific directories, such as Android/FlyingCarpet, which contains the Android application code, including the app’s manifest and main activity files. The MainActivity.kt file in particular indicates a well-structured approach to handling the user interface for sending and receiving files. Additionally, the presence of files like Bluetooth.kt and Utilities.kt suggests that the developers have modularized functionalities, making the codebase easier to maintain and extend. \n\nFlyingCarpet is beneficial in several real-world scenarios. For instance, developers working in a corporate setting may need to transfer sensitive data between devices without exposing it to the internet. FlyingCarpet allows for secure, direct file transfers in such environments. Another use case emerges in educational institutions where students often need to share large files, like presentations or projects, without relying on institutional WiFi or internet access. Furthermore, software engineers working on cross-platform applications can leverage FlyingCarpet to streamline testing and deployment processes across devices and operating systems, reducing the friction associated with file exchanges.\n\nUltimately, FlyingCarpet represents a significant advancement in the domain of file transfer solutions. Its blend of cross-platform functionality, reliance on ad hoc WiFi, and modular architecture highlights the project's commitment to user needs and developer convenience. As our reliance on mobile and multi-device environments continues to grow, tools like FlyingCarpet will play an essential role in enhancing productivity and simplifying interactions between diverse systems. The project not only fills a vital niche but also encourages further exploration of open-source solutions that prioritize interoperability and user empowerment.",
      "url": "https://github.com/yebeai/FlyingCarpet",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "spieglt/FlyingCarpet",
        "url": "https://github.com/spieglt/FlyingCarpet",
        "stars": 4969
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 3, 2026",
      "updatedAt": "February 3, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 115,
        "directories": {
          "(root)": 6,
          ".github": 1,
          "Android": 54,
          "Flying Carpet": 29,
          "core": 14,
          "fastlane": 3,
          "screenshots": 8
        },
        "languages": {
          "YAML": 1,
          "Kotlin": 9,
          "TOML": 3,
          "Rust": 15,
          "JSON": 2,
          "CSS": 2,
          "JavaScript": 2,
          "HTML": 1,
          "Markdown": 1
        },
        "frameworks": [],
        "packageManager": "cargo",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "Flying Carpet/src-tauri/src/main.rs",
          "Flying Carpet/src/index.html",
          "Flying Carpet/src/main.js",
          "core/src/lib.rs"
        ],
        "configFiles": [
          "Android/FlyingCarpet/app/build.gradle",
          "Android/FlyingCarpet/build.gradle",
          "Cargo.toml",
          "Flying Carpet/src-tauri/Cargo.toml",
          "core/Cargo.toml"
        ],
        "dependencies": [
          "Android/FlyingCarpet/app/build.gradle",
          "Android/FlyingCarpet/build.gradle",
          "Cargo.toml",
          "Flying Carpet/src-tauri/Cargo.toml",
          "core/Cargo.toml"
        ],
        "testFiles": [
          "Android/FlyingCarpet/app/src/androidTest/java/dev/spiegl/flyingcarpet/ExampleInstrumentedTest.kt",
          "Android/FlyingCarpet/app/src/test/java/dev/spiegl/flyingcarpet/ExampleUnitTest.kt"
        ],
        "docs": [
          "LICENSE.txt",
          "README.md"
        ],
        "fileTypes": {
          ".yml": 1,
          ".gradle": 3,
          ".pro": 1,
          ".kt": 9,
          ".xml": 16,
          ".png": 31,
          ".webp": 10,
          ".properties": 2,
          ".jar": 1,
          ".bat": 1,
          ".lock": 1,
          ".toml": 3,
          ".rs": 15,
          ".json": 2,
          ".icns": 1,
          ".ico": 1,
          ".css": 2,
          ".js": 2,
          ".html": 1,
          ".txt": 3,
          ".md": 1
        }
      }
    },
    {
      "id": 1149200284,
      "name": "unbound-dashboard",
      "displayName": "unbound dashboard",
      "description": "Unbound Dashboard In Grafana With Prometheus & Loki",
      "summary": "Managing DNS infrastructure in production environments comes with its own set of challenges, especially when it comes to gaining real visibility into query performance, cache hit ratios, and security-related event logs. Unbound, a popular validating, recursive, and caching DNS resolver, is widely used for its security and performance, but its telemetry isn’t immediately accessible in a form that’s actionable for operators. The lack of a modern, consolidated dashboard for Unbound metrics and logs is a pain point for teams seeking to optimize and secure their DNS layer—particularly in resource-constrained environments like Raspberry Pi deployments.\n\nThe unbound-dashboard project directly addresses this gap by providing an integrated Grafana dashboard tailored to Unbound, leveraging Prometheus for metrics and Loki for log aggregation. Unlike generic Grafana dashboards that attempt to cover a wide array of services, this project is laser-focused on Unbound, including a Go-based custom metrics exporter designed specifically for the resolver. There’s also a strong emphasis on running efficiently on ARM64 hardware, with deployment tested on Raspberry Pi 4 using a minimal Linux distribution (raspios-bookworm-arm64-lite). The dashboard aims to be “turn-key” for DNS-focused monitoring: the provided configuration files and installation instructions are curated to help users avoid unnecessary bloat and optimize for low memory footprint.\n\nLooking at the file structure, it’s clear the maintainer values reproducibility and operational clarity. The README.md serves as both a guide and a reference, outlining not just installation steps but also architectural choices—like the decision to use Prometheus with a custom Go exporter rather than node or default Prometheus exporters, which are removed for leaner operation. The release.md file indicates an active release process, and info.md dives into dashboard specifics. The inclusion of screenshots/dashboard-2.3.png and a screenshots.md file signals a commitment to transparency; users can see exactly what they’re getting before they even start. Notably, configuration files such as grafana.ini and prometheus.yml are shipped as part of releases, reflecting a practical approach: users don’t need to waste time tuning these for embedded deployment. The project’s OSS-first orientation is evident, with explicit guidance to avoid unnecessary enterprise packages that add overhead.\n\nThis dashboard is particularly valuable in scenarios where minimal hardware is a constraint—think home lab enthusiasts, edge deployments, or small business networks running Raspberry Pi. For example, a developer running a local DNS resolver for IoT devices can use this dashboard to monitor query rates and security events without investing in expensive hardware or commercial monitoring solutions. Another use case is for security-conscious operators who want to audit DNS traffic for signs of malware or data exfiltration; by leveraging Loki’s log aggregation, they can quickly surface anomalous patterns. Finally, anyone experimenting with DNS caching performance—say, optimizing cache sizes and TTLs for a busy office LAN—can get real-time feedback on configuration changes with minimal setup friction.\n\nWhat stands out about unbound-dashboard is its opinionated approach to telemetry: it isn’t trying to be everything for everyone. By removing node exporters, shipping tuned configuration files, and focusing exclusively on Unbound, it delivers a streamlined experience that respects both hardware limitations and operational realities. This is a sensible model for open source infra tooling—keep scope narrow, optimize defaults, and document rigorously. For teams and individuals who care about DNS performance and security but don’t want to babysit a sprawling monitoring stack, this project is a thoughtful, practical solution. It’s a reminder that the best open source tools often solve one problem exceptionally well, with just enough flexibility and documentation to make them extensible.",
      "url": "https://github.com/yebeai/unbound-dashboard",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "ar51an/unbound-dashboard",
        "url": "https://github.com/ar51an/unbound-dashboard",
        "stars": 617
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 3, 2026",
      "updatedAt": "February 3, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 7,
        "directories": {
          "(root)": 4,
          "screenshots": 3
        },
        "languages": {
          "Markdown": 4
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".md": 4,
          ".png": 1
        }
      }
    },
    {
      "id": 1149198037,
      "name": "memora",
      "displayName": "memora",
      "description": "No description available",
      "summary": "In the evolving landscape of AI development, the ability to grant artificial intelligence agents persistent memory is a critical challenge. Modern AI systems often struggle with context retention, limiting their ability to build nuanced, long-term understanding across sessions or tasks. This is especially problematic in applications such as personal assistants, research tools, or multi-agent systems, where continuity and semantic awareness are key. Enter Memora, a lightweight solution designed to address this gap by providing AI agents with a robust memory storage system, complete with semantic search capabilities, knowledge graph visualization, and cross-session context management. While the repository itself lacks stars or recognition, its origin as a fork from the well-regarded agentic-mcp-tools/memora suggests a promising foundation.\n\nMemora is an MCP (Memory-Centric Processing) server designed to empower AI systems with scalable, persistent memory. Its standout feature is its ability to organize, search, and cross-reference information using hierarchical structures, vector embeddings, and typed edges within knowledge graphs. What sets Memora apart is its lightweight nature and modularity—it’s not just another monolithic data storage system but a carefully designed toolkit for memory management. Developers can choose between local storage using SQLite or cloud-based solutions like Cloudflare D1, offering flexibility for different deployment scenarios. The project’s dedication to semantic search and memory linking ensures that it’s not merely a data dump but an intelligent memory system capable of contextually relevant retrieval and deduplication.\n\nA closer look at the file structure reveals the architectural patterns underpinning Memora’s design. The repository is divided into two major components: claude-plugin, which integrates Memora into Claude Code workflows, and memora-graph, which manages the memory storage and visualization functionalities. The claude-plugin directory includes hooks and handlers (posttooluse.py, session_start.py) that facilitate interaction between Memora and AI agents, ensuring seamless integration with Claude MCP environments. Meanwhile, the memora-graph directory houses core functionalities such as API endpoints (graph.ts, memories.ts, r2/[[path]].ts) and scripts for cloud synchronization (setup-cloudflare.sh, sync-to-d1.py). The presence of a tsconfig.json file indicates a TypeScript-based implementation, which is a deliberate choice for building scalable and maintainable APIs. Additionally, the public/index.html and visualization tools like Mermaid rendering suggest a focus on user-friendly interfaces, particularly for graph-based memory exploration.\n\nMemora’s utility shines in scenarios where long-term memory is critical. Consider a research assistant powered by an LLM that needs to track references, deduplicate similar findings, and organize insights into a knowledge graph. Memora’s semantic search and memory linking capabilities enable such an assistant to retrieve related information while maintaining a hierarchical structure for better organization. Another compelling use case is in multi-agent systems where agents need to collaborate on complex tasks across sessions. Memora’s event notification system and cross-referencing ensure that agents can communicate effectively, share context, and avoid redundant efforts. Developers building interactive dashboards or analytics tools will also benefit from the live graph server, which provides real-time visualizations of memory clusters and relationships, facilitating deeper insights.\n\nAt its core, Memora offers a glimpse into what AI systems could achieve with persistent, intelligent memory. While the repository itself may not yet have widespread recognition, its design is thoughtful, modular, and clearly aimed at solving real-world problems. The integration with Claude Code and the ability to seamlessly switch between local and cloud storage makes it versatile for a wide range of applications. Developers looking to build smarter, context-aware systems will find Memora to be a powerful building block, enabling AI agents to evolve from reactive tools to dynamic collaborators. As AI continues to push boundaries, projects like Memora remind us that memory is not just a technical feature—it’s the cornerstone of intelligence.",
      "url": "https://github.com/yebeai/memora",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "agentic-mcp-tools/memora",
        "url": "https://github.com/agentic-mcp-tools/memora",
        "stars": 296
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 3, 2026",
      "updatedAt": "February 3, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 50,
        "directories": {
          "(root)": 5,
          "claude-plugin": 5,
          "media": 7,
          "memora-graph": 17,
          "memora": 13,
          "nvim": 1,
          "tests": 2
        },
        "languages": {
          "Markdown": 4,
          "JSON": 5,
          "Python": 19,
          "TypeScript": 5,
          "HTML": 1,
          "Shell": 2,
          "TOML": 3,
          "Lua": 1
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "memora-graph/public/index.html",
          "memora-graph/worker/src/index.ts",
          "memora/__main__.py",
          "memora/graph/server.py",
          "memora/server.py"
        ],
        "configFiles": [
          "memora-graph/package.json",
          "memora-graph/tsconfig.json",
          "pyproject.toml"
        ],
        "dependencies": [
          "memora-graph/package-lock.json",
          "memora-graph/package.json",
          "pyproject.toml"
        ],
        "testFiles": [
          "tests/__init__.py",
          "tests/test_cloud_backends.py"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "claude-plugin/README.md",
          "memora-graph/README.md"
        ],
        "fileTypes": {
          ".md": 4,
          ".json": 5,
          ".py": 19,
          ".gif": 2,
          ".jpg": 1,
          ".png": 4,
          ".ts": 5,
          ".html": 1,
          ".sh": 2,
          ".toml": 3,
          ".lua": 1
        }
      }
    },
    {
      "id": 1148352676,
      "name": "PythonRobotics",
      "displayName": "PythonRobotics",
      "description": "Python sample codes and textbook for robotics algorithms.",
      "summary": "The Problem\n\nGetting robotics algorithms off the ground is a pain. You want to try SLAM, path planning, or basic arm navigation, but every tutorial is either half-baked, buried in MATLAB, or assumes you have a $10k robot lying around. You need working Python code, not another academic PDF.\n\nWhat This Does\n\nPythonRobotics dumps a ton of actual Python scripts for robotics algorithms into folders like AerialNavigation, ArmNavigation, and so on. You get working code for everything from drone3dtrajectoryfollowing.py to rrtstarsevenjointarmcontrol.py, not just some pseudocode and a wish for luck. Each folder is pretty much a mini textbook—look at ArmNavigation/armobstaclenavigation/armobstaclenavigation.py for obstacle avoidance with robotic arms, or AerialNavigation/rocketpoweredlanding/rocketpoweredlanding.py if you’re feeling SpaceX-y.\n\nThe repo doesn’t hide behind abstraction or a labyrinth of classes. Most scripts are straight up, readable, and runnable. The CI configs (.github/workflows/LinuxCI.yml, etc.) mean the code actually runs, not just \"works on my machine\" nonsense.\n\nReal-World Use\n\nSay you want to mess with RRT* path planning for a robotic arm. Crack open ArmNavigation/rrtstarsevenjointarmcontrol/rrtstarsevenjointarmcontrol.py, read a few dozen lines, and you can tweak the joint limits or obstacles directly. Want to simulate a drone trajectory? Open AerialNavigation/drone3dtrajectoryfollowing/drone3dtrajectoryfollowing.py and run it—no need for a ROS install or a PhD. Most scripts will plot results with matplotlib, so you actually see what’s going on.\n\nfrom ArmNavigation.njointarmtopointcontrol import njointarmtopointcontrol\n\nnjointarmtopointcontrol.main()\n\nPlug in your parameters, hit run, and watch the arm move.\n\nThe Bottom Line\n\nPythonRobotics is a goldmine if you want working code for classic robotics algorithms—especially for students, hobbyists, or anyone sick of lecture slides. Don’t expect fancy frameworks or production-ready abstractions. If you want plug-and-play scripts you can hack apart, this is your repo. If you want something \"enterprise,\" look elsewhere.",
      "url": "https://github.com/yebeai/PythonRobotics",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "AtsushiSakai/PythonRobotics",
        "url": "https://github.com/AtsushiSakai/PythonRobotics",
        "stars": 28739
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 2, 2026",
      "updatedAt": "February 2, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".circleci": 1,
          ".github": 11,
          "(root)": 9,
          "AerialNavigation": 6,
          "ArmNavigation": 12,
          "Bipedal": 3,
          "InvertedPendulum": 2,
          "Localization": 8,
          "Mapping": 16,
          "MissionPlanning": 5,
          "PathPlanning": 92,
          "PathTracking": 12,
          "SLAM": 17,
          "docs": 6
        },
        "languages": {
          "YAML": 12,
          "Markdown": 7,
          "Python": 161,
          "reStructuredText": 1,
          "CSS": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          "docs/Makefile"
        ],
        "dependencies": [],
        "testFiles": [
          "PathPlanning/SpiralSpanningTreeCPP/map/test.png",
          "PathPlanning/SpiralSpanningTreeCPP/map/test_2.png",
          "PathPlanning/SpiralSpanningTreeCPP/map/test_3.png",
          "PathPlanning/WavefrontCPP/map/test.png",
          "PathPlanning/WavefrontCPP/map/test_2.png",
          "PathPlanning/WavefrontCPP/map/test_3.png"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "SLAM/GraphBasedSLAM/data/README.rst",
          "docs/Makefile",
          "docs/README.md",
          "docs/_static/.gitkeep",
          "docs/_static/custom.css",
          "docs/_static/img/doc_ci.png",
          "docs/_static/img/source_link_1.png"
        ],
        "fileTypes": {
          ".yml": 12,
          ".md": 7,
          ".py": 161,
          ".csv": 2,
          ".xml": 1,
          ".npy": 2,
          ".png": 8,
          ".rst": 1,
          ".g2o": 1,
          ".css": 1
        }
      }
    },
    {
      "id": 1148261974,
      "name": "TradingAgents",
      "displayName": "TradingAgents",
      "description": "TradingAgents: Multi-Agents LLM Financial Trading Framework",
      "summary": "Financial markets are complex, noisy, and increasingly influenced by both quantitative data and qualitative narratives. Traditional algorithmic trading often struggles to incorporate real-time news, sentiment, and fundamental analysis alongside technical signals. As AI and large language models (LLMs) evolve, the opportunity arises to build trading systems that mimic the collaborative expertise of human teams—each specializing in a domain and contributing to a holistic strategy. But orchestrating these multi-domain perspectives within a single framework is a daunting engineering challenge, and most open-source projects fall short in creating truly modular, extensible solutions that mirror organizational reality.\n\nTradingAgents addresses this gap, offering a multi-agent LLM-powered trading framework modeled after real-world trading firms. Unlike monolithic bots or simple rule-based scripts, TradingAgents decomposes the trading process into specialized agents—fundamental analysts, sentiment experts, technical analysts, traders, and risk managers. Each agent leverages LLMs for domain-specific reasoning and participates in dynamic inter-agent discussions. This collaborative architecture sets TradingAgents apart: the system is designed not just for execution, but for research into agent-driven strategy formation and cross-domain synthesis, enabling developers to simulate and study how teams of AI agents tackle the markets together.\n\nLooking at the file structure, the architectural intent is clear. The core logic resides in the tradingagents/agents directory, subdivided by specialization: analysts (with files like fundamentalsanalyst.py, marketanalyst.py, and news_analyst.py) encapsulate distinct knowledge domains, allowing for independent extension or replacement. The main.py at the root is likely the entry point, orchestrating agent interactions. CLI functionality is robust, with cli/main.py, models.py, and utils.py supporting a command-line interface for rapid prototyping and testing. The presence of assets/cli/ subfolder—full of illustrative screenshots—suggests user-centric design and documentation. Configuration is handled via .env.example and pyproject.toml, while setup.py and requirements.txt ensure reproducibility and easy installation. The modularity and clear separation of concerns—agents, CLI, utilities—make the codebase tractable and extensible, crucial for research and iterative development.\n\nDevelopers can leverage TradingAgents in several scenarios. First, researchers studying agent collaboration in financial contexts can use the framework to prototype new LLM-based strategies, experimenting with agent roles and communication protocols. Second, quant teams seeking to build explainable AI-driven trading systems can deploy TradingAgents to integrate fundamental, news, and technical analysis into a single workflow, improving transparency and auditability. Finally, builders of trading dashboards or educational tools can use the CLI and agent APIs to showcase how different perspectives influence trading decisions, providing users with interactive learning environments or demo platforms.\n\nTradingAgents matters because it advances the state of open-source trading frameworks toward a more realistic, modular, and collaborative paradigm. By abstracting trading into specialized agents, each powered by LLMs and capable of dynamic interaction, it opens new avenues for research, transparency, and innovation. The separation of agent logic, orchestration, and interface design is not just good engineering—it reflects the way real trading firms operate. For developers serious about building or studying multi-agent financial AI, TradingAgents is a step forward in both architecture and ambition.",
      "url": "https://github.com/yebeai/TradingAgents",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "TauricResearch/TradingAgents",
        "url": "https://github.com/TauricResearch/TradingAgents",
        "stars": 30896
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 2, 2026",
      "updatedAt": "February 2, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 73,
        "directories": {
          "(root)": 11,
          "assets": 11,
          "cli": 5,
          "tradingagents": 46
        },
        "languages": {
          "Markdown": 1,
          "Python": 53,
          "TOML": 1
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "cli/main.py",
          "main.py",
          "setup.py",
          "tradingagents/graph/setup.py"
        ],
        "configFiles": [
          ".env.example",
          "pyproject.toml",
          "requirements.txt",
          "setup.py",
          "tradingagents/graph/setup.py"
        ],
        "dependencies": [
          "pyproject.toml",
          "requirements.txt"
        ],
        "testFiles": [
          "test.py"
        ],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".example": 1,
          ".md": 1,
          ".png": 11,
          ".py": 53,
          ".txt": 2,
          ".toml": 1,
          ".lock": 1
        }
      }
    },
    {
      "id": 1148064168,
      "name": "airllm",
      "displayName": "airllm",
      "description": "AirLLM 70B inference with single 4GB GPU",
      "summary": "The Problem\nRunning large language models (LLMs) usually requires hefty resources. Most setups are limited by GPU memory, making it a pain to execute models like the 70B AirLLM or the 405B Llama3. For anyone with a single 4GB GPU, this has been a real bottleneck. Forget about quantization or distillation; you just want to run inference without needing a bank loan.\n\nWhat This Does\nAirLLM tackles this head-on by optimizing memory usage, letting you run 70B models on a single 4GB GPU. Dive into files like airllm/airllm/airllm.py for the core functionalities or check out airllm/examples/runalltypesofmodels.ipynb for practical examples. The AutoModel feature in airllm/airllm/automodel.py is a nice touch; it automatically detects model types, so you don't have to remember which class to use for each model.\n\nThe repo also includes model-specific scripts like airllm/airllm/airllmllamamlx.py for the Llama series. This makes it easier to implement specific models without diving deep into the codebase. If you need to persist models, the airllm/persist/ directory has you covered with modelpersister.py and its friends.\n\nReal-World Use\nSay you want to run inference on a Llama3 model. After installing the package with pip install airllm, you can initialize the model directly in your script:\n\nfrom airllm import AirLLMLlama2\n\nmodel = AirLLMLlama2(repoid=\"huggingfacemodel_id\")\nresult = model.infer(\"What’s the weather like today?\")\n\nThis straightforward approach means you can focus on results rather than wrestling with setup.\n\nThe Bottom Line\nAirLLM is a solid choice if you're stuck with limited GPU resources and need to run large models. It's lightweight, well-structured, and gets the job done without unnecessary complexity. However, if you're working with smaller projects or models, this might feel like overkill. For anyone serious about LLMs on a budget, it’s worth a look.",
      "url": "https://github.com/yebeai/airllm",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "0xSojalSec/airllm",
        "url": "https://github.com/0xSojalSec/airllm",
        "stars": 2686
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 2, 2026",
      "updatedAt": "February 2, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 79,
        "directories": {
          ".github": 1,
          "(root)": 6,
          "air_llm": 36,
          "anima_100k": 8,
          "assets": 11,
          "data": 2,
          "eval": 1,
          "examples": 1,
          "rlhf": 7,
          "scripts": 1,
          "training": 5
        },
        "languages": {
          "YAML": 1,
          "Markdown": 7,
          "Python": 30,
          "JSON": 2,
          "Shell": 4
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "air_llm/setup.py"
        ],
        "configFiles": [
          "air_llm/setup.py",
          "requirements.txt"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [
          "air_llm/tests/__init__.py",
          "air_llm/tests/test_automodel.py",
          "air_llm/tests/test_compression.py",
          "air_llm/tests/test_notebooks/test_compression.ipynb",
          "air_llm/tests/test_notebooks/test_mixtral.ipynb",
          "air_llm/tests/test_notebooks/test_mlx.ipynb",
          "air_llm/tests/test_notebooks/test_models_transformer_4_35_2.ipynb",
          "air_llm/tests/test_notebooks/test_models_transformer_4_36_2_torch_2_1_2.ipynb",
          "air_llm/tests/test_notebooks/test_sealllm.ipynb",
          "scripts/test_cn_dataset_lenghts.py"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "README_ja.md",
          "air_llm/LICENSE",
          "air_llm/README.md",
          "anima_100k/README.md",
          "rlhf/README.md",
          "training/README.md",
          "training/README_en.md"
        ],
        "fileTypes": {
          ".yml": 1,
          ".md": 7,
          ".py": 30,
          ".ipynb": 14,
          ".jsonl": 1,
          ".json": 2,
          ".sh": 4,
          ".png": 13,
          ".jpeg": 1,
          ".jpg": 1,
          ".txt": 1,
          ".csv": 1
        }
      }
    },
    {
      "id": 1147949997,
      "name": "ML-Papers-Explained",
      "displayName": "ML Papers Explained",
      "description": "Explanation to key concepts in ML",
      "summary": "The Problem\nUnderstanding machine learning papers can feel like deciphering ancient hieroglyphics. For newcomers and seasoned developers alike, the jargon and dense concepts often lead to confusion. You might spend hours reading a paper only to walk away with more questions than answers.\n\nWhat This Does\nThe ML-Papers-Explained repo tackles this issue head-on by breaking down key concepts in machine learning. The README.md file houses a curated list of influential papers, complete with concise descriptions that highlight their significance in the field. Each entry links to a detailed explanation, allowing for deeper understanding without sifting through the original dense text.\n\nFor instance, the entry for the Transformer introduces the multi-head attention mechanism, a crucial innovation for language tasks. Want to know what made BERT a household name? The repo succinctly outlines how it unified architectures for various tasks, making it a staple in NLP.\n\nReal-World Use\nImagine you're tasked with building a chatbot and need to choose the right model. By browsing this repo, you can quickly scan through entries like GPT 2 and RoBERTa, comparing their strengths and weaknesses. You can take snippets from the explanations to justify your choices in a team meeting or design document. \n\nPseudo-code to illustrate model selection\nselectedmodel = \"GPT 2\"  # Based on the insights from the repo\ntrainchatbot(selectedmodel, trainingdata)\n\nThe Bottom Line\nThis repo is a solid resource for anyone looking to demystify machine learning papers without drowning in academia. While it’s not going to replace a deep dive into the papers themselves, it’s perfect for getting a quick grasp on the essentials. If you’re in ML and need a quick reference, this might just save you a headache. Just don’t expect any code examples—this is all about the theory.",
      "url": "https://github.com/yebeai/ML-Papers-Explained",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "dair-ai/ML-Papers-Explained",
        "url": "https://github.com/dair-ai/ML-Papers-Explained",
        "stars": 8530
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1542831371-29b0f74f9713?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 2, 2026",
      "updatedAt": "February 2, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 1,
        "directories": {
          "(root)": 1
        },
        "languages": {
          "Markdown": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".md": 1
        }
      }
    },
    {
      "id": 1147737999,
      "name": "deepseek-ocr-client-macos",
      "displayName": "deepseek ocr client macos",
      "description": "A real-time Electron-based desktop GUI for DeepSeek-OCR",
      "summary": "The Problem\n\nOCR models are getting better, but most of them still require clunky Python scripts or weird web UIs. If you want to process screenshots, PDFs, or random image docs on your desktop, you’re stuck juggling CLI tools, browser tabs, or some sketchy Windows EXE. GPU acceleration? Good luck.\n\nWhat This Does\n\ndeepseek-ocr-client-macos wraps DeepSeek-OCR in a desktop GUI using Electron. You get a drag-and-drop interface (index.html, renderer.js), real-time OCR, and GPU support. The backend is pure Python (backend/ocr_server.py) and fires up with start.py, handling all the OCR calls and CUDA stuff. Electron talks to Python via HTTP, so the whole thing stays modular—not some gross monkey-patched hack.\n\nUploading images is dead simple: drag files onto the app, or use the click-to-select zone. You run OCR, click regions to copy, or export results as ZIPs with markdown. The code is quick-and-dirty (check out the TODOs in the README), but it actually works. Windows is the main target, but start-client.sh is there for macOS/Linux—if you feel like debugging.\n\nReal-World Use\n\nSay you’ve got a folder full of scanned invoices. Fire up the app, drag them in, hit \"Run OCR.\" The backend spins up DeepSeek on your GPU, spits out text regions, and you can copy/click/export as you like. If you want batch processing or PDF support, you’ll have to hack it yourself or wait for a PR. Here’s a typical workflow:\n\nWindows\nstart-client.bat\nmacOS/Linux (experimental)\n./start-client.sh\n\nThen just interact with the GUI. No need to mess with Python environments or CUDA paths—assuming your GPU works.\n\nThe Bottom Line\n\nIf you need real-time OCR on your desktop and you’re sick of web tools or janky scripts, this is a solid option. The codebase is messy, but it’s honest about it. Windows users will have the easiest time; Linux/macOS folks should expect bugs. Not for the faint of heart, but great if you want DeepSeek-OCR in a GUI without reinventing the wheel.",
      "url": "https://github.com/yebeai/deepseek-ocr-client-macos",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Dogacel/deepseek-ocr-client-macos",
        "url": "https://github.com/Dogacel/deepseek-ocr-client-macos",
        "stars": 30
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1607799279861-4dd421887fb3?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 2, 2026",
      "updatedAt": "February 2, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 17,
        "directories": {
          "(root)": 13,
          "backend": 2,
          "docs": 2
        },
        "languages": {
          "Markdown": 2,
          "Python": 3,
          "HTML": 1,
          "JavaScript": 2,
          "JSON": 2,
          "Shell": 1,
          "CSS": 1
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "index.html",
          "main.js"
        ],
        "configFiles": [
          "package.json",
          "requirements.txt"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json",
          "requirements.txt"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE.md",
          "README.md",
          "docs/images/document.gif",
          "docs/images/document2.png"
        ],
        "fileTypes": {
          ".md": 2,
          ".py": 3,
          ".gif": 1,
          ".png": 1,
          ".html": 1,
          ".js": 2,
          ".json": 2,
          ".txt": 1,
          ".bat": 1,
          ".sh": 1,
          ".css": 1
        }
      }
    },
    {
      "id": 1147736985,
      "name": "tensortrade",
      "displayName": "tensortrade",
      "description": "An open source reinforcement learning framework for training, evaluating, and deploying robust trading agents.",
      "summary": "TensorTrade: Reinforcement Learning for Trading Agents  \n\nThe Problem  \nAlgorithmic trading sounds cool until you try building something from scratch. Between managing data pipelines, designing trading environments, and implementing reinforcement learning agents, it's a hot mess. TensorTrade tackles this chaos by offering a framework that handles the boring plumbing so you can focus on designing profitable strategies.  \n\nWhat This Does  \nTensorTrade organizes trading environments into modular components. Think gym meets Wall Street. You’ve got pieces like actionstrategy for agent actions, rewardstrategy for defining how your agent gets rewarded, and featurepipeline for preparing data. Everything is meant to be plug-and-play, so if your custom multidiscreteactionstrategy tanked last week, you can swap in something else without rewriting half your code.  \n\nThe repo is structured cleanly—sort of. The docs/source/agents folder covers integrations with frameworks like TensorForce and Stable Baselines, while docs/source/api digs into specific modules like tensortrade.actions. The Dockerfile is there for containerizing your experiments, and the Makefile helps automate common tasks like testing. The tutorial linked in the README is pretty solid for getting a basic agent running, assuming you already know your way around gym and tensorflow.  \n\nReal-World Use  \nImagine you're building a trading bot to handle crypto arbitrage. You’d start by setting up a featurepipeline to preprocess market data (think moving averages or RSI). Then you'd pick an actionstrategy, like discreteactionstrategy, to decide whether to buy, hold, or sell. Finally, you'd define a rewardstrategy to penalize losses and reward profitable trades.  \n\nHere’s a quick example:  \n\nfrom tensortrade.actions import DiscreteActionStrategy  \nfrom tensortrade.rewards import RiskAdjustedReturnsStrategy  \n\nactionstrategy = DiscreteActionStrategy(nactions=3)  \nrewardstrategy = RiskAdjustedReturnsStrategy()  \n\nPlug these into your TensorTrade environment and let your agent learn the magic.  \n\nTensorTrade lets you mix and match components without worrying about the backend details. The modular design is helpful if you want to test new strategies or switch to a different reinforcement learning library halfway through your project.  \n\nThe Bottom Line  \nTensorTrade is solid for experimenting with reinforcement learning in trading but feels like overkill for small projects or single-asset bots. The modular structure is nice, but the docs could be more beginner-friendly. If you're already comfortable with tensorflow and gym, this is worth exploring. Otherwise, expect a learning curve.",
      "url": "https://github.com/yebeai/tensortrade",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "codeninja/tensortrade",
        "url": "https://github.com/codeninja/tensortrade",
        "stars": 33
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 2, 2026",
      "updatedAt": "February 2, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 153,
        "directories": {
          "(root)": 12,
          ".github": 5,
          "docs": 67,
          "examples": 19,
          "tensortrade": 44,
          "tests": 6
        },
        "languages": {
          "YAML": 4,
          "Markdown": 18,
          "CSS": 1,
          "reStructuredText": 46,
          "Python": 52
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": "pip",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "Travis CI",
        "entryPoints": [
          "setup.py"
        ],
        "configFiles": [
          "Dockerfile",
          "Makefile",
          "docs/Makefile",
          "docs/requirements.txt",
          "examples/requirements.txt",
          "requirements.txt",
          "setup.cfg",
          "setup.py"
        ],
        "dependencies": [
          "docs/requirements.txt",
          "examples/requirements.txt",
          "requirements.txt"
        ],
        "testFiles": [
          "examples/test_keras_plot_model.png",
          "examples/test_keras_plot_model_1.png",
          "tests/__init__.py",
          "tests/tensortrade/__init__.py",
          "tests/tensortrade/features/stationarity/test_fractional_difference.py",
          "tests/tensortrade/features/test_feature_pipeline.py",
          "tests/tensortrade/rewards/test_risk_adjusted_return_strategy.py",
          "tests/tensortrade/test_component_registration.py"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "docs/.readthedocs.yml",
          "docs/Makefile",
          "docs/README.md",
          "docs/requirements.txt",
          "docs/source/_static/favicon.ico",
          "docs/source/_static/logo.jpg",
          "docs/source/_static/theme_overrides.css",
          "docs/source/agents/learning_agents.md",
          "docs/source/agents/stable_baselines.md",
          "docs/source/agents/tensorforce.md",
          "docs/source/api/modules.rst",
          "docs/source/api/tensortrade.actions.action_strategy.rst",
          "docs/source/api/tensortrade.actions.continuous_action_strategy.rst",
          "docs/source/api/tensortrade.actions.discrete_action_strategy.rst",
          "docs/source/api/tensortrade.actions.multi_discrete_action_strategy.rst",
          "docs/source/api/tensortrade.actions.rst",
          "docs/source/api/tensortrade.environments.rst",
          "docs/source/api/tensortrade.environments.trading_environment.rst",
          "docs/source/api/tensortrade.exchanges.instrument_exchange.rst",
          "docs/source/api/tensortrade.exchanges.live.ccxt_exchange.rst",
          "docs/source/api/tensortrade.exchanges.live.interactive_brokers_exchange.rst",
          "docs/source/api/tensortrade.exchanges.live.robinhood_exchange.rst",
          "docs/source/api/tensortrade.exchanges.live.rst",
          "docs/source/api/tensortrade.exchanges.rst",
          "docs/source/api/tensortrade.exchanges.simulated.fbm_exchange.rst",
          "docs/source/api/tensortrade.exchanges.simulated.gan_exchange.rst",
          "docs/source/api/tensortrade.exchanges.simulated.rst",
          "docs/source/api/tensortrade.exchanges.simulated.simulated_exchange.rst",
          "docs/source/api/tensortrade.features.feature_pipeline.rst",
          "docs/source/api/tensortrade.features.feature_transformer.rst",
          "docs/source/api/tensortrade.features.indicators.rst",
          "docs/source/api/tensortrade.features.indicators.simple_moving_average.rst",
          "docs/source/api/tensortrade.features.indicators.talib_indicator.rst",
          "docs/source/api/tensortrade.features.rst",
          "docs/source/api/tensortrade.features.scalers.min_max_normalizer.rst",
          "docs/source/api/tensortrade.features.scalers.rst",
          "docs/source/api/tensortrade.features.scalers.standard_normalizer.rst",
          "docs/source/api/tensortrade.features.stationarity.fractional_difference.rst",
          "docs/source/api/tensortrade.features.stationarity.rst",
          "docs/source/api/tensortrade.rewards.reward_strategy.rst",
          "docs/source/api/tensortrade.rewards.risk_adjusted_return_strategy.rst",
          "docs/source/api/tensortrade.rewards.rst",
          "docs/source/api/tensortrade.rewards.simple_profit_strategy.rst",
          "docs/source/api/tensortrade.rst",
          "docs/source/api/tensortrade.slippage.random_slippage_model.rst",
          "docs/source/api/tensortrade.slippage.rst",
          "docs/source/api/tensortrade.slippage.slippage_model.rst",
          "docs/source/api/tensortrade.strategies.rst",
          "docs/source/api/tensortrade.strategies.stable_baselines_strategy.rst",
          "docs/source/api/tensortrade.strategies.tensorforce_trading_strategy.rst",
          "docs/source/api/tensortrade.strategies.trading_strategy.rst",
          "docs/source/api/tensortrade.trades.rst",
          "docs/source/api/tensortrade.trades.trade.rst",
          "docs/source/api/tensortrade.trades.trade_type.rst",
          "docs/source/api/tensortrade.version.rst",
          "docs/source/components/action_strategy.md",
          "docs/source/components/components.md",
          "docs/source/components/feature_pipeline.md",
          "docs/source/components/instrument_exchange.md",
          "docs/source/components/reward_strategy.md",
          "docs/source/components/trading_environment.md",
          "docs/source/components/trading_strategy.md",
          "docs/source/conf.py",
          "docs/source/examples/train_and_evaluate.ipynb",
          "docs/source/index.rst",
          "docs/source/landing.md",
          "docs/source/overview/getting_started.md"
        ],
        "fileTypes": {
          ".yml": 4,
          ".md": 18,
          ".in": 1,
          ".txt": 3,
          ".ico": 1,
          ".jpg": 2,
          ".css": 1,
          ".rst": 46,
          ".py": 52,
          ".ipynb": 6,
          ".jpeg": 8,
          ".gif": 1,
          ".png": 3,
          ".cfg": 1
        }
      }
    },
    {
      "id": 1147655405,
      "name": "city-roads",
      "displayName": "city roads",
      "description": "Visualization of all roads within any city",
      "summary": "Cities are increasingly becoming data-rich environments, yet visualizing the intricate web of roads that connect urban spaces remains a challenge. Traditional mapping solutions often present a static view, lacking the dynamic interaction necessary to analyze urban mobility, planning, and infrastructure. The city-roads project addresses this gap by allowing users to render and interact with a comprehensive visualization of all roads within a city, providing a powerful tool for urban analysis and design.\n\nThe city-roads project, forked from the popular anvaka/city-roads repository, stands out for its ability to visualize entire cities using data fetched from OpenStreetMap via the Overpass API. This approach allows developers and urban planners to access a wealth of geographic data while avoiding the limitations of static maps. What sets city-roads apart is its unique caching mechanism that enables faster access to road data for over 3,000 cities with populations exceeding 100,000. By utilizing a simple protobuf format to cache city data, the project not only enhances performance but also minimizes the impact of Overpass API's rate limits, making it a robust solution for data-heavy visualizations.\n\nA closer look at the file structure reveals a well-organized architecture that supports both the UI and the underlying logic. The presence of Vue components, such as src/components/ColorPicker.vue and src/App.vue, indicates a modern front-end framework that enables responsive interactions and dynamic rendering. The API.md file is particularly noteworthy as it documents the Scene API, providing developers with the necessary tools to build custom scripts on top of city-roads. This extensibility is further evidenced by the city-script repository, which showcases potential applications and scripts that can be developed using the city-roads framework. Additionally, the presence of a babel.config.js file suggests that the project is built with modern JavaScript capabilities, allowing for smooth cross-browser compatibility.\n\nDevelopers can leverage city-roads in various scenarios. For instance, urban planners can utilize the visualization to present potential new road layouts to stakeholders, allowing for interactive discussions about infrastructure changes. Data scientists looking to analyze traffic patterns can use the project to visualize road networks in conjunction with traffic data, leading to insights on congestion and urban mobility. Moreover, educators can use city-roads as a teaching tool, helping students understand urban geography and the complexities of city planning through interactive visualizations.\n\nThe importance of city-roads lies in its ability to democratize access to urban data, transforming how we visualize and analyze city infrastructures. By offering a platform that combines powerful visualizations with scripting capabilities, it invites developers to explore innovative applications in urban studies, transportation, and geography. The project exemplifies how open-source solutions can bridge gaps in traditional mapping technologies, fostering a deeper understanding of the urban environments we inhabit. As cities continue to evolve, tools like city-roads will be essential in shaping our approach to urban planning and development.",
      "url": "https://github.com/yebeai/city-roads",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "anvaka/city-roads",
        "url": "https://github.com/anvaka/city-roads",
        "stars": 9015
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 2, 2026",
      "updatedAt": "February 2, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 56,
        "directories": {
          "(root)": 13,
          ".github": 1,
          "images": 1,
          "src": 40,
          "static": 1
        },
        "languages": {
          "YAML": 1,
          "Markdown": 2,
          "JavaScript": 27,
          "Shell": 1,
          "HTML": 1,
          "JSON": 2,
          "Vue": 12,
          "Protocol Buffers": 1
        },
        "frameworks": [
          "React",
          "Vue"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "index.html",
          "src/main.js"
        ],
        "configFiles": [
          ".eslintrc.cjs",
          "package.json",
          "vite.config.js"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md",
          "src/components/vue3-color/LICENSE"
        ],
        "fileTypes": {
          ".cjs": 1,
          ".yml": 1,
          ".md": 2,
          ".js": 27,
          ".sh": 1,
          ".png": 1,
          ".html": 1,
          ".json": 2,
          ".vue": 12,
          ".proto": 1,
          ".styl": 1
        }
      }
    },
    {
      "id": 1147363801,
      "name": "exportdash.cam",
      "displayName": "exportdash.cam",
      "description": "No description available",
      "summary": "If you've ever tried to manage Tesla dashcam footage, you're familiar with the unwieldy sprawl of 1-minute video clips, each holding a fragment of a drive, along with poorly surfaced telemetry data. For developers, car enthusiasts, or fleet managers hoping to analyze incidents, reconstruct routes, or simply export a polished video with context overlays, the out-of-the-box experience is frustrating. The raw video files are packed with valuable metadata—speed, GPS, pedal states—but accessing, visualizing, and exporting this information is not trivial. This is the gap ExportDash aims to fill: a client-side solution that transforms the fragmented, opaque TeslaCam folder into an interactive, richly annotated playback and export platform.\n\nExportDash stands out by rethinking how Tesla dashcam data is presented and processed. Unlike most viewers that simply stitch together the clips, ExportDash merges consecutive videos seamlessly, overlays telemetry data in real-time, and offers flexible multi-camera layouts with synchronized map tracking. The innovation is in its deep integration of vehicle metadata—extracted from embedded SEI blocks using Tesla’s official protobuf schema—and its ability to export video clips with telemetry burned in, all without uploading data to a server. The 100% client-side design ensures privacy and performance, making it ideal for sensitive footage or quick, local analysis.\n\nThe file structure reveals a modern, modular architecture centered on Next.js 15 with App Router. The src/components directory is the heart of the UI: VideoPlayer.tsx manages multiple camera feeds and controls, TelemetryCard.tsx overlays speed and G-forces, TelemetryTimeline.tsx visualizes pedal and steering events, and MapView.tsx synchronizes GPS data with playback using Leaflet and OpenStreetMap. DropZone.tsx handles the drag-and-drop import of the TeslaCam folder, parsing video files and metadata client-side. The hooks/useSeiData.ts module abstracts the extraction and time-syncing of SEI telemetry, powered by lib/dashcam-mp4.ts, which parses MP4 containers and decodes protobuf blocks. VideoExporter.tsx leverages WebCodecs to enable efficient, browser-based video export with overlays. The Dockerfile and docker-compose.yml files signal a production-ready deployment story, while nginx.conf hints at static asset optimization. This organization reflects a strong separation of concerns: UI, data extraction, export, and deployment are cleanly split, enabling maintainability and extensibility.\n\nDevelopers can immediately leverage ExportDash in several scenarios. First, those building custom analytics or incident review tools for fleets can fork the repo, extend TelemetryCard.tsx or TelemetryTimeline.tsx for specialized overlays, and integrate their own event detection logic. Second, hobbyists or researchers working with TeslaCam data can use DropZone.tsx and hooks/useSeiData.ts to rapidly prototype new visualizations or export workflows, benefitting from the browser-based processing and privacy guarantees. Third, anyone aiming to automate video export (with telemetry overlays) for insurance or legal purposes will find VideoExporter.tsx and the underlying WebCodecs pipeline invaluable—no need for server-side processing or manual annotation.\n\nThe significance of ExportDash lies in its approach: it democratizes access to rich automotive telemetry, using open web technologies and open-source patterns, while respecting user privacy. By combining protobuf decoding, modern video APIs, and interactive mapping—all client-side—it enables new workflows for reviewing, sharing, and analyzing dashcam footage. For developers, it’s a blueprint for building privacy-preserving, high-performance media apps; for end users, it’s the missing link between raw TeslaCam data and actionable insight. This project underscores how thoughtful engineering can unlock the latent value in proprietary data formats, transforming them into tools for transparency, safety, and creativity.",
      "url": "https://github.com/yebeai/exportdash.cam",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "nobig-deals/exportdash.cam",
        "url": "https://github.com/nobig-deals/exportdash.cam",
        "stars": 88
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 1, 2026",
      "updatedAt": "February 1, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 49,
        "directories": {
          "(root)": 13,
          "public": 19,
          "src": 17
        },
        "languages": {
          "Markdown": 1,
          "YAML": 1,
          "TypeScript": 5,
          "JSON": 3,
          "Protocol Buffers": 1,
          "CSS": 1,
          "TSX": 11
        },
        "frameworks": [
          "React",
          "Next.js",
          "Docker"
        ],
        "packageManager": "npm",
        "hasDocker": true,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [
          "Dockerfile",
          "docker-compose.yml",
          "next.config.ts",
          "package.json",
          "tsconfig.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".md": 1,
          ".yml": 1,
          ".mjs": 2,
          ".ts": 5,
          ".conf": 1,
          ".json": 3,
          ".svg": 7,
          ".png": 11,
          ".proto": 1,
          ".ico": 1,
          ".css": 1,
          ".tsx": 11
        }
      }
    },
    {
      "id": 1147362869,
      "name": "transformer-explainer",
      "displayName": "transformer explainer",
      "description": "Transformer Explained Visually: Learn How LLM Transformer Models Work with Interactive Visualization",
      "summary": "Understanding the inner workings of large language models (LLMs) can feel like unraveling a black box. Despite their widespread use in applications from chatbots to code generation, the mechanics behind models like GPT-2 or GPT-3 often remain opaque to most developers and researchers. This lack of transparency can hinder innovation and limit how effectively these models are applied to solve real-world problems. Enter the Transformer Explainer, an interactive visualization tool designed to demystify Transformer-based models. By making these complex systems more accessible, the Transformer Explainer bridges the gap between theoretical understanding and practical application.\n\nAt its core, the Transformer Explainer is a web-based application that allows users to interact with a live GPT-2 model directly in their browser. What sets this project apart is its ability to break the model's inference process into digestible components. Users can input text and observe, in real time, how the Transformer model processes that input to predict the next tokens. This is not just a passive visualization; the tool enables exploration of key elements like attention mechanisms, embeddings, and layer operations, all of which are critical to understanding how Transformers generate text. It doesn’t just show you what happens—it teaches you why and how it happens. \n\nA closer look at its file structure reveals how this functionality is achieved. The project is built using Svelte, a modern JavaScript framework optimized for creating highly reactive user interfaces. The src/components directory contains an array of modular Svelte components, each representing a distinct part of the Transformer model. For example, Attention.svelte and AttentionMatrix.svelte focus on visualizing the all-important attention mechanism, while Embedding.svelte and Mlp.svelte handle the representation of word embeddings and multi-layer perceptrons, respectively. The inclusion of files like LayerNormPopover.svelte and DropoutPopover.svelte suggests that the tool goes beyond surface-level explanations to examine deeper architectural concepts like normalization and regularization. This modular design pattern facilitates clarity, maintainability, and scalability, making the project an excellent case study for frontend engineering.\n\nFor developers and researchers, the Transformer Explainer has clear use cases. First, it serves as an invaluable educational resource for those new to NLP or Transformer models. Instead of wading through dense academic papers, learners can see how core concepts like attention weights or softmax operations manifest in practice. Second, it provides model designers and practitioners with a debugging and interpretability tool. By visually breaking down the inference process, developers can better understand how their models behave on specific inputs, potentially revealing biases or weaknesses. Lastly, it’s a fantastic resource for educators in AI and machine learning. By integrating this tool into lectures or workshops, instructors can make complex topics more engaging and digestible.\n\nUltimately, the Transformer Explainer matters because it embodies a shift toward transparency and accessibility in AI. As models grow larger and more complex, tools like this will become essential for fostering innovation and trust. A project like this not only equips developers to use LLMs more effectively but also encourages critical thinking about their limitations and ethical implications. Transformer Explainer is more than a visualization tool—it’s a step toward making AI a more collaborative and comprehensible field for everyone.",
      "url": "https://github.com/yebeai/transformer-explainer",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "poloclub/transformer-explainer",
        "url": "https://github.com/poloclub/transformer-explainer",
        "stars": 6833
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 1, 2026",
      "updatedAt": "February 1, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 166,
        "directories": {
          "(root)": 15,
          "src": 79,
          "static": 72
        },
        "languages": {
          "Markdown": 1,
          "JSON": 3,
          "JavaScript": 10,
          "HTML": 1,
          "Svelte": 50,
          "TypeScript": 15,
          "CSS": 1,
          "SCSS": 2,
          "Python": 4
        },
        "frameworks": [
          "React",
          "Svelte",
          "Tailwind"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "src/constants/examples/index.js",
          "src/store/index.ts"
        ],
        "configFiles": [
          ".eslintrc.cjs",
          ".prettierrc",
          "package.json",
          "tailwind.config.js",
          "tsconfig.json",
          "vite.config.ts"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".cjs": 1,
          ".md": 1,
          ".json": 3,
          ".js": 10,
          ".html": 1,
          ".svelte": 50,
          ".ts": 15,
          ".css": 1,
          ".scss": 2,
          ".py": 4,
          ".png": 8,
          ".part0": 1,
          ".part1": 1,
          ".part10": 1,
          ".part11": 1,
          ".part12": 1,
          ".part13": 1,
          ".part14": 1,
          ".part15": 1,
          ".part16": 1,
          ".part17": 1,
          ".part18": 1,
          ".part19": 1,
          ".part2": 1,
          ".part20": 1,
          ".part21": 1,
          ".part22": 1,
          ".part23": 1,
          ".part24": 1,
          ".part25": 1,
          ".part26": 1,
          ".part27": 1,
          ".part28": 1,
          ".part29": 1,
          ".part3": 1,
          ".part30": 1,
          ".part31": 1,
          ".part32": 1,
          ".part33": 1,
          ".part34": 1,
          ".part35": 1,
          ".part36": 1,
          ".part37": 1,
          ".part38": 1,
          ".part39": 1,
          ".part4": 1,
          ".part40": 1,
          ".part41": 1,
          ".part42": 1,
          ".part43": 1,
          ".part44": 1,
          ".part45": 1,
          ".part46": 1,
          ".part47": 1,
          ".part48": 1,
          ".part49": 1,
          ".part5": 1,
          ".part50": 1,
          ".part51": 1,
          ".part52": 1,
          ".part53": 1,
          ".part54": 1,
          ".part55": 1,
          ".part56": 1,
          ".part57": 1,
          ".part58": 1,
          ".part59": 1,
          ".part6": 1,
          ".part60": 1,
          ".part61": 1,
          ".part62": 1,
          ".part7": 1,
          ".part8": 1,
          ".part9": 1,
          ".txt": 1
        }
      }
    },
    {
      "id": 1147349482,
      "name": "rpsync",
      "displayName": "rpsync",
      "description": "Gather your online presence stats in a small local database.",
      "summary": "In an era where social media platforms proliferate, the challenge of managing and analyzing data across these diverse channels has never been greater. Users often find themselves grappling with disparate analytics tools that compromise data privacy and ownership. The fragmentation of data management leads to inefficiencies and a lack of control over personal analytics. Enter RPSync, a powerful solution designed to address these pain points by allowing users to collect, visualize, and own their social media statistics—all from a local, privacy-first environment.\n\nRPSync is a command center for social media analytics that emphasizes data sovereignty. This open-source project allows users to run a self-hosted application that aggregates statistics from platforms like Instagram, TikTok, and YouTube. What sets RPSync apart is its commitment to privacy; users' data remains on their local machine, eliminating concerns about third-party access or monetization. Furthermore, RPSync provides a unified dashboard for visualizing analytics, along with seamless data export capabilities to formats like NocoDB and CSV. The project is not only free but is backed by an active community, giving developers a stake in its evolution.\n\nDelving into the technical architecture of RPSync reveals a well-organized structure that promotes ease of use and extensibility. The presence of a docker-compose.yml file indicates a containerized approach, allowing for simplified deployment and scalability. The application leverages Docker to manage its dependencies, including a PostgreSQL database service defined within the same compose file. The modular organization of the codebase, particularly in the internal/api/handlers/ directory, showcases a clean separation of concerns. Each handler file—such as auth.go and stats.go—manages distinct functionalities, following RESTful API patterns that facilitate maintainability and future enhancements. The install.sh script further simplifies the setup process, automating deployment configurations while allowing customization through environment variables.\n\nRPSync's architecture lends itself to various use cases that can significantly benefit developers and end-users alike. For instance, a digital marketing agency could utilize RPSync to centralize analytics across multiple client accounts, allowing for streamlined reporting and data analysis without compromising client data privacy. Additionally, content creators can leverage RPSync to track their performance metrics across platforms, gaining insights that inform content strategy and engagement efforts. Lastly, developers interested in building custom analytics solutions can fork RPSync, extending its capabilities or integrating it with other applications, all while maintaining data integrity.\n\nUltimately, RPSync matters in a landscape where data privacy and ownership are increasingly critical. As users become more aware of their digital footprints, tools like RPSync empower them to take control of their data, ensuring it remains private and manageable. By combining a user-friendly interface with robust backend architecture, RPSync not only addresses a pressing need but also sets a precedent for how open-source projects can prioritize user autonomy in the digital age. As the project evolves, it has the potential to become a cornerstone for developers and users alike, reinforcing the importance of local data management in a world dominated by cloud services.",
      "url": "https://github.com/yebeai/rpsync",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "fluffyriot/rpsync",
        "url": "https://github.com/fluffyriot/rpsync",
        "stars": 21
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 1, 2026",
      "updatedAt": "February 1, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 167,
        "directories": {
          "(root)": 11,
          ".github": 1,
          "docker": 1,
          "internal": 77,
          "sql": 45,
          "static": 18,
          "templates": 14
        },
        "languages": {
          "YAML": 2,
          "Markdown": 1,
          "Shell": 2,
          "Go": 78,
          "SQL": 45,
          "CSS": 1,
          "JSON": 2,
          "JavaScript": 1,
          "HTML": 14
        },
        "frameworks": [
          "React",
          "Docker"
        ],
        "packageManager": "go modules",
        "hasDocker": true,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "main.go",
          "templates/index.html"
        ],
        "configFiles": [
          "Dockerfile",
          "docker-compose.yml",
          "go.mod"
        ],
        "dependencies": [
          "go.mod"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".yml": 2,
          ".md": 1,
          ".sh": 2,
          ".mod": 1,
          ".sum": 1,
          ".go": 78,
          ".sql": 45,
          ".css": 1,
          ".png": 13,
          ".ico": 1,
          ".svg": 1,
          ".json": 2,
          ".js": 1,
          ".html": 14
        }
      }
    },
    {
      "id": 1147084813,
      "name": "noteGPT",
      "displayName": "noteGPT",
      "description": "Record voice notes & transcribe, summarize, and get tasks",
      "summary": "Taking effective notes during meetings is a perennial challenge for both individuals and teams—especially when action items get lost in lengthy transcripts or, worse, never make it past the chaos of raw voice recordings. The rise of AI-powered transcription and summarization tools has addressed some of these pain points, but integrating seamless workflows that actually generate actionable insights remains elusive. That’s where noteGPT steps into the gap: an open source, Next.js-based project designed to turn your voice notes into transcriptions, summaries, and—most importantly—actionable tasks, in seconds.\n\nnoteGPT distinguishes itself not by chasing another “speech-to-text” solution, but by orchestrating a pipeline that leverages best-in-class AI services for transcription (OpenAI Whisper via Replicate), summarization and embeddings (Together.ai), and robust backend logic (Convex). What’s most compelling here is the focus on generating action items from the chaos of meeting notes—bridging the gap between raw data and productivity. The user experience is driven by a streamlined UI (with components like RecordedfileItemCard.tsx and RecordingDesktop.tsx) and authentication is handled via Clerk, meaning the project is production-ready in terms of both security and usability out of the box.\n\nExamining the file structure, several architectural decisions stand out. The separation of concerns is clear: the app directory houses Next.js app routes and key logic, such as the recording flow (app/record/page.tsx, app/recording/[id]/page.tsx) and the dashboard (app/dashboard/page.tsx, app/dashboard/action-items/ais.tsx). Convex serves as the backend—managing both data storage and serverless cloud functions—while integration points for external AI services are likely encapsulated within these server components. Notably, the vector search and embeddings functionality (enabled by Convex and Together.ai) suggests that not only are transcriptions stored, but they’re also indexed for semantic search and fast retrieval. The UI is modular and reusable, with dedicated directories for dashboard, home, and recording components, all styled via Tailwind CSS. This modularity, combined with the use of environment variables for API keys and service configuration (as outlined in .example.env and the README), means the stack is both scalable and straightforward to deploy.\n\nFor developers, noteGPT unlocks several compelling scenarios. First, building an internal tool for distributed teams who need searchable, summarized meeting archives—where the friction of manual note-taking and task tracking is replaced by automated, AI-driven flows. Second, integrating voice note capture and summarization into customer support workflows, enabling staff to record client calls and instantly extract follow-up actions, all secured behind Clerk authentication. Third, as a foundation for more complex productivity solutions, noteGPT’s clear separation of frontend, backend, and AI orchestration makes it an excellent starting point for those looking to add custom integrations (like pushing summaries to Notion, as hinted in the future tasks).\n\nThe real significance of noteGPT lies in its architectural choices and its composability. By marrying a modern Next.js frontend with Convex’s reactive backend and best-of-breed AI services, it offers more than a template—it’s a reference implementation for how to weave together authentication, vector search, LLMs, and cloud functions in a way that’s not only developer-friendly but extensible. For engineers looking to build the next generation of productivity tools, noteGPT isn’t just a playground for AI APIs; it’s a showcase of pragmatic, production-grade patterns that solve real workflow problems.",
      "url": "https://github.com/yebeai/noteGPT",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "jxnl/noteGPT",
        "url": "https://github.com/jxnl/noteGPT",
        "stars": 55
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 1, 2026",
      "updatedAt": "February 1, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 66,
        "directories": {
          "(root)": 11,
          "app": 14,
          "components": 13,
          "convex": 13,
          "lib": 1,
          "public": 13,
          "styles": 1
        },
        "languages": {
          "Markdown": 2,
          "TSX": 24,
          "TypeScript": 12,
          "CSS": 1,
          "JavaScript": 5,
          "JSON": 4
        },
        "frameworks": [
          "React",
          "Next.js",
          "Express",
          "Tailwind"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "convex/_generated/server.js"
        ],
        "configFiles": [
          ".prettierrc",
          "convex/tsconfig.json",
          "next.config.js",
          "package.json",
          "tailwind.config.ts",
          "tsconfig.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "README.md",
          "convex/README.md"
        ],
        "fileTypes": {
          ".env": 1,
          ".md": 2,
          ".tsx": 24,
          ".ts": 12,
          ".ico": 1,
          ".css": 1,
          ".js": 5,
          ".json": 4,
          ".svg": 8,
          ".png": 4,
          ".jpeg": 1,
          ".ttf": 1
        }
      }
    },
    {
      "id": 1147016082,
      "name": "botmaker",
      "displayName": "botmaker",
      "description": "UI/app to Create containerized OpenClaw bots",
      "summary": "Managing containerized AI bots across multiple platforms can be a daunting challenge for developers, especially when juggling diverse requirements like multi-AI provider configurations, secure secrets management, and smooth integration with communication channels like Telegram or Discord. Many teams struggle to unify these needs into a cohesive workflow, often resorting to ad-hoc scripts or brittle solutions that don’t scale. This is where the BotMaker project steps in—a powerful, modular tool designed to simplify the process of creating and managing containerized OpenClaw bots with a streamlined web interface and a well-thought-out architecture.\n\nAt its core, BotMaker is a full-stack application that abstracts the complexities of running AI chatbots inside Docker containers. It provides a clean React-based dashboard for bot creation, monitoring, and diagnostics, while the backend, built with Fastify and TypeScript, handles container orchestration and state management. What sets BotMaker apart is its focus on modularity and isolation. Each bot runs in its own Docker container, with per-bot credential isolation via a file-based secrets management system. This design not only enhances security but also ensures that the failure or misconfiguration of one bot doesn't impact others. Additionally, BotMaker supports multiple AI providers, including OpenAI, Anthropic, and Google Gemini, making it a versatile tool for developers working across different AI ecosystems.\n\nThe repository's file structure reveals a meticulous approach to planning and development. The .planning/ directory is particularly noteworthy, containing detailed documentation files like REQUIREMENTS.md, ROADMAP.md, and a phased approach to implementation. For example, the 01-foundation and 02-docker-integration subdirectories outline specific research, planning, and verification steps for each development phase. This level of transparency is rare in open-source projects and speaks to the maintainers’ commitment to thoughtful, iterative development. The backend architecture, housed in the src/ directory, leverages Dockerode for container management and SQLite for lightweight bot metadata storage. Meanwhile, the frontend, located in the dashboard/ directory, employs Vite for a fast development workflow and React for building dynamic UI components. The use of ESLint with TypeScript strict mode underscores the project’s emphasis on code quality and maintainability.\n\nDevelopers can leverage BotMaker in a variety of scenarios. For instance, a small startup looking to deploy AI-powered chatbot support on multiple platforms could use BotMaker to set up and manage bots for Telegram and Discord without worrying about container orchestration or security. Similarly, a research team working on fine-tuning AI models could use BotMaker’s multi-AI provider support to quickly prototype bots using OpenAI and Anthropic APIs, while isolating each experiment in its own container. Even larger enterprises with complex infrastructure needs could adopt BotMaker to monitor resource utilization and clean up orphaned containers, thanks to its built-in health check and resource stats APIs.\n\nWhat makes BotMaker particularly impactful is its ability to bridge the gap between accessibility and scalability. By providing a cohesive UI for managing bots and a robust backend for container orchestration, it empowers developers to focus on building intelligent features rather than wrestling with infrastructure challenges. Its modular architecture also makes it highly extensible, whether you’re integrating new AI providers or customizing deployment workflows. BotMaker reminds us that thoughtful design and developer-first tooling can turn even complex problems into manageable solutions. For developers working with AI bots in containerized environments, this project is one to watch—or contribute to.",
      "url": "https://github.com/yebeai/botmaker",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "jgarzik/botmaker",
        "url": "https://github.com/jgarzik/botmaker",
        "stars": 232
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 1, 2026",
      "updatedAt": "February 1, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 196,
        "directories": {
          "(root)": 9,
          ".planning": 24,
          "dashboard": 145,
          "scripts": 4,
          "src": 14
        },
        "languages": {
          "Markdown": 24,
          "JSON": 8,
          "JavaScript": 2,
          "HTML": 1,
          "TSX": 44,
          "TypeScript": 69,
          "CSS": 41,
          "YAML": 1,
          "Shell": 3
        },
        "frameworks": [
          "React",
          "Docker"
        ],
        "packageManager": "npm",
        "hasDocker": true,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "dashboard/index.html",
          "dashboard/src/App.tsx",
          "dashboard/src/config/channels/index.ts",
          "dashboard/src/config/providers/index.ts",
          "dashboard/src/dashboard/index.ts",
          "dashboard/src/diagnostics/index.ts",
          "dashboard/src/hooks/index.ts",
          "dashboard/src/layout/index.ts",
          "dashboard/src/ui/index.ts",
          "dashboard/src/wizard/components/index.ts",
          "dashboard/src/wizard/index.ts",
          "dashboard/src/wizard/pages/index.ts",
          "src/db/index.ts",
          "src/index.ts",
          "src/server.ts"
        ],
        "configFiles": [
          "Dockerfile",
          "dashboard/package.json",
          "dashboard/tsconfig.json",
          "dashboard/vite.config.ts",
          "docker-compose.yml",
          "package.json",
          "tsconfig.json"
        ],
        "dependencies": [
          "dashboard/package-lock.json",
          "dashboard/package.json",
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [
          "dashboard/src/test/setup.ts",
          "dashboard/src/wizard/components/CollapsibleSection.test.tsx",
          "dashboard/src/wizard/components/TemplateCard.test.tsx",
          "dashboard/src/wizard/context/WizardContext.test.tsx",
          "scripts/test-docker.ts",
          "scripts/test-e2e.sh"
        ],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".md": 24,
          ".json": 8,
          ".js": 2,
          ".html": 1,
          ".tsx": 44,
          ".ts": 69,
          ".css": 41,
          ".yml": 1,
          ".sh": 3
        }
      }
    },
    {
      "id": 1146559362,
      "name": "onshape-mcp",
      "displayName": "onshape mcp",
      "description": "Added more functionalities to hedless' OnShape MCP server.",
      "summary": "The Problem\nCAD modeling can be a pain, especially when you're trying to automate tasks in Onshape. Manual processes suck time and can lead to human error. You want to quickly manage documents, create sketches, and add features without fumbling through a GUI or typing in the Onshape UI every single time. \n\nWhat This Does\nThe onshape-mcp repository enhances the original hedless Onshape MCP server by adding new features like gear creation and edge querying. You can dive into the onshapemcp/api folder, where files like client.py and documents.py manage API interactions. If you’re looking to add gears, check out the onshapemcp/builders/gear.py, which allows you to customize teeth count and gear ratios. \n\nInstallation is straightforward. After cloning the repo, just set up your virtual environment and install dependencies. Don't forget to configure your API keys in your environment variables or .env file. Running the server is as simple as executing onshape-mcp or python -m onshapemcp.server. \n\nReal-World Use\nImagine you need to create a series of gears for a mechanical design. Instead of manually crafting each one in Onshape, you can leverage the gear.py functionality to programmatically generate all required components. Here’s a quick snippet to create a gear with 20 teeth:\n\nfrom onshapemcp.builders.gear import Gear\n\ngear = Gear(teeth=20, module=2, ratio=1)\ngear.create()\n\nYou can then automate the rest of your design workflow, linking parts and features without lifting a finger in the Onshape UI. \n\nThe Bottom Line\nIf you're serious about automating your CAD workflow in Onshape, this repo is worth checking out. It’s a solid enhancement to the original MCP server, with useful additions like gear creation and edge discovery. Just know that if your project is small, this level of automation might be overkill. But for extensive automation tasks, it’s a no-brainer.",
      "url": "https://github.com/yebeai/onshape-mcp",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "clarsbyte/onshape-mcp",
        "url": "https://github.com/clarsbyte/onshape-mcp",
        "stars": 153
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 31, 2026",
      "updatedAt": "January 31, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 51,
        "directories": {
          "(root)": 10,
          ".github": 1,
          "docs": 10,
          "onshape_mcp": 16,
          "tests": 14
        },
        "languages": {
          "YAML": 1,
          "Markdown": 13,
          "JSON": 1,
          "Python": 29,
          "TOML": 1
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "onshape_mcp/server.py"
        ],
        "configFiles": [
          "Makefile",
          "pyproject.toml",
          "requirements.txt"
        ],
        "dependencies": [
          "pyproject.toml",
          "requirements.txt"
        ],
        "testFiles": [
          ".github/workflows/test.yml",
          "docs/TESTING.md",
          "docs/TEST_SUMMARY.md",
          "pytest.ini",
          "tests/README.md",
          "tests/TEST_RESULTS.md",
          "tests/__init__.py",
          "tests/api/__init__.py",
          "tests/api/test_client.py",
          "tests/api/test_documents.py",
          "tests/api/test_partstudio.py",
          "tests/api/test_variables.py",
          "tests/builders/__init__.py",
          "tests/builders/test_extrude.py",
          "tests/builders/test_sketch.py",
          "tests/builders/test_thicken.py",
          "tests/conftest.py",
          "tests/test_server.py"
        ],
        "docs": [
          "README.md",
          "docs/DEV_SETUP.md",
          "docs/EDGE_QUERY_FEATURE.md",
          "docs/FEATURE_SUMMARY.md",
          "docs/GEAR_FEATURE.md",
          "docs/NEXT_STEPS_GEOMETRY_REFERENCES.md",
          "docs/ONSHAPE_API_IMPROVEMENTS.md",
          "docs/QUICK_START.md",
          "docs/SKETCH_PLANE_REFERENCE_GUIDE.md",
          "docs/TESTING.md",
          "docs/TEST_SUMMARY.md",
          "tests/README.md"
        ],
        "fileTypes": {
          ".yml": 1,
          ".md": 13,
          ".json": 1,
          ".py": 29,
          ".toml": 1,
          ".ini": 1,
          ".txt": 1,
          ".lock": 1
        }
      }
    },
    {
      "id": 1146558633,
      "name": "flowsint",
      "displayName": "flowsint",
      "description": "A modern platform for visual, flexible, and extensible graph-based investigations. For cybersecurity analysts and investigators.",
      "summary": "In today’s cybersecurity landscape, analysts and investigators regularly face the challenge of piecing together complex digital evidence from disparate sources. Investigating malicious domains, tracing attack infrastructure, or mapping social connections often means wrangling dozens of tools, exporting CSVs, and manually building out relationship diagrams. The process is not only cumbersome but also prone to error and inefficiency. What if there was a platform that allowed you to visually explore relationships, automate enrichment, and maintain full control of your sensitive data—without sacrificing extensibility or ethical boundaries?\n\nFlowsint sets out to solve this exact problem. Unlike traditional OSINT tools that are either narrowly focused or closed-source, Flowsint is an open-source graph-based investigation platform tailored for cybersecurity professionals. Its core value lies in its modularity and transparency: every enrichment step, data flow, and transformation is both visible and customizable. The project is not just another web dashboard; it’s a flexible, extensible system where investigators can automate complex workflows, integrate external intelligence sources, and maintain forensic rigor. The commitment to ethical use, highlighted by a dedicated ETHICS.md and mandatory local data storage, further distinguishes Flowsint in a field fraught with privacy concerns.\n\nTechnically, Flowsint exhibits a thoughtful architecture that balances separation of concerns with extensibility. The repository’s file structure reveals a multi-module design: flowsint-core acts as the orchestrator, managing vaults, Celery tasks, and shared utilities, while flowsint-types provides Pydantic models for strict type validation—a must for reliable data pipelines. Enrichment logic is encapsulated in flowsint-enrichers, isolating scanning and enrichment from core orchestration. The backend API, exposed via FastAPI in flowsint-api, is decoupled from the frontend (flowsint-app), following modern service separation best practices. Infrastructure is containerized via Docker, with distinct docker-compose.dev.yml and docker-compose.prod.yml files enabling easy local development and production deployment. The presence of a Makefile (make prod) and carefully organized CI workflows (.github/workflows/images.yml) indicates mature DevOps hygiene. Moreover, the use of Alembic migrations within flowsint-api/alembic/versions suggests that data schema evolution is first-class—critical for investigative tools that must adapt to ever-changing threat landscapes.\n\nFlowsint’s approach unlocks several practical scenarios for developers and analysts. First, consider a threat intelligence team tasked with mapping the infrastructure of a phishing campaign: using Flowsint, they can import suspicious domains, resolve related IPs, enumerate subdomains, and pivot to ASN and organization data—all visually, with each step automated and recorded. Second, a SOC analyst investigating account compromises can enrich email addresses to uncover breach exposure, Gravatar profiles, and social footprints, quickly assembling evidence for incident response. Third, developers building custom OSINT workflows can leverage Flowsint’s N8n connector, integrating graph-based investigations with broader automation pipelines—without writing glue code from scratch. The modular architecture ensures that new enrichers or integrations can be added with minimal friction, making the platform future-proof for evolving investigative techniques.\n\nUltimately, Flowsint exemplifies the kind of open-source tooling the security community needs: transparent, ethical, and developer-friendly. By prioritizing extensibility, privacy, and usability, it offers a foundation for both rapid prototyping and rigorous investigations. Its careful separation of core, enrichers, API, and frontend—each visible in the repo’s structure—enables contributors to focus on what matters most: building reliable, auditable intelligence workflows. For anyone tired of stitching together single-purpose scripts or wrestling with black-box SaaS platforms, Flowsint is a promising blueprint for the next generation of investigative tooling.",
      "url": "https://github.com/yebeai/flowsint",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "reconurge/flowsint",
        "url": "https://github.com/reconurge/flowsint",
        "stars": 2603
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 31, 2026",
      "updatedAt": "January 31, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 15,
          ".github": 1,
          ".husky": 1,
          "flowsint-api": 71,
          "flowsint-app": 112
        },
        "languages": {
          "YAML": 5,
          "JSON": 7,
          "Markdown": 8,
          "JavaScript": 1,
          "Python": 62,
          "Shell": 1,
          "TOML": 1,
          "HTML": 1,
          "TypeScript": 14,
          "TSX": 20
        },
        "frameworks": [
          "React",
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "flowsint-api/app/main.py",
          "flowsint-app/index.html"
        ],
        "configFiles": [
          ".env.example",
          "Makefile",
          "docker-compose.dev.yml",
          "docker-compose.prod.yml",
          "docker-compose.yml",
          "flowsint-api/Dockerfile",
          "flowsint-api/pyproject.toml",
          "flowsint-app/.eslintrc.cjs",
          "flowsint-app/.prettierrc.yaml",
          "flowsint-app/Dockerfile",
          "flowsint-app/Dockerfile.dev",
          "flowsint-app/package.json"
        ],
        "dependencies": [
          "flowsint-api/pyproject.toml",
          "flowsint-app/package.json"
        ],
        "testFiles": [],
        "docs": [
          "CHANGELOG.md",
          "LICENSE",
          "README.md",
          "flowsint-api/README.md",
          "flowsint-api/alembic/README",
          "flowsint-app/README.md",
          "flowsint-app/src/api/README-query-keys.md",
          "flowsint-app/src/components/analyses/README.md"
        ],
        "fileTypes": {
          ".example": 1,
          ".yml": 4,
          ".json": 7,
          ".md": 8,
          ".js": 1,
          ".ini": 1,
          ".py": 62,
          ".mako": 1,
          ".sh": 1,
          ".toml": 1,
          ".cfg": 1,
          ".cjs": 1,
          ".yaml": 1,
          ".dev": 1,
          ".html": 1,
          ".conf": 1,
          ".ico": 2,
          ".png": 2,
          ".svg": 52,
          ".ts": 14,
          ".tsx": 20
        }
      }
    },
    {
      "id": 1146458743,
      "name": "claude-supermemory",
      "displayName": "claude supermemory",
      "description": "Enable Claude Code to learn in real-time, update it's knowledge, and grow with you, using supermemory.",
      "summary": "The Problem\n\nClaude is great at code Q&A, but it has the memory of a goldfish. Every new session, it forgets what you did, what you like, and how your project works. You end up repeating yourself, re-explaining conventions, and manually pasting context like a caveman.\n\nWhat This Does\n\nclaude-supermemory bolts persistent, session-spanning memory onto Claude Code using Supermemory. Whenever you start a session, src/context-hook.js grabs relevant context from Supermemory and injects it directly so Claude \"remembers\" your tools, preferences, and recent tasks. As you chat, src/add-memory.js captures each turn and stores it for future reference. There's a plugin folder full of scripts (plugin/scripts/add-memory.cjs, plugin/scripts/context-hook.cjs, etc.) handling the plumbing so you don't have to.\n\nWant to index your codebase? Run /claude-supermemory:index and it crawls your project, logs architecture and conventions, then stores them in Supermemory. All config lives in src/lib/settings.js and an optional ~/.supermemory-claude/settings.json where you can blacklist noisy tools or tweak debug logging.\n\nReal-World Use\n\nSay you're bouncing between three microservices, all with different conventions. You set your API key, install the plugin, and start a session. Claude greets you with context like:\n\n<supermemory-context>\nUser Profile (Persistent)\nPrefers TypeScript over JavaScript\nUses Bun as package manager\nRecent Context\nWorking on authentication flow\n</supermemory-context>\n\nYou ask, \"What did we do last Tuesday on auth?\" It searches your chat history and codebase using the super-search skill, then actually answers. No more copy-paste, no more \"remind me what we're working on.\"\n\nThe Bottom Line\n\nIf you're tired of your chatbot forgetting everything, this plugin is worth a shot. It works best for bigger projects and teams where context actually matters. Setup is a little fiddly (API keys, config files), and if you hate cloud anything, skip it. For anyone who treats Claude like a coding partner, persistent memory is a sanity-saver.",
      "url": "https://github.com/yebeai/claude-supermemory",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "supermemoryai/claude-supermemory",
        "url": "https://github.com/supermemoryai/claude-supermemory",
        "stars": 2242
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 31, 2026",
      "updatedAt": "January 31, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 39,
        "directories": {
          ".claude-plugin": 1,
          ".github": 1,
          "(root)": 5,
          "plugin": 14,
          "scripts": 1,
          "src": 17
        },
        "languages": {
          "JSON": 9,
          "YAML": 1,
          "Markdown": 4,
          "JavaScript": 16,
          "HTML": 2
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          "package.json",
          "plugin/package.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json",
          "plugin/package-lock.json",
          "plugin/package.json"
        ],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".json": 9,
          ".yml": 1,
          ".md": 4,
          ".cjs": 6,
          ".js": 16,
          ".html": 2
        }
      }
    },
    {
      "id": 1146452585,
      "name": "cashu-skill",
      "displayName": "cashu skill",
      "description": "A Cashu wallet skill for AI agents",
      "summary": "The Problem\nManaging Cashu ecash tokens and interacting with Bitcoin Lightning mints can be a real headache. For developers and users alike, juggling wallets, mints, and transaction histories often involves bouncing between multiple tools. You need a solution that simplifies these tasks without unnecessary complexity.\n\nWhat This Does\nEnter the cashu-skill repository. This project offers a lightweight command-line interface (CLI) specifically designed for handling Cashu wallets. The core functionality is neatly encapsulated in cli/wallet.mjs, which serves as the entry point for interacting with your wallet. You can execute commands like balance to check your total balance or history to view your transaction logs—all from the terminal. \n\nThe project structure is simple, with vital files such as package.json for dependencies and wallet.mjs for the main logic. It even uses SQLite to store wallet data in ~/.cashu-wallet/wallet.db, ensuring you don’t lose track of your tokens. No fancy abstractions here; just straightforward operations.\n\nReal-World Use\nImagine you just received a payment in Bitcoin and want to convert it into Cashu tokens. You’d fire up your terminal, navigate to the cli directory, and run node wallet.mjs invoice <amount>. This command generates a Lightning invoice to mint your tokens. After that, you could check the status of your mint with check-invoice <quote-id>. Simple, right? Just remember to keep your seed phrase handy if you need to restore your wallet later with restore <mint-url>.\n\nThe Bottom Line\nOverall, cashu-skill is a practical tool for anyone needing to manage Cashu tokens efficiently. It’s not going to win any awards for being user-friendly—if you're not comfortable with a CLI, this isn’t for you. But if you’re a developer or someone who prefers a no-nonsense approach, this tool hits the mark. Just keep in mind that it lacks a test runner and might feel a bit bare-bones for more extensive use cases.",
      "url": "https://github.com/yebeai/cashu-skill",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "cashubtc/cashu-skill",
        "url": "https://github.com/cashubtc/cashu-skill",
        "stars": 22
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 31, 2026",
      "updatedAt": "January 31, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 7,
        "directories": {
          "(root)": 4,
          "cli": 3
        },
        "languages": {
          "Markdown": 2,
          "JSON": 1
        },
        "frameworks": [
          "React"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [
          "cli/package.json"
        ],
        "dependencies": [
          "cli/package.json"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".md": 2,
          ".json": 1,
          ".mjs": 1
        }
      }
    },
    {
      "id": 1146446852,
      "name": "livecc",
      "displayName": "livecc",
      "description": "LiveCC: Learning Video LLM with Streaming Speech Transcription at Scale (CVPR 2025)",
      "summary": "Real-time video commentary powered by AI has long been a holy grail for interactive media, sports broadcasting, and live event coverage. The challenge lies not just in parsing complex visual information, but in synchronizing it with streaming speech, generating meaningful, contextual commentary on the fly. Existing solutions often struggle to scale, either bottlenecked by slow transcription, limited video understanding, or the inability to operate in true streaming scenarios. LiveCC addresses this gap, promising a Video Large Language Model (LLM) that delivers state-of-the-art performance in both real-time and offline benchmarks by integrating a novel video-ASR streaming method.\n\nAt its core, LiveCC is engineered to fuse visual and audio modalities, enabling a LLM to generate live commentary with unprecedented accuracy and speed. Unlike typical multimodal models, LiveCC is explicitly tailored for streaming workflows, both in its architecture and its data pipeline. The repository’s lineage—forked from showlab/livecc—shows a commitment to open research, while its rapid integration with Hugging Face resources (models, datasets, demos) signals a focus on reproducibility and accessibility. The project stands out by not merely offering an academic model, but by providing tooling for seamless end-to-end deployment, from dataset creation to inference, with support for large-scale training.\n\nA closer look at the file structure reveals an architecture optimized for modularity and scalability. The data directory encapsulates dataset logic (lmmdataset.py) and a robust production pipeline. The production subfolder is particularly notable, containing scripts for distributed audio-visual processing—such as distributedlighterasd (audio-visual speaker diarization), distributedlmm4asd.py (LLM integration with ASD), and distributedwhisperx.py (streaming speech transcription). The presence of facedetector.py and facetracker.py underlines that LiveCC handles complex video analytics, extracting faces and tracking them for context-aware commentary. Meanwhile, the demo layer (demo/app.py, demo/cli.py) ensures quick access via Gradio and CLI, lowering the barrier for experimentation. The use of modern Python (>=3.11), PyTorch (torch==2.6.0), Transformers (>=4.50.0), and specialized packages like flash-attn and insightface reflects a stack curated for both performance and extensibility.\n\nLiveCC is particularly well-suited for developers building interactive video platforms, automated sports broadcasters, or educational tools that require real-time analysis of lectures and events. For instance, a sports analytics startup could leverage LiveCC’s streaming pipeline to generate live commentary and player insights, using facetracker.py to follow key athletes and distributedwhisperx.py to transcribe and contextualize crowd reactions. Another scenario is live classroom transcription and analysis—combining languagedetect.py and makeprompt.py to generate summaries or Q&A in real time. Even traditional media houses can deploy LiveCC as an offline benchmark tool, comparing live-generated commentary with post-event summaries for quality assurance.\n\nWhat makes LiveCC compelling is its focus on the practical realities of streaming AI: distributed processing, efficient token management, and modular integration with state-of-the-art models. The project doesn’t just push a new model, but offers a blueprint for scaling video-LLM systems—from data collection (appendjsonlseeks.py, pretrainto_clips.py) to production-grade inference. As AI moves deeper into live media, projects like LiveCC will be foundational, not just for technical innovation but for democratizing access to advanced multimodal intelligence. The takeaway is clear: LiveCC isn’t just another research repo—it’s a toolkit for building the next generation of interactive, context-aware video applications.",
      "url": "https://github.com/yebeai/livecc",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "showlab/livecc",
        "url": "https://github.com/showlab/livecc",
        "stars": 427
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1607799279861-4dd421887fb3?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 31, 2026",
      "updatedAt": "January 31, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 95,
        "directories": {
          "(root)": 8,
          "data": 24,
          "demo": 8,
          "evaluation": 25,
          "livecc-utils": 8,
          "scripts": 3,
          "utils": 2,
          "webpage": 17
        },
        "languages": {
          "Markdown": 5,
          "Python": 46,
          "JSON": 3,
          "HTML": 1,
          "TOML": 1,
          "Shell": 2,
          "CSS": 5,
          "JavaScript": 6
        },
        "frameworks": [
          "Flask"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "data/production/distributed_lighter_asd/main.py",
          "demo/app.py",
          "demo/cli.py",
          "index.html",
          "webpage/static/js/index.js"
        ],
        "configFiles": [
          "livecc-utils/pyproject.toml"
        ],
        "dependencies": [
          "livecc-utils/pyproject.toml"
        ],
        "testFiles": [],
        "docs": [
          "README.md",
          "data/production/README.md",
          "data/production/distributed_lighter_asd/LICENSE",
          "data/production/distributed_lighter_asd/README.md",
          "livecc-utils/README.md"
        ],
        "fileTypes": {
          ".md": 5,
          ".py": 46,
          ".model": 1,
          ".mp4": 4,
          ".jsonl": 7,
          ".txt": 4,
          ".json": 3,
          ".html": 1,
          ".whl": 1,
          ".gz": 1,
          ".toml": 1,
          ".sh": 2,
          ".css": 5,
          ".png": 2,
          ".js": 6,
          ".pdf": 1
        }
      }
    },
    {
      "id": 1146441263,
      "name": "agent-shell",
      "displayName": "agent shell",
      "description": "A native Emacs buffer to interact with LLM agents powered by ACP",
      "summary": "When working with large language models (LLMs), the challenge of efficiently managing interactions often arises for developers and researchers alike. Whether it's debugging code, navigating complex APIs, or collaborating with AI-driven agents for creative or analytical tasks, the lack of seamless integration between development environments and these agents can be a significant bottleneck. Enter agent-shell, a native Emacs buffer designed to bridge this gap by providing a streamlined interface for interacting with LLM agents powered by the Agent Client Protocol (ACP). For Emacs users who thrive in a keyboard-centric workflow, agent-shell offers a unique solution that enhances productivity and flexibility.\n\nAt its core, agent-shell is more than just a chat interface for LLMs. It leverages ACP—a standardized protocol for client-agent communication—to create a highly modular and extensible environment. Unlike web-based tools or standalone interfaces, agent-shell embeds directly into Emacs, making it a natural extension for developers who already use Emacs for coding, writing, or managing projects. With support for a wide range of ACP-driven agents like Google's Gemini CLI, Anthropic's Claude Code, OpenAI's Codex, and more, agent-shell empowers users to interact with these tools without ever leaving their editor. This tight integration is particularly appealing for those who rely on Emacs for its programmable nature and its ability to unify disparate workflows under one roof.\n\nLooking under the hood, the architecture of agent-shell reveals thoughtful design principles aimed at modularity and extensibility. The repository's file structure hints at a well-organized codebase, where each agent-specific integration is encapsulated in its own .el file, such as agent-shell-anthropic.el for Claude Code or agent-shell-openai.el for OpenAI's Codex. This approach ensures that each agent's functionality is isolated, making it easier to maintain, debug, and expand. The presence of utility modules like agent-shell-completion.el and agent-shell-ui.el further suggests a focus on enhancing user experience, with features like intelligent auto-completion and a polished interface. Additionally, the tests/ directory highlights a commitment to robust testing practices, housing files like agent-shell-runner-tests.el and agent-shell-tests.el to validate critical components. This attention to detail not only instills confidence in the stability of the tool but also provides a blueprint for contributors to extend its capabilities.\n\nThe use cases for agent-shell are compelling and diverse. First, imagine a developer working on a codebase that heavily relies on AI-assisted code generation or debugging. By integrating directly with tools like Codex or Claude, agent-shell allows them to quickly query the LLM for code suggestions, explanations, or fixes—all without switching contexts. This eliminates the friction of toggling between browser-based tools and the editor, resulting in a more fluid workflow. Second, researchers exploring novel applications of LLMs can use agent-shell as a sandbox for experimentation, leveraging its support for multiple agents to compare outputs, test hypotheses, or prototype new ideas. Finally, teams conducting collaborative code reviews or documentation tasks can benefit from agent-shell's ability to interface with tools like Goose CLI or Cursor agent, streamlining processes that involve AI-driven insights.\n\nWhat makes agent-shell particularly significant is its alignment with the philosophy of Emacs itself: empowering users to shape their environment to fit their needs. While many tools cater to LLM interactions, few integrate as seamlessly into a development ecosystem as agent-shell does within Emacs. By leveraging ACP and providing out-of-the-box support for numerous agents, it positions itself as a valuable asset for developers, researchers, and teams working at the intersection of AI and software development. For those already invested in Emacs, agent-shell is not merely an add-on—it's a natural extension that amplifies the potential of their workflows. As AI continues to evolve, tools like agent-shell remind us of the importance of thoughtful integration, where the user experience is as much a priority as the underlying functionality.",
      "url": "https://github.com/yebeai/agent-shell",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "xenodium/agent-shell",
        "url": "https://github.com/xenodium/agent-shell",
        "stars": 748
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 31, 2026",
      "updatedAt": "January 31, 2026",
      "readTime": 4,
      "knowledgeGraph": {
        "totalFiles": 36,
        "directories": {
          ".github": 3,
          "(root)": 24,
          "tests": 9
        },
        "languages": {
          "YAML": 1,
          "Markdown": 2
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [
          "tests/.dir-locals.el",
          "tests/agent-shell-anthropic-tests.el",
          "tests/agent-shell-fakes.el",
          "tests/agent-shell-runner-tests.el",
          "tests/agent-shell-tests.el",
          "tests/gemini-multiple-permissions.traffic",
          "tests/gemini-permission.traffic",
          "tests/gemini-wrong-output-grouping.traffic",
          "tests/user-message-chunk.traffic"
        ],
        "docs": [
          "LICENSE",
          "README.org"
        ],
        "fileTypes": {
          ".yml": 1,
          ".md": 2,
          ".org": 1,
          ".el": 24,
          ".png": 3,
          ".traffic": 4
        }
      }
    },
    {
      "id": 1146300152,
      "name": "openpilot",
      "displayName": "openpilot",
      "description": "openpilot is an operating system for robotics. Currently, it upgrades the driver assistance system on 300+ supported cars.",
      "summary": "The Problem\n\nStock driver assistance on most cars is garbage—either too conservative, too dumb, or just plain annoying. Manufacturers ship half-baked lane keeping and cruise control, then lock you out of meaningful customization. If you want something actually useful, you're stuck waiting for their next recall.\n\nWhat This Does\n\nopenpilot rips out the limitations and turns your car into a programmable robot. The repo is basically the brains for a comma 3X device, letting you run smarter driver assistance on top of 300+ supported vehicles. The real action lives in subfolders—hardware integration, model code, and a mess of config files. For example, all the GitHub Actions in .github/workflows/ automate builds, tests, and releases; you’ll see stuff like tests.yaml for CI and release.yaml for pushing new versions. The actual car support is mapped out in docs/CARS.md, so you know if your ride is covered before you waste a weekend.\n\nInstall is stupid simple: run bash <(curl -fsSL openpilot.comma.ai) and you're off to the races. If you want to get hands-on, you can run nightly branches using the URLs in the README, or mess with your own fork and push updates straight to your comma device.\n\nReal-World Use\n\nLet’s say you’ve got a Honda Civic and a comma 3X. You grab the harness, flash the device using openpilot.comma.ai, and suddenly your car can keep lanes, adapt speed, and brake like it actually cares about your commute. Want to tweak behavior? Fork the repo, update some control logic, and deploy your branch via a custom install URL. You’ll see test results in GitHub thanks to tests.yaml—failures mean you broke something, congrats.\n\nThe Bottom Line\n\nopenpilot is the closest thing to open-source autopilot for normal people. It’s dead simple to install, but if you want to tinker, you’ll need to wade through real engineering code—no toy demos here. If you care about car automation and hate waiting on automakers, this is the only game in town. Just don’t expect hand-holding or stability if you’re living on nightly branches.",
      "url": "https://github.com/yebeai/openpilot",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "commaai/openpilot",
        "url": "https://github.com/commaai/openpilot",
        "stars": 60177
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 30, 2026",
      "updatedAt": "January 30, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 23,
          ".github": 24,
          ".vscode": 3,
          "cereal": 19,
          "common": 64,
          "docs": 30,
          "openpilot": 6,
          "release": 8,
          "scripts": 21,
          "selfdrive": 2
        },
        "languages": {
          "YAML": 23,
          "Markdown": 30,
          "JSON": 3,
          "Python": 56,
          "C/C++ Header": 13,
          "CSS": 1,
          "TOML": 2,
          "Shell": 22,
          "C": 1
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "Jenkins",
        "entryPoints": [],
        "configFiles": [
          "Dockerfile.openpilot",
          "Dockerfile.openpilot_base",
          "pyproject.toml"
        ],
        "dependencies": [
          "pyproject.toml"
        ],
        "testFiles": [
          ".github/workflows/tests.yaml",
          "cereal/messaging/tests/__init__.py",
          "cereal/messaging/tests/test_messaging.py",
          "cereal/messaging/tests/test_pub_sub_master.py",
          "cereal/messaging/tests/test_services.py",
          "common/tests/.gitignore",
          "common/tests/__init__.py",
          "common/tests/test_file_helpers.py",
          "common/tests/test_markdown.py",
          "common/tests/test_params.cc",
          "common/tests/test_params.py",
          "common/tests/test_runner.cc",
          "common/tests/test_simple_kalman.py",
          "common/tests/test_swaglog.cc",
          "common/tests/test_util.cc",
          "common/transformations/tests/__init__.py",
          "common/transformations/tests/test_coordinates.py",
          "common/transformations/tests/test_orientation.py",
          "conftest.py",
          "scripts/jenkins_loop_test.sh"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "cereal/README.md",
          "common/transformations/README.md",
          "docs/CARS.md",
          "docs/CONTRIBUTING.md",
          "docs/DEBUGGING_SAFETY.md",
          "docs/INTEGRATION.md",
          "docs/LIMITATIONS.md",
          "docs/README.md",
          "docs/SAFETY.md",
          "docs/assets/icon-star-empty.svg",
          "docs/assets/icon-star-full.svg",
          "docs/assets/icon-star-half.svg",
          "docs/assets/icon-youtube.svg",
          "docs/assets/three-back.svg",
          "docs/car-porting/brand-port.md",
          "docs/car-porting/car-state-signals.md",
          "docs/car-porting/model-port.md",
          "docs/car-porting/reverse-engineering.md",
          "docs/car-porting/what-is-a-car-port.md",
          "docs/concepts/glossary.md",
          "docs/concepts/logs.md",
          "docs/concepts/safety.md",
          "docs/contributing/architecture.md",
          "docs/contributing/roadmap.md",
          "docs/css/tooltip.css",
          "docs/getting-started/what-is-openpilot.md",
          "docs/glossary.toml",
          "docs/hooks/glossary.py",
          "docs/how-to/connect-to-comma.md",
          "docs/how-to/replay-a-drive.md",
          "docs/how-to/turn-the-speed-blue.md",
          "docs/index.md",
          "release/README.md"
        ],
        "fileTypes": {
          ".yml": 4,
          ".md": 30,
          ".yaml": 19,
          ".json": 3,
          ".openpilot": 1,
          ".openpilot_base": 1,
          ".py": 56,
          ".capnp": 5,
          ".cc": 12,
          ".h": 13,
          ".pyx": 1,
          ".svg": 5,
          ".css": 1,
          ".toml": 2,
          ".sh": 22,
          ".c": 1
        }
      }
    },
    {
      "id": 1146298231,
      "name": "agent-lightning",
      "displayName": "agent lightning",
      "description": "The absolute trainer to light up AI agents.",
      "summary": "The Problem\nTraining AI agents can be a real pain in the neck. You want them to learn and optimize, but every framework has its quirks. If you’ve ever wrestled with multiple agents across different frameworks, you know the frustration of trying to get them to play nice. Most solutions require extensive code changes, which is a recipe for headaches and wasted time.\n\nWhat This Does\nEnter agent-lightning, your ticket to a smoother training experience. This repo allows you to optimize agents without having to change their existing code—well, almost. It supports various frameworks like LangChain and OpenAI Agent SDK, and even lets you work without one at all. The core feature is its ability to selectively optimize agents in a multi-agent setup, making it a versatile tool.\n\nThe workflow files in .github/workflows/ are set up for continuous integration and testing. For instance, badge-unit.yml handles unit tests, while benchmark.yml can help you evaluate performance metrics. These workflows ensure that your code remains stable as you make optimizations.\n\nReal-World Use\nImagine you have a multi-agent system for a chatbot that needs to be more responsive. Instead of rewriting everything, you can integrate agent-lightning with minimal fuss. Just install it using:\n\npip install agentlightning\n\nThen, you can apply reinforcement learning or prompt optimization strategies to your agents. You might also find the examples in the examples/ folder useful for seeing how to implement it in practice.\n\nThe Bottom Line\nagent-lightning is a solid tool for developers who want to optimize AI agents without diving into a code overhaul. It’s not for everyone—if your project is small or simple, this might be overkill. But for those dealing with complex multi-agent systems, this repo can save you headaches and time. Just be prepared for the learning curve if you’re not familiar with the underlying frameworks.",
      "url": "https://github.com/yebeai/agent-lightning",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "microsoft/agent-lightning",
        "url": "https://github.com/microsoft/agent-lightning",
        "stars": 15209
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 30, 2026",
      "updatedAt": "January 30, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 10,
          ".github": 33,
          "agentlightning": 99,
          "contrib": 11,
          "dashboard": 47
        },
        "languages": {
          "YAML": 35,
          "Markdown": 8,
          "Python": 98,
          "Shell": 2,
          "TypeScript": 18,
          "TSX": 18,
          "JSON": 3,
          "JavaScript": 1,
          "HTML": 1
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "agentlightning/server.py",
          "agentlightning/verl/__main__.py",
          "dashboard/.storybook/main.ts",
          "dashboard/public/index.html",
          "dashboard/src/App.tsx",
          "dashboard/src/features/config/index.ts",
          "dashboard/src/features/resources/index.ts",
          "dashboard/src/features/rollouts/index.ts",
          "dashboard/src/features/traces/index.ts"
        ],
        "configFiles": [
          "dashboard/.prettierrc.mjs",
          "dashboard/package.json"
        ],
        "dependencies": [
          "dashboard/package-lock.json",
          "dashboard/package.json"
        ],
        "testFiles": [
          ".github/workflows/badge-latest.yml",
          ".github/workflows/tests-full.yml",
          ".github/workflows/tests.yml",
          "dashboard/.storybook/vitest.setup.ts",
          "dashboard/src/features/resources/resources.test.ts",
          "dashboard/src/features/rollouts/rollouts.test.ts"
        ],
        "docs": [
          "LICENSE",
          "RAI_README.md",
          "README.md",
          "contrib/README.md",
          "contrib/recipes/search_r1/README.md",
          "dashboard/README.md"
        ],
        "fileTypes": {
          ".yml": 33,
          ".yaml": 2,
          ".md": 8,
          ".py": 98,
          ".poml": 5,
          ".sh": 2,
          ".mjs": 1,
          ".ts": 18,
          ".tsx": 18,
          ".json": 3,
          ".js": 1,
          ".cjs": 1,
          ".html": 1,
          ".svg": 1
        }
      }
    },
    {
      "id": 1146154240,
      "name": "latitude-llm",
      "displayName": "latitude llm",
      "description": "Latitude is the open-source prompt engineering platform to build, evaluate, and refine your prompts with AI",
      "summary": "The Problem\nPrompt engineering is a nightmare without proper tooling. Teams often struggle to track how their prompts perform in production. Debugging issues becomes a scavenger hunt, and you end up with more question marks than answers. Latitude aims to fix this mess by giving you visibility and control over your AI interactions.\n\nWhat This Does\nLatitude is an open-source platform that lets you build, evaluate, and refine your prompts effectively. It starts with observability—capturing critical data like prompts, inputs/outputs, and latency. The .github/workflows folder is packed with CI/CD workflows that automate tests, linting, and deployments, streamlining your development pipeline.\n\nYou can manage datasets under the /skills/promptl directory for batch testing and regression checks. Plus, the prompt optimizer (GEPA) function helps you tweak prompts against your evaluation suite to minimize failures. This means you can actually track performance over time and make informed adjustments rather than throwing darts in the dark.\n\nReal-World Use\nImagine you're deploying a new AI feature, and you want to ensure it doesn't break anything. You'd start by adding the telemetry SDK as outlined in the README. Then, create your datasets and evals to measure performance. Once that's set up, publish your changes and deploy via the gateway. The built-in rollback workflows can save your skin if something goes sideways—just a quick call to rollback-deployment.yml, and you're back in business.\n\nDeploying a new version\n$ git commit -m \"Add new prompt for customer queries\"\n$ git push origin main\n\nThe Bottom Line\nLatitude looks solid for teams serious about AI deployment and prompt management. The observability and evaluation features are handy, especially for larger projects that can't afford to wing it. If you're a solo developer or just tinkering, though, this might feel like overkill. But if you want to stop guessing and start measuring, Latitude is worth a shot.",
      "url": "https://github.com/yebeai/latitude-llm",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "latitude-dev/latitude-llm",
        "url": "https://github.com/latitude-dev/latitude-llm",
        "stars": 3917
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 30, 2026",
      "updatedAt": "January 30, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 13,
          ".github": 22,
          ".skills": 2,
          ".vscode": 1,
          "apps": 162
        },
        "languages": {
          "YAML": 24,
          "Markdown": 7,
          "JSON": 6,
          "TypeScript": 132,
          "Python": 16,
          "TOML": 1
        },
        "frameworks": [
          "React",
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "apps/console/src/index.ts",
          "apps/engine/app/main.py",
          "apps/engine/app/rpc/server.py",
          "apps/gateway/src/middlewares/rateLimit/index.ts",
          "apps/gateway/src/openApi/schemas/index.ts",
          "apps/gateway/src/openApi/tags/index.ts",
          "apps/gateway/src/routes/api/index.ts",
          "apps/gateway/src/routes/api/v3/conversations/annotate/index.ts",
          "apps/gateway/src/routes/api/v3/conversations/attach/index.ts",
          "apps/gateway/src/routes/api/v3/conversations/chat/index.ts",
          "apps/gateway/src/routes/api/v3/conversations/get/index.ts",
          "apps/gateway/src/routes/api/v3/conversations/index.ts",
          "apps/gateway/src/routes/api/v3/conversations/stop/index.ts",
          "apps/gateway/src/routes/api/v3/datasetRows/index.ts",
          "apps/gateway/src/routes/api/v3/datasets/index.ts",
          "apps/gateway/src/routes/api/v3/projects/index.ts",
          "apps/gateway/src/routes/api/v3/projects/versions/documents/createOrUpdate/index.ts",
          "apps/gateway/src/routes/api/v3/projects/versions/documents/get/index.ts",
          "apps/gateway/src/routes/api/v3/projects/versions/documents/getAll/index.ts",
          "apps/gateway/src/routes/api/v3/projects/versions/documents/getOrCreate/index.ts",
          "apps/gateway/src/routes/api/v3/projects/versions/documents/index.ts",
          "apps/gateway/src/routes/api/v3/projects/versions/documents/run/index.ts"
        ],
        "configFiles": [
          ".env.example",
          ".prettierrc",
          ".prettierrcignore",
          "apps/console/.eslintrc.json",
          "apps/console/package.json",
          "apps/console/tsconfig.json",
          "apps/engine/pyproject.toml",
          "apps/gateway/.eslintrc.json",
          "apps/gateway/docker/Dockerfile",
          "apps/gateway/package.json"
        ],
        "dependencies": [
          "apps/console/package.json",
          "apps/engine/pyproject.toml",
          "apps/gateway/package.json"
        ],
        "testFiles": [
          ".github/workflows/test.yml",
          "apps/engine/scripts/test.py",
          "apps/gateway/appspec.yml",
          "apps/gateway/misc/load-test.mjs",
          "apps/gateway/scripts/test-rate-limit.cjs",
          "apps/gateway/src/common/createRequestAbortSignal.test.ts",
          "apps/gateway/src/routes/api/v3/conversations/annotate/annotate.handler.test.ts",
          "apps/gateway/src/routes/api/v3/conversations/chat/chat.handler.test.ts",
          "apps/gateway/src/routes/api/v3/conversations/get/get.handler.test.ts",
          "apps/gateway/src/routes/api/v3/datasetRows/create/create.handler.test.ts",
          "apps/gateway/src/routes/api/v3/datasetRows/destroy/destroy.handler.test.ts",
          "apps/gateway/src/routes/api/v3/datasetRows/get/get.handler.test.ts",
          "apps/gateway/src/routes/api/v3/datasetRows/getAll/getAll.handler.test.ts",
          "apps/gateway/src/routes/api/v3/datasetRows/update/update.handler.test.ts",
          "apps/gateway/src/routes/api/v3/datasets/create/create.handler.test.ts",
          "apps/gateway/src/routes/api/v3/datasets/destroy/destroy.handler.test.ts",
          "apps/gateway/src/routes/api/v3/datasets/get/get.handler.test.ts",
          "apps/gateway/src/routes/api/v3/datasets/getAll/getAll.handler.test.ts",
          "apps/gateway/src/routes/api/v3/datasets/update/update.handler.test.ts",
          "apps/gateway/src/routes/api/v3/projects/create/create.handler.test.ts",
          "apps/gateway/src/routes/api/v3/projects/getAll/getAll.handler.test.ts",
          "apps/gateway/src/routes/api/v3/projects/push/push.handler.test.ts",
          "apps/gateway/src/routes/api/v3/projects/versions/create/createCommit.test.ts",
          "apps/gateway/src/routes/api/v3/projects/versions/documents/create/create.handler.test.ts",
          "apps/gateway/src/routes/api/v3/projects/versions/documents/createOrUpdate/createOrUpdate.handler.test.ts",
          "apps/gateway/src/routes/api/v3/projects/versions/documents/get/get.handler.test.ts",
          "apps/gateway/src/routes/api/v3/projects/versions/documents/getAll/getAll.handler.test.ts",
          "apps/gateway/src/routes/api/v3/projects/versions/documents/getOrCreate/getOrCreate.handler.test.ts",
          "apps/gateway/src/routes/api/v3/projects/versions/documents/logs/create.handler.test.ts",
          "apps/gateway/src/routes/api/v3/projects/versions/documents/run/run.handler.test.ts"
        ],
        "docs": [
          ".github/workflows/validate-typescript-sdk-changelog.yml",
          "LICENSE",
          "README.md",
          "apps/engine/README.md"
        ],
        "fileTypes": {
          ".example": 1,
          ".yml": 24,
          ".md": 7,
          ".json": 6,
          ".ts": 132,
          ".py": 16,
          ".toml": 1,
          ".lock": 1,
          ".mjs": 1,
          ".cjs": 1
        }
      }
    },
    {
      "id": 1146121145,
      "name": "OpenCoder-llm",
      "displayName": "OpenCoder llm",
      "description": "The Open Cookbook for Top-Tier Code Large Language Model",
      "summary": "Modern software teams face a persistent challenge: finding open, high-quality code large language models (LLMs) that rival proprietary solutions in both performance and transparency. Whether you’re automating code generation, building intelligent code review tools, or supporting multilingual development workflows, the right CodeLLM can make or break your productivity. Yet most models are either locked behind paywalls or lack the robust datasets and evaluation frameworks necessary for trustworthy results. This is why OpenCoder-llm stands out—a community-driven initiative tackling the reproducibility and accessibility gaps in CodeLLM development.\n\nOpenCoder-llm is not just another code-generating model; it’s a comprehensive cookbook for building, evaluating, and refining top-tier code LLMs. With transparent releases spanning data cleaning pipelines, intermediate checkpoints, high-quality code datasets, and an evaluation framework, OpenCoder aims to democratize the process of training and benchmarking CodeLLMs. What makes it unique is its scope and commitment to openness: from raw pretraining data (2.5 trillion tokens, 90% code, 10% web) to supervised finetuning on millions of examples, all artifacts are released for reproducibility. Unlike most open models, OpenCoder is multilingual—supporting English and Chinese—and comes with both base and instruct variants, enabling a range of downstream applications.\n\nThe architecture of OpenCoder-llm is modular and thoughtfully organized, as evidenced by its file structure. The heart of its evaluation framework lies in the OpenCodeEval directory, which is split into distinct components. The src/backend submodule abstracts inference providers, with files like openai.py and vllm.py implementing adapters for API-based and local inference respectively. This pattern allows seamless switching between backends, making the framework extensible for both proprietary and open models. Benchmarking is handled through src/benchmark, where each major dataset—HumanEval, LeetCode, MBPP, BigCodeBench—gets its own dedicated Python module. This separation of concerns facilitates easy addition of new benchmarks and provides reproducible, transparent evaluation. Data files such as BigCodeBench.jsonl and 20240121-Jul.jsonl are versioned and structured for large-scale testing. The presence of intermediate checkpoints and meta-data files further demonstrates OpenCoder’s commitment to open science: everything from cleaned datasets to the evaluation pipeline can be traced, reproduced, and improved.\n\nDevelopers will find OpenCoder-llm invaluable in several scenarios. First, for those training their own CodeLLMs, the data filtering pipeline and openly released datasets provide a high-quality foundation, eliminating the need to rely on noisy or proprietary corpora. Second, research teams evaluating new architectures or fine-tuning strategies can leverage the OpenCodeEval framework to benchmark against established datasets, ensuring results are meaningful and comparable. Third, toolmakers building code assistants or auto-completion engines can use OpenCoder’s pretrained models as drop-in replacements, benefiting from both the performance and the ability to inspect, modify, or extend the models as needed.\n\nThe significance of OpenCoder-llm goes beyond its immediate utility. In an era where AI transparency is increasingly demanded, but rarely delivered, OpenCoder proves that top-tier code LLMs can be built, evaluated, and shared openly without sacrificing quality. Its modular architecture, extensible evaluation suite, and carefully curated datasets set a new standard for reproducibility in code AI research. For teams navigating the trade-offs between proprietary and open models, OpenCoder-llm is a clear signal that the open source community can—and will—deliver competitive, trustworthy alternatives.",
      "url": "https://github.com/yebeai/OpenCoder-llm",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "OpenCoder-llm/OpenCoder-llm",
        "url": "https://github.com/OpenCoder-llm/OpenCoder-llm",
        "stars": 2045
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 30, 2026",
      "updatedAt": "January 30, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 55,
        "directories": {
          "(root)": 3,
          "OpenCodeEval": 45,
          "sft": 7
        },
        "languages": {
          "Markdown": 3,
          "Python": 21,
          "Shell": 3,
          "JSON": 2
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "OpenCodeEval/src/main.py"
        ],
        "configFiles": [
          "sft/requirements.txt"
        ],
        "dependencies": [
          "sft/requirements.txt"
        ],
        "testFiles": [
          "OpenCodeEval/src/eval/__pycache__/unit_test.cpython-310.pyc",
          "OpenCodeEval/src/eval/__pycache__/unittest_execution.cpython-310.pyc",
          "OpenCodeEval/src/eval/unit_test.py"
        ],
        "docs": [
          "LICENSE",
          "OpenCodeEval/README.md",
          "README.md",
          "sft/README.md"
        ],
        "fileTypes": {
          ".md": 3,
          ".txt": 2,
          ".py": 21,
          ".pyc": 14,
          ".jsonl": 8,
          ".sh": 3,
          ".json": 2
        }
      }
    },
    {
      "id": 1146014641,
      "name": "awesome-ralph",
      "displayName": "awesome ralph",
      "description": "A curated list of resources about Ralph, the AI coding technique that runs AI coding agents in automated loops until specifications are fulfilled.",
      "summary": "In the ever-evolving world of AI and autonomous systems, one of the most pressing challenges developers face is achieving consistent, high-quality outcomes from generative coding agents. AI models like OpenAI’s GPT or Anthropic's Claude are incredibly powerful, but their outputs can be unpredictable and often require significant human intervention to course-correct. What if there was a way to harness these tools in a more deterministic, loop-driven fashion—achieving results that align precisely with predefined specifications? Enter \"Ralph,\" a novel AI coding technique designed with automation, persistence, and validation at its heart. The open source repository awesome-ralph serves as a curated library of resources for developers looking to adopt and master this approach.\n\nAt its core, Ralph is a methodology that leverages AI coding agents in an automated loop until the desired output meets the given specifications. The name \"Ralph\" is derived from its playful inspiration, Ralph Wiggum, a character known for his quirky, unconventional logic. Despite its humorous branding, the technique is grounded in rigorous principles. The loop itself is strikingly simple in design: persist the AI's progress into files and version control, reject invalid outputs through tests and lints, and reset the AI's context with every iteration to avoid accumulation of irrelevant or erroneous data. Its mantra, \"Sit on the loop, not in it,\" emphasizes the importance of tooling and automation over manual oversight. This approach transforms the role of the developer into more of an orchestrator, fine-tuning inputs and constraints while the loop does the heavy lifting.\n\nFrom a technical standpoint, the repository offers a wealth of resources that dive deep into the Ralph technique, from its philosophical underpinnings to practical implementation. The file structure itself is minimalist but deliberate. For instance, the loop.sh script serves as the backbone of the operation, implementing the infinite loop that drives the process. The inclusion of separate prompt files (PROMPTbuild.md and PROMPTplan.md) reflects Ralph’s structured workflow, which is divided into three distinct phases: defining requirements, planning the implementation, and executing the build. By decoupling planning and building into separate prompts, Ralph avoids ambiguity and ensures each iteration is laser-focused on fulfilling its specific objectives. The repository also emphasizes the importance of \"backpressure,\" a concept where invalid outputs are systematically rejected—but without creating bottlenecks that would stall progress. This is where tools like linters, unit tests, and type checkers come into play, acting as automated gatekeepers for quality control.\n\nThe use cases for Ralph are as varied as they are compelling. One scenario where it shines is in the creation of complex, multi-step scripts or workflows that would otherwise require significant human intervention to debug and refine. For example, developers could use Ralph to iteratively generate and test a CI/CD pipeline configuration, where each loop generates YAML snippets, runs them against validators, and persists progress into Git. Another powerful application is in prototyping AI-generated libraries or APIs. By feeding Ralph a high-level specification, developers can rapidly bootstrap functional codebases, complete with tests, documentation, and type annotations, all while maintaining tight control over quality through automated validation.\n\nPerhaps the most intriguing use case is in multi-agent systems, where different AI models collaborate to achieve a shared goal. For instance, one agent could specialize in generating unit tests while another focuses on implementation, with Ralph orchestrating the interaction between them. This modularity makes the technique highly adaptable to a variety of workflows, from individual developers experimenting with AI-driven coding to larger teams integrating autonomous agents into their software development lifecycle.\n\nWhat makes Ralph truly significant is its philosophical shift in how we view AI in software development. Rather than treating AI as a black-box assistant that occasionally produces useful outputs, Ralph treats it as a deterministic tool—albeit one that needs a tightly controlled environment to function effectively. By embracing the loop as the fundamental unit of work, developers can build systems that are both robust and transparent, with every decision and iteration documented in version control. This approach not only enhances reproducibility but also aligns well with modern software engineering practices, where iterative development and continuous integration are the norm.\n\nIn a world increasingly reliant on AI, techniques like Ralph offer a glimpse into what the future of autonomous software development could look like. By combining simplicity, automation, and validation, it provides a framework that developers can trust to deliver results—deterministically bad or not—in an otherwise unpredictable landscape. If you're a developer intrigued by the potential of AI-driven coding but wary of its pitfalls, the resources in the awesome-ralph repository are well worth exploring.",
      "url": "https://github.com/yebeai/awesome-ralph",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "snwfdhmp/awesome-ralph",
        "url": "https://github.com/snwfdhmp/awesome-ralph",
        "stars": 751
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 30, 2026",
      "updatedAt": "January 30, 2026",
      "readTime": 4,
      "knowledgeGraph": {
        "totalFiles": 3,
        "directories": {
          ".github": 1,
          "(root)": 2
        },
        "languages": {
          "YAML": 1,
          "Markdown": 2
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "CONTRIBUTING.md",
          "README.md"
        ],
        "fileTypes": {
          ".yml": 1,
          ".md": 2
        }
      }
    },
    {
      "id": 1145974214,
      "name": "Vision-Agents",
      "displayName": "Vision Agents",
      "description": "Open Vision Agents by Stream. Build Vision Agents quickly with any model or video provider. Uses Stream's edge network for ultra-low latency.",
      "summary": "In an era driven by real-time data and video interactions, the demand for intelligent video processing solutions is rapidly increasing. Consider the challenges faced by developers who want to create applications that can analyze video feeds live, responding to events as they happen. Traditional methods of implementing video AI can lead to high latency, inadequate scalability, and complex integrations across multiple services. Stream's Vision Agents project aims to solve these issues by providing a framework that unifies various AI models and video sources, enabling developers to build responsive, low-latency applications tailored to their specific use cases.\n\nVision Agents offers a robust platform designed for real-time video AI, leveraging an edge network to minimize latency to as low as 30 milliseconds. This open-source project allows developers to construct multi-modal AI agents that can watch, listen, and interpret video streams effectively. Unlike other solutions that lock users into proprietary ecosystems, Vision Agents is built to work with any video edge network, making it adaptable for various environments. The use of native APIs from prominent language models such as OpenAI and Claude ensures that developers can always access the latest capabilities without being hindered by outdated integrations.\n\nDiving deeper into the architecture, the file structure reveals a well-organized repository that facilitates both development and deployment. The core of the project resides in the agents-core/visionagents directory, featuring essential modules like agentlauncher.py, which is responsible for initializing agents, and agent_types.py, where different agent functionalities are defined. The presence of a .github directory with various workflows indicates a commitment to continuous integration and delivery, ensuring that code quality is maintained through automated testing and deployment processes. Additionally, the DEVELOPMENT.md file provides guidance on contributing to the project, showcasing an inclusive approach to community involvement.\n\nThe potential use cases for Vision Agents are extensive. For instance, in sports coaching, developers can create applications that analyze player movements and offer real-time feedback using YOLO for object detection and Gemini for language processing. This enables a more interactive coaching experience, allowing trainers to provide immediate insights. Another compelling scenario is the deployment of a security camera system capable of detecting package theft in real-time. By integrating face recognition and object detection, developers can automate the generation of alerts and even create \"WANTED\" posters to circulate on social media, thereby enhancing community safety. Such applications not only demonstrate the versatility of Vision Agents but also highlight the importance of real-time responses in critical situations.\n\nIn conclusion, the Vision Agents project is a significant advancement in the realm of video AI solutions. By combining low-latency processing with an open architecture, it empowers developers to create sophisticated applications that can transform industries ranging from sports to security. As the demand for real-time video analytics continues to grow, projects like Vision Agents will play a pivotal role in shaping the future of AI-driven video experiences. The emphasis on community contributions and adaptability further cements its place as a valuable resource in the open-source landscape, encouraging innovation and collaboration among developers.",
      "url": "https://github.com/yebeai/Vision-Agents",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "GetStream/Vision-Agents",
        "url": "https://github.com/GetStream/Vision-Agents",
        "stars": 6762
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 30, 2026",
      "updatedAt": "January 30, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".claude": 1,
          "(root)": 13,
          ".cursor": 1,
          ".github": 7,
          "agents-core": 80,
          "assets": 9,
          "docs": 10,
          "examples": 78,
          "plugins": 1
        },
        "languages": {
          "Markdown": 39,
          "YAML": 19,
          "TOML": 8,
          "Python": 102,
          "JSON": 1,
          "Shell": 1
        },
        "frameworks": [
          "Docker",
          "Kubernetes"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          ".env.example",
          "agents-core/pyproject.toml",
          "examples/.env.example",
          "examples/01_simple_agent_example/pyproject.toml",
          "examples/02_golf_coach_example/pyproject.toml",
          "examples/03_phone_and_rag_example/pyproject.toml",
          "examples/05_security_camera_example/pyproject.toml",
          "examples/06_prometheus_metrics_example/docker-compose.yml",
          "examples/06_prometheus_metrics_example/pyproject.toml",
          "examples/07_deploy_example/.env.example",
          "examples/07_deploy_example/Dockerfile",
          "examples/07_deploy_example/Dockerfile.gpu",
          "examples/07_deploy_example/docker-compose.yml",
          "examples/07_deploy_example/pyproject.toml",
          "examples/08_agent_server_example/pyproject.toml"
        ],
        "dependencies": [
          "agents-core/pyproject.toml",
          "examples/01_simple_agent_example/pyproject.toml",
          "examples/02_golf_coach_example/pyproject.toml",
          "examples/03_phone_and_rag_example/pyproject.toml",
          "examples/05_security_camera_example/pyproject.toml",
          "examples/06_prometheus_metrics_example/pyproject.toml",
          "examples/07_deploy_example/pyproject.toml",
          "examples/08_agent_server_example/pyproject.toml"
        ],
        "testFiles": [
          ".github/workflows/run_tests.yml",
          "agents-core/vision_agents/core/llm/llm_test.py",
          "agents-core/vision_agents/core/tts/manual_test.py",
          "agents-core/vision_agents/core/tts/testing.py",
          "conftest.py",
          "docs/ai/instructions/ai-tests.md",
          "examples/03_phone_and_rag_example/conftest.py",
          "examples/03_phone_and_rag_example/pytest.ini"
        ],
        "docs": [
          ".claude/agents/repo-workflow-guide.md",
          "LICENSE",
          "README.md",
          "agents-core/README.md",
          "agents-core/vision_agents/core/turn_detection/README.md",
          "docs/ai/instructions/ai-events-example.md",
          "docs/ai/instructions/ai-llm.md",
          "docs/ai/instructions/ai-plugin.md",
          "docs/ai/instructions/ai-realtime-llm.md",
          "docs/ai/instructions/ai-stt.md",
          "docs/ai/instructions/ai-tests.md",
          "docs/ai/instructions/ai-tts.md",
          "docs/ai/instructions/ai-turn-detector.md",
          "docs/ai/instructions/ai-update.md",
          "docs/ai/instructions/ai-utils.md",
          "examples/01_simple_agent_example/README.md",
          "examples/02_golf_coach_example/README.md",
          "examples/03_phone_and_rag_example/README.md",
          "examples/04_football_commentator_example/README.md",
          "examples/05_security_camera_example/README.md",
          "examples/06_prometheus_metrics_example/README.md",
          "examples/07_deploy_example/README.md",
          "examples/08_agent_server_example/README.md",
          "plugins/README.md"
        ],
        "fileTypes": {
          ".md": 39,
          ".yaml": 7,
          ".mdc": 1,
          ".example": 4,
          ".yml": 12,
          ".toml": 8,
          ".py": 102,
          ".gif": 5,
          ".png": 5,
          ".lock": 7,
          ".ini": 1,
          ".json": 1,
          ".sh": 1,
          ".gpu": 1,
          ".tpl": 1
        }
      }
    },
    {
      "id": 1145936432,
      "name": "openskills",
      "displayName": "openskills",
      "description": "Universal skills loader for AI coding agents - npm i -g openskills",
      "summary": "OpenSkills: The Universal Skills Loader for AI Agents\n\nThe Problem\n\nIf you’ve ever tried to get different AI coding agents to play nice with each other, you know the pain. Each one has its own way of managing skills, leaving you with a mess of incompatible formats and a headache. Enter OpenSkills, which aims to be the universal translator for skill sets across various AI platforms.\n\nWhat This Does\n\nOpenSkills is a CLI tool that standardizes the installation and management of skills for multiple AI agents like Claude Code, Cursor, and Codex. You can install skills from the Anthropic marketplace or any GitHub repo. The project structure includes the essential files like .github/ISSUETEMPLATE/, which is a good start if you want to track bugs or feature requests.\n\nTo get going, just run:\n\nnpx openskills install anthropics/skills\nnpx openskills sync\n\nThis puts the skills where they need to be—either in the local project under ./.claude/skills or globally if you choose the --global flag. The AGENTS.md file generated by OpenSkills mirrors the required <availableskills> XML format, making it easy for any agent to fetch the necessary skills without needing to be Claude Code itself.\n\nReal-World Use\n\nImagine you’re working on a project that needs PDF manipulation. Instead of wrestling with different formats, simply install the skills you need using OpenSkills:\n\nnpx openskills install your-org/pdf-skills\n\nNow, you can invoke it directly:\n\nnpx openskills read pdf\n\nThis keeps your context clean and ensures you’re only loading the skills you actually need when you need them.\n\nThe Bottom Line\n\nOpenSkills simplifies the management of AI skills across platforms, making it a solid tool for developers working with multiple agents. The setup is straightforward, and the ability to load skills on-demand is a nice touch. However, if you’re only using one agent, this might be overkill. For multi-agent setups, it’s a lifesaver. Just be aware that it’s still in early stages—hence the lack of stars. If you’re keen on future-proofing your AI projects, give it a shot.",
      "url": "https://github.com/yebeai/openskills",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "numman-ali/openskills",
        "url": "https://github.com/numman-ali/openskills",
        "stars": 8589
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 30, 2026",
      "updatedAt": "January 30, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 94,
        "directories": {
          ".github": 52,
          "(root)": 14,
          "assets": 1,
          "examples": 2,
          "src": 16,
          "tests": 9
        },
        "languages": {
          "Markdown": 53,
          "YAML": 2,
          "JSON": 8,
          "TypeScript": 27
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "src/cli.ts"
        ],
        "configFiles": [
          "package.json",
          "tsconfig.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [
          "tests/commands/install.test.ts",
          "tests/commands/sync.test.ts",
          "tests/commands/update.test.ts",
          "tests/integration/e2e.test.ts",
          "tests/utils/dirs.test.ts",
          "tests/utils/skill-metadata.test.ts",
          "tests/utils/skill-names.test.ts",
          "tests/utils/skills.test.ts",
          "tests/utils/yaml.test.ts",
          "vitest.config.ts"
        ],
        "docs": [
          "CHANGELOG.md",
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".md": 53,
          ".yml": 2,
          ".json": 8,
          ".svg": 1,
          ".ts": 27
        }
      }
    },
    {
      "id": 1145804711,
      "name": "ColossalAI",
      "displayName": "ColossalAI",
      "description": "Making large AI models cheaper, faster and more accessible",
      "summary": "The Problem\nTraining large AI models is a resource-hungry endeavor. If you're not sporting a bank of NVIDIA H200s or equivalent, you might as well be trying to race a Ferrari with a tricycle. The costs associated with infrastructure and computational power can be prohibitive, leaving smaller teams out in the cold. ColossalAI steps in to change that.\n\nWhat This Does\nColossalAI is designed to make the training of large models not just possible but also affordable. It emphasizes parallelism and efficient resource utilization to maximize performance while minimizing costs. Check out the README.md for a quick overview of how to get started, and don’t miss the examples folder for practical implementations.\n\nThe repository is built with a clear file structure. For example, the .github/workflows directory contains various CI/CD configurations to ensure that your builds are tested across multiple scenarios. This means you can develop with confidence, knowing that your changes won't break anything important.\n\nReal-World Use\nImagine you’re gearing up to train a Llama-like model. You can kick off the training process with a simple script using commands from the examples directory. For instance, if you want to run a benchmark with a 7B model on an 8-card setup, you just have to tweak your config.yaml file to specify the zero2(dp8) parallelism strategy. \n\nHere's a basic code snippet to give you a head start:\n\npython train.py --model-size 7B --gpus 8 --parallelism zero2(dp8) --batch-size 36\n\nWith that, you’re off to the races, efficiently utilizing the underlying hardware without breaking the bank.\n\nThe Bottom Line\nColossalAI provides a pragmatic approach to training large AI models by optimizing resource use. It’s a solid choice for teams that need to scale up without scaling out their budgets. However, if you’re just dabbling in AI or working on small projects, this might be overkill. Stick to lighter frameworks unless you plan on diving deep into the world of large-scale model training.",
      "url": "https://github.com/yebeai/ColossalAI",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "hpcaitech/ColossalAI",
        "url": "https://github.com/hpcaitech/ColossalAI",
        "stars": 41363
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 30, 2026",
      "updatedAt": "January 30, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 13,
          ".github": 42,
          "applications": 145
        },
        "languages": {
          "JSON": 16,
          "YAML": 32,
          "Markdown": 14,
          "Python": 112,
          "Shell": 9
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "applications/Colossal-LLaMA/setup.py"
        ],
        "configFiles": [
          "applications/Colossal-LLaMA/requirements.txt",
          "applications/Colossal-LLaMA/setup.py",
          "applications/ColossalChat/coati/distributed/zero_bubble/requirements.txt"
        ],
        "dependencies": [
          "applications/Colossal-LLaMA/requirements.txt",
          "applications/ColossalChat/coati/distributed/zero_bubble/requirements.txt"
        ],
        "testFiles": [
          ".github/workflows/compatiblity_test_on_dispatch.yml",
          ".github/workflows/compatiblity_test_on_pr.yml",
          ".github/workflows/compatiblity_test_on_schedule.yml",
          ".github/workflows/doc_test_on_pr.yml",
          ".github/workflows/doc_test_on_schedule.yml",
          ".github/workflows/release_test_pypi_before_merge.yml",
          ".github/workflows/report_test_coverage.yml",
          ".github/workflows/run_chatgpt_unit_tests.yml",
          ".github/workflows/run_colossalqa_unit_tests.yml",
          "applications/ColossalChat/benchmarks/prepare_dummy_test_dataset.py",
          "applications/ColossalChat/coati/distributed/reward/code_reward/testing_util.py"
        ],
        "docs": [
          ".github/workflows/README.md",
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "applications/Colossal-LLaMA/README.md",
          "applications/Colossal-LLaMA/docs/example_13b.md",
          "applications/Colossal-LLaMA/docs/example_7b.md",
          "applications/ColossalChat/LICENSE",
          "applications/ColossalChat/README.md",
          "applications/ColossalChat/benchmarks/README.md",
          "applications/ColossalChat/coati/distributed/README.md",
          "applications/ColossalChat/coati/distributed/zero_bubble/README.md",
          "applications/ColossalChat/coati/ray/README.md",
          "applications/ColossalChat/examples/README.md"
        ],
        "fileTypes": {
          ".json": 16,
          ".yml": 31,
          ".md": 14,
          ".py": 112,
          ".cfg": 1,
          ".yaml": 1,
          ".in": 1,
          ".example": 1,
          ".txt": 5,
          ".sh": 9
        }
      }
    },
    {
      "id": 1145798797,
      "name": "Paper2Code",
      "displayName": "Paper2Code",
      "description": "Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning",
      "summary": "The Problem\nEver tried translating a complex scientific paper into code? It’s like deciphering hieroglyphics while blindfolded. Researchers publish great ideas, but turning those into functional code often feels like a Herculean task. You spend hours reading, understanding, and then implementing algorithms that are buried beneath dense text and equations. Enter Paper2Code, which aims to automate this headache.\n\nWhat This Does\nPaper2Code is designed to convert scientific papers into usable code repositories using a three-stage pipeline: planning, analysis, and code generation. The magic happens in the codes directory, where scripts like 1planning.py and 3coding.py work to break down the paper's content and churn out actual code. Need to extract configurations? Check out 1.1extractconfig.py. Each script is tailored for a specific part of the process, giving you a modular approach to tackle the task.\n\nThe output is organized into the outputs folder, where you'll find subdirectories for analyzingartifacts, codingartifacts, and planningartifacts, making it easy to track what was generated. If you’re looking to run it, you’ll find the scripts/run.sh handy for executing the whole pipeline, whether you’re using OpenAI's API or open-source models like deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct.\n\nReal-World Use\nImagine you have a PDF of a groundbreaking paper, say “Attention Is All You Need”. You can convert it to a structured JSON format using s2orc-doc2json, then feed that into Paper2Code. Just set your OPENAIAPI_KEY, run the provided bash scripts, and voilà—you’ll have a structured code repository generated from the paper’s content, ready for you to refine and use in your projects.\n\nThe Bottom Line\nPaper2Code is a solid tool for researchers and developers who want to skip the grunt work of translating papers into code. It’s not perfect—there’s a learning curve, and if your paper is too niche, results may vary. But for common algorithms and methodologies, it’s a time-saver. If you frequently deal with ML papers, this is worth a look; just don’t expect it to handle every edge case without some manual tweaking.",
      "url": "https://github.com/yebeai/Paper2Code",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "going-doer/Paper2Code",
        "url": "https://github.com/going-doer/Paper2Code",
        "stars": 4186
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1531482615713-2afd69097998?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 30, 2026",
      "updatedAt": "January 30, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 30,
        "directories": {
          "(root)": 3,
          "assets": 1,
          "codes": 13,
          "data": 5,
          "examples": 4,
          "scripts": 4
        },
        "languages": {
          "Markdown": 2,
          "Python": 13,
          "JSON": 3,
          "Shell": 4
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [
          "requirements.txt"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md",
          "data/paper2code/README.md"
        ],
        "fileTypes": {
          ".md": 2,
          ".png": 1,
          ".py": 13,
          ".json": 3,
          ".zip": 1,
          ".txt": 3,
          ".pdf": 1,
          ".tex": 1,
          ".sh": 4
        }
      }
    },
    {
      "id": 1134338060,
      "name": "AI-research-SKILLs",
      "displayName": "AI research SKILLs",
      "description": "Comprehensive open-source library of AI research and engineering skills for any AI model. Package the skills and your claude code/codex/gemini agent will be an AI research agent with full horsepower. Maintained by Orchestra Research.",
      "summary": "AI research is accelerating rapidly, but the complexity of engineering workflows remains a major bottleneck. Even seasoned practitioners find themselves mired in the minutiae of configuring distributed training, wrangling tokenizers, or debugging obscure infrastructure issues—when their real goal is scientific discovery. For anyone building advanced AI agents or research automation tools, the challenge isn’t just access to models, but the ability to orchestrate the full research stack, reliably and repeatably. This is precisely the gap AI-research-SKILLs aims to fill.\n\nAI-research-SKILLs is an open-source library designed to encapsulate expert-level research engineering skills for any AI model. Unlike generic tutorials or fragmented repo guides, this project is a curated set of production-grade \"skills\"—self-contained modules that encode the best practices, troubleshooting guides, and reference patterns for real-world AI workflows. What sets it apart is both scope and depth: skills span everything from model architecture and tokenization to multimodal pipelines, MLOps, and mechanistic interpretability. Each skill is tightly scoped to a framework or task (e.g., LitGPT, Mamba, HuggingFace tokenizers) and is backed by real code snippets, documentation links, and workflow recipes. This transforms a coding agent—or any LLM-based tool—into a research agent with comprehensive engineering horsepower.\n\nTechnically, the architecture is modular and extensible. The file structure reflects a highly organized taxonomy: skills are grouped into numbered directories by domain, such as 01-model-architecture and 02-tokenization. Within each, you’ll find folders for frameworks (e.g., litgpt, mamba, nanogpt, rwkv), each containing a core SKILL.md—the canonical guide for that framework. Reference subfolders like references/custom-models.md or references/training-guide.md provide deep dives into implementation details, benchmarks, and advanced recipes. The presence of a .github/workflows/sync-skills.yml hints at automated CI/CD for skill updates, while .claude-plugin/marketplace.json likely powers marketplace integration for skill discovery and installation. The README’s marketplace install syntax (/plugin install skill-name@ai-research-skills) demonstrates a plug-and-play philosophy, enabling agents or developers to selectively augment capabilities via CLI. The structure is opinionated: each skill is atomic, well-documented, and production-focused, with explicit separation between high-level overview (SKILL.md) and technical deep dives (references).\n\nFor developers and teams building AI automation, there are immediate use cases. First, research agents powered by LLMs—such as Claude, Codex, or Gemini—can be upgraded with domain-specific skills, allowing them to autonomously run experiments, fine-tune models, or troubleshoot distributed training. Second, platform engineers can leverage these skills to bootstrap reproducible pipelines for data processing, model deployment, or evaluation, sidestepping the usual knowledge gaps when integrating new frameworks. Third, educators or technical writers can use the repository as a source of canonical, up-to-date engineering patterns—each skill is essentially a living expert guide, capable of being programmatically queried or embedded into documentation.\n\nThe underlying insight is that research engineering needs abstraction as much as raw compute or models. By distilling best practices, bug fixes, and production wisdom into atomic \"skills,\" AI-research-SKILLs bridges the gap between theoretical capability and practical implementation. For anyone serious about building autonomous AI research systems, this library is not just a convenience—it’s an infrastructure layer. It enables agents and developers alike to move from tinkering to executing robust, reproducible experiments. In a field where wasted engineering cycles are the norm, this approach is both pragmatic and transformative.",
      "url": "https://github.com/yebeai/AI-research-SKILLs",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Orchestra-Research/AI-Research-SKILLs",
        "url": "https://github.com/Orchestra-Research/AI-Research-SKILLs",
        "stars": 4082
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1607799279861-4dd421887fb3?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 14, 2026",
      "updatedAt": "January 29, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".claude-plugin": 1,
          ".github": 1,
          "(root)": 1,
          "01-model-architecture": 18,
          "02-tokenization": 9,
          "03-fine-tuning": 19,
          "04-mechanistic-interpretability": 16,
          "05-data-processing": 7,
          "06-post-training": 18,
          "07-safety-alignment": 4,
          "08-distributed-training": 28,
          "09-infrastructure": 10,
          "10-optimization": 21,
          "11-evaluation": 10,
          "12-inference-serving": 18,
          "13-mlops": 13,
          "14-agents": 6
        },
        "languages": {
          "JSON": 1,
          "YAML": 1,
          "Markdown": 185,
          "Python": 2
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "01-model-architecture/mamba/references/training-guide.md",
          "04-mechanistic-interpretability/nnsight/references/README.md",
          "04-mechanistic-interpretability/pyvene/references/README.md",
          "04-mechanistic-interpretability/saelens/references/README.md",
          "04-mechanistic-interpretability/transformer-lens/references/README.md",
          "06-post-training/grpo-rl-training/README.md",
          "08-distributed-training/megatron-core/references/parallelism-guide.md",
          "11-evaluation/lm-evaluation-harness/references/benchmark-guide.md"
        ],
        "fileTypes": {
          ".json": 1,
          ".yml": 1,
          ".md": 185,
          ".py": 2
        }
      }
    },
    {
      "id": 1145412760,
      "name": "BitNet",
      "displayName": "BitNet",
      "description": "Official inference framework for 1-bit LLMs",
      "summary": "Large Language Models (LLMs) have revolutionized the way we interact with technology, offering capabilities like natural language understanding, code generation, and contextual conversation. However, their immense computational requirements often make them impractical for deployment on local devices or edge hardware. This challenge is particularly pressing for developers and organizations aiming to leverage LLMs in resource-constrained environments without sacrificing performance or accuracy. Enter BitNet, an innovative inference framework designed specifically for the next era of 1-bit LLMs. By drastically reducing model precision while maintaining lossless performance, BitNet addresses some of the most significant bottlenecks in deploying LLMs at scale, enabling faster, more efficient, and cost-effective inference.\n\nBitNet, forked from Microsoft’s popular repository of the same name, is built to serve as the official inference framework for 1-bit LLMs, such as the groundbreaking BitNet b1.58 models. What sets this framework apart is its ability to enable high-speed, low-energy inference with minimal loss in model performance. By leveraging optimized 1.58-bit quantization and custom-built GPU and CPU kernels, BitNet achieves impressive speedups—up to 6.17x on x86 CPUs—while slashing energy consumption by over 80% in some cases. These optimizations allow even large-scale models, such as a 100B parameter LLM, to perform in near real-time on modest consumer hardware. This technological leap is crucial for expanding LLM accessibility beyond high-performance data centers, making it plausible to run advanced AI models on local devices like laptops, smartphones, or edge servers.\n\nFrom a technical perspective, BitNet’s architecture is meticulous and modular, as evident from its well-structured repository. The gpu/bitnetkernels directory is at the heart of its performance breakthroughs, housing CUDA-based implementations (bitnetkernels.cu) and supporting header files (bitnetkernels.h). These files are complemented by a Python-based build system (setup.py) that simplifies kernel compilation and deployment. Beyond the GPU optimizations, the repository includes utilities such as convertcheckpoint.py and convertsafetensors.py for seamless model format conversions, as well as packweight.py for efficient weight storage. The inclusion of stats.py and test.py reflects a strong emphasis on benchmarking and validation, ensuring that performance gains are both measurable and reproducible. Meanwhile, the include directory provides additional low-level optimizations, with key files like gemm-config.h and ggml-bitnet.h defining core matrix multiplication configurations tailored for 1-bit inference.\n\nBitNet’s use cases are as compelling as its technical underpinnings. First, developers aiming to deploy LLMs on edge devices will find BitNet indispensable. Imagine a scenario where an enterprise needs to run a customer service chatbot on an IoT device in a retail store. With BitNet’s efficient quantization and low power consumption, this chatbot could process queries locally, avoiding latency issues associated with cloud-based inference. Second, researchers and engineers working on large-scale model experimentation can leverage BitNet to prototype ideas on consumer-grade hardware before scaling to clusters. For instance, training or fine-tuning a 2B parameter model using BitNet’s GPU kernels could drastically reduce the time and cost of experimentation. Finally, BitNet opens up opportunities for developers focused on privacy-centric applications. By enabling local inference of 1-bit LLMs, sensitive data never has to leave the device, addressing privacy concerns often associated with cloud-hosted AI services.\n\nThe implications of BitNet’s innovations are profound. By proving that high-performance, low-bit inference is not just possible but practical, BitNet is lowering the barriers to entry for LLM adoption. This is particularly critical as AI continues to permeate industries where hardware resources are limited, such as healthcare, manufacturing, and education. Moreover, its open-source nature ensures that developers can both contribute to and benefit from ongoing advancements, fostering a collaborative ecosystem that accelerates innovation. In a world where the demand for energy-efficient AI is only growing, BitNet demonstrates how clever engineering and open collaboration can reshape the boundaries of what’s possible for large language models.",
      "url": "https://github.com/yebeai/BitNet",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "microsoft/BitNet",
        "url": "https://github.com/microsoft/BitNet",
        "stars": 28631
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 29, 2026",
      "updatedAt": "January 29, 2026",
      "readTime": 4,
      "knowledgeGraph": {
        "totalFiles": 71,
        "directories": {
          "(root)": 11,
          "assets": 4,
          "docs": 1,
          "gpu": 16,
          "include": 2,
          "media": 2,
          "preset_kernels": 12,
          "src": 9,
          "utils": 14
        },
        "languages": {
          "Markdown": 6,
          "C/C++ Header": 9,
          "Shell": 3,
          "Python": 25,
          "C++": 2
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "gpu/bitnet_kernels/setup.py"
        ],
        "configFiles": [
          "CMakeLists.txt",
          "gpu/bitnet_kernels/setup.py",
          "gpu/requirements.txt",
          "requirements.txt",
          "src/CMakeLists.txt"
        ],
        "dependencies": [
          "gpu/requirements.txt",
          "requirements.txt"
        ],
        "testFiles": [
          "gpu/test.py",
          "utils/test_gemm_kernel.sh",
          "utils/test_perplexity.py",
          "utils/test_power.sh"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "docs/codegen.md",
          "gpu/README.md",
          "src/README.md"
        ],
        "fileTypes": {
          ".txt": 4,
          ".md": 6,
          ".png": 10,
          ".cu": 1,
          ".h": 9,
          ".sh": 3,
          ".py": 25,
          ".model": 1,
          ".mp4": 1,
          ".ini": 6,
          ".cpp": 2
        }
      }
    },
    {
      "id": 1144613221,
      "name": "droidrun",
      "displayName": "droidrun",
      "description": "Automate your mobile devices with natural language commands - an LLM agnostic mobile Agent 🤖",
      "summary": "The rapid evolution of mobile technology has transformed our daily lives, but with it comes the challenge of managing multiple devices, applications, and services. For developers and users alike, the ability to automate mobile interactions in a seamless and intuitive manner is crucial. Imagine being able to issue natural language commands to control your device, schedule tasks, or even execute complex multi-step workflows without diving deep into the underlying code. This is where DroidRun steps in—a framework that leverages the power of large language models (LLMs) to bring natural language processing to mobile device automation.\n\nDroidRun is not just another automation tool; it represents a paradigm shift in how we interact with our mobile devices. Unlike traditional automation frameworks that often require extensive coding knowledge, DroidRun allows users to control both Android and iOS devices using natural language commands. This unique capability is supported by its agnostic design, which accommodates various LLM providers, including OpenAI, Anthropic, and others. The framework is built for developers seeking to empower users with intelligent mobile control, enabling applications to perform intricate tasks with minimal input. The inclusion of features like planning capabilities for multi-step tasks and an extendable Python API sets it apart in the crowded landscape of automation tools.\n\nA closer look at the architecture of DroidRun reveals a well-structured and organized codebase designed for extensibility and maintainability. The presence of a Dockerfile indicates that the project is containerized, allowing developers to easily deploy the application across different environments. The .github/workflows directory contains several YAML files for continuous integration and deployment, showcasing a commitment to modern software development practices. Notably, the documentation files in the docs folder—such as architecture.mdx and features—provide in-depth insights into how to implement and leverage the framework effectively. This attention to documentation is crucial for onboarding new users and contributors, ensuring that the community can grow and thrive.\n\nDroidRun's capabilities lend themselves to a variety of practical use cases. For instance, a developer could create a personal assistant application that allows users to book accommodations or manage their social media presence through simple voice commands. By integrating the provided CLI and the Python API, developers can build custom automations tailored to specific needs, such as automatically saving streaks on language learning applications. Additionally, its ability to analyze screenshots for visual context means that developers can create features that rely on visual feedback, further enhancing user experience.\n\nThe implications of DroidRun extend beyond mere convenience; they signal a shift towards more intuitive human-computer interactions. As we increasingly rely on mobile devices for everyday tasks, the need for automation frameworks that understand and interpret human language becomes vital. By democratizing the ability to automate tasks through natural language, DroidRun opens the door for developers to create applications that are not only powerful but also user-friendly. In a world where time and efficiency are paramount, tools like DroidRun are not just nice to have—they are essential for driving innovation in mobile technology.",
      "url": "https://github.com/yebeai/droidrun",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "droidrun/droidrun",
        "url": "https://github.com/droidrun/droidrun",
        "stars": 7782
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 28, 2026",
      "updatedAt": "January 28, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 193,
        "directories": {
          "(root)": 13,
          ".github": 6,
          "docs": 55,
          "droidrun": 117,
          "static": 2
        },
        "languages": {
          "YAML": 8,
          "Markdown": 5,
          "CSS": 1,
          "JSON": 2,
          "Python": 104,
          "Shell": 1,
          "TOML": 1
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "droidrun/__main__.py",
          "droidrun/cli/main.py",
          "droidrun/macro/__main__.py",
          "droidrun/macro/cli.py",
          "setup.py"
        ],
        "configFiles": [
          "Dockerfile",
          "pyproject.toml",
          "setup.py"
        ],
        "dependencies": [
          "pyproject.toml"
        ],
        "testFiles": [],
        "docs": [
          "CHANGELOG.md",
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "docs/concepts/architecture.mdx",
          "docs/concepts/events-and-workflows.mdx",
          "docs/concepts/prompts.mdx",
          "docs/concepts/scripter-agent.mdx",
          "docs/concepts/shared-state.mdx",
          "docs/custom.css",
          "docs/docs.json",
          "docs/favicon.png",
          "docs/features/app-cards.mdx",
          "docs/features/credentials.mdx",
          "docs/features/custom-tools.mdx",
          "docs/features/custom-variables.mdx",
          "docs/features/structured-output.mdx",
          "docs/features/telemetry.mdx",
          "docs/features/tracing.mdx",
          "docs/guides/cli.mdx",
          "docs/guides/device-setup.mdx",
          "docs/guides/docker.mdx",
          "docs/guides/migration-v3-to-v4.mdx",
          "docs/guides/overview.mdx",
          "docs/logo/dark.svg",
          "docs/logo/light.svg",
          "docs/overview.mdx",
          "docs/quickstart.mdx",
          "docs/sdk/adb-tools.mdx",
          "docs/sdk/base-tools.mdx",
          "docs/sdk/configuration.mdx",
          "docs/sdk/droid-agent.mdx",
          "docs/sdk/ios-tools.mdx",
          "docs/sdk/reference.mdx",
          "docs/v1/concepts/agent.mdx",
          "docs/v1/concepts/android-control.mdx",
          "docs/v1/concepts/portal-app.mdx",
          "docs/v1/overview.mdx",
          "docs/v1/quickstart.mdx",
          "docs/v2/concepts/agent.mdx",
          "docs/v2/concepts/android-control.mdx",
          "docs/v2/concepts/planning.mdx",
          "docs/v2/concepts/portal-app.mdx",
          "docs/v2/concepts/tracing.mdx",
          "docs/v2/overview.mdx",
          "docs/v2/quickstart.mdx",
          "docs/v3/concepts/agent.mdx",
          "docs/v3/concepts/android-tools.mdx",
          "docs/v3/concepts/models.mdx",
          "docs/v3/concepts/portal-app.mdx",
          "docs/v3/guides/cli.mdx",
          "docs/v3/guides/gemini.mdx",
          "docs/v3/guides/ollama.mdx",
          "docs/v3/guides/openailike.mdx",
          "docs/v3/guides/overview.mdx",
          "docs/v3/guides/telemetry.mdx",
          "docs/v3/images/portal_apk.png",
          "docs/v3/overview.mdx",
          "docs/v3/quickstart.mdx",
          "droidrun/config/app_cards/README.md"
        ],
        "fileTypes": {
          ".yml": 6,
          ".md": 5,
          ".in": 1,
          ".mdx": 49,
          ".css": 1,
          ".json": 2,
          ".png": 4,
          ".svg": 2,
          ".py": 104,
          ".yaml": 2,
          ".jinja2": 9,
          ".sh": 1,
          ".toml": 1,
          ".lock": 1
        }
      }
    },
    {
      "id": 1144228304,
      "name": "whodb",
      "displayName": "whodb",
      "description": "A lightweight next-gen data explorer - Postgres, MySQL, SQLite, MongoDB, Redis, MariaDB, Elastic Search, and Clickhouse with Chat interface",
      "summary": "The Problem\nDatabase management tools are often bloated, slow, and a headache to use. Developers need solutions that don’t require watching paint dry while waiting for queries to run. WhoDB tackles this pain point head-on by offering a lightweight, fast alternative that fits right into your workflow without the usual bloat.\n\nWhat This Does\nWhoDB is a multi-database client that supports PostgreSQL, MySQL, SQLite, MongoDB, Redis, MariaDB, Elastic Search, and Clickhouse. You can find the core documentation in files like docs/commands.md, which details how to navigate the command line interface (CLI), and docs/plugin-architecture.md, which explains how to extend functionality. The app is built with Go and React, ensuring that it remains lightweight at under 50MB while still packing some serious punch.\n\nIts AI capabilities are a standout feature. With support for natural language processing, you can convert phrases into SQL queries, making it easier to interact with your databases. You can find more about this in docs/sql-security.md where the implications of using AI in querying are discussed.\n\nReal-World Use\nImagine you're debugging a production issue and need to query a MongoDB database. Instead of writing out complex queries, you type a natural language question like, “Show me all orders from last month.” WhoDB translates that into the appropriate SQL or MongoDB query under the hood. You can also manage your data visually, thanks to the spreadsheet-like interface, which is a huge time-saver for data-heavy tasks. \n\nFor example, you can run a command from the CLI, whodb query \"SELECT * FROM orders WHERE date > '2023-09-01'\", and instantly get your results without the hassle of a clunky UI getting in the way.\n\nThe Bottom Line\nWhoDB is a solid choice for developers looking for a fast and efficient database management tool. It’s particularly useful for those who need to manage multiple databases and want to avoid the bloated features of traditional tools. The AI capabilities are a nice touch, but they might be overkill for smaller projects. If you're tired of waiting forever for your queries to run, give WhoDB a shot—it might just save you some sanity.",
      "url": "https://github.com/yebeai/whodb",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "clidey/whodb",
        "url": "https://github.com/clidey/whodb",
        "stars": 4651
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1542831371-29b0f74f9713?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 28, 2026",
      "updatedAt": "January 28, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".claude": 11,
          "(root)": 13,
          ".github": 38,
          ".vscode": 1,
          "cli": 109,
          "core": 28
        },
        "languages": {
          "Markdown": 40,
          "YAML": 32,
          "Shell": 5,
          "JSON": 11,
          "Go": 89
        },
        "frameworks": [
          "React",
          "Docker"
        ],
        "packageManager": "pnpm",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "cli/cmd/arm_warning.go",
          "cli/cmd/cmd_test.go",
          "cli/cmd/columns.go",
          "cli/cmd/completion.go",
          "cli/cmd/connect.go",
          "cli/cmd/connections.go",
          "cli/cmd/export.go",
          "cli/cmd/history.go",
          "cli/cmd/mcp.go",
          "cli/cmd/mcp_test.go",
          "cli/cmd/programmatic_commands_test.go",
          "cli/cmd/query.go",
          "cli/cmd/root.go",
          "cli/cmd/schemas.go",
          "cli/cmd/tables.go",
          "cli/cmd/test_env_test.go",
          "cli/cmd/version.go",
          "cli/main.go",
          "cli/pkg/mcp/server.go"
        ],
        "configFiles": [
          "cli/Dockerfile",
          "cli/Makefile",
          "cli/go.mod",
          "cli/npm-package/packages/whodb-cli-darwin-arm64/package.json",
          "cli/npm-package/packages/whodb-cli-darwin-x64/package.json",
          "cli/npm-package/packages/whodb-cli-linux-arm/package.json",
          "cli/npm-package/packages/whodb-cli-linux-arm64/package.json",
          "cli/npm-package/packages/whodb-cli-linux-x64/package.json",
          "cli/npm-package/packages/whodb-cli-win32-arm64/package.json",
          "cli/npm-package/packages/whodb-cli-win32-x64/package.json",
          "cli/npm-package/packages/whodb-cli/package.json",
          "core/Dockerfile"
        ],
        "dependencies": [
          "cli/go.mod",
          "cli/npm-package/packages/whodb-cli-darwin-arm64/package.json",
          "cli/npm-package/packages/whodb-cli-darwin-x64/package.json",
          "cli/npm-package/packages/whodb-cli-linux-arm/package.json",
          "cli/npm-package/packages/whodb-cli-linux-arm64/package.json",
          "cli/npm-package/packages/whodb-cli-linux-x64/package.json",
          "cli/npm-package/packages/whodb-cli-win32-arm64/package.json",
          "cli/npm-package/packages/whodb-cli-win32-x64/package.json",
          "cli/npm-package/packages/whodb-cli/package.json"
        ],
        "testFiles": [
          "cli/cmd/cmd_test.go",
          "cli/cmd/mcp_test.go",
          "cli/cmd/programmatic_commands_test.go",
          "cli/cmd/test_env_test.go",
          "cli/e2e/e2e_test.go",
          "cli/internal/config/config_test.go",
          "cli/internal/database/integration_test.go",
          "cli/internal/database/manager_test.go",
          "cli/internal/database/test_env_test.go",
          "cli/internal/history/history_test.go",
          "cli/internal/tui/browser_view_test.go",
          "cli/internal/tui/chat_view_test.go",
          "cli/internal/tui/columns_view_test.go",
          "cli/internal/tui/connection_view_test.go",
          "cli/internal/tui/editor_view_test.go",
          "cli/internal/tui/export_view_test.go",
          "cli/internal/tui/history_view_test.go",
          "cli/internal/tui/model_test.go",
          "cli/internal/tui/results_view_test.go",
          "cli/internal/tui/schema_view_test.go",
          "cli/internal/tui/test_env_test.go",
          "cli/internal/tui/where_view_test.go",
          "cli/pkg/mcp/credentials_test.go",
          "cli/pkg/mcp/server_test.go",
          "cli/pkg/mcp/tools_test.go",
          "cli/pkg/mcp/validation_test.go",
          "cli/pkg/output/output_test.go",
          "cli/testutil/helpers.go"
        ],
        "docs": [
          ".claude/docs/aws-integration.md",
          ".claude/docs/ci-cd.md",
          ".claude/docs/cli.md",
          ".claude/docs/cloud-providers.md",
          ".claude/docs/commands.md",
          ".claude/docs/desktop.md",
          ".claude/docs/documentation.md",
          ".claude/docs/localization.md",
          ".claude/docs/plugin-architecture.md",
          ".claude/docs/sql-security.md",
          ".claude/docs/verification.md",
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "cli/README.md",
          "cli/external-plugin/whodb/README.md",
          "cli/npm-package/packages/whodb-cli/README.md"
        ],
        "fileTypes": {
          ".md": 40,
          ".yml": 24,
          ".png": 1,
          ".desktop": 1,
          ".sh": 5,
          ".template": 3,
          ".plist": 1,
          ".json": 11,
          ".go": 89,
          ".mod": 1,
          ".sum": 1,
          ".ps1": 1,
          ".yaml": 8,
          ".baml": 3
        }
      }
    },
    {
      "id": 1144189579,
      "name": "open-webui",
      "displayName": "open webui",
      "description": "User-friendly AI Interface (Supports Ollama, OpenAI API, ...)",
      "summary": "The Problem\nDeploying AI models can be a pain. Between managing dependencies, ensuring compatibility with different APIs, and dealing with user permissions, it’s a recipe for frustration. If you want a user-friendly interface that handles all of this while keeping things offline, you’re in luck. \n\nWhat This Does\nOpen WebUI is a self-hosted platform that simplifies AI deployment. It's built to support various LLM runners like Ollama and OpenAI-compatible APIs. The Dockerfile in the repo makes it straightforward to set up the environment, while the .env.example gives you a solid template for environment variables.\n\nThe real magic happens in the README.md where you’ll find installation instructions and key features. The project’s structure includes a Model Builder that allows users to create and add custom models through the Web UI. You can also see .github workflows for CI/CD that help automate your build and deployment processes. Want to customize or add features? The plugin system has your back.\n\nReal-World Use\nImagine you want to integrate an OpenAI model for a chatbot in your app. Set up your environment using the Dockerfile, then tweak the config.yaml to point to your OpenAI API endpoint. Once that's done, you can use the built-in voice call feature, allowing users to interact hands-free. Integrate multiple speech-to-text providers like OpenAI or Azure, and you’re ready for action. All while keeping user permissions in check through the granular roles set up in the permissions system.\n\nThe Bottom Line\nOpen WebUI is a solid choice for those who need an offline AI interface without the hassle. It’s feature-rich, from voice calls to persistent storage, making it more than just a pretty UI. However, if you’re working on a small project, this might feel like overkill. Ideal for teams looking to deploy AI at scale without reinventing the wheel.",
      "url": "https://github.com/yebeai/open-webui",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "open-webui/open-webui",
        "url": "https://github.com/open-webui/open-webui",
        "stars": 125151
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 28, 2026",
      "updatedAt": "January 28, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 19,
          ".github": 16,
          "backend": 165
        },
        "languages": {
          "YAML": 11,
          "Markdown": 5,
          "Shell": 1,
          "Python": 149,
          "JSON": 8
        },
        "frameworks": [
          "Django",
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "backend/open_webui/main.py",
          "backend/open_webui/retrieval/loaders/main.py",
          "backend/open_webui/retrieval/vector/main.py",
          "backend/open_webui/retrieval/web/main.py"
        ],
        "configFiles": [
          ".env.example",
          ".eslintrc.cjs",
          ".prettierrc",
          "Dockerfile",
          "Makefile"
        ],
        "dependencies": [],
        "testFiles": [
          ".github/workflows/integration-test.disabled",
          "backend/open_webui/retrieval/web/testdata/bing.json",
          "backend/open_webui/retrieval/web/testdata/brave.json",
          "backend/open_webui/retrieval/web/testdata/google_pse.json",
          "backend/open_webui/retrieval/web/testdata/searchapi.json",
          "backend/open_webui/retrieval/web/testdata/searxng.json",
          "backend/open_webui/retrieval/web/testdata/serper.json",
          "backend/open_webui/retrieval/web/testdata/serply.json",
          "backend/open_webui/retrieval/web/testdata/serpstack.json"
        ],
        "docs": [
          "CHANGELOG.md",
          "CONTRIBUTOR_LICENSE_AGREEMENT",
          "LICENSE",
          "LICENSE_HISTORY",
          "LICENSE_NOTICE",
          "README.md",
          "backend/data/readme.txt",
          "backend/open_webui/data/readme.txt",
          "backend/open_webui/migrations/README"
        ],
        "fileTypes": {
          ".example": 1,
          ".cjs": 1,
          ".yml": 6,
          ".yaml": 5,
          ".md": 5,
          ".disabled": 4,
          ".txt": 2,
          ".sh": 1,
          ".py": 149,
          ".ini": 1,
          ".mako": 1,
          ".json": 8
        }
      }
    },
    {
      "id": 1143911102,
      "name": "andrej-karpathy-skills",
      "displayName": "andrej karpathy skills",
      "description": "No description available",
      "summary": "The Problem\n\nEver worked with a language model that just can’t get its act together? Andrej Karpathy nails it when he points out that these models often make wild assumptions, run with them, and create a mess. They misinterpret requirements, overcomplicate everything, and can’t even clean up their own dead code. This repo tackles those pain points head-on.\n\nWhat This Does\n\nThis repository gives you CLAUDE.md, a set of guidelines to improve your coding practices when using AI. The guidelines are based on Karpathy’s insights, packed into four principles that aim to simplify and clarify your coding process.\n\nYou'll find the CLAUDE.md file that lays out the principles, and the .claude/skills/karpathy-guidelines.md file that expands on these principles in detail. Each principle targets specific issues: whether it’s slashing through overengineering, ensuring your code is as simple as possible, or making surgical changes only where necessary, this repo has you covered.\n\nReal-World Use\n\nImagine you’re about to write a function that processes user input. Instead of saying, \"Make it validate,\" you’d rewrite that to \"Write tests for invalid inputs, then make them pass.\" This is way more actionable and keeps you accountable. If you’re working in a team, sharing this CLAUDE.md ensures everyone is on the same page about how to approach coding tasks with clarity and purpose.\n\nHere's a quick snippet to illustrate the surgical changes principle:\n\nOriginal code\ndef processdata(data):\n    # This function does too much and needs simplification\n    pass\n\nYour change\ndef processdata(data):\n    # Clean and focused on processing\n    pass  # Only doing what was requested\n\nThe Bottom Line\n\nOverall, the andrej-karpathy-skills repo is a solid tool for anyone looking to refine their coding habits when working with AI. The guidelines are practical and, frankly, necessary for keeping code clean and efficient. It’s not rocket science, but if you want to avoid AI-induced chaos, this is worth a look. Just don't expect it to do the work for you; you still need to think critically.",
      "url": "https://github.com/yebeai/andrej-karpathy-skills",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "forrestchang/andrej-karpathy-skills",
        "url": "https://github.com/forrestchang/andrej-karpathy-skills",
        "stars": 6975
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 28, 2026",
      "updatedAt": "January 28, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 3,
        "directories": {
          ".claude": 1,
          "(root)": 2
        },
        "languages": {
          "Markdown": 3
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          ".claude/skills/karpathy-guidelines.md",
          "README.md"
        ],
        "fileTypes": {
          ".md": 3
        }
      }
    },
    {
      "id": 1143585924,
      "name": "pricewise",
      "displayName": "pricewise",
      "description": "Dive into web scraping and build a Next.js 13 eCommerce price tracker within a single video that teaches you data scraping, cron jobs, sending emails, deployment, and more.",
      "summary": "Price tracking for e-commerce is an evergreen challenge: consumers want to know when a product’s price drops, businesses need competitive intelligence, and developers often face the daunting task of building reliable scrapers, real-time monitors, and notification systems from scratch. Most open-source solutions either focus on scraping or offer simplistic notification logic, leaving much to be desired in terms of scalability, maintainability, and developer experience. The pricewise repository, forked from adrianhajdin/pricewise, offers a modern, full-stack solution that tackles these challenges head-on, combining robust scraping, automation, and user engagement in a Next.js 13 application.\n\nAt its core, pricewise is not just another price tracker. Its uniqueness lies in integrating data scraping, cron job automation, and email notifications in a cohesive architecture, all while leveraging the latest Next.js features. One standout aspect is its embrace of Bright Data’s webunlocker, a commercial-grade scraping proxy, which sidesteps the headaches of anti-bot detection and captchas. Users can track Amazon products by submitting URLs, and the system keeps tabs on price changes and stock status, sending timely email alerts. This isn’t merely about scraping and sending emails; the project demonstrates how to design a production-grade, user-facing app with real-time data, modular UI components, and seamless deployment practices.\n\nTechnically, the file structure reveals an intentional separation of concerns and scalable patterns. The app directory follows Next.js 13’s App Router conventions, with API routes like app/api/cron/route.ts handling backend automation. Scraping logic is encapsulated in lib/scraper/index.ts, supported by Cheerio for DOM parsing. Database models reside in lib/models/product.model.ts, with lib/mongoose.ts abstracting MongoDB connectivity—a clean approach to data persistence. Email notifications are managed in lib/nodemailer/index.ts, ensuring communication is decoupled from business logic. UI elements such as components/HeroCarousel.tsx, ProductCard.tsx, and Modal.tsx illustrate reusable, accessible design, while Tailwind CSS in app/globals.css provides rapid styling without sacrificing maintainability. The presence of next.config.js and postcss.config.js signals attention to build optimization and CSS tooling. Overall, this architecture promotes modularity, testability, and easy onboarding for developers.\n\nThere are several valuable scenarios for developers. First, anyone building a SaaS product with price monitoring—say, for travel, retail, or inventory management—can fork pricewise as a rapid foundation. Second, teams seeking to automate data collection and notification workflows (not just for e-commerce) will find the cron job patterns in app/api/cron/route.ts and the decoupled notification logic in lib/nodemailer/index.ts instructive. Lastly, developers keen to learn scalable scraping without running afoul of anti-bot defenses can study the integration of Bright Data and Cheerio in lib/scraper/index.ts; this approach is applicable to any web data extraction task where resilience and accuracy matter.\n\nThe real insight here is that modern price tracking isn’t just about scraping and displaying numbers—it’s about architecting a system that works reliably at scale, is easy to extend, and delivers meaningful user engagement. Pricewise showcases how to combine Next.js, powerful third-party scraping, automation via cron, and modular notification systems into a developer-friendly package. It's a template for anyone seeking to blend real-time data, automation, and user experience in their own projects. The patterns and abstractions here are worth studying, even if your domain isn’t e-commerce: this is how you build robust, maintainable, and impactful web automation tools in 2024.",
      "url": "https://github.com/yebeai/pricewise",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "adrianhajdin/pricewise",
        "url": "https://github.com/adrianhajdin/pricewise",
        "stars": 638
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 27, 2026",
      "updatedAt": "January 27, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 58,
        "directories": {
          "(root)": 8,
          "app": 6,
          "components": 6,
          "lib": 6,
          "public": 31,
          "types": 1
        },
        "languages": {
          "Markdown": 1,
          "TypeScript": 9,
          "CSS": 1,
          "TSX": 9,
          "JavaScript": 2,
          "JSON": 3
        },
        "frameworks": [
          "React",
          "Next.js",
          "Tailwind"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "lib/actions/index.ts",
          "lib/nodemailer/index.ts",
          "lib/scraper/index.ts",
          "types/index.ts"
        ],
        "configFiles": [
          "next.config.js",
          "package.json",
          "tailwind.config.ts",
          "tsconfig.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".md": 1,
          ".ts": 9,
          ".ico": 1,
          ".css": 1,
          ".tsx": 9,
          ".js": 2,
          ".json": 3,
          ".svg": 31
        }
      }
    },
    {
      "id": 1143543271,
      "name": "mapcn",
      "displayName": "mapcn",
      "description": "Beautiful map components. 100% Free, Zero config, one command setup.",
      "summary": "Building modern, interactive maps for web applications often comes with a steep learning curve. Developers face challenges like configuring map libraries, managing basemaps, setting up controls, and ensuring compatibility with UI frameworks. These complexities can slow development and introduce unnecessary overhead. This is where mapcn comes in—a free and open-source project designed to simplify the entire process. With its zero-configuration setup and rich feature set, mapcn offers developers a streamlined way to integrate beautiful, functional maps into their applications.\n\nAt its core, mapcn is a collection of pre-built map components built on top of MapLibre GL, styled with Tailwind CSS, and designed to integrate seamlessly with the component patterns provided by shadcn/ui. What sets mapcn apart is its dedication to developer experience: a single-command setup eliminates configuration hassles, and its components are fully composable, allowing developers to build complex map-based UIs with minimal effort. Features like theme-aware rendering, built-in controls (zoom, compass, fullscreen), and support for routes, markers, and popups add to its appeal. Moreover, the project’s open-source nature and MIT license ensure flexibility for both personal and commercial use.\n\nA glance at the file structure reveals the architectural choices behind mapcn. The project uses Next.js, as evidenced by the next.config.ts file and the routing patterns in src/app. The component-based architecture is modular and well-scoped. For example, the directory src/app/(home)/_components/examples contains specialized components like analytics-example.tsx and trail-example.tsx, demonstrating how developers can quickly assemble specific map functionalities. This modularity extends to the documentation components found in src/app/docs, such as code-block.tsx and component-preview.tsx, which likely power an interactive documentation site. Additionally, the presence of public/maps/registry.json hints at a centralized registry for managing map configurations, making it easier to handle multiple basemap providers or custom map styles. The use of modern tooling, such as PostCSS (postcss.config.mjs) and ESLint (eslint.config.mjs), ensures adherence to best practices, while the inclusion of funding metadata (.github/FUNDING.yml) suggests an eye toward sustainability.\n\nThe practical use cases for mapcn are compelling. First, a logistics company could leverage the routing features to visualize delivery paths on a custom basemap, with minimal effort thanks to the delivery-example.tsx component. Second, urban mobility apps focused on electric vehicle charging stations could use the ev-charging-example.tsx component to display charging points, complete with markers and popups for detailed information. Third, startups building data dashboards could integrate interactive analytics visualizations using the analytics-example.tsx component, creating a polished, interactive user experience without having to build from scratch. These scenarios highlight how mapcn lowers the barrier to entry for map-based applications, enabling developers to focus on their core business logic rather than wrestling with mapping infrastructure.\n\nThis project is significant not just for what it offers today, but for the broader implications it carries. By abstracting away the complexities of map integration, mapcn democratizes access to professional-grade mapping tools. Its thoughtful design choices—like compatibility with shadcn/ui and Tailwind CSS—reflect modern development trends, making it an excellent fit for teams already invested in these ecosystems. Moreover, its reliance on MapLibre GL and open-source licensing aligns with the growing demand for greater transparency and community-driven innovation in software development. For developers looking to integrate maps into their applications, mapcn is not just a tool—it’s a window into the future of modular, easy-to-use, and open web development.",
      "url": "https://github.com/yebeai/mapcn",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "AnmolSaini16/mapcn",
        "url": "https://github.com/AnmolSaini16/mapcn",
        "stars": 6085
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 27, 2026",
      "updatedAt": "January 27, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 85,
        "directories": {
          ".cursor": 1,
          ".github": 1,
          "(root)": 11,
          "public": 4,
          "src": 68
        },
        "languages": {
          "YAML": 1,
          "Markdown": 1,
          "JSON": 7,
          "TypeScript": 6,
          "TSX": 62,
          "CSS": 1
        },
        "frameworks": [
          "React",
          "Next.js"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "src/app/(home)/_components/examples/index.tsx"
        ],
        "configFiles": [
          "next.config.ts",
          "package.json",
          "tsconfig.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md",
          "src/app/docs/_components/code-block.tsx",
          "src/app/docs/_components/component-preview-client.tsx",
          "src/app/docs/_components/component-preview.tsx",
          "src/app/docs/_components/copy-button.tsx",
          "src/app/docs/_components/docs-sidebar.tsx",
          "src/app/docs/_components/docs-toc.tsx",
          "src/app/docs/_components/docs.tsx",
          "src/app/docs/_components/examples/advanced-usage-example.tsx",
          "src/app/docs/_components/examples/basic-map-example.tsx",
          "src/app/docs/_components/examples/cluster-example.tsx",
          "src/app/docs/_components/examples/custom-layer-example.tsx",
          "src/app/docs/_components/examples/draggable-marker-example.tsx",
          "src/app/docs/_components/examples/layer-markers-example.tsx",
          "src/app/docs/_components/examples/map-controls-example.tsx",
          "src/app/docs/_components/examples/markers-example.tsx",
          "src/app/docs/_components/examples/osrm-route-example.tsx",
          "src/app/docs/_components/examples/popup-example.tsx",
          "src/app/docs/_components/examples/route-example.tsx",
          "src/app/docs/_components/examples/standalone-popup-example.tsx",
          "src/app/docs/advanced-usage/page.tsx",
          "src/app/docs/api-reference/page.tsx",
          "src/app/docs/basic-map/page.tsx",
          "src/app/docs/clusters/page.tsx",
          "src/app/docs/controls/page.tsx",
          "src/app/docs/installation/page.tsx",
          "src/app/docs/layout.tsx",
          "src/app/docs/markers/page.tsx",
          "src/app/docs/page.tsx",
          "src/app/docs/popups/page.tsx",
          "src/app/docs/routes/page.tsx"
        ],
        "fileTypes": {
          ".mdc": 1,
          ".yml": 1,
          ".md": 1,
          ".json": 7,
          ".mjs": 2,
          ".ts": 6,
          ".png": 1,
          ".svg": 1,
          ".tsx": 62,
          ".css": 1
        }
      }
    },
    {
      "id": 1143529961,
      "name": "clearcam",
      "displayName": "clearcam",
      "description": "Add object detection, tracking, mobile notifications, and search to any security camera.",
      "summary": "The Problem\nSecurity cameras are great, but they’re often just passive observers. If you’ve got a regular camera, you’re stuck with endless video files and no real way to sift through what’s important. You want to know when something’s happening, not just record everything and pray you catch it later.\n\nWhat This Does\nEnter clearcam, a project that turns your RTSP-enabled camera or even an old iPhone into a smart security solution. The heart of the project is in the clearcam.py file, which handles object detection and tracking, sending you mobile notifications when something important happens. You can run it locally after installing dependencies listed in requirements.txt, like ffmpeg and tinygrad, which are essential for processing video feeds.\n\nThe Android app lives under android/clearcam/app, with MainActivity.kt serving as the entry point to the app. It’s where you can manage your camera feeds and settings. The code is straightforward enough for anyone familiar with Android development to dive in and tweak things. And if you need to build it from scratch, just clone the repo and follow the instructions in the README.md.\n\nReal-World Use\nImagine you’re away from home and you want to make sure your package isn’t stolen from your porch. With clearcam, you can run the server on your machine, enter your Clearcam premium user ID, and get notifications when someone approaches. Just set up your camera, fire up the local server with python3 clearcam.py, and browse to localhost:8080 to see the live feed. If a package thief shows up, you’ll get an alert on your phone. Easy peasy.\n\nThe Bottom Line\nThis is a solid project if you’re willing to tinker a bit. It’s not for everyone—if you want plug-and-play, look elsewhere. But if you have some coding chops and want a DIY security solution, clearcam does the job. Just remember, this is a work in progress, and with zero stars on GitHub, you might be diving into the deep end alone.",
      "url": "https://github.com/yebeai/clearcam",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "roryclear/clearcam",
        "url": "https://github.com/roryclear/clearcam",
        "stars": 659
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 27, 2026",
      "updatedAt": "January 27, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 186,
        "directories": {
          "(root)": 11,
          "android": 62,
          "detection": 1,
          "images": 12,
          "ios": 80,
          "ocsort_tracker": 8,
          "test": 9,
          "utils": 3
        },
        "languages": {
          "Markdown": 2,
          "Python": 15,
          "JSON": 4,
          "Kotlin": 9,
          "TOML": 1,
          "C/C++ Header": 18,
          "HTML": 4
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [
          "android/clearcam/app/build.gradle",
          "android/clearcam/build.gradle",
          "requirements.txt"
        ],
        "dependencies": [
          "android/clearcam/app/build.gradle",
          "android/clearcam/build.gradle",
          "requirements.txt"
        ],
        "testFiles": [
          "android/clearcam/.idea/inspectionProfiles/Project_Default.xml",
          "android/clearcam/app/src/androidTest/java/com/rors/clearcam/ExampleInstrumentedTest.kt",
          "android/clearcam/app/src/test/java/com/rors/clearcam/ExampleUnitTest.kt",
          "clearcam.spec",
          "cocotest.py",
          "test/clip_images/.DS_Store",
          "test/clip_images/embeddings.pkl",
          "test/clip_images/f40.jpg",
          "test/clip_images/micra.jpg",
          "test/test_clip.py",
          "test/test_db.py",
          "test/test_mot.py",
          "test/tracker_inputs.pkl",
          "test/videos/MOT16-03.mp4"
        ],
        "docs": [
          "LICENSE.md",
          "README.md"
        ],
        "fileTypes": {
          ".md": 2,
          ".py": 15,
          ".xml": 22,
          ".gradle": 3,
          ".json": 4,
          ".pro": 1,
          ".kt": 9,
          ".png": 31,
          ".webp": 15,
          ".properties": 2,
          ".toml": 1,
          ".jar": 1,
          ".bat": 1,
          ".apk": 1,
          ".spec": 1,
          ".jpg": 5,
          ".pbxproj": 1,
          ".xcworkspacedata": 1,
          ".h": 18,
          ".m": 19,
          ".storyboard": 2,
          ".plist": 1,
          ".storekit": 1,
          ".entitlements": 1,
          ".strings": 7,
          ".html": 4,
          ".pyc": 4,
          ".txt": 1,
          ".pkl": 2,
          ".mp4": 1,
          ".gz": 1
        }
      }
    },
    {
      "id": 1143249672,
      "name": "scx_horoscope",
      "displayName": "scx horoscope",
      "description": "Astrological CPU Scheduler",
      "summary": "Modern CPU schedulers are built on rational algorithms—prioritizing tasks based on resource demands, user input, and system heuristics. Yet, anyone who’s wrestled with sluggish desktop responsiveness or unexplained latency spikes knows there’s often a missing dimension: unpredictability, the subtle influences that defy explanation. What if, instead of fighting this chaos, we embraced it? Enter scxhoroscope, a project that radically reimagines process scheduling by channeling the principles of astrology. This isn’t a tongue-in-cheek simulation; it’s a fully functional Linux schedext scheduler that leverages real planetary positions, zodiac signs, and astrological rules to make time-slicing decisions—all loaded directly into the kernel.\n\nUnlike conventional schedulers that optimize for throughput or fairness, scxhoroscope injects cosmic context into every scheduling choice. It computes planetary positions using the astro crate, assigns astrological affinities to tasks, and dynamically adjusts priorities based on lunar phases, retrograde motion, and elemental oppositions. The result is a system where the fate of your processes is not just determined by demand, but also by whether Mercury is in retrograde or if the Moon is full. From a technical standpoint, this is a fascinating blend of computational astronomy, symbolic classification, and kernel integration—bridging the esoteric with the practical.\n\nThe architecture reveals a tightly organized Rust project, with clear modular boundaries. The src/astrology directory holds the core logic: mod.rs orchestrates planetary calculations (planets.rs), task classification (tasks.rs), and scheduling rules (scheduler.rs). Integration with Linux is handled via BPF: main.bpf.c provides the kernel-side logic, while bpf.rs, bpfintf.rs, and bpfskel.rs handle userspace/kernel communication using the scxrustlandcore framework. Elemental boosts and retrograde penalties are applied through deterministic formulas, with lunar phase detection baked into the scheduling loop. The presence of build.rs and Cargo.toml signals a modern Rust build, while intf.h and demo.tape hint at low-level interfaces and test harnesses. ASTROLOGY.md documents the domain logic, reinforcing the project’s commitment to explainable scheduling.\n\nThere are several scenarios where scxhoroscope can be genuinely useful—or at least provocative. For developers building real-time systems or experimenting with alternative scheduling policies, this project is a goldmine for testing how non-traditional signals affect process prioritization. Desktop users with a penchant for cosmic alignment can use it to boost interactive tasks during full moons, or intentionally throttle CPU-hungry processes when Mars is retrograde. In research settings, scxhoroscope provides a rich framework for exploring how external signals—astrological, environmental, or otherwise—can modulate kernel behavior, informing future adaptive schedulers. Even DevOps engineers might find value in its \"cosmic weather reports,\" offering real-time guidance for system tuning based on planetary alignments.\n\nUltimately, scxhoroscope matters because it challenges the orthodoxy of system scheduling. By fusing deterministic code with symbolic rules from astrology, it demonstrates that kernel-level decisions can be influenced by factors outside the traditional model. Whether you view this as an experiment in cosmic chaos or a practical tool for adaptive scheduling, it pushes the boundaries of what’s possible in kernel development. This kind of playful yet rigorous exploration is exactly what open source should foster: not just incremental improvement, but radical rethinking of how our systems interact with the world—both logical and illogical.",
      "url": "https://github.com/yebeai/scx_horoscope",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "zampierilucas/scx_horoscope",
        "url": "https://github.com/zampierilucas/scx_horoscope",
        "stars": 1206
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 27, 2026",
      "updatedAt": "January 27, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 19,
        "directories": {
          "(root)": 10,
          ".vscode": 1,
          "src": 8
        },
        "languages": {
          "JSON": 1,
          "Markdown": 2,
          "TOML": 1,
          "Rust": 9,
          "C/C++ Header": 1,
          "C": 1
        },
        "frameworks": [],
        "packageManager": "cargo",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "src/main.rs"
        ],
        "configFiles": [
          "Cargo.toml"
        ],
        "dependencies": [
          "Cargo.toml"
        ],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".json": 1,
          ".md": 2,
          ".lock": 1,
          ".toml": 1,
          ".rs": 9,
          ".gif": 1,
          ".tape": 1,
          ".h": 1,
          ".c": 1
        }
      }
    },
    {
      "id": 1142734373,
      "name": "globalthreatmap",
      "displayName": "globalthreatmap",
      "description": "Global threat map. Learn wars, conflicts, military bases and history of nations. ",
      "summary": "In an increasingly interconnected world, staying informed about global conflicts, geopolitical developments, and military activities is more critical than ever. Governments, NGOs, journalists, and security analysts all require tools that provide real-time, actionable intelligence. Yet, many existing solutions are either locked behind expensive subscriptions or lack the depth and interactivity needed for nuanced analysis. The Global Threat & Event Intelligence Map repository aims to address this gap, offering a robust, open-source platform designed to visualize real-time security events and historical conflicts on an interactive map. With its feature-rich infrastructure and open-ended extensibility, this project represents a valuable resource for developers and organizations needing an intuitive, data-driven approach to global threat monitoring.\n\nAt its core, the Global Threat & Event Intelligence Map is a situational awareness platform that aggregates and visualizes global security data. What sets this project apart is its ability to seamlessly integrate real-time event mapping with detailed historical and geopolitical context. Using Mapbox for its interactive map foundation, the platform displays a range of events, from protests and natural disasters to military conflicts and geopolitical tensions, with color-coded threat levels. The inclusion of features like an event feed, military base overlays, and AI-powered conflict analysis makes it a uniquely comprehensive OSINT (Open Source Intelligence) tool. Moreover, the platform’s ability to generate in-depth intelligence dossiers and export research in various formats (such as CSV and PowerPoint) illustrates its utility for analysts, researchers, and even educators.\n\nFrom a technical perspective, the repository showcases thoughtful architectural patterns and a modern tech stack. Built on Next.js 16 with the App Router, it takes full advantage of server-side rendering and dynamic routing for high performance and scalability. The file structure is modular and intuitive, with dedicated directories for API routes (app/api) and reusable UI components (components). For example, the app/api/countries/conflicts/route.ts file provides endpoint logic for fetching country-specific conflict data, while components like components/map/threat-map.tsx handle the presentation layer for visualizing these events. The use of Tailwind CSS v4 ensures a clean and responsive UI, while react-map-gl integrates seamlessly with Mapbox for advanced geospatial functionality. State management is handled by Zustand, a lightweight but powerful library, and zod is used for schema validation, ensuring data integrity throughout the application. This combination of tools and design patterns not only reflects modern best practices but also makes the project accessible to contributors looking to extend its capabilities.\n\nThe potential use cases for this platform are vast and compelling. First, it can serve as a crucial tool for journalists and researchers who need to monitor breaking geopolitical events in real time. The event feed and threat map provide a bird’s-eye view of global developments, allowing reporters to quickly identify and contextualize events. Second, the platform is a valuable asset for NGOs and humanitarian organizations operating in conflict zones. The ability to overlay military base locations, ongoing conflicts, and historical tensions can help these groups make informed decisions about where and how to deploy resources. Finally, security analysts and policy advisors can use the AI-powered deep research features to build detailed intelligence dossiers on specific entities or conflicts, extracting actionable insights backed by data and cited sources.\n\nThis project is not just another visualization tool; it’s a step toward democratizing access to actionable intelligence. By combining real-time data aggregation, historical context, and advanced visualization techniques, the Global Threat & Event Intelligence Map empowers users to make informed decisions in an increasingly complex world. For developers, it’s also a masterclass in building scalable, modular applications with modern web technologies. Whether you’re looking to deploy it as-is or use it as a foundation for your own OSINT tools, this repository offers both the functionality and flexibility to meet a wide range of needs. In a domain often dominated by proprietary tools, this project is a reminder of the power and importance of open-source innovation.",
      "url": "https://github.com/yebeai/globalthreatmap",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "unicodeveloper/globalthreatmap",
        "url": "https://github.com/unicodeveloper/globalthreatmap",
        "stars": 1239
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1531482615713-2afd69097998?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 26, 2026",
      "updatedAt": "January 26, 2026",
      "readTime": 4,
      "knowledgeGraph": {
        "totalFiles": 64,
        "directories": {
          "(root)": 10,
          "app": 15,
          "components": 25,
          "hooks": 2,
          "lib": 8,
          "stores": 3,
          "types": 1
        },
        "languages": {
          "Markdown": 1,
          "TypeScript": 26,
          "TSX": 29,
          "CSS": 1,
          "JSON": 3,
          "YAML": 1
        },
        "frameworks": [
          "React",
          "Next.js",
          "Tailwind"
        ],
        "packageManager": "pnpm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "components/auth/index.ts",
          "types/index.ts"
        ],
        "configFiles": [
          ".env.example",
          "next.config.ts",
          "package.json",
          "tailwind.config.ts",
          "tsconfig.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".example": 1,
          ".md": 1,
          ".ts": 26,
          ".tsx": 29,
          ".css": 1,
          ".json": 3,
          ".yaml": 1,
          ".mjs": 1
        }
      }
    },
    {
      "id": 1142307628,
      "name": "self.so",
      "displayName": "self.so",
      "description": "LinkedIn -> personal site generator",
      "summary": "In an era where personal branding has become paramount, individuals often struggle to effectively showcase their skills and experiences online. While platforms like LinkedIn provide a structured format for professional profiles, they often lack the customization and personal touch that many users desire. Enter Self.so, an open-source personal site generator that seeks to bridge this gap by allowing users to seamlessly convert their LinkedIn profiles into personalized websites. This unique approach not only enhances personal branding but also empowers users to present their professional narrative in a manner that reflects their individuality.\n\nSelf.so leverages a combination of modern technologies to create a user-friendly interface for building personal sites. The project is built on Next.js, which is notable for its server-side rendering capabilities and API routes, making it an ideal choice for a dynamic web application. The README highlights the integration of Clerk for authentication, ensuring that users can securely manage their accounts. Additionally, the use of Together.ai for language model capabilities allows the application to process and extract relevant information from PDFs uploaded by users, significantly enhancing the user experience. The project’s architecture is structured around a modular directory layout, which promotes maintainability and scalability—evident in files like app/api/resume/route.ts, which likely handles the interactions related to resume uploads.\n\nDiving deeper into the technical specifications, the file structure reveals a well-organized setup. The presence of tests/generateResumeObject.test.ts and tests/setup.ts indicates a commitment to rigorous testing practices, essential for maintaining code quality in an evolving codebase. Furthermore, the use of S3 for object storage and Upstash for Redis indicates a blend of reliable cloud services that support the application's performance and scalability needs. The modularity of the application is underscored by directories like app/[username]/, which suggests a dynamic routing system that personalizes content for each user based on their input. This level of detail in architecture not only enhances user experience but also simplifies future feature additions, as outlined in the project's future tasks.\n\nConsider a developer looking to build a portfolio site that automatically updates with new projects or experiences. Self.so could serve as the backbone for such a project, allowing seamless integration of professional information from LinkedIn while providing a customizable front end that can be tailored to the developer's preferences. Another scenario could involve a recruitment consultant who wishes to provide clients with a personalized dashboard showcasing their qualifications and project history. By utilizing Self.so, they could efficiently create and manage multiple personal sites for different clients, all while leveraging the underlying automation of PDF extraction and data structuring provided by the platform.\n\nUltimately, the significance of Self.so lies not just in its functionality but in its embodiment of the open-source ethos. It addresses a widespread need for personalized digital identities while allowing developers to contribute to and extend its capabilities. The project stands as a testament to the potential of community-driven development in creating tools that can significantly impact how individuals present themselves online. As more developers explore and contribute to Self.so, the possibilities for customization and innovation within personal branding are virtually limitless.",
      "url": "https://github.com/yebeai/self.so",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Nutlope/self.so",
        "url": "https://github.com/Nutlope/self.so",
        "stars": 2895
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1542831371-29b0f74f9713?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 26, 2026",
      "updatedAt": "January 26, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 157,
        "directories": {
          "(root)": 15,
          ".github": 1,
          "__tests__": 2,
          "app": 23,
          "components": 83,
          "hooks": 3,
          "lib": 11,
          "public": 18,
          "styles": 1
        },
        "languages": {
          "YAML": 2,
          "Markdown": 2,
          "TypeScript": 27,
          "TSX": 95,
          "CSS": 2,
          "JSON": 3
        },
        "frameworks": [
          "React",
          "Next.js",
          "Tailwind"
        ],
        "packageManager": "pnpm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "components/icons/index.ts"
        ],
        "configFiles": [
          ".prettierrc",
          "next.config.mjs",
          "package.json",
          "tailwind.config.ts",
          "tsconfig.json"
        ],
        "dependencies": [
          "package.json"
        ],
        "testFiles": [
          ".github/workflows/test.yml",
          "__tests__/generateResumeObject.test.ts",
          "__tests__/setup.ts",
          "components/ui/aspect-ratio.tsx",
          "vitest.config.ts"
        ],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".env": 1,
          ".yml": 1,
          ".md": 2,
          ".ts": 27,
          ".tsx": 95,
          ".ico": 1,
          ".css": 2,
          ".txt": 1,
          ".json": 3,
          ".mjs": 2,
          ".yaml": 1,
          ".png": 8,
          ".svg": 8,
          ".jpg": 2
        }
      }
    },
    {
      "id": 1142301808,
      "name": "open-lovable",
      "displayName": "open lovable",
      "description": "🔥 Clone and recreate any website as a modern React app in seconds",
      "summary": "The Problem\nBuilding a React app from scratch can be a slog. You spend hours setting up your environment, configuring your dependencies, and wrestling with various APIs. If you're just trying to clone a website for a side project or demo, that long setup process feels like overkill. \n\nWhat This Does\nEnter Open Lovable. This repo lets you clone and recreate any website as a modern React app in seconds. It’s packed with APIs in the app/api/ directory, like analyze-edit-intent/route.ts and scrape-url-enhanced/route.ts, specifically aimed at simplifying the process of getting your shiny new React app up and running.\n\nThe setup is straightforward. You clone the repo, install dependencies with pnpm install (or your package manager of choice), and set up your .env.local with the necessary API keys. The instructions are all right there in the README.md, making it easy to get started. Just follow the prompts, run pnpm dev, and you’re off to the races at http://localhost:3000.\n\nReal-World Use\nImagine you want to clone a simple blog site for a personal project. With Open Lovable, you could quickly set up a sandbox environment using Vercel or E2B, depending on your preference. You’d configure your .env.local with your Firecrawl API key and maybe an OpenAI key if you want some AI magic in your app. After that, you could use the create-ai-sandbox endpoint to generate a scaffold of your app. A few tweaks later, and voila! You’ve got a working React app that looks like the original site you cloned.\n\nExample command to create a sandbox\ncurl -X POST http://localhost:3000/api/create-ai-sandbox -d '{\"url\":\"https://example-blog.com\"}'\n\nThe Bottom Line\nOpen Lovable is a neat tool if you're looking to clone websites quickly without diving deep into the setup. It's great for prototyping or testing ideas but might be overkill for simple projects where manual cloning could be quicker. If you’re comfortable with APIs and want to have some fun building with AI, give it a shot. Just don’t expect it to replace a solid understanding of React fundamentals.",
      "url": "https://github.com/yebeai/open-lovable",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "firecrawl/open-lovable",
        "url": "https://github.com/firecrawl/open-lovable",
        "stars": 24310
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 26, 2026",
      "updatedAt": "January 26, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".cursor": 1,
          "(root)": 6,
          "app": 36,
          "atoms": 1,
          "components": 156
        },
        "languages": {
          "JSON": 10,
          "Markdown": 3,
          "TypeScript": 45,
          "TSX": 132,
          "CSS": 3
        },
        "frameworks": [
          "React"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "components/app/(home)/sections/hero/Pixi/tickers/features/index.ts",
          "components/shared/buttons/index.ts",
          "components/shared/effects/flame/index.ts",
          "components/shared/effects/index.ts",
          "components/shared/logo-cloud/index.ts"
        ],
        "configFiles": [
          ".env.example"
        ],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md",
          "components/shared/header/BrandKit/_svg/Guidelines.tsx",
          "components/shared/header/Nav/_svg/Changelog.tsx"
        ],
        "fileTypes": {
          ".json": 10,
          ".example": 1,
          ".md": 3,
          ".ts": 45,
          ".tsx": 132,
          ".ico": 1,
          ".woff": 2,
          ".css": 3,
          ".lock": 1
        }
      }
    },
    {
      "id": 1142274543,
      "name": "Prometheus",
      "displayName": "Prometheus",
      "description": "🧠 Prometheus: A Knowledge-Graph-Driven 🤖 AI Agent that maps 🗺, understands 🧩, and repairs 🛠 complex codebases — not by guessing, but by reasoning. ⚡",
      "summary": "Modern software development is often plagued by complexity: sprawling codebases, fragile integrations, and technical debt that stifles innovation. As teams grow and projects evolve, understanding and maintaining a codebase becomes an uphill battle. Enter Prometheus, a knowledge-graph-driven AI agent designed to tackle this very challenge. Unlike other AI tools that rely on probabilistic guesses, Prometheus takes a reasoning-first approach to mapping, analyzing, and refactoring complex codebases. For developers and organizations aiming to build robust, maintainable software, Prometheus represents a significant paradigm shift.\n\nAt its core, Prometheus is not just another AI-powered code generator or assistant. Its primary value proposition lies in its ability to autonomously reason about software systems using knowledge graphs. By constructing an internal representation of your codebase and its dependencies, Prometheus aims to identify bottlenecks, detect architectural flaws, and propose actionable solutions. This reasoning-based approach is what differentiates it from more generic tools. While many AI solutions focus on rapid prototyping, often at the expense of code quality, Prometheus is designed for long-term maintainability and precision. This makes it particularly appealing for enterprise-grade applications where reliability, security, and cost control are paramount.\n\nA quick dive into Prometheus' file structure reveals a carefully organized system that hints at its multi-agent architecture. The primary code resides in the prometheus/app directory, which is further divided into modules like api, routes, and submodules for specific functionalities such as auth.py and github.py. The modular breakdown indicates a microservices-inspired design, where each component is responsible for a distinct slice of functionality. The inclusion of a docker-compose.yml file and a Dockerfile also signals that the project is built with containerization in mind, enabling seamless deployment and scalability. The presence of .github/workflows files such as pytestandcoverage.yml and ruff_check.yml reflects a strong focus on CI/CD practices, emphasizing code quality and maintainability through automated testing and linting.\n\nThe knowledge-graph-driven aspect of Prometheus is further supported by its documentation, particularly the docs/Multi-Agent-Architecture.md file. This document outlines how Prometheus orchestrates multiple agents to analyze and interact with the codebase. For example, one agent might map dependencies while another identifies areas requiring refactoring. This layered, multi-agent approach ensures that Prometheus can handle a wide range of tasks without overwhelming individual components. Additionally, the Evaluation-log.md and GitHub-Issue-Debug-Guide.md files suggest that the team has invested heavily in debugging workflows and evaluation metrics, ensuring that the tool’s recommendations are both accurate and actionable.\n\nThe potential use cases for Prometheus are significant. Imagine a legacy codebase that has grown unruly over years of feature additions and hotfixes. Instead of spending weeks deciphering the code manually, Prometheus could generate a comprehensive knowledge graph to reveal hidden dependencies, dead code, and performance bottlenecks. Another scenario involves onboarding new developers. Rather than relying on outdated documentation or tribal knowledge, a team could use Prometheus to create an up-to-date map of the system, accelerating the onboarding process. Additionally, for teams working in regulated industries like healthcare or finance, Prometheus can help ensure compliance by identifying potential violations in architectural patterns or coding standards.\n\nPrometheus matters because it addresses a fundamental issue in software engineering: the gap between understanding and execution. Codebases are not static; they evolve, accumulate debt, and eventually become unmanageable if left unchecked. Prometheus provides a systematic way to keep this complexity in check, empowering developers to focus on building features rather than firefighting technical debt. While it is still early days for the project—this fork currently has no stars—the solid foundation provided by its predecessor (EuniAI/Prometheus with 648 stars) and its unique approach make it one to watch. For teams serious about building sustainable software, Prometheus could be the tool to transform chaos into clarity.",
      "url": "https://github.com/yebeai/Prometheus",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "EuniAI/Prometheus",
        "url": "https://github.com/EuniAI/Prometheus",
        "stars": 692
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 26, 2026",
      "updatedAt": "January 26, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 9,
          ".github": 5,
          "docs": 8,
          "prometheus": 178
        },
        "languages": {
          "Markdown": 8,
          "YAML": 3,
          "Python": 178
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "prometheus/app/api/main.py",
          "prometheus/app/main.py"
        ],
        "configFiles": [
          "Dockerfile",
          "docker-compose.yml"
        ],
        "dependencies": [],
        "testFiles": [
          ".github/workflows/pytest_and_coverage.yml",
          "prometheus/lang_graph/nodes/bug_get_regression_tests_selection_node.py",
          "prometheus/lang_graph/nodes/bug_get_regression_tests_subgraph_node.py",
          "prometheus/lang_graph/nodes/general_test_node.py",
          "prometheus/lang_graph/nodes/general_test_structured_node.py",
          "prometheus/lang_graph/nodes/get_pass_regression_test_patch_check_result_node.py",
          "prometheus/lang_graph/nodes/get_pass_regression_test_patch_subgraph_node.py",
          "prometheus/lang_graph/nodes/get_pass_regression_test_patch_update_node.py",
          "prometheus/lang_graph/nodes/run_existing_tests_node.py",
          "prometheus/lang_graph/nodes/run_existing_tests_structure_node.py",
          "prometheus/lang_graph/nodes/run_existing_tests_subgraph_node.py",
          "prometheus/lang_graph/nodes/run_regression_tests_node.py",
          "prometheus/lang_graph/nodes/run_regression_tests_structure_node.py",
          "prometheus/lang_graph/nodes/run_regression_tests_subgraph_node.py",
          "prometheus/lang_graph/nodes/user_defined_test_node.py",
          "prometheus/lang_graph/subgraphs/bug_get_regression_tests_state.py",
          "prometheus/lang_graph/subgraphs/bug_get_regression_tests_subgraph.py",
          "prometheus/lang_graph/subgraphs/build_and_test_state.py",
          "prometheus/lang_graph/subgraphs/build_and_test_subgraph.py",
          "prometheus/lang_graph/subgraphs/get_pass_regression_test_patch_state.py",
          "prometheus/lang_graph/subgraphs/get_pass_regression_test_patch_subgraph.py",
          "prometheus/lang_graph/subgraphs/run_existing_tests_state.py",
          "prometheus/lang_graph/subgraphs/run_existing_tests_subgraph.py",
          "prometheus/lang_graph/subgraphs/run_regression_tests_state.py",
          "prometheus/lang_graph/subgraphs/run_regression_tests_subgraph.py"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "docs/Evaluation-log.md",
          "docs/GitHub-Issue-Debug-Guide.md",
          "docs/Multi-Agent-Architecture.md",
          "docs/static/images/barChart.png",
          "docs/static/images/comparison_deepseek_July08.png",
          "docs/static/images/delysium.jpg",
          "docs/static/images/delysium_logo.svg",
          "docs/static/images/icon.jpg"
        ],
        "fileTypes": {
          ".md": 8,
          ".yml": 3,
          ".png": 2,
          ".jpg": 2,
          ".svg": 1,
          ".env": 1,
          ".py": 178
        }
      }
    },
    {
      "id": 1141961085,
      "name": "knowledge",
      "displayName": "knowledge",
      "description": "Open-source personal bookmarks search engine",
      "summary": "In an age where information overload is the norm, effectively managing personal knowledge can feel overwhelming. Developers, researchers, and lifelong learners often find themselves juggling countless bookmarks, articles, and snippets from various platforms, making it increasingly difficult to retrieve relevant information when needed. This is where the Knowledge project shines, offering a solution that automates the aggregation of digital interactions into a personal search engine, enabling users to transform their digital footprints into a navigable knowledge graph.\n\nKnowledge is an open-source web application that effectively consolidates data from platforms like GitHub, HackerNews, Zotero, and HuggingFace, automatically organizing and storing this information in a user-friendly manner. What sets it apart is its ability to create a knowledge graph that visually represents the connections between topics, enhancing the way users can search and engage with their saved content. The application is not only a personal knowledge base but also an innovative search engine that leverages data from various sources, allowing users to discover relationships between their interests and activities.\n\nFrom a technical standpoint, the architecture of Knowledge is well-structured and reflects modern best practices. The project utilizes a FastAPI backend, which is lightweight and efficient for building APIs. The backend is automatically deployed using GitHub Actions workflows, as indicated by the .github/workflows directory, which includes database.yml, flyio.yml, and lint.yml files. These workflows handle the daily extraction of data from user accounts, manage the deployment process to Fly.io, and ensure code quality through linting. The data itself is organized in the database/ directory, with files such as database.json for raw records and triples.json for storing the knowledge graph data. The use of serialized models, as seen in pipeline.pkl, indicates a thoughtful approach to optimizing the search experience through machine learning techniques.\n\nDevelopers can find several practical use cases for the Knowledge project. For instance, a software engineer frequently exploring new libraries on GitHub could use Knowledge to automatically track and categorize their interactions, allowing for quick retrieval of resources when working on related projects. Similarly, a researcher utilizing Zotero for academic papers could leverage the search engine to quickly find relevant articles and their connections to ongoing research topics. Additionally, educators might benefit from using Knowledge to curate and organize digital resources, making it easier to share valuable content with students.\n\nIn conclusion, Knowledge represents a significant advancement in personal knowledge management, addressing a critical gap in how we interact with and retrieve information in an increasingly complex digital landscape. By automating data aggregation and providing a visual representation of knowledge connections, it empowers users to make sense of their digital lives efficiently. As the project evolves, it has the potential to become an indispensable tool for anyone looking to enhance their information retrieval capabilities and better manage their intellectual resources. This project not only exemplifies the power of open-source collaboration but also highlights the ongoing need for innovative solutions in personal knowledge management.",
      "url": "https://github.com/yebeai/knowledge",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "raphaelsty/knowledge",
        "url": "https://github.com/raphaelsty/knowledge",
        "stars": 726
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 25, 2026",
      "updatedAt": "January 25, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 76,
        "directories": {
          "(root)": 14,
          ".github": 3,
          "api": 1,
          "database": 4,
          "docs": 21,
          "img": 10,
          "knowledge_database": 23
        },
        "languages": {
          "YAML": 5,
          "Python": 25,
          "JSON": 3,
          "JavaScript": 2,
          "HTML": 1,
          "Markdown": 2,
          "TypeScript": 2,
          "CSS": 1,
          "TOML": 2
        },
        "frameworks": [
          "React",
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "docs/index.html"
        ],
        "configFiles": [
          "Dockerfile",
          "Makefile",
          "docs/pkg/package.json",
          "pyproject.toml"
        ],
        "dependencies": [
          "docs/pkg/package.json",
          "pyproject.toml"
        ],
        "testFiles": [
          "pytest.ini"
        ],
        "docs": [
          "LICENSE",
          "docs/colbert.worker.js",
          "docs/favicon_io/android-chrome-192x192.png",
          "docs/favicon_io/android-chrome-512x512.png",
          "docs/favicon_io/apple-touch-icon.png",
          "docs/favicon_io/favicon-16x16.png",
          "docs/favicon_io/favicon-32x32.png",
          "docs/favicon_io/favicon.ico",
          "docs/favicon_io/site.webmanifest",
          "docs/github.png",
          "docs/hackernews.png",
          "docs/index.html",
          "docs/pkg/.gitignore",
          "docs/pkg/LICENSE",
          "docs/pkg/README.md",
          "docs/pkg/package.json",
          "docs/pkg/pylate_rs.d.ts",
          "docs/pkg/pylate_rs.js",
          "docs/pkg/pylate_rs_bg.wasm",
          "docs/pkg/pylate_rs_bg.wasm.d.ts",
          "docs/style.css",
          "docs/twitter.png",
          "readme.md"
        ],
        "fileTypes": {
          ".yml": 4,
          ".yaml": 1,
          ".py": 25,
          ".json": 3,
          ".pkl": 1,
          ".js": 2,
          ".png": 17,
          ".ico": 1,
          ".webmanifest": 1,
          ".html": 1,
          ".md": 2,
          ".ts": 2,
          ".wasm": 1,
          ".css": 1,
          ".toml": 2,
          ".gif": 1,
          ".ini": 1,
          ".lock": 1
        }
      }
    },
    {
      "id": 1141954679,
      "name": "taipy",
      "displayName": "taipy",
      "description": "Turns Data and AI algorithms into production-ready web applications in no time.",
      "summary": "The Problem\nBuilding production-ready web applications for data and AI can be a real headache. You often end up juggling multiple frameworks, languages, and tools just to get a simple data visualization running. Data scientists shouldn’t have to moonlight as full-stack developers to deploy their models.\n\nWhat This Does\nEnter Taipy, a Python-centric tool that claims to simplify this mess. With just a pip install taipy, you’re ready to roll. The core of Taipy is its Python library, which manages user interface generation, data integration, and pipeline orchestration—basically, everything you need to get a web app off the ground without diving into the deep end of web development.\n\nThe taipy folder structure is pretty straightforward, but it’s packed with goodies. For instance, the .github/workflows directory is loaded with CI/CD workflows that automate tasks like dependency management and code quality checks. You can easily set up your deployment scripts and version management using the built-in command line interface.\n\nReal-World Use\nImagine you’re a data scientist with a trained machine learning model, and you want to expose it as a web application. With Taipy, you can create a simple app where users input data, and the model churns out predictions—all within a couple of hours. You might set up a config.yaml to define your data sources and authentication rules, while the taipy Designer helps you build out the UI without needing to touch HTML.\n\nHere’s a snippet that shows how easy it is to define a pipeline:\n\nfrom taipy import Gui\n\ndef mypipeline(data):\n    # some processing steps\n    return processeddata\n\nGui.addpage(\"/predict\", mypipeline)\n\nWith just that, you can set up a page that takes input and displays output without fussing with front-end code.\n\nThe Bottom Line\nTaipy is solid for those who want to focus on data and AI without the web dev baggage. It’s not suitable for small, one-off projects due to its complexity and overhead. Stick to it if you're building something more substantial and need a structured way to deploy and manage your applications. For quick prototypes, though, you might want to look elsewhere.",
      "url": "https://github.com/yebeai/taipy",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Avaiga/taipy",
        "url": "https://github.com/Avaiga/taipy",
        "stars": 19088
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 25, 2026",
      "updatedAt": "January 25, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 14,
          ".github": 31,
          "doc": 155
        },
        "languages": {
          "YAML": 29,
          "Markdown": 7,
          "JavaScript": 2,
          "Python": 150,
          "JSON": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [
          "Pipfile"
        ],
        "testFiles": [
          ".github/actions/gui-test/action.yml",
          ".github/actions/gui-test/e2e/action.yml",
          ".github/actions/gui-test/prefix/action.yml",
          ".github/actions/gui-test/pyi/action.yml",
          ".github/workflows/overall-tests.yml",
          ".github/workflows/partial-tests.yml",
          ".github/workflows/trigger-integration-tests.yml"
        ],
        "docs": [
          ".license-header",
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "doc/gui/examples/Alert.py",
          "doc/gui/examples/README.md",
          "doc/gui/examples/async_callback.py",
          "doc/gui/examples/binding_lov_is_enum/__init__.py",
          "doc/gui/examples/binding_lov_is_enum/builder.py",
          "doc/gui/examples/binding_lov_is_enum/markdown.py",
          "doc/gui/examples/blocks/dialog_labels/__init__.py",
          "doc/gui/examples/blocks/dialog_labels/builder.py",
          "doc/gui/examples/blocks/dialog_labels/markdown.py",
          "doc/gui/examples/blocks/dialog_show_hide/__init__.py",
          "doc/gui/examples/blocks/dialog_show_hide/builder.py",
          "doc/gui/examples/blocks/dialog_show_hide/markdown.py",
          "doc/gui/examples/blocks/layout_fit/__init__.py",
          "doc/gui/examples/blocks/layout_fit/builder.py",
          "doc/gui/examples/blocks/layout_fit/markdown.py",
          "doc/gui/examples/blocks/pane_anchor/__init__.py",
          "doc/gui/examples/blocks/pane_anchor/builder.py",
          "doc/gui/examples/blocks/pane_anchor/markdown.py",
          "doc/gui/examples/blocks/pane_as_page/__init__.py",
          "doc/gui/examples/blocks/pane_as_page/builder.py",
          "doc/gui/examples/blocks/pane_as_page/markdown.py",
          "doc/gui/examples/blocks/pane_persistent/__init__.py",
          "doc/gui/examples/blocks/pane_persistent/builder.py",
          "doc/gui/examples/blocks/pane_persistent/markdown.py",
          "doc/gui/examples/blocks/pane_simple/__init__.py",
          "doc/gui/examples/blocks/pane_simple/builder.py",
          "doc/gui/examples/blocks/pane_simple/markdown.py",
          "doc/gui/examples/blocks/pane_simple_lambda/__init__.py",
          "doc/gui/examples/blocks/pane_simple_lambda/builder.py",
          "doc/gui/examples/blocks/pane_simple_lambda/markdown.py",
          "doc/gui/examples/broadcast.py",
          "doc/gui/examples/broadcast_callback.py",
          "doc/gui/examples/broadcast_change.py",
          "doc/gui/examples/builder_lambda_property.py",
          "doc/gui/examples/charts/advanced_animation.py",
          "doc/gui/examples/charts/advanced_annotations.py",
          "doc/gui/examples/charts/advanced_large_datasets.py",
          "doc/gui/examples/charts/advanced_python_lib.py",
          "doc/gui/examples/charts/advanced_selection.py",
          "doc/gui/examples/charts/advanced_shapes.py",
          "doc/gui/examples/charts/advanced_unbalanced_datasets.py",
          "doc/gui/examples/charts/bar_facing.py",
          "doc/gui/examples/charts/bar_multiple.py",
          "doc/gui/examples/charts/bar_simple.py",
          "doc/gui/examples/charts/bar_stacked.py",
          "doc/gui/examples/charts/basics_multiple.py",
          "doc/gui/examples/charts/basics_simple.py",
          "doc/gui/examples/charts/basics_timeline.py",
          "doc/gui/examples/charts/basics_title.py",
          "doc/gui/examples/charts/basics_two_y_axis.py",
          "doc/gui/examples/charts/basics_xrange.py",
          "doc/gui/examples/charts/bubble_hover.py",
          "doc/gui/examples/charts/bubble_simple.py",
          "doc/gui/examples/charts/bubble_symbols.py",
          "doc/gui/examples/charts/candlestick_simple.py",
          "doc/gui/examples/charts/candlestick_styling.py",
          "doc/gui/examples/charts/candlestick_timeseries.py",
          "doc/gui/examples/charts/continuous_error_multiple.py",
          "doc/gui/examples/charts/continuous_error_simple.py",
          "doc/gui/examples/charts/error_bars_asymmetric.py",
          "doc/gui/examples/charts/error_bars_simple.py",
          "doc/gui/examples/charts/example_rebuild.py",
          "doc/gui/examples/charts/filled_area_normalized.py",
          "doc/gui/examples/charts/filled_area_overlay.py",
          "doc/gui/examples/charts/filled_area_simple.py",
          "doc/gui/examples/charts/filled_area_stacked.py",
          "doc/gui/examples/charts/funnel_area.py",
          "doc/gui/examples/charts/funnel_area_multiple.py",
          "doc/gui/examples/charts/funnel_multiple.py",
          "doc/gui/examples/charts/funnel_simple.py",
          "doc/gui/examples/charts/funnel_styling.py",
          "doc/gui/examples/charts/gantt_simple.py",
          "doc/gui/examples/charts/heatmap_annotated.py",
          "doc/gui/examples/charts/heatmap_colorscale.py",
          "doc/gui/examples/charts/heatmap_drawing_on_top.py",
          "doc/gui/examples/charts/heatmap_simple.py",
          "doc/gui/examples/charts/heatmap_unbalanced.py",
          "doc/gui/examples/charts/heatmap_unequal_cell_sizes.py",
          "doc/gui/examples/charts/histogram_binning_function.py",
          "doc/gui/examples/charts/histogram_cumulative.py",
          "doc/gui/examples/charts/histogram_horizontal.py",
          "doc/gui/examples/charts/histogram_nbins.py",
          "doc/gui/examples/charts/histogram_normalized.py",
          "doc/gui/examples/charts/histogram_overlay.py",
          "doc/gui/examples/charts/histogram_simple.py",
          "doc/gui/examples/charts/histogram_stacked.py",
          "doc/gui/examples/charts/line_style.py",
          "doc/gui/examples/charts/line_texts.py",
          "doc/gui/examples/charts/map_bubbles.py",
          "doc/gui/examples/charts/map_lines.py",
          "doc/gui/examples/charts/map_simple.py",
          "doc/gui/examples/charts/matplotlib/__init__.py",
          "doc/gui/examples/charts/matplotlib/builder.py",
          "doc/gui/examples/charts/matplotlib/image.py",
          "doc/gui/examples/charts/matplotlib/markdown.py",
          "doc/gui/examples/charts/pie_multiple.py",
          "doc/gui/examples/charts/pie_simple.py",
          "doc/gui/examples/charts/pie_styling.py",
          "doc/gui/examples/charts/polar_angular_axis.py",
          "doc/gui/examples/charts/polar_area.py",
          "doc/gui/examples/charts/polar_multiple.py",
          "doc/gui/examples/charts/polar_sectors.py",
          "doc/gui/examples/charts/polar_simple.py",
          "doc/gui/examples/charts/polar_tick_texts.py",
          "doc/gui/examples/charts/radar_multiple.py",
          "doc/gui/examples/charts/radar_simple.py",
          "doc/gui/examples/charts/scatter_classification.py",
          "doc/gui/examples/charts/scatter_more_styling.py",
          "doc/gui/examples/charts/scatter_regression.py",
          "doc/gui/examples/charts/scatter_styling.py",
          "doc/gui/examples/charts/treemap_hierarchical.py",
          "doc/gui/examples/charts/treemap_hierarchical_values.py",
          "doc/gui/examples/charts/treemap_simple.py",
          "doc/gui/examples/charts/waterfall_period_levels.py",
          "doc/gui/examples/charts/waterfall_simple.py",
          "doc/gui/examples/charts/waterfall_styling.py",
          "doc/gui/examples/controls/alice-avatar.png",
          "doc/gui/examples/controls/beatrix-avatar.png",
          "doc/gui/examples/controls/button_action.py",
          "doc/gui/examples/controls/button_icon.py",
          "doc/gui/examples/controls/button_lambda.py",
          "doc/gui/examples/controls/button_simple.py",
          "doc/gui/examples/controls/button_size.py",
          "doc/gui/examples/controls/button_stylekit.py",
          "doc/gui/examples/controls/button_styling.py",
          "doc/gui/examples/controls/button_variant.py",
          "doc/gui/examples/controls/charles-avatar.png",
          "doc/gui/examples/controls/chat_calculator.py",
          "doc/gui/examples/controls/chat_discuss.py",
          "doc/gui/examples/controls/chat_images.py",
          "doc/gui/examples/controls/chat_messages.py",
          "doc/gui/examples/controls/chat_streaming.py",
          "doc/gui/examples/controls/column_name_styling.py",
          "doc/gui/examples/controls/datanode_viewer_json.json",
          "doc/gui/examples/controls/datanode_viewer_json.py",
          "doc/gui/examples/controls/date_format.py",
          "doc/gui/examples/controls/date_min_max.py",
          "doc/gui/examples/controls/date_not_editable.py",
          "doc/gui/examples/controls/date_range_labels.py",
          "doc/gui/examples/controls/date_range_simple.py",
          "doc/gui/examples/controls/date_range_styling.py",
          "doc/gui/examples/controls/date_range_with_time.py",
          "doc/gui/examples/controls/date_range_with_time_analog_picker.py",
          "doc/gui/examples/controls/date_simple.py",
          "doc/gui/examples/controls/date_styling.py",
          "doc/gui/examples/controls/date_with_time.py",
          "doc/gui/examples/controls/date_with_time_analog_picker.py",
          "doc/gui/examples/controls/file_download_dynamic.py",
          "doc/gui/examples/controls/file_download_dynamic_temp_file.py",
          "doc/gui/examples/controls/file_selector_image.py",
          "doc/gui/examples/controls/file_selector_simple.py",
          "doc/gui/examples/controls/input_active.py",
          "doc/gui/examples/controls/input_change_delay_on_change.py",
          "doc/gui/examples/controls/input_line_shown.py",
          "doc/gui/examples/controls/input_multiline.py"
        ],
        "fileTypes": {
          ".yml": 28,
          ".md": 7,
          ".js": 2,
          ".yaml": 1,
          ".in": 1,
          ".py": 150,
          ".png": 3,
          ".json": 1
        }
      }
    },
    {
      "id": 1141952729,
      "name": "Smartstore",
      "displayName": "Smartstore",
      "description": "A modular, scalable and ultra-fast open-source all-in-one eCommerce platform built on ASP.NET Core 7",
      "summary": "The Problem\nSetting up an eCommerce platform can be a nightmare. You need multi-language support, payment gateways, SEO-friendly product pages, and a responsive design—all while worrying about scalability for future growth. Most solutions either force you into a one-size-fits-all box or require a ton of custom code that feels like digging your own grave.\n\nWhat This Does\nEnter Smartstore. This open-source platform is built on ASP.NET Core 9 and offers a modular architecture that lets you pick and choose the features you need. The Smartstore.sln file is your entry point for building the solution, and the Dockerfile makes deployment a breeze. Want to customize themes? The powerful theme engine is located in the assets folder, allowing you to tweak the look with minimal fuss.\n\nThe README.md provides a solid overview and links to the Developer Guide, which is a good starting point if you need to dive deeper into the specifics. Plus, the structure is set up for easy collaboration with .github workflows—automating tasks like publishing releases and managing issues right out of the box.\n\nReal-World Use\nImagine you’re starting a new online store for custom sneakers. You set up your product catalog with a few variants and bundles, leveraging the built-in support for unlimited products. Using the simple UI, you configure the site to be multi-currency and multi-language. When you're ready to deploy, just run docker-compose up (assuming you've set up your Docker environment) and voilà, you're live. Need to tweak the frontend? Dive into the assets directory to modify the images and styles as needed.\n\nThe Bottom Line\nSmartstore has the potential to be a solid choice for medium to large-scale eCommerce projects, especially if you're already in the .NET ecosystem. It’s modular and scalable, which is great, but honestly, it might be overkill for smaller shops that just want to sell a few products. If you're ready to invest the time to learn the ins and outs, you'll find a lot to like here. Just don’t expect a quick setup—this isn’t a plug-and-play solution.",
      "url": "https://github.com/yebeai/Smartstore",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "smartstore/Smartstore",
        "url": "https://github.com/smartstore/Smartstore",
        "stars": 1464
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 25, 2026",
      "updatedAt": "January 25, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 26,
          ".github": 6,
          ".nuke": 2,
          "assets": 8,
          "build": 12,
          "dev-docs": 122,
          "src": 24
        },
        "languages": {
          "Shell": 9,
          "Markdown": 121,
          "YAML": 6,
          "JSON": 4,
          "Docker": 2,
          "C#": 6
        },
        "frameworks": [
          "Express",
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          "Dockerfile",
          "Dockerfile.dockerignore",
          "docker-compose.postgres.yml",
          "docker-compose.sqlserver.yml",
          "docker-compose.yml"
        ],
        "dependencies": [],
        "testFiles": [
          "dev-docs/.gitbook/assets/barcodetester.png"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "build/README.md",
          "changelog.md",
          "dev-docs/.gitbook/assets/Profiling_MiniProfiler.png",
          "dev-docs/.gitbook/assets/allow.png",
          "dev-docs/.gitbook/assets/barcodetester.png",
          "dev-docs/.gitbook/assets/disallow.png",
          "dev-docs/.gitbook/assets/inherited-allow.png",
          "dev-docs/.gitbook/assets/inherited-disallow.png",
          "dev-docs/.gitbook/assets/migration-history.png",
          "dev-docs/.gitbook/assets/ngrok.png",
          "dev-docs/.gitbook/assets/permission-tree.png",
          "dev-docs/.gitbook/assets/scheduling-minimal-task-component.png",
          "dev-docs/AGENTS.md",
          "dev-docs/README.md",
          "dev-docs/STATE.md",
          "dev-docs/SUMMARY.md",
          "dev-docs/advanced/async-state.md",
          "dev-docs/advanced/di-best-practices.md",
          "dev-docs/advanced/distributed-locking.md",
          "dev-docs/advanced/performance-guide.md",
          "dev-docs/advanced/service-tier-best-practices.md",
          "dev-docs/advanced/view-precompilation.md",
          "dev-docs/appendix/changelog.md",
          "dev-docs/appendix/cheat-sheet.md",
          "dev-docs/appendix/glossary.md",
          "dev-docs/appendix/tips-and-tricks/README.md",
          "dev-docs/appendix/tips-and-tricks/tenants.md",
          "dev-docs/compose/modules/README.md",
          "dev-docs/compose/modules/controllers-and-viewcomponents.md",
          "dev-docs/compose/modules/deploying-modules.md",
          "dev-docs/compose/modules/examples/README.md",
          "dev-docs/compose/modules/examples/adding-menu-items.md",
          "dev-docs/compose/modules/examples/adding-tabs.md",
          "dev-docs/compose/modules/examples/creating-a-block.md",
          "dev-docs/compose/modules/examples/creating-a-domain-entity.md",
          "dev-docs/compose/modules/examples/creating-a-export-provider.md",
          "dev-docs/compose/modules/examples/creating-a-widget-provider.md",
          "dev-docs/compose/modules/filters.md",
          "dev-docs/compose/modules/getting-started-with-modules.md",
          "dev-docs/compose/modules/licensable-modules.md",
          "dev-docs/compose/modules/localizing-modules.md",
          "dev-docs/compose/modules/tutorials/building-a-simple-hello-world-module.md",
          "dev-docs/compose/theming/README.md",
          "dev-docs/compose/theming/asset-bundling.md",
          "dev-docs/compose/theming/getting-started-with-themes.md",
          "dev-docs/compose/theming/tag-helpers.md",
          "dev-docs/compose/theming/theme-configuration.md",
          "dev-docs/compose/theming/theme-inheritance.md",
          "dev-docs/compose/theming/theme-styling.md",
          "dev-docs/framework/advanced/README.md",
          "dev-docs/framework/advanced/cookie-consent.md",
          "dev-docs/framework/advanced/data-access-deep-dive/README.md",
          "dev-docs/framework/advanced/data-access-deep-dive/database-batch-operations.md",
          "dev-docs/framework/advanced/data-access-deep-dive/dbcontextfactory.md",
          "dev-docs/framework/advanced/data-access-deep-dive/dbcontextscope.md",
          "dev-docs/framework/advanced/data-access-deep-dive/search-query-expressions.md",
          "dev-docs/framework/advanced/data-access-deep-dive/useful-extensions.md",
          "dev-docs/framework/advanced/generic-attributes.md",
          "dev-docs/framework/advanced/linkresolver.md",
          "dev-docs/framework/advanced/native-libraries.md",
          "dev-docs/framework/advanced/qr-codes.md",
          "dev-docs/framework/advanced/sync-mapping.md",
          "dev-docs/framework/advanced/troubleshooting.md",
          "dev-docs/framework/advanced/type-conversion.md",
          "dev-docs/framework/commerce/README.md",
          "dev-docs/framework/commerce/cart.md",
          "dev-docs/framework/commerce/catalog.md",
          "dev-docs/framework/commerce/creating-a-payment-provider.md",
          "dev-docs/framework/commerce/pricing.md",
          "dev-docs/framework/commerce/rules-engine.md",
          "dev-docs/framework/commerce/shipment.md",
          "dev-docs/framework/commerce/tax.md",
          "dev-docs/framework/content/README.md",
          "dev-docs/framework/content/imaging.md",
          "dev-docs/framework/content/localization.md",
          "dev-docs/framework/content/media-system-and-imaging.md",
          "dev-docs/framework/content/menus.md",
          "dev-docs/framework/content/multistore.md",
          "dev-docs/framework/content/page-builder-and-blocks.md",
          "dev-docs/framework/content/seo.md",
          "dev-docs/framework/content/topics-and-pages.md",
          "dev-docs/framework/content/widgets.md",
          "dev-docs/framework/platform/README.md",
          "dev-docs/framework/platform/bootstrapping.md",
          "dev-docs/framework/platform/caching.md",
          "dev-docs/framework/platform/configuration.md",
          "dev-docs/framework/platform/data-modelling/README.md",
          "dev-docs/framework/platform/data-modelling/model-mapping.md",
          "dev-docs/framework/platform/database-migrations.md",
          "dev-docs/framework/platform/diagnostics.md",
          "dev-docs/framework/platform/events.md",
          "dev-docs/framework/platform/export.md",
          "dev-docs/framework/platform/hooks.md",
          "dev-docs/framework/platform/identity.md",
          "dev-docs/framework/platform/import.md",
          "dev-docs/framework/platform/io-abstraction.md",
          "dev-docs/framework/platform/logging.md",
          "dev-docs/framework/platform/modularity-and-providers.md",
          "dev-docs/framework/platform/output-cache.md",
          "dev-docs/framework/platform/scheduling.md",
          "dev-docs/framework/platform/search.md",
          "dev-docs/framework/platform/security.md",
          "dev-docs/framework/platform/templating.md",
          "dev-docs/framework/platform/validation.md",
          "dev-docs/framework/web-api/README.md",
          "dev-docs/framework/web-api/appendix.md",
          "dev-docs/framework/web-api/authentication.md",
          "dev-docs/framework/web-api/breaking-changes-in-web-api-5.md",
          "dev-docs/framework/web-api/examples/README.md",
          "dev-docs/framework/web-api/examples/customers.md",
          "dev-docs/framework/web-api/examples/importprofiles.md",
          "dev-docs/framework/web-api/examples/orders.md",
          "dev-docs/framework/web-api/examples/products.md",
          "dev-docs/framework/web-api/help-and-tools.md",
          "dev-docs/framework/web-api/prerequisites.md",
          "dev-docs/framework/web-api/web-api-in-detail.md",
          "dev-docs/getting-started/architecture-overview.md",
          "dev-docs/getting-started/data-access.md",
          "dev-docs/getting-started/dependency-injection.md",
          "dev-docs/getting-started/deployment-and-build.md",
          "dev-docs/getting-started/domain.md",
          "dev-docs/getting-started/how-to-contribute.md",
          "dev-docs/getting-started/source-code-organization.md",
          "dev-docs/readme/coding-standards.md"
        ],
        "fileTypes": {
          ".sh": 9,
          ".md": 121,
          ".yml": 6,
          ".json": 4,
          ".props": 6,
          ".dockerignore": 1,
          ".dockerfile": 2,
          ".sln": 2,
          ".png": 18,
          ".cmd": 6,
          ".ps1": 1,
          ".bat": 1,
          ".config": 1,
          ".cs": 6,
          ".targets": 4,
          ".csproj": 2,
          ".dotsettings": 1,
          ".dll": 2,
          ".proj": 1
        }
      }
    },
    {
      "id": 1141941601,
      "name": "fuji-web",
      "displayName": "fuji web",
      "description": "Fuji is an AI agent that lives in your browser's sidepanel. You can now get tasks done online with a single command!",
      "summary": "The Problem\nNavigating the web can be tedious. Need to fill out a form, scrape some data, or perform a repetitive task? You’re stuck clicking and typing while the web does its usual dance. Enter Fuji-Web, your AI sidekick that can automate tasks with a single command. \n\nWhat This Does\nFuji-Web lives in your browser's sidepanel and understands user intent to automate tasks. The manifest.js file is your entry point for the extension, handling configuration and permissions. After setting up your OpenAI or Anthropic API key, just type your task in the sidepanel and let Fuji do the heavy lifting.\n\nWant to build from source? Check out package.json and jest.config.js for dependencies and testing configurations. If you're diving into the code, src has the main logic where the magic happens. \n\nReal-World Use\nImagine you're a data analyst. You frequently extract tables from web pages. Instead of manually copying and pasting, you could tell Fuji: \"Extract the sales data table from this page.\" Fuji recognizes the table structure and handles the extraction. That’s a few clicks saved, and you can focus on actual analysis instead of data wrangling.\n\nCode Snippet\n\n// In your API call function\nconst response = await fetch(url, {\n    method: 'POST',\n    headers: {\n        'Authorization': Bearer ${apiKey},\n        'Content-Type': 'application/json',\n    },\n    body: JSON.stringify({ task: 'extract_table', pageUrl: currentPageUrl }),\n});\n\nThe Bottom Line\nFuji-Web is a nifty tool for anyone tired of mundane web tasks. It’s a solid project if you often find yourself repeating the same actions online. Just be aware that it might not be the best fit for small, quick jobs—sometimes it's just easier to do it yourself. If you're looking to boost productivity while surfing the web, give it a shot. And if you're not into browser extensions, well, this isn't going to change your mind.",
      "url": "https://github.com/yebeai/fuji-web",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "normal-computing/fuji-web",
        "url": "https://github.com/normal-computing/fuji-web",
        "stars": 585
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 25, 2026",
      "updatedAt": "January 25, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 164,
        "directories": {
          "(root)": 25,
          ".github": 8,
          ".husky": 2,
          "media": 1,
          "public": 1,
          "src": 110,
          "test-utils": 1,
          "utils": 16
        },
        "languages": {
          "Markdown": 7,
          "YAML": 6,
          "JavaScript": 7,
          "JSON": 5,
          "SCSS": 4,
          "TSX": 33,
          "TypeScript": 70,
          "HTML": 7,
          "CSS": 9
        },
        "frameworks": [
          "React",
          "Tailwind"
        ],
        "packageManager": "pnpm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "src/common/App.tsx",
          "src/common/CustomKnowledgeBase/index.tsx",
          "src/helpers/index.ts",
          "src/helpers/knowledge/index.ts",
          "src/pages/background/index.ts",
          "src/pages/content/index.ts",
          "src/pages/content/mainWorld/index.ts",
          "src/pages/devtools/index.html",
          "src/pages/devtools/index.ts",
          "src/pages/newtab/index.html",
          "src/pages/newtab/index.tsx",
          "src/pages/options/index.html",
          "src/pages/options/index.tsx",
          "src/pages/panel/index.html",
          "src/pages/panel/index.tsx",
          "src/pages/permission/index.html",
          "src/pages/popup/index.html",
          "src/pages/popup/index.tsx",
          "src/pages/sidepanel/index.html",
          "src/pages/sidepanel/index.tsx",
          "utils/manifest-parser/index.ts",
          "utils/reload/interpreter/index.ts"
        ],
        "configFiles": [
          ".env.example",
          ".eslintrc",
          ".prettierrc",
          "jest.config.js",
          "package.json",
          "tailwind.config.js",
          "tsconfig.json",
          "vite.config.ts"
        ],
        "dependencies": [
          "package.json"
        ],
        "testFiles": [
          ".github/workflows/test.yml",
          "src/helpers/shrinkHTML/templatize.test.ts",
          "test-utils/jest.setup.js"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "CONTRIBUTING_KNOWLEDGE.md",
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".example": 1,
          ".md": 7,
          ".yml": 5,
          ".js": 7,
          ".png": 2,
          ".json": 5,
          ".yaml": 1,
          ".svg": 1,
          ".scss": 4,
          ".tsx": 33,
          ".ts": 70,
          ".html": 7,
          ".css": 9,
          ".mjs": 1
        }
      }
    },
    {
      "id": 1141918485,
      "name": "awesome-os-setup",
      "displayName": "awesome os setup",
      "description": " Windows, Linux & MacOS automated scripts & docs to improve your UX & productivity (including WSL2, conda, GPU drivers & development tools)",
      "summary": "The Problem\nSetting up your development environment can be a nightmare. Between installing essential tools, configuring terminals, and dealing with OS-specific quirks, you can waste hours just trying to get everything right. If you’re juggling multiple operating systems like Windows, Linux, and macOS, the pain multiplies.\n\nWhat This Does\nEnter the awesome-os-setup repo. It provides automated scripts and documentation to get your OS set up quickly and consistently. The installunix.sh and installwindows.ps1 scripts are your one-stop installers—just run them and watch as they handle everything from package installations to terminal configurations. The unified package catalog in src/awesomeos/config/packages.yaml means you don't have to hunt down dependencies for each OS. \n\nAdditionally, the repo includes a Python TUI (main.py) that detects your OS and offers a menu of system actions, making it easier to manage your environment without diving deep into the command line. \n\nReal-World Use\nImagine you’re setting up a new machine for development. You pop open your terminal and run:\n\nsh -c \"$(wget https://raw.githubusercontent.com/AmineDjeghri/awesome-os-setup/main/installunix.sh -O -)\"\n\nor on Windows:\n\niex ((New-Object System.Net.WebClient).DownloadString('https://raw.githubusercontent.com/AmineDjeghri/awesome-os-setup/main/install_windows.ps1'))\n\nThese commands will automatically install Zsh, Oh My Zsh, and your preferred terminal tools. If you're working with WSL, the repo also provides utilities to manage your distros, making it easy to switch between Linux environments without the usual hassle.\n\nThe Bottom Line\nawesome-os-setup is a decent solution for anyone tired of manual setups across multiple OSs. The scripts are straightforward and save time, but they might feel overkill if you're only working in one environment. If you bounce between Windows and Linux frequently, this is worth a look; otherwise, stick to manual setups for simplicity.",
      "url": "https://github.com/yebeai/awesome-os-setup",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "AmineDjeghri/awesome-os-setup",
        "url": "https://github.com/AmineDjeghri/awesome-os-setup",
        "stars": 535
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 25, 2026",
      "updatedAt": "January 25, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 101,
        "directories": {
          "(root)": 13,
          ".github": 10,
          "docs": 16,
          "makefiles": 7,
          "scripts": 1,
          "src": 51,
          "tests": 3
        },
        "languages": {
          "YAML": 14,
          "Markdown": 12,
          "Shell": 3,
          "TOML": 2,
          "Python": 29,
          "JSON": 6,
          "CSS": 3,
          "HTML": 2,
          "JavaScript": 1
        },
        "frameworks": [
          "Django",
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "src/awesome_os/frontend/main.py"
        ],
        "configFiles": [
          ".env.example",
          "Makefile",
          "pyproject.toml",
          "tests/archlinux/Dockerfile"
        ],
        "dependencies": [
          "pyproject.toml"
        ],
        "testFiles": [
          ".github/workflows/tests.yaml",
          "makefiles/test.mk",
          "tests/archlinux/Dockerfile",
          "tests/archlinux/README.md",
          "tests/archlinux/run.sh"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "docs/JetBrainsMonoNerdFont-Regular.zip",
          "docs/android-tv/readme.md",
          "docs/apps/apps_configuration_and_shorcuts.md",
          "docs/apps/awesome_websites_browser_extensions.md",
          "docs/apps_configuration_and_shorcuts.md",
          "docs/awesome_websites_browser_extensions.md",
          "docs/home-assistant/readme.md",
          "docs/images/desktop_with_terminals.jpeg",
          "docs/images/logo.png",
          "docs/images/windows_setup_image.jpeg",
          "docs/images/windows_wsl_terminal.png",
          "docs/images/windows_wsl_terminal_taskbar.png",
          "docs/linux/README.md",
          "docs/macos_darwin/README.md",
          "docs/macos_darwin/SCR-20241117-sbna.png",
          "docs/windows_workflow/README.md",
          "tests/archlinux/README.md"
        ],
        "fileTypes": {
          ".example": 1,
          ".yml": 4,
          ".yaml": 10,
          ".md": 12,
          ".zip": 3,
          ".jpeg": 2,
          ".png": 4,
          ".sh": 2,
          ".ps1": 1,
          ".mk": 7,
          ".toml": 2,
          ".py": 29,
          ".rayconfig": 1,
          ".json": 6,
          ".zsh": 1,
          ".css": 3,
          ".html": 2,
          ".js": 1,
          ".bat": 1,
          ".reg": 2,
          ".lock": 1
        }
      }
    },
    {
      "id": 1141910416,
      "name": "SnackBase",
      "displayName": "SnackBase",
      "description": "SnackBase is a Python/FastAPI-based BaaS providing auto-generated REST APIs, multi-tenancy, row-level security, authentication, enterprise OAuth/SAML, and comprehensive admin UI.",
      "summary": "In today's fast-paced development environment, teams often face the daunting challenge of building scalable backends that can adapt to a myriad of user needs without sacrificing security or performance. As applications grow in complexity, developers must also contend with the intricacies of multi-tenancy, user authentication, and real-time data access. SnackBase emerges as a robust solution to these challenges, offering developers a backend-as-a-service (BaaS) framework that not only accelerates the development process but also provides essential features like auto-generated REST APIs, multi-tenancy, and comprehensive security protocols.\n\nSnackBase leverages Python and FastAPI to deliver a self-hosted BaaS solution that stands out in its capability to generate REST APIs dynamically while supporting row-level security and enterprise-grade authentication mechanisms such as OAuth and SAML. The repository’s architecture is thoughtfully designed, separating concerns into distinct layers, as evidenced by its file structure. For instance, the .agent/rules/ directory outlines various rules that govern API routes, authentication, and multi-tenancy, indicating a clear emphasis on modularity and maintainability. With approximately 525 files and 195,000 lines of code, SnackBase encapsulates a mature and feature-rich environment that rivals existing solutions while allowing for customization and self-hosting.\n\nDiving deeper into its architecture, SnackBase employs a clean architecture model, where the domain, application, and infrastructure layers are distinctly separated. This separation fosters easier testing and maintenance, making use of patterns such as the hook system outlined in .agent/rules/hooks-system.md for extensibility. The inclusion of a robust audit logging feature, as described in .agent/rules/audit-logging.md, ensures that developers can keep track of user actions, an essential aspect for compliance and security in enterprise applications. Furthermore, the database migration management using Alembic—highlighted by the alembic/ directory—facilitates seamless schema evolution, which is crucial as applications scale and change over time.\n\nThe practical applications of SnackBase are numerous. Consider a SaaS startup aiming to provide a platform for various clients, each with unique data requirements. SnackBase makes it simple to implement multi-tenancy, where each client’s data is securely isolated while sharing the same infrastructure. Additionally, for developers building internal tools, SnackBase’s auto-generated admin UI allows for rapid deployment of management interfaces, dramatically reducing the time from concept to production. Another compelling scenario is for enterprises needing to integrate complex authentication workflows. SnackBase’s built-in support for OAuth and SAML can streamline user management while ensuring compliance with security policies.\n\nUltimately, SnackBase represents a significant advancement in the realm of backend development. It not only simplifies the complexities associated with building scalable and secure applications but also provides a foundation that can adapt to diverse use cases. By adopting SnackBase, developers can focus on delivering business value instead of getting bogged down by backend intricacies. As the ecosystem of open-source projects continues to expand, solutions like SnackBase highlight the importance of embracing flexibility and security in application development, making it a pivotal choice for modern software engineers.",
      "url": "https://github.com/yebeai/SnackBase",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "lalitgehani/SnackBase",
        "url": "https://github.com/lalitgehani/SnackBase",
        "stars": 118
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 25, 2026",
      "updatedAt": "January 25, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".agent": 11,
          "(root)": 11,
          "alembic": 22,
          "docs": 29,
          "examples": 127
        },
        "languages": {
          "Markdown": 46,
          "Python": 21,
          "YAML": 1,
          "JavaScript": 4,
          "HTML": 4,
          "JSON": 20,
          "TSX": 51,
          "CSS": 7,
          "TypeScript": 26
        },
        "frameworks": [
          "React",
          "Express",
          "Docker"
        ],
        "packageManager": "npm",
        "hasDocker": true,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "examples/feature-voting-app/index.html",
          "examples/feature-voting-app/src/App.tsx",
          "examples/feature-voting-app/src/types/index.ts",
          "examples/realtime-demo-app/index.html",
          "examples/realtime-demo-app/src/App.tsx",
          "examples/realtime-demo-app/src/types/index.ts",
          "examples/to-do-app-single-tenant/index.html",
          "examples/to-do-app-single-tenant/src/App.tsx",
          "examples/to-do-app-single-tenant/src/types/index.ts",
          "examples/to-do-app/index.html",
          "examples/to-do-app/src/App.tsx",
          "examples/to-do-app/src/types/index.ts"
        ],
        "configFiles": [
          ".env.example",
          "Dockerfile",
          "docker-compose.yml",
          "examples/feature-voting-app/.env.example",
          "examples/feature-voting-app/package.json",
          "examples/feature-voting-app/tsconfig.json",
          "examples/feature-voting-app/vite.config.ts",
          "examples/realtime-demo-app/.env.example",
          "examples/realtime-demo-app/package.json",
          "examples/realtime-demo-app/tsconfig.json",
          "examples/realtime-demo-app/vite.config.ts",
          "examples/to-do-app-single-tenant/.env.example",
          "examples/to-do-app-single-tenant/package.json",
          "examples/to-do-app-single-tenant/tsconfig.json",
          "examples/to-do-app-single-tenant/vite.config.ts",
          "examples/to-do-app/.env.example",
          "examples/to-do-app/package.json",
          "examples/to-do-app/tsconfig.json"
        ],
        "dependencies": [
          "examples/feature-voting-app/package-lock.json",
          "examples/feature-voting-app/package.json",
          "examples/realtime-demo-app/package-lock.json",
          "examples/realtime-demo-app/package.json",
          "examples/to-do-app-single-tenant/package-lock.json",
          "examples/to-do-app-single-tenant/package.json",
          "examples/to-do-app/package-lock.json",
          "examples/to-do-app/package.json"
        ],
        "testFiles": [
          "docs/guides/testing.md"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "alembic/README",
          "docs/README.md",
          "docs/api-examples.md",
          "docs/architecture.md",
          "docs/concepts/README.md",
          "docs/concepts/authentication.md",
          "docs/concepts/collections.md",
          "docs/concepts/multi-tenancy.md",
          "docs/concepts/security.md",
          "docs/deployment.md",
          "docs/frontend.md",
          "docs/guides/README.md",
          "docs/guides/adding-api-endpoints.md",
          "docs/guides/creating-custom-hooks.md",
          "docs/guides/extending-snackbase.md",
          "docs/guides/oauth-overview.md",
          "docs/guides/oauth-setup-apple.md",
          "docs/guides/oauth-setup-github.md",
          "docs/guides/oauth-setup-google.md",
          "docs/guides/oauth-setup-microsoft.md",
          "docs/guides/saml-setup-azure-ad.md",
          "docs/guides/saml-setup-generic.md",
          "docs/guides/saml-setup-okta.md",
          "docs/guides/testing.md",
          "docs/guides/writing-rules.md",
          "docs/hooks.md",
          "docs/macros.md",
          "docs/permissions.md",
          "docs/quick-start.md",
          "docs/realtime.md",
          "examples/feature-voting-app/README.md",
          "examples/realtime-demo-app/README.md",
          "examples/to-do-app-single-tenant/README.md",
          "examples/to-do-app/README.md"
        ],
        "fileTypes": {
          ".md": 46,
          ".example": 5,
          ".ini": 1,
          ".py": 21,
          ".mako": 1,
          ".yml": 1,
          ".js": 4,
          ".html": 4,
          ".json": 20,
          ".tsx": 51,
          ".css": 7,
          ".ts": 26,
          ".svg": 3
        }
      }
    },
    {
      "id": 1141897721,
      "name": "drawdb",
      "displayName": "drawdb",
      "description": "Free, simple, and intuitive online database diagram editor and SQL generator.",
      "summary": "The Problem\nDesigning databases is often a headache. You’ve got to visualize relationships, write SQL, and if you're lucky, you can do it all without losing your mind in a sea of complex tools. Most solutions either require a steep learning curve or force you to sign up for accounts you don’t want. Enter drawDB—a straightforward web-based database diagram editor that lets you whip up ER diagrams and generate SQL scripts without the usual fuss.\n\nWhat This Does\ndrawDB gives you a simple drag-and-drop interface to create database schemas right in your browser. The core files, like src/App.jsx and the various animation components in src/animations/, help ensure a smooth user experience. You can clone the repo, run npm install, and fire it up locally with npm run dev. Want to deploy it? Just build with npm run build or use Docker with the Dockerfile and compose.yml for easy containerization.\n\nThe project is structured to keep things clean. For instance, the src/api/ folder contains essential APIs like email.js for sending notifications or gists.js for handling user-generated content. You can even tweak configurations with .env.sample if you want to set up sharing capabilities.\n\nReal-World Use\nImagine you're tasked with designing a database for a new app. You open drawDB, create your tables with a few clicks, and lay out the relationships visually. Need SQL? Just click a button to export it. No need to write a single line of code by hand. If your team wants to collaborate, set up the server following the instructions in the README, and you're good to go.\n\ndocker run -p 3000:80 drawdb\n\nNow your teammates can access the editor from their browsers.\n\nThe Bottom Line\ndrawDB is a solid tool for anyone needing to visualize and generate SQL without the typical overhead. It's perfect for small projects or for developers looking to prototype quickly. Just remember, if your project scales up, you might need something more robust. But for simplicity and ease of use, it's hard to beat.",
      "url": "https://github.com/yebeai/drawdb",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "drawdb-io/drawdb",
        "url": "https://github.com/drawdb-io/drawdb",
        "stars": 36771
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 25, 2026",
      "updatedAt": "January 25, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 15,
          ".github": 5,
          "public": 3,
          "src": 177
        },
        "languages": {
          "YAML": 4,
          "Markdown": 4,
          "JSON": 3,
          "HTML": 1,
          "JavaScript": 78,
          "JSX": 77,
          "CSS": 2
        },
        "frameworks": [
          "React",
          "Express",
          "Docker"
        ],
        "packageManager": "npm",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "index.html",
          "src/App.jsx",
          "src/components/CodeEditor/index.jsx",
          "src/hooks/index.js"
        ],
        "configFiles": [
          ".eslintrc.cjs",
          ".prettierrc.json",
          "Dockerfile",
          "package.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [
          "src/components/EditorSidePanel/NotesTab/NoteInfo.jsx",
          "src/components/EditorSidePanel/NotesTab/NotesTab.jsx",
          "src/components/EditorSidePanel/NotesTab/SearchBar.jsx"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".sample": 1,
          ".cjs": 1,
          ".yml": 4,
          ".md": 4,
          ".json": 3,
          ".png": 23,
          ".html": 1,
          ".js": 78,
          ".ico": 1,
          ".txt": 1,
          ".jsx": 77,
          ".css": 2
        }
      }
    },
    {
      "id": 1141883561,
      "name": "OCRFlux",
      "displayName": "OCRFlux",
      "description": "OCRFlux is a lightweight yet powerful multimodal toolkit that significantly advances PDF-to-Markdown conversion, excelling in complex layout handling, complicated table parsing and cross-page content merging.",
      "summary": "In the digital age, the ability to convert complex documents into accessible formats is more crucial than ever. Many businesses and researchers grapple with the inefficient and often inaccurate conversion of PDFs and images into readable text formats. This challenge is particularly pronounced when dealing with documents that contain intricate layouts, such as academic papers, reports, and technical manuals. The need for a solution that can decode these complexities while maintaining fidelity to the original content is what drives the development of tools like OCRFlux.\n\nOCRFlux aims to bridge the gap in PDF-to-Markdown conversion by offering a multimodal toolkit designed for superior parsing capabilities. Unlike conventional OCR tools that may falter with complex layouts or cross-page content, OCRFlux leverages state-of-the-art techniques to ensure that text is extracted in a natural reading order, even in the presence of multi-column layouts, figures, and insets. Its ability to handle complicated tables and equations, combined with seamless cross-page merging of tables and paragraphs, sets it apart from existing solutions. The underlying architecture utilizes a 3B parameter Vision-Language Model (VLM), allowing it to operate efficiently on consumer-grade GPUs, such as the GTX 3090.\n\nA closer examination of the file structure reveals the modular design of OCRFlux, which aids in its extensibility and maintainability. The core functionality resides in the ocrflux directory, where critical scripts such as inference.py, pipeline.py, and jsonltomarkdown.py orchestrate the conversion process. The eval directory is equally significant, containing various evaluation scripts and benchmarks like evalpageto_markdown.py to assess performance against established models. Furthermore, the presence of a Dockerfile indicates that OCRFlux is designed with containerization in mind, promoting easy deployment across different environments. This architectural decision is vital for developers who wish to integrate OCRFlux into their existing workflows without the hassles of environment compatibility.\n\nDevelopers can envision several practical use cases for OCRFlux. For instance, academic institutions could utilize this toolkit to digitize large volumes of research papers, streamlining the process of converting inaccessible PDFs into Markdown files that are easily searchable and indexable. Similarly, businesses dealing with legacy documents can leverage OCRFlux to extract valuable data from historical reports, enabling data analysis and insights that were previously locked in unstructured formats. Additionally, content creators and technical writers can benefit from OCRFlux when repurposing existing documents into web-friendly formats, enhancing accessibility and user engagement.\n\nUltimately, the significance of OCRFlux lies in its potential to revolutionize the way we interact with document content. By providing a robust solution that combines advanced parsing techniques with user-friendly functionality, it empowers users to convert complex documents into structured formats effortlessly. This capability not only saves time and resources but also enhances the quality of information dissemination across various sectors. As more developers adopt and contribute to this open-source project, we can expect it to evolve further, pushing the boundaries of what is possible in document processing and accessibility.",
      "url": "https://github.com/yebeai/OCRFlux",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "chatdoc-com/OCRFlux",
        "url": "https://github.com/chatdoc-com/OCRFlux",
        "stars": 2484
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 25, 2026",
      "updatedAt": "January 25, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 35,
        "directories": {
          "(root)": 6,
          ".github": 1,
          "eval": 12,
          "images": 5,
          "ocrflux": 11
        },
        "languages": {
          "YAML": 1,
          "Markdown": 1,
          "Shell": 2,
          "Python": 21,
          "TOML": 1
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          "Dockerfile",
          "pyproject.toml"
        ],
        "dependencies": [
          "pyproject.toml"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md",
          "images/license.svg"
        ],
        "fileTypes": {
          ".yml": 1,
          ".md": 1,
          ".sh": 2,
          ".py": 21,
          ".png": 1,
          ".svg": 4,
          ".toml": 1
        }
      }
    },
    {
      "id": 1141866071,
      "name": "flight-path",
      "displayName": "flight path",
      "description": "Simulate flight path visualization using Three.js.",
      "summary": "In an era where air travel continues to demand efficiency and innovation, real-time visualization of flight paths offers an invaluable tool for both aviation professionals and enthusiasts. The ability to simulate and visualize flight data can aid airlines in optimizing routes, assist air traffic controllers in managing airspace, and provide aviation students with a hands-on learning experience. However, traditional flight simulation tools often fall short in providing a visually compelling and interactive experience. This is where the Flight Path project shines, offering a state-of-the-art 3D flight path visualization built on Three.js.\n\nThe Flight Path project is designed to create an interactive simulation of flight paths around a photorealistic Earth, leveraging WebGL for GPU-accelerated rendering. What sets this project apart is its combination of high-fidelity graphics and real-time interactivity, enabling users to visualize thousands of flights simultaneously. The architectural design of the project is modular, with a clear separation of concerns, allowing developers to easily extend functionality. For instance, the src/managers directory, which houses various control managers like FlightControlsManager.ts and EarthControlsManager.ts, encapsulates specific functionalities, making the codebase maintainable and scalable. The use of TypeScript adds type safety and enhances the development experience, allowing for better code quality and fewer runtime errors.\n\nDiving deeper into the project, the src/common directory contains essential files like Data.ts, Types.ts, and Utils.ts, which centralize data management and utility functions. This promotes reusability across different modules and simplifies the implementation of new features. The src/flights directory emphasizes the simulation aspect, with Flight.ts managing flight data and FlightUtils.ts providing utility functions for manipulating flight paths. The architecture promotes a clear flow of data and responsibilities, making it easy for new contributors to understand and integrate their features.\n\nThe Flight Path project serves multiple use cases that developers and organizations can leverage. For educational institutions, it can be an excellent tool for teaching aerodynamics and flight mechanics in real-time, allowing students to visualize theoretical concepts. Airlines can utilize the simulation for route optimization, analyzing various flight paths under different conditions. Additionally, game developers can adapt the framework for creating immersive flight simulation experiences in gaming environments, where realistic graphics and interactivity are paramount.\n\nIn conclusion, the Flight Path project represents a significant advancement in how we visualize flight data. Its combination of advanced graphics, modular architecture, and real-time interactivity makes it an essential tool for various stakeholders in the aviation sector. By providing an engaging way to simulate and analyze flight paths, this project not only enhances understanding and efficiency but also opens avenues for innovation in aviation technology. The potential applications are vast, and as the project evolves, it may well redefine standards for flight simulation tools.",
      "url": "https://github.com/yebeai/flight-path",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "jeantimex/flight-path",
        "url": "https://github.com/jeantimex/flight-path",
        "stars": 201
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1531482615713-2afd69097998?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 25, 2026",
      "updatedAt": "January 25, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 44,
        "directories": {
          "(root)": 9,
          "public": 9,
          "src": 26
        },
        "languages": {
          "JSON": 4,
          "Markdown": 1,
          "HTML": 1,
          "TypeScript": 19,
          "CSS": 1,
          "JavaScript": 1
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "index.html",
          "src/App.ts",
          "src/main.ts"
        ],
        "configFiles": [
          ".prettierrc.json",
          "package.json",
          "tsconfig.json",
          "vite.config.js"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".json": 4,
          ".md": 1,
          ".html": 1,
          ".svg": 8,
          ".jpg": 1,
          ".ts": 19,
          ".frag": 3,
          ".vert": 3,
          ".css": 1,
          ".js": 1
        }
      }
    },
    {
      "id": 1141846456,
      "name": "SimpleMem",
      "displayName": "SimpleMem",
      "description": "SimpleMem: Efficient Lifelong Memory for LLM Agents",
      "summary": "In the realm of conversational AI and large language models (LLMs), memory management remains a significant challenge. As these models engage in extended dialogues, they often grapple with retaining context and relevant information over time. This limitation can lead to fragmented conversations, where valuable insights are lost or misinterpreted. The SimpleMem project addresses this pressing issue by providing an efficient lifelong memory solution for LLM agents, enabling them to retain and utilize information across interactions seamlessly. \n\nSimpleMem stands out from other memory management systems through its innovative approach, which revolves around a three-stage pipeline aimed at maximizing information density while minimizing token usage. The key to its architecture lies in Semantic Lossless Compression, which allows SimpleMem to distill dialogue into meaningful, self-contained atomic facts. This is achieved through a process that encompasses semantic structured compression, structured indexing, and adaptive retrieval. The documentation highlights that the system not only retains context but does so in a way that enhances performance metrics, as evidenced by the reported F1 score of 43.24% at a minimal token cost of approximately 550. \n\nExamining the file structure reveals the thoughtful organization of the project. The core functionalities can be found within the MCP/reference/core/ directory, which includes essential components such as answergenerator.py, hybridretriever.py, and memorybuilder.py. These files implement the core algorithms that power SimpleMem's memory management capabilities. For instance, memorybuilder.py is crucial for constructing the semantic memory, leveraging structured indexing to evolve fragmented data into coherent insights. The presence of testing scripts, such as testref/testadvanced.py, showcases a commitment to maintaining code quality and reliability as the project evolves. The frontend components in MCP/frontend/ suggest that SimpleMem is not just a backend solution; it is designed for integration into various applications, providing a complete ecosystem for developers.\n\nDevelopers can leverage SimpleMem in several ways. One prominent use case is within customer support chatbots, where maintaining context over extended conversations can significantly improve user experience. By utilizing SimpleMem, a chatbot can recall previous interactions, thereby reducing redundancy and enhancing the relevance of responses. Another application lies in collaborative platforms where multiple users interact over time, such as project management tools. Here, SimpleMem can help retain critical project history and decisions, allowing team members to access and build upon prior discussions without losing context. Lastly, educational applications could benefit from SimpleMem by enabling personalized learning experiences that adapt based on previous interactions and user preferences.\n\nIn conclusion, SimpleMem's approach to memory management for LLM agents is not just a technical innovation; it represents a necessary evolution in how machines interact with human users over time. By prioritizing efficient memory retention and retrieval, SimpleMem allows for more coherent and meaningful conversations, which is essential in applications where context is critical. As AI continues to permeate various aspects of our lives, the importance of effective memory systems like SimpleMem cannot be overstated. Its potential to enhance user interactions makes it a project worth following and contributing to as it develops.",
      "url": "https://github.com/yebeai/SimpleMem",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "aiming-lab/SimpleMem",
        "url": "https://github.com/aiming-lab/SimpleMem",
        "stars": 3011
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1542831371-29b0f74f9713?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 25, 2026",
      "updatedAt": "January 25, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 97,
        "directories": {
          "(root)": 8,
          "MCP": 47,
          "SKILL": 22,
          "core": 4,
          "database": 1,
          "docs": 1,
          "fig": 5,
          "models": 2,
          "test_ref": 3,
          "tests": 1,
          "utils": 3
        },
        "languages": {
          "Markdown": 10,
          "Python": 62,
          "JavaScript": 1,
          "HTML": 1,
          "CSS": 1
        },
        "frameworks": [
          "Django",
          "Express"
        ],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "MCP/frontend/app.js",
          "MCP/frontend/index.html",
          "MCP/reference/main.py",
          "SKILL/simplemem-skill/src/main.py",
          "main.py"
        ],
        "configFiles": [
          "MCP/reference/requirements.txt",
          "MCP/requirements.txt",
          "SKILL/simplemem-skill/requirements.txt",
          "requirements.txt"
        ],
        "dependencies": [
          "MCP/reference/requirements.txt",
          "MCP/requirements.txt",
          "SKILL/simplemem-skill/requirements.txt",
          "requirements.txt"
        ],
        "testFiles": [
          "MCP/reference/test_locomo10.py",
          "MCP/reference/test_ref/load_dataset.py",
          "MCP/reference/test_ref/test_advanced.py",
          "MCP/reference/test_ref/utils.py",
          "test_locomo10.py",
          "test_ref/load_dataset.py",
          "test_ref/test_advanced.py",
          "test_ref/utils.py",
          "tests/test_vector_store.py"
        ],
        "docs": [
          "LICENSE",
          "MCP/README.md",
          "MCP/reference/README.md",
          "README.md",
          "SKILL/README.md",
          "SKILL/simplemem-skill/references/import-guide.md",
          "SKILL/simplemem-skill/references/openrouter-guide.md",
          "docs/PACKAGE_USAGE.md"
        ],
        "fileTypes": {
          ".md": 10,
          ".py": 62,
          ".js": 1,
          ".html": 1,
          ".css": 1,
          ".example": 3,
          ".png": 6,
          ".mp4": 2,
          ".jpg": 2,
          ".txt": 4,
          ".skill": 1
        }
      }
    },
    {
      "id": 1141836340,
      "name": "hivemind",
      "displayName": "hivemind",
      "description": "Decentralized deep learning in PyTorch. Built to train models on thousands of volunteers across the world.",
      "summary": "In an era where data is the new oil, the demand for powerful machine learning models continues to surge. Traditional centralized training methods, while effective, often fall short in leveraging distributed resources, which can lead to bottlenecks and underutilization of available computational power. Imagine a world where researchers across universities and organizations can collaboratively train large-scale deep learning models without a single point of failure or control. This vision is at the heart of Hivemind, an innovative PyTorch library designed for decentralized deep learning. By enabling model training across a distributed network of volunteers, Hivemind not only democratizes access to advanced machine learning capabilities but also enhances the resilience and scalability of training processes.\n\nHivemind stands out due to its decentralized architecture, which utilizes a Distributed Hash Table (DHT) for connectivity among nodes, eliminating the need for a master node. This approach allows for a truly peer-to-peer network where fault tolerance is built into the training process, enabling forward and backward passes to succeed even when some nodes are unresponsive. The library's decentralized parameter averaging method iteratively aggregates model updates from multiple workers, minimizing the need for global synchronization and thus reducing the overhead typically associated with distributed training. Moreover, the ability to train neural networks of arbitrary sizes using the Decentralized Mixture-of-Experts architecture opens the door for innovative approaches to model design, making it a unique asset for developers looking to push the boundaries of what deep learning can achieve.\n\nDelving into the file structure, Hivemind's organization reflects its robust architecture. The presence of multiple benchmarking scripts in the benchmarks/ directory, such as benchmarkaveraging.py and benchmarkthroughput.py, indicates an emphasis on performance evaluation and optimization. This is crucial in a decentralized setting where network conditions can vary significantly. Furthermore, the .github/workflows/ directory reveals a commitment to continuous integration and deployment, with workflows set up for running tests, checking styles, and deploying Docker images. Such automation is essential for maintaining code quality and ensuring that contributions from a diverse set of developers do not degrade the system's reliability.\n\nHivemind is not just a theoretical concept; it's already being applied in real-world scenarios. For instance, the Petals project utilizes Hivemind to create a decentralized platform for inference and fine-tuning of large language models, effectively leveraging the collective power of many contributors. Similarly, the Training Transformers Together initiative showcases how collaborative training can yield impressive results in generating complex models like text-to-image transformers. These use cases illustrate how Hivemind can facilitate significant advancements in natural language processing and other domains by allowing diverse teams to share resources and expertise seamlessly.\n\nThe relevance of Hivemind in today’s landscape cannot be overstated. As the demand for powerful AI models grows, the need for innovative solutions that can harness distributed resources becomes critical. By allowing decentralized training, Hivemind addresses the challenges of data privacy, resource allocation, and model robustness—all of which are crucial for the future of AI development. As more developers recognize the potential of decentralized collaboration, projects like Hivemind could redefine how machine learning models are built and trained, paving the way for breakthroughs that may have once seemed unattainable.",
      "url": "https://github.com/yebeai/hivemind",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "learning-at-home/hivemind",
        "url": "https://github.com/learning-at-home/hivemind",
        "stars": 2391
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1607799279861-4dd421887fb3?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 25, 2026",
      "updatedAt": "January 25, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 198,
        "directories": {
          ".github": 9,
          "(root)": 14,
          "benchmarks": 5,
          "docs": 23,
          "examples": 7,
          "hivemind": 105,
          "tests": 35
        },
        "languages": {
          "Markdown": 12,
          "YAML": 9,
          "Python": 145,
          "CSS": 1,
          "reStructuredText": 7,
          "Protocol Buffers": 7,
          "TOML": 1
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": "pip",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "hivemind/moe/server/server.py",
          "setup.py"
        ],
        "configFiles": [
          "Dockerfile",
          "docs/Makefile",
          "examples/albert/requirements.txt",
          "pyproject.toml",
          "requirements.txt",
          "setup.py"
        ],
        "dependencies": [
          "examples/albert/requirements.txt",
          "pyproject.toml",
          "requirements.txt"
        ],
        "testFiles": [
          ".github/workflows/run-tests-on-modal.yml",
          ".github/workflows/run-tests.yml",
          "hivemind/proto/test.proto",
          "tests/conftest.py",
          "tests/test_allreduce.py",
          "tests/test_allreduce_fault_tolerance.py",
          "tests/test_auth.py",
          "tests/test_averaging.py",
          "tests/test_cli_scripts.py",
          "tests/test_compression.py",
          "tests/test_connection_handler.py",
          "tests/test_custom_experts.py",
          "tests/test_dht.py",
          "tests/test_dht_crypto.py",
          "tests/test_dht_experts.py",
          "tests/test_dht_node.py",
          "tests/test_dht_protocol.py",
          "tests/test_dht_schema.py",
          "tests/test_dht_storage.py",
          "tests/test_dht_validation.py",
          "tests/test_expert_backend.py",
          "tests/test_moe.py",
          "tests/test_multiaddr.py",
          "tests/test_multiaddr_protocols.py",
          "tests/test_multiaddr_transforms.py",
          "tests/test_optimizer.py",
          "tests/test_p2p_daemon.py",
          "tests/test_p2p_daemon_bindings.py",
          "tests/test_p2p_servicer.py",
          "tests/test_relays.py",
          "tests/test_routing.py",
          "tests/test_start_server.py",
          "tests/test_training.py",
          "tests/test_util_modules.py",
          "tests/test_utils/custom_networks.py",
          "tests/test_utils/dht_swarms.py",
          "tests/test_utils/networking.py",
          "tests/test_utils/p2p_daemon.py"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "docs/Makefile",
          "docs/_static/bug.gif",
          "docs/_static/bug.odp",
          "docs/_static/bug_preview.gif",
          "docs/_static/dht.odp",
          "docs/_static/dht.png",
          "docs/_static/favicon.png",
          "docs/_static/fix_rtd.css",
          "docs/conf.py",
          "docs/index.rst",
          "docs/make.bat",
          "docs/modules/averaging.rst",
          "docs/modules/client.rst",
          "docs/modules/dht.rst",
          "docs/modules/index.rst",
          "docs/modules/optim.rst",
          "docs/modules/server.rst",
          "docs/user/acknowledgements.md",
          "docs/user/benchmarks.md",
          "docs/user/contributing.md",
          "docs/user/dht.md",
          "docs/user/moe.md",
          "docs/user/quickstart.md",
          "examples/albert/README.md"
        ],
        "fileTypes": {
          ".md": 12,
          ".yml": 9,
          ".cff": 1,
          ".py": 145,
          ".gif": 2,
          ".odp": 2,
          ".png": 2,
          ".css": 1,
          ".rst": 7,
          ".bat": 1,
          ".txt": 4,
          ".proto": 7,
          ".toml": 1
        }
      }
    },
    {
      "id": 1140388909,
      "name": "flux2.c",
      "displayName": "flux2.c",
      "description": "Flux 2 image generation model pure C inference",
      "summary": "In an era where image generation models have become ubiquitous, the challenge lies not just in creating compelling visual content but in doing so under constraints that many traditional frameworks cannot accommodate. For developers working on resource-limited environments or those looking for pure performance without the overhead of a Python stack, the need for a lightweight, efficient solution is pressing. Enter Flux 2, a pure C inference model that leverages the power of image generation without requiring a complex setup or extensive dependencies. This project addresses the pain points of memory consumption and dependency management that often plague developers attempting to implement machine learning models.\n\nFlux 2 is a unique implementation of the FLUX.2-klein-4B model, designed specifically for generating images from text prompts. What sets it apart is its complete reliance on the C programming language and its minimal dependency footprint. Unlike many modern frameworks that require Python runtimes and complex installations, Flux 2 stands alone, functioning seamlessly in environments with as little as 8GB of RAM. The project boasts optional MPS and BLAS acceleration, facilitating performance optimization on specific hardware, particularly on Apple Silicon. The README highlights its ability to run in contexts where Python libraries like TensorFlow or PyTorch might falter, making it a robust choice for developers with unique constraints.\n\nDiving into the architecture, the file structure reveals a well-organized setup that reflects the project’s functionality. Key files such as flux.c, fluximage.c, and fluxtransformer.c encapsulate the core logic for image generation and transformation, while fluxtokenizer.c and fluxqwen3_tokenizer.c handle the intricacies of text processing. This separation of concerns allows for easier maintenance and potential extensions in the future. The inclusion of Makefile enables straightforward builds tailored to the desired backend—whether it’s the high-performance MPS for Apple devices or a more generic approach. Moreover, the debug directory suggests an emphasis on testing and validation, essential for ensuring the model's functionality in diverse scenarios.\n\nDevelopers can leverage Flux 2 in various contexts. For instance, in a scenario where a graphic designer needs to generate quick concept art based on descriptive prompts, Flux 2 allows for rapid iteration without the overhead of a heavyweight framework. Similarly, researchers working on low-resource devices can utilize the model for real-time image generation without sacrificing performance. Finally, game developers looking to create dynamic textures or assets on-the-fly can integrate Flux 2 into their pipeline, enabling a more fluid creative process.\n\nIn a landscape rich with options, Flux 2 offers a compelling alternative for image generation that emphasizes efficiency and simplicity. Its pure C implementation ensures that it can run in environments where traditional frameworks cannot, addressing the growing need for lightweight machine learning tools. By focusing on memory efficiency and eliminating unnecessary dependencies, Flux 2 not only empowers developers working in constrained settings but also challenges the status quo of machine learning deployment. For those ready to explore this new frontier, Flux 2 stands as a testament to the potential of low-level programming in the realm of modern AI applications.",
      "url": "https://github.com/yebeai/flux2.c",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "antirez/iris.c",
        "url": "https://github.com/antirez/iris.c",
        "stars": 1863
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 23, 2026",
      "updatedAt": "January 23, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 44,
        "directories": {
          "(root)": 29,
          "debug": 2,
          "images": 7,
          "test_vectors": 6
        },
        "languages": {
          "Markdown": 4,
          "Python": 4,
          "Shell": 1,
          "C": 13,
          "C/C++ Header": 6
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "main.c"
        ],
        "configFiles": [
          "Makefile"
        ],
        "dependencies": [],
        "testFiles": [
          "run_test.py",
          "test_vectors/README.md",
          "test_vectors/img2img_input_256x256.png",
          "test_vectors/reference_1step_64x64_seed42.png",
          "test_vectors/reference_2step_64x64_seed42.png",
          "test_vectors/reference_4step_512x512_seed123.png",
          "test_vectors/reference_img2img_256x256_seed456.png"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "images/README.md",
          "test_vectors/README.md"
        ],
        "fileTypes": {
          ".md": 4,
          ".py": 4,
          ".sh": 1,
          ".c": 13,
          ".h": 6,
          ".m": 1,
          ".metal": 1,
          ".png": 11
        }
      }
    },
    {
      "id": 1140078061,
      "name": "Cuda-Rocm-port",
      "displayName": "Cuda Rocm port",
      "description": "Open source neural network chess engine with GPU acceleration and broad hardware support.",
      "summary": "In an era where artificial intelligence (AI) and machine learning (ML) are making unprecedented strides, the world of chess has also been transformed. Traditional chess engines, while powerful, often lack the nuanced understanding that neural networks can provide. The challenge lies in harnessing this potential while ensuring compatibility across a vast array of hardware. This is where the Cuda-Rocm-port repository comes into play. It addresses a critical need: to create a neural network chess engine that is not only capable of deep strategic thinking but also optimized for GPU acceleration across various platforms.\n\nCuda-Rocm-port builds upon the foundations of the LeelaChessZero project, leveraging neural network architectures to improve the decision-making process in chess. Its unique selling point lies in its ability to utilize GPU acceleration, which significantly enhances computation speed and performance. Unlike traditional engines that might rely solely on CPU calculations, Cuda-Rocm-port taps into the power of graphics processing units (GPUs), making it possible to evaluate millions of positions in a fraction of the time. The integration of multiple backends such as CUDA, SYCL, and OpenBLAS ensures that the engine is adaptable, catering to both NVIDIA and AMD hardware. This flexibility sets it apart in a field where performance and accessibility are paramount.\n\nDiving deeper into its architecture, we can glean valuable insights from the file structure. The presence of .circleci and .appveyor.yml files indicates a commitment to continuous integration and deployment, which is essential for maintaining code quality and automating testing processes. The inclusion of BUILD scripts for different platforms (like build.sh and build-sycl.cmd) showcases a multi-faceted approach to building the engine, allowing developers to easily compile the codebase on various operating systems. Moreover, the .clang-format file suggests a standardized coding style, which is crucial for collaborative projects. The CITATION.cff and AUTHORS files reflect an academic appreciation for the contributions made by the community, fostering an environment of collaboration and acknowledgment that can drive innovation.\n\nDevelopers can leverage Cuda-Rocm-port in several specific scenarios. First, for AI researchers, this repository provides a robust platform to experiment with neural network architectures in a familiar domain. The ability to utilize GPU acceleration opens new avenues for training models that can outperform traditional engines in complex positions. Secondly, game developers interested in integrating advanced AI into their products can utilize this chess engine as a backend, offering their users a challenging opponent. Lastly, educators and hobbyists can use Cuda-Rocm-port as an example of how neural networks can be applied to classical problems, serving as a practical case study for those learning about AI and machine learning.\n\nIn conclusion, Cuda-Rocm-port is more than just a neural network chess engine; it represents a significant step forward in the intersection of AI and gaming. By combining advanced neural network techniques with the computational power of GPUs and ensuring broad hardware compatibility, it opens the door for a new generation of chess engines that can think deeply and quickly. For developers, this repository is not just a tool; it is a testament to the potential of open-source collaboration in advancing technology. Embracing such projects is crucial as we move towards an increasingly AI-driven future.",
      "url": "https://github.com/yebeai/Cuda-Rocm-port",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "biplabs/lc0",
        "url": "https://github.com/biplabs/lc0",
        "stars": 0
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 22, 2026",
      "updatedAt": "January 22, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".circleci": 2,
          "(root)": 20,
          ".github": 1,
          "OpenBench": 1,
          "cross-files": 4,
          "dist": 6,
          "proto": 3,
          "scripts": 18,
          "src": 145
        },
        "languages": {
          "YAML": 2,
          "Markdown": 7,
          "Shell": 2,
          "Protocol Buffers": 3,
          "TOML": 1,
          "Python": 13,
          "C/C++ Header": 55,
          "C++": 4
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "CircleCI",
        "entryPoints": [],
        "configFiles": [
          ".circleci/Dockerfile",
          "OpenBench/Makefile",
          "pyproject.toml"
        ],
        "dependencies": [
          "pyproject.toml"
        ],
        "testFiles": [
          "src/chess/board_test.cc",
          "src/chess/position_test.cc",
          "src/engine_test.cc"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "README.md",
          "changelog.txt",
          "dist/README-cuda.txt",
          "dist/README-onnx-dml.txt",
          "dist/README-onnx-trt.txt",
          "src/neural/backends/blas/README.md",
          "src/neural/backends/cuda/readme.txt",
          "src/neural/backends/opencl/README.md"
        ],
        "fileTypes": {
          ".yml": 2,
          ".md": 7,
          ".cff": 1,
          ".cmd": 10,
          ".sh": 2,
          ".txt": 6,
          ".build": 2,
          ".proto": 3,
          ".toml": 1,
          ".py": 13,
          ".bat": 2,
          ".h": 55,
          ".cc": 49,
          ".ispc": 3,
          ".cu": 4,
          ".inc": 2,
          ".hlsl": 8,
          ".mm": 2,
          ".opencl": 11,
          ".hip": 2,
          ".cpp": 4
        }
      }
    },
    {
      "id": 1140075360,
      "name": "freelens",
      "displayName": "freelens",
      "description": "Free IDE for Kubernetes",
      "summary": "The Problem\nManaging Kubernetes clusters can feel like trying to juggle flaming swords. The command-line interface is powerful but often overwhelming, especially when you're knee-deep in YAML files and deployment configs. For developers who just want to get their apps running without wrestling with kubectl commands, a user-friendly interface is a must.\n\nWhat This Does\nEnter Freelens—your new best friend for Kubernetes management. It's a free IDE that gives you a GUI to handle your clusters without the headache. The project structure shows that it’s well thought out. For instance, the .github/workflows directory contains all sorts of CI/CD goodness, including integration-tests.yaml and unit-tests.yaml, ensuring that your deployments are as stable as your coffee addiction.\n\nThe README file is surprisingly straightforward, guiding you through installation on macOS and Linux. Want to install it on macOS? Just run brew install --cask freelens. Need it on Linux? Check the requirements and grab the package from the releases page. Simple as that.\n\nReal-World Use\nImagine you're working on a microservices project, and you need to deploy updates across several pods. Instead of manually running kubectl apply -f service.yaml a dozen times, you can use Freelens to visualize and manage those services in one place. The GUI will let you see the status of your pods, logs, and even resource usage without diving into the terminal. This is especially handy when you're debugging or scaling services—just point, click, and let the app do the heavy lifting.\n\nThe Bottom Line\nFreelens is a solid choice for developers who want to avoid the command line for Kubernetes management. It’s still in the early stages—zero stars on GitHub isn’t a great look, but it’s forked from a popular project, so there’s potential. If you're managing multiple clusters or just prefer a GUI over a terminal, give it a shot. For small projects, though, it might feel like using a sledgehammer to crack a nut.",
      "url": "https://github.com/yebeai/freelens",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "freelensapp/freelens",
        "url": "https://github.com/freelensapp/freelens",
        "stars": 4665
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 22, 2026",
      "updatedAt": "January 22, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 21,
          ".github": 23,
          ".trunk": 2,
          "freelens": 59,
          "packages": 95
        },
        "languages": {
          "YAML": 27,
          "Markdown": 8,
          "Shell": 4,
          "JavaScript": 9,
          "TypeScript": 83,
          "JSON": 11,
          "HTML": 1,
          "TSX": 7
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "pnpm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "freelens/src/main/index.ts",
          "freelens/src/renderer/index.ts",
          "freelens/webpack/main.ts",
          "packages/business-features/keyboard-shortcuts/index.ts",
          "packages/cluster-settings/index.ts",
          "packages/cluster-sidebar/index.ts",
          "packages/core/__mocks__/@sentry/electron/main.ts",
          "packages/core/src/common/catalog-entities/index.ts"
        ],
        "configFiles": [
          "freelens/integration/tsconfig.json",
          "freelens/jest.config.js",
          "freelens/package.json",
          "freelens/tsconfig.json",
          "jest.config.js",
          "package.json",
          "packages/business-features/keyboard-shortcuts/jest.config.js",
          "packages/business-features/keyboard-shortcuts/package.json",
          "packages/business-features/keyboard-shortcuts/tsconfig.json",
          "packages/business-features/keyboard-shortcuts/webpack.config.js",
          "packages/cluster-settings/package.json",
          "packages/cluster-settings/tsconfig.json",
          "packages/cluster-settings/webpack.config.js",
          "packages/cluster-sidebar/jest.config.js",
          "packages/cluster-sidebar/package.json",
          "packages/cluster-sidebar/tsconfig.json",
          "packages/cluster-sidebar/webpack.config.js",
          "packages/core/jest.config.js",
          "packages/core/package.json"
        ],
        "dependencies": [
          "freelens/package.json",
          "package.json",
          "packages/business-features/keyboard-shortcuts/package.json",
          "packages/cluster-settings/package.json",
          "packages/cluster-sidebar/package.json",
          "packages/core/package.json"
        ],
        "testFiles": [
          ".github/workflows/integration-tests.yaml",
          ".github/workflows/unit-tests.yaml",
          "freelens/integration/__tests__/app-preferences.tests.ts",
          "freelens/integration/__tests__/cluster-pages.tests.ts",
          "freelens/integration/__tests__/command-palette.tests.ts",
          "freelens/integration/__tests__/extensions.tests.ts",
          "packages/business-features/keyboard-shortcuts/src/__snapshots__/keyboard-shortcuts.test.tsx.snap",
          "packages/business-features/keyboard-shortcuts/src/keyboard-shortcuts.test.tsx",
          "packages/cluster-sidebar/src/order-of-sidebar-items.test.ts",
          "packages/core/src/common/__tests__/catalog-category-registry.test.ts",
          "packages/core/src/common/__tests__/catalog-entity.test.tsx",
          "packages/core/src/common/__tests__/create-resource-stack.test.ts",
          "packages/core/src/common/__tests__/kube-helpers.test.ts",
          "packages/core/src/common/__tests__/timezones.test.ts",
          "packages/core/src/common/__tests__/user-store.test.ts",
          "packages/core/src/common/app-paths/app-paths.test.ts",
          "packages/core/src/common/catalog-entities/__tests__/kubernetes-cluster.test.ts"
        ],
        "docs": [
          ".github/workflows/npm-licenses.yaml",
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "freelens/license-header.txt",
          "packages/business-features/keyboard-shortcuts/README.md",
          "packages/cluster-settings/README.md"
        ],
        "fileTypes": {
          ".yml": 5,
          ".md": 8,
          ".sh": 4,
          ".yaml": 22,
          ".json5": 1,
          ".jsonc": 2,
          ".aa": 1,
          ".asc": 1,
          ".list": 1,
          ".sources": 1,
          ".conf": 1,
          ".plist": 2,
          ".icns": 1,
          ".ico": 2,
          ".svg": 2,
          ".png": 17,
          ".nsh": 2,
          ".xml": 1,
          ".js": 9,
          ".ts": 83,
          ".json": 11,
          ".txt": 1,
          ".html": 1,
          ".snap": 1,
          ".tsx": 7
        }
      }
    },
    {
      "id": 1139979665,
      "name": "alt-sendme",
      "displayName": "alt sendme",
      "description": "Send files and folders anywhere in the world without storing in cloud - any size, any format, no accounts, no restrictions.",
      "summary": "The Problem\nFile sharing is a pain. Email attachments have size limits, cloud services want your personal info, and traditional FTP is a relic. We’re all tired of the endless back-and-forth just to send a file, especially when you need to send large folders or sensitive data. \n\nWhat This Does\nEnter alt-sendme. This tool lets you send files and folders directly between devices, skipping the cloud entirely. It uses peer-to-peer networking, which means no one else is holding your data hostage. You create a one-time share code, or \"ticket,\" after dropping your file into the app. \n\nUnder the hood, alt-sendme utilizes iroh, a modern alternative to older tech like WebRTC. For those curious, the core logic lives in sendme/src/core/. The send.rs and receive.rs files handle sending and receiving, while types.rs defines the data structures. If you want to dive deeper, the README.md lays out the simple installation process and features.\n\nReal-World Use\nImagine you're at a coffee shop, and your buddy needs a massive video file for their project. Instead of fumbling with Google Drive or a USB stick, you just drag the file into alt-sendme, which generates a ticket. Send them the ticket via text. They paste it into their app, and boom — file transfer starts. You can even interrupt the transfer, and it picks up where it left off. \n\nYou can get started easily by downloading the appropriate version from the Releases page. It’s available for Windows, macOS, and Linux, so there's no excuse.\n\nThe Bottom Line\nalt-sendme cuts through the clutter of traditional file sharing. It’s especially useful for larger files and sensitive data transfers, and best of all, you don’t have to deal with annoying accounts or privacy concerns. On the downside, if you’re only sharing small files occasionally, this might be overkill. But for developers or anyone frequently sharing large files, it’s worth a look.",
      "url": "https://github.com/yebeai/alt-sendme",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "tonyantony300/alt-sendme",
        "url": "https://github.com/tonyantony300/alt-sendme",
        "stars": 5502
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1531482615713-2afd69097998?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 22, 2026",
      "updatedAt": "January 22, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 116,
        "directories": {
          ".github": 5,
          "(root)": 13,
          "assets": 3,
          "scripts": 4,
          "sendme": 9,
          "src-tauri": 16,
          "web-app": 66
        },
        "languages": {
          "YAML": 3,
          "Markdown": 5,
          "JSON": 31,
          "JavaScript": 5,
          "TOML": 2,
          "Rust": 12,
          "TypeScript": 21,
          "HTML": 1,
          "TSX": 21,
          "CSS": 1
        },
        "frameworks": [
          "React",
          "Tailwind"
        ],
        "packageManager": "cargo",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "sendme/src/lib.rs",
          "src-tauri/src/main.rs",
          "web-app/index.html",
          "web-app/src/App.tsx",
          "web-app/src/i18n/index.ts"
        ],
        "configFiles": [
          "package.json",
          "sendme/Cargo.toml",
          "src-tauri/Cargo.toml",
          "tailwind.config.js",
          "tsconfig.json",
          "vite.config.ts"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json",
          "sendme/Cargo.toml",
          "src-tauri/Cargo.toml"
        ],
        "testFiles": [],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".yml": 3,
          ".md": 5,
          ".gif": 1,
          ".png": 5,
          ".json": 31,
          ".js": 5,
          ".lock": 2,
          ".toml": 2,
          ".rs": 12,
          ".icns": 1,
          ".ico": 1,
          ".ts": 21,
          ".html": 1,
          ".tsx": 21,
          ".css": 1
        }
      }
    },
    {
      "id": 1139978512,
      "name": "deepseek_ocr_app",
      "displayName": "deepseek ocr app",
      "description": "A quick vibe coded app for deepseek OCR",
      "summary": "The Problem\nDealing with scanned documents can be a nightmare. You have a PDF full of text and images, but you need that data in a usable format—like Markdown or Word. Manually extracting text or attempting to convert it with basic tools is tedious and often results in messy outputs. Enter deepseekocrapp, which promises to make this process a whole lot easier.\n\nWhat This Does\nThis app combines a FastAPI backend and a React frontend to tackle OCR (Optical Character Recognition) head-on. You can upload PDFs up to 100MB and the app will process them page by page, extracting text and even images. Check out backend/pdfutils.py for the guts of the PDF processing logic, while frontend/src/components/ImageUpload.jsx handles the user interface for file uploads.\n\nOnce your document is processed, you can export it in multiple formats like Markdown, HTML, or even Word using the functionality in backend/formatconverter.py. Need a structured output? The app has you covered with JSON export options too. The docker-compose.yml file makes it easy to spin up the whole application with a single command.\n\nReal-World Use\nImagine you’re a researcher with hundreds of pages of scanned academic papers. Instead of spending hours retyping or messing around with subpar OCR tools, you can simply upload your PDF, select \"PDF Processing,\" and let the app do its magic. As it processes, you get real-time updates on progress. Once done, you can export everything to Markdown for your wiki or to Word for collaboration with colleagues. Check out the API docs at http://localhost:8000/docs to see how to integrate this into your workflow programmatically.\n\nThe Bottom Line\ndeepseekocrapp is a solid choice for anyone needing reliable OCR capabilities with multi-format exports. The setup is straightforward, especially with Docker. However, if you're just looking to convert a handful of documents, this might feel like overkill. If you work with lots of scanned documents regularly, though, this tool will save you time and headaches.",
      "url": "https://github.com/yebeai/deepseek_ocr_app",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "rdumasia303/deepseek_ocr_app",
        "url": "https://github.com/rdumasia303/deepseek_ocr_app",
        "stars": 1726
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1542831371-29b0f74f9713?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 22, 2026",
      "updatedAt": "January 22, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 41,
        "directories": {
          "(root)": 5,
          "assets": 4,
          "backend": 5,
          "frontend": 27
        },
        "languages": {
          "Markdown": 2,
          "Python": 3,
          "YAML": 1,
          "JavaScript": 4,
          "HTML": 1,
          "JSON": 4,
          "CSS": 2,
          "JSX": 7,
          "TSX": 2,
          "TypeScript": 1
        },
        "frameworks": [
          "React",
          "Express",
          "Tailwind",
          "Docker"
        ],
        "packageManager": "pip",
        "hasDocker": true,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "backend/main.py",
          "frontend/index.html",
          "frontend/src/App.jsx",
          "frontend/src/App.tsx"
        ],
        "configFiles": [
          ".env.example",
          "backend/Dockerfile",
          "backend/requirements.txt",
          "docker-compose.yml",
          "frontend/Dockerfile",
          "frontend/package.json",
          "frontend/tailwind.config.js",
          "frontend/tsconfig.json",
          "frontend/vite.config.js",
          "frontend/vite.config.ts"
        ],
        "dependencies": [
          "backend/requirements.txt",
          "frontend/package.json"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md",
          "frontend/README.md"
        ],
        "fileTypes": {
          ".example": 1,
          ".md": 2,
          ".png": 4,
          ".py": 3,
          ".txt": 1,
          ".yml": 1,
          ".js": 4,
          ".html": 1,
          ".conf": 1,
          ".json": 4,
          ".svg": 2,
          ".css": 2,
          ".jsx": 7,
          ".tsx": 2,
          ".ts": 1
        }
      }
    },
    {
      "id": 1139975787,
      "name": "OpenGlasses",
      "displayName": "OpenGlasses",
      "description": "3D-printable wearable that fuses AI, design, and human expression — turning ordinary glasses into extraordinary minds.",
      "summary": "In an era where technology increasingly intersects with personal expression, the demand for customizable and interactive wearables is on the rise. Traditional glasses serve a functional purpose, but what if they could also embody the user's identity, mood, or even engage with AI? This is where OpenGlasses steps in, offering a compelling solution that transforms a mundane accessory into a dynamic, AI-powered wearable. As creators and developers, we often seek tools that allow for innovation and personalization, and OpenGlasses presents a unique opportunity to explore these dimensions.\n\nOpenGlasses is a 3D-printable wearable that integrates artificial intelligence with fashion, aiming to redefine how we interact with technology in our daily lives. The project stands out due to its open-source approach, encouraging community collaboration and creativity to enhance its capabilities. Unlike conventional wearables that often require proprietary software and hardware, OpenGlasses invites developers to assemble their own devices, modify the architecture, and contribute to the ecosystem. This democratization of technology not only fosters innovation but also enables users to imbue their wearables with personal significance.\n\nFrom a technical perspective, the architecture of OpenGlasses is intriguing. The core components include a Raspberry Pi Zero 2 W, which acts as the microprocessor connecting the hardware to AI software, and a Speaker/Microphone HAT that facilitates voice interactions. The file structure reveals a well-organized approach to development, with the scripts/init.py file likely serving as an entry point for initializing software functionalities, perhaps managing the AI interactions and device communication. The inclusion of safety precautions demonstrates a thoughtful design process, particularly regarding the handling of lithium batteries, which are essential for mobile applications. This attention to detail indicates that the project not only focuses on functionality but also prioritizes user safety.\n\nThe potential use cases for OpenGlasses are diverse. For developers interested in AI, it offers a platform to experiment with natural language processing and voice recognition technologies. Imagine a scenario where a fashion designer integrates OpenGlasses into a runway show, enabling the glasses to change color or display patterns based on the audience's reactions, creating an interactive experience. Additionally, educators could leverage OpenGlasses in classrooms, providing students with a hands-on project that combines engineering, design, and AI, fostering a new generation of innovators. Lastly, hobbyists in the maker community can utilize OpenGlasses to create personalized devices that reflect their unique identities or interests, further expanding the project’s reach.\n\nUltimately, OpenGlasses matters because it embodies the future of wearables—where technology is not just an accessory but an extension of our individuality. By blending AI with personal expression, OpenGlasses challenges the norms of how we perceive and interact with technology. It opens the door to a new realm of possibilities for developers, makers, and creators alike, inviting them to contribute to a project that is as much about community as it is about innovation. As we continue to explore the intersection of technology and personal identity, OpenGlasses stands as a testament to the power of open-source collaboration, urging us to rethink the role of wearables in our lives.",
      "url": "https://github.com/yebeai/OpenGlasses",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "0xaiwhisperer/OpenGlasses",
        "url": "https://github.com/0xaiwhisperer/OpenGlasses",
        "stars": 126
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 22, 2026",
      "updatedAt": "January 22, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 4,
        "directories": {
          "3d printables": 1,
          "(root)": 1,
          "assets": 1,
          "scripts": 1
        },
        "languages": {
          "Markdown": 1,
          "Python": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [
          "3d printables/latest_iteration_v1.stl"
        ],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".stl": 1,
          ".md": 1,
          ".png": 1,
          ".py": 1
        }
      }
    },
    {
      "id": 1139899467,
      "name": "system-prompts-and-models-of-ai-tools",
      "displayName": "system prompts and models of ai tools",
      "description": "FULL Augment Code, Claude Code, Cluely, CodeBuddy, Comet, Cursor, Devin AI, Junie, Kiro, Leap.new, Lovable, Manus, NotionAI, Orchids.app, Perplexity, Poke, Qoder, Replit, Same.dev, Trae, Traycer AI, VSCode Agent, Warp.dev, Windsurf, Xcode, Z.ai Code, Dia & v0. (And other Open Sourced) System Prompts, Internal Tools & AI Models",
      "summary": "The Problem\nDeveloping AI tools can be a convoluted mess, especially when it comes to crafting effective prompts. You know the struggle: you need to fine-tune your models, but finding reliable, well-structured prompts is like searching for a needle in a haystack. You end up wasting time reinventing the wheel instead of building on proven foundations.\n\nWhat This Does\nEnter the system-prompts-and-models-of-ai-tools repository. It’s a treasure trove of system prompts and related tools for various AI models like Claude, GPT, and others. You’ll find files like Amp/gpt-5.yaml and Anthropic/Claude Code/Prompt.txt, which provide ready-to-use prompts to get you off the ground. The structured format lets you dive straight into what works instead of sifting through irrelevant fluff.\n\nThe folder structure is straightforward, with distinct directories for each AI tool. For instance, Augment Code/claude-4-sonnet-tools.json is a well-defined JSON file that outlines the tools for the Claude model. Whether you're tweaking an existing model or creating a new one, this repo serves as a solid reference point.\n\nReal-World Use\nImagine you’re working on a project that requires real-time coding assistance. You grab the prompt from Cursor Prompts/Agent Prompt v1.2.txt and tweak it to suit your needs. You can quickly test it in an environment like VSCode, using VSCode Agent to run it live. You’ll save hours of back-and-forth just trying to get your prompts right.\n\nHere’s a quick snippet to illustrate how you might load a prompt:\n\nwith open('Cursor Prompts/Agent Prompt v1.2.txt') as f:\n    prompt = f.read()\nNow use 'prompt' with your AI model\n\nThe Bottom Line\nThis repo is a solid resource if you're serious about AI tool development. The organization is clear, and the prompts are varied enough to cater to different needs. However, if you're working on a small-scale project, this might feel like overkill. It’s best suited for teams or individuals looking to dig deep into AI prompt engineering without starting from scratch.",
      "url": "https://github.com/yebeai/system-prompts-and-models-of-ai-tools",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "x1xhlol/system-prompts-and-models-of-ai-tools",
        "url": "https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools",
        "stars": 125753
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1607799279861-4dd421887fb3?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 22, 2026",
      "updatedAt": "January 22, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 106,
        "directories": {
          ".github": 1,
          "Amp": 4,
          "Anthropic": 6,
          "Augment Code": 4,
          "Cluely": 2,
          "CodeBuddy Prompts": 2,
          "Comet Assistant": 1,
          "Cursor Prompts": 7,
          "Devin AI": 2,
          "Emergent": 2,
          "Google": 3,
          "Junie": 1,
          "Kiro": 3,
          "(root)": 2,
          "Leap.new": 2,
          "Lovable": 2,
          "Manus Agent Tools & Prompt": 4,
          "NotionAi": 2,
          "Open Source prompts": 7,
          "Orchids.app": 2,
          "Perplexity": 1,
          "Poke": 7,
          "Qoder": 3,
          "Replit": 2,
          "Same.dev": 2,
          "Trae": 3,
          "Traycer AI": 4,
          "VSCode Agent": 9,
          "Warp.dev": 1,
          "Windsurf": 2,
          "Xcode": 6,
          "Z.ai Code": 1,
          "assets": 3,
          "dia": 1,
          "v0 Prompts and Tools": 2
        },
        "languages": {
          "YAML": 3,
          "Markdown": 3,
          "JSON": 16
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [
          "Kiro/Spec_Prompt.txt"
        ],
        "docs": [
          "Amp/README.md",
          "LICENSE.md",
          "README.md"
        ],
        "fileTypes": {
          ".yml": 1,
          ".md": 3,
          ".yaml": 2,
          ".png": 4,
          ".txt": 79,
          ".json": 16
        }
      }
    },
    {
      "id": 1139314661,
      "name": "uber",
      "displayName": "uber",
      "description": "Build a full-stack Uber Clone Application with Expo’s latest features and lightning-fast edge-ready Postgres database in React Native.",
      "summary": "In today's fast-paced world, ride-hailing apps have become an essential service for urban mobility. However, building a full-fledged application that can compete with industry giants like Uber or Lyft can seem daunting for many developers. The complexities of real-time data, payment processing, and user authentication often deter budding programmers from attempting to create their own versions of these applications. The Uber Clone repository on GitHub addresses this challenge head-on, offering a comprehensive and educational framework for developers looking to build a similar application using modern technologies.\n\nThe Uber Clone project stands out not just as a mere template but as a fully-fledged learning resource that empowers developers to grasp the intricacies of a full-stack application. Built with React Native and Expo, it leverages the power of a serverless PostgreSQL database and integrates payment processing via Stripe. This combination of technologies allows developers to create a responsive, user-friendly mobile application that can manage various aspects of ride-hailing, including user authentication, ride management, and real-time location tracking. By following the detailed tutorial associated with this repository, developers can learn not only how to implement these features but also the underlying principles of modern app development.\n\nDelving deeper into the architecture, the file structure reveals a well-organized and modular approach to building the application. For instance, the API-related files are neatly categorized within the app/(api) directory, with specific functionalities clearly delineated. This includes files like user+api.ts for user management and ride/create+api.ts for ride creation, ensuring that each concern is addressed in isolation. The use of Zustand for state management enhances the app's reactivity, allowing for a seamless user experience. Furthermore, the incorporation of Google Maps for live location tracking and autocomplete search functionalities showcases a sophisticated use of third-party services, which are crucial for a ride-hailing app.\n\nDevelopers can find several use cases for this repository. First, it serves as an excellent starting point for those looking to enter the mobile app development space. By building a project of this scale, they gain hands-on experience in integrating various technologies and solving real-world problems such as payment processing and geolocation services. Second, this repository can be a valuable resource for seasoned developers aiming to explore the capabilities of modern frameworks like React Native and Expo, providing them with a practical application of these technologies. Lastly, organizations looking to prototype ride-hailing solutions can leverage this application as a foundation, significantly reducing the development time while ensuring a robust architecture.\n\nThis project exemplifies the importance of open-source contributions in the developer community. By providing a comprehensive tutorial along with a fully functional codebase, it bridges the gap between theory and practice, enabling developers to build meaningful applications. The Uber Clone repository not only demonstrates how to create a competitive ride-hailing app but also emphasizes the value of structured learning through hands-on experience. As we move towards an increasingly app-centric world, resources like these will be pivotal in shaping the next generation of developers equipped to tackle complex real-world challenges.",
      "url": "https://github.com/yebeai/uber",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "adrianhajdin/uber",
        "url": "https://github.com/adrianhajdin/uber",
        "stars": 1701
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 21, 2026",
      "updatedAt": "January 21, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 108,
        "directories": {
          "(root)": 11,
          ".vscode": 1,
          "app": 23,
          "assets": 55,
          "components": 9,
          "constants": 1,
          "lib": 4,
          "scripts": 1,
          "store": 1,
          "types": 2
        },
        "languages": {
          "JavaScript": 4,
          "JSON": 5,
          "Markdown": 1,
          "TypeScript": 15,
          "TSX": 26
        },
        "frameworks": [
          "React",
          "Express",
          "Tailwind"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "app/index.tsx",
          "constants/index.ts",
          "store/index.ts"
        ],
        "configFiles": [
          ".eslintrc.js",
          "package.json",
          "tailwind.config.js",
          "tsconfig.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".js": 4,
          ".json": 5,
          ".md": 1,
          ".ts": 15,
          ".tsx": 26,
          ".ttf": 14,
          ".png": 41,
          ".zip": 1
        }
      }
    },
    {
      "id": 1139260317,
      "name": "document-to-podcast",
      "displayName": "document to podcast",
      "description": "Blueprint by Mozilla.ai for generating podcasts from documents using local AI",
      "summary": "In today's fast-paced world, content consumption is evolving. Many individuals and organizations find it challenging to keep up with lengthy documents, research papers, or reports. The need for converting these static texts into engaging audio formats has never been more significant. Imagine being able to listen to a comprehensive research paper on your morning commute, transforming an otherwise tedious task into an effortless experience. This is precisely the problem that the Document-to-Podcast project by Mozilla.ai aims to solve, providing a streamlined solution to convert documents into podcasts using local AI without the need for external APIs or GPU resources.\n\nDocument-to-Podcast is a blueprint designed to convert documents into audio podcasts featuring two speakers, thereby enhancing accessibility and user engagement. What sets this project apart is its commitment to local processing. By eliminating the need for cloud-based services, it not only ensures privacy but also makes the technology more accessible to users who may not have the resources for high-performance computing. The project leverages open-source AI models, allowing users to harness the power of advanced machine learning without the complexity typically associated with such technologies. With an architecture that prioritizes local execution, Document-to-Podcast presents a unique solution in the growing landscape of AI-based content conversion tools.\n\nDiving into the technical architecture, the repository showcases a well-structured file organization that enhances collaboration and ease of use. The presence of .devcontainer/devcontainer.json indicates that the project is set up for a seamless development experience using Visual Studio Code's Remote Development capabilities, allowing developers to start contributing without extensive setup. The demo folder contains essential files such as app.py and notebook.ipynb, which provide practical examples of how to implement the functionality in a user-friendly manner. The robust CI/CD workflows found in the .github/workflows directory, such as docs.yaml and tests.yaml, ensure that documentation and code are maintained with high quality, enabling continuous deployment and integration. Additionally, the inclusion of CONTRIBUTING.md and CODEOFCONDUCT.md reflects the project's commitment to fostering an inclusive community around its development.\n\nSeveral use cases can benefit significantly from the Document-to-Podcast project. For educators, converting lecture notes or educational materials into audio formats can enhance learning experiences, especially for auditory learners. Researchers can transform lengthy papers into podcasts, sharing their findings in a more digestible format with a wider audience. Moreover, businesses can utilize this tool to create audio summaries of important reports, allowing employees to stay informed while multitasking. Each of these scenarios highlights the versatility and potential impact of the technology in diverse fields.\n\nAs the demand for innovative content consumption methods grows, projects like Document-to-Podcast are crucial for bridging the gap between traditional text-based content and modern audio formats. By empowering users to convert documents into engaging podcasts locally, Mozilla.ai's blueprint is not just a technical achievement but a step toward democratizing access to information. The implications extend beyond mere convenience; they resonate with the broader trend of making technology more user-friendly and privacy-conscious. In a world where attention spans are shortening, the ability to listen to documents rather than read them could redefine how we engage with information, making this project a noteworthy contribution to the open-source landscape.",
      "url": "https://github.com/yebeai/document-to-podcast",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "mozilla-ai/document-to-podcast",
        "url": "https://github.com/mozilla-ai/document-to-podcast",
        "stars": 173
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 21, 2026",
      "updatedAt": "January 21, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 65,
        "directories": {
          ".devcontainer": 1,
          "(root)": 9,
          ".github": 11,
          "demo": 4,
          "docs": 12,
          "example_data": 5,
          "images": 3,
          "src": 11,
          "tests": 9
        },
        "languages": {
          "JSON": 1,
          "YAML": 12,
          "Markdown": 12,
          "Shell": 1,
          "Python": 22,
          "CSS": 1,
          "HTML": 1,
          "TOML": 1
        },
        "frameworks": [
          "Flask",
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "demo/app.py",
          "src/document_to_podcast/cli.py"
        ],
        "configFiles": [
          "demo/Dockerfile",
          "pyproject.toml"
        ],
        "dependencies": [
          "pyproject.toml"
        ],
        "testFiles": [
          ".github/workflows/tests.yaml",
          "tests/conftest.py",
          "tests/e2e/test_document_to_podcast.py",
          "tests/integration/test_data_load_and_clean.py",
          "tests/integration/test_url_input.py",
          "tests/unit/inference/test_model_loaders.py",
          "tests/unit/inference/test_text_to_speech.py",
          "tests/unit/inference/test_text_to_text.py",
          "tests/unit/preprocessing/test_data_cleaners.py",
          "tests/unit/preprocessing/test_data_loaders.py"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "docs/api.md",
          "docs/assets/custom.css",
          "docs/cli.md",
          "docs/customization.md",
          "docs/future-features-contributions.md",
          "docs/getting-started.md",
          "docs/images/Blueprint-logo-black-flavicon.png",
          "docs/images/Blueprint-logo-black.png",
          "docs/images/Blueprint-logo-white.png",
          "docs/images/document-to-podcast-diagram.png",
          "docs/index.md",
          "docs/step-by-step-guide.md"
        ],
        "fileTypes": {
          ".json": 1,
          ".yaml": 10,
          ".yml": 2,
          ".md": 12,
          ".sh": 1,
          ".py": 22,
          ".ipynb": 1,
          ".css": 1,
          ".png": 7,
          ".docx": 1,
          ".pdf": 1,
          ".html": 1,
          ".toml": 1
        }
      }
    },
    {
      "id": 1139147416,
      "name": "rzweb",
      "displayName": "rzweb",
      "description": "A complete browser-based reverse engineering platform built on Rizin, running entirely client-side via WebAssembly.",
      "summary": "In the ever-evolving landscape of software development, the need for efficient and accessible reverse engineering tools has never been more critical. Developers often face the daunting task of analyzing binaries without the luxury of sophisticated IDEs or local installations, especially in environments where security and privacy are paramount. RzWeb addresses this gap, offering a unique solution that allows developers to analyze binaries directly in their browsers, ensuring minimal friction and maximum security.\n\nRzWeb is a complete browser-based reverse engineering platform built on the powerful Rizin framework, which has been designed to run entirely client-side using WebAssembly. This means that users can drop a binary file onto the webpage and start analyzing it immediately, without worrying about installations or uploads. What sets RzWeb apart from traditional reverse engineering tools is its commitment to privacy—since all operations occur on the client side, users retain full control over their binaries, which never leave their devices. The integrated terminal gives users full access to Rizin's command line interface, allowing for intuitive command execution and analysis of various binary formats, including ELF, PE/PE+, and Mach-O.\n\nDelving into the technical architecture of RzWeb, it employs modern web technologies to deliver a seamless user experience. The frontend is built with React and TypeScript, ensuring robust type safety and component-driven development. The use of Tailwind CSS for styling allows for rapid UI development while maintaining a clean and responsive design. The state management is handled by Zustand, which provides a lightweight solution for managing application state without the complexity of more heavyweight alternatives. The terminal component, implemented using xterm.js, offers a familiar command-line interface for executing Rizin commands directly in the browser. The backend heavy lifting is performed by Rizin, which is compiled to WebAssembly using Emscripten, allowing it to run efficiently in the browser environment (as indicated by the presence of the public/coi-serviceworker.min.js file for caching).\n\nRzWeb is particularly beneficial in several scenarios. First, security researchers analyzing potentially malicious binaries can utilize RzWeb to dissect and understand threats without risking exposure of sensitive data. By dropping unknown executables directly into RzWeb, they can leverage commands like afl to list functions or pdf to disassemble code, all while ensuring that the binary remains on their local system. Second, students and educators in reverse engineering courses can benefit from RzWeb’s hands-on approach to learning. With no installation required, instructors can easily demonstrate reverse engineering techniques in real-time, fostering a more interactive learning environment. Lastly, developers working on firmware analysis can take advantage of RzWeb’s support for raw binary formats, enabling them to explore and analyze device firmware without the complications of setting up a local reverse engineering environment.\n\nIn conclusion, RzWeb is not just another reverse engineering tool; it represents a paradigm shift in how developers can access and analyze binary files. By leveraging the capabilities of WebAssembly and a modern frontend stack, RzWeb provides a powerful, privacy-focused solution that simplifies the reverse engineering process. As the demand for such tools grows, RzWeb positions itself as a vital resource for both seasoned professionals and newcomers alike, reinforcing the notion that effective analysis should be accessible, secure, and efficient. This project underscores the importance of innovation in open-source tools, paving the way for new possibilities in the realm of software analysis.",
      "url": "https://github.com/yebeai/rzweb",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "IndAlok/rzweb",
        "url": "https://github.com/IndAlok/rzweb",
        "stars": 638
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 21, 2026",
      "updatedAt": "January 21, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 80,
        "directories": {
          "(root)": 16,
          "public": 10,
          "scripts": 1,
          "src": 53
        },
        "languages": {
          "JSON": 5,
          "Markdown": 1,
          "Shell": 1,
          "JavaScript": 3,
          "HTML": 1,
          "TSX": 25,
          "TypeScript": 29,
          "CSS": 1
        },
        "frameworks": [
          "React",
          "Tailwind"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "index.html",
          "src/components/file/index.ts",
          "src/components/terminal/index.ts",
          "src/components/ui/index.ts",
          "src/components/views/index.ts",
          "src/constants/index.ts",
          "src/hooks/index.ts",
          "src/lib/rizin/index.ts",
          "src/lib/utils/index.ts",
          "src/pages/index.ts",
          "src/providers/index.ts",
          "src/stores/index.ts",
          "src/types/index.ts"
        ],
        "configFiles": [
          ".eslintrc.json",
          "package.json",
          "tailwind.config.ts",
          "tsconfig.json",
          "vite.config.ts"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".json": 5,
          ".md": 1,
          ".sh": 1,
          ".js": 3,
          ".html": 1,
          ".png": 6,
          ".svg": 1,
          ".cjs": 1,
          ".tsx": 25,
          ".ts": 29,
          ".css": 1,
          ".tsbuildinfo": 2
        }
      }
    },
    {
      "id": 1138317939,
      "name": "xai-sdk-python",
      "displayName": "xai sdk python",
      "description": "The official Python SDK for the xAI API",
      "summary": "In the ever-evolving landscape of artificial intelligence, developers often grapple with the complexity of integrating various AI models and APIs into their applications. The challenge lies not only in the technical aspects of these integrations but also in ensuring that the solutions are both scalable and maintainable. This is where the xAI Python SDK comes into play, providing a streamlined interface for developers to interact with xAI's powerful APIs. It caters to the increasing demand for flexibility and ease of use, especially in applications that require real-time interaction with AI models, such as chatbots and content generation systems.\n\nThe xAI Python SDK is designed specifically for developers who wish to leverage xAI's capabilities, providing a gRPC-based library that supports both synchronous and asynchronous operations. This dual-client approach is a significant differentiator, as it allows developers to choose the best implementation based on their application's architecture. The SDK’s design emphasizes simplicity and intuitiveness, enabling developers to focus on building features rather than wrestling with complex integration issues. The comprehensive documentation available at docs.x.ai enhances this experience, offering practical guides and examples that facilitate rapid onboarding.\n\nDiving deeper into the architecture of the xAI SDK, we can observe a well-structured file hierarchy that supports robust development practices. The presence of a .github directory indicates a commitment to maintaining high standards for collaboration and code quality, featuring templates for issues and pull requests, as well as CI/CD workflows such as ci.yaml for continuous integration and release.yaml for automated deployment. This structure not only streamlines the development process but also encourages contributions from the community, as evidenced by its forked origin from the xai-org/xai-sdk-python repository, which boasts 350 stars. The use of examples/aio for asynchronous usage scenarios highlights the SDK's capability to handle modern asynchronous programming patterns, which are crucial for responsive applications.\n\nSeveral use cases illustrate the practical benefits of the xAI SDK. First, developers building chat applications can utilize the SDK's multi-turn chat capabilities for creating conversational agents that maintain context across interactions. This is facilitated by the append method, which manages conversation history seamlessly. Secondly, the SDK can be employed in content generation scenarios, where textual or visual outputs are needed on-demand. For instance, generating images based on user prompts can enhance user engagement in creative applications, and the provided examples showcase how easily a developer can implement such functionality. Lastly, the SDK's support for function calling opens up possibilities for more sophisticated applications, such as integrating AI-driven decision-making into business workflows.\n\nThe xAI Python SDK represents a significant leap forward in the accessibility and usability of AI technologies for developers. By combining a thoughtful design with a robust feature set, it simplifies the process of integrating advanced AI capabilities into applications. As developers continue to seek efficient ways to harness AI, tools like the xAI SDK will play a critical role in bridging the gap between complex AI models and practical, user-friendly applications. This SDK not only empowers developers to build innovative solutions but also fosters a community-driven approach to AI, ensuring continuous improvement and adaptation in a rapidly changing technological landscape.",
      "url": "https://github.com/yebeai/xai-sdk-python",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "xai-org/xai-sdk-python",
        "url": "https://github.com/xai-org/xai-sdk-python",
        "stars": 368
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1531482615713-2afd69097998?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 20, 2026",
      "updatedAt": "January 20, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".github": 9,
          "(root)": 10,
          "examples": 36,
          "src": 123,
          "tests": 22
        },
        "languages": {
          "YAML": 8,
          "Markdown": 6,
          "TOML": 2,
          "Python": 153
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "tests/server.py"
        ],
        "configFiles": [
          "pyproject.toml"
        ],
        "dependencies": [
          "pyproject.toml"
        ],
        "testFiles": [
          "tests/__init__.py",
          "tests/aio/__init__.py",
          "tests/aio/auth_test.py",
          "tests/aio/chat_test.py",
          "tests/aio/client_test.py",
          "tests/aio/collections_test.py",
          "tests/aio/files_test.py",
          "tests/aio/image_test.py",
          "tests/aio/models_test.py",
          "tests/aio/tokenize_test.py",
          "tests/chat_test.py",
          "tests/server.py",
          "tests/sync/__init__.py",
          "tests/sync/auth_test.py",
          "tests/sync/chat_test.py",
          "tests/sync/client_test.py",
          "tests/sync/collections_test.py",
          "tests/sync/files_test.py",
          "tests/sync/image_test.py",
          "tests/sync/models_test.py",
          "tests/sync/tokenize_test.py",
          "tests/telemetry_test.py"
        ],
        "docs": [
          "CHANGELOG.md",
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".yml": 3,
          ".md": 6,
          ".yaml": 5,
          ".toml": 2,
          ".py": 153,
          ".pyi": 28
        }
      }
    },
    {
      "id": 1138316487,
      "name": "x-algorithm",
      "displayName": "x algorithm",
      "description": "Algorithm powering the For You feed on X",
      "summary": "The Problem\nThe social media landscape is cluttered with irrelevant content that can drown out posts from accounts you actually care about. Users often miss important updates while scrolling through a sea of noise. The goal here is to fix that by providing a more personalized feed that truly reflects user interests.\n\nWhat This Does\nThe x-algorithm repository contains the core algorithm for the \"For You\" feed on X, effectively mixing in-network and out-of-network posts. The architecture is split into several key components: Home Mixer orchestrates everything, while the Candidate Pipeline handles the heavy lifting of scoring and filtering posts. \n\nIn the candidate-pipeline/, you'll find files like scorer.rs and filter.rs that implement the logic for ranking posts based on user engagement history and preferences. The home-mixer/ directory contains various candidatehydrators that fetch and prepare the data for the algorithm. The phoenixcandidatepipeline.rs file is particularly crucial as it integrates outputs from both in-network and out-of-network sources.\n\nReal-World Use\nImagine a user named Alex who engages frequently with tech content but has a soft spot for cooking videos. With this algorithm, Alex will see tech posts from accounts he follows (from Thunder) and also get recommended cooking videos from a broader scope (via Phoenix). If you check out the README.md, it explains how the queryhydrator.rs collects Alex's engagement history to refine recommendations. \n\nTo visualize this in code, consider how scorer.rs might weigh posts based on previous likes: \n\nlet score = calculateengagementscore(post, userengagementhistory);\n\nThe Bottom Line\nThis algorithm is a solid step toward a personalized experience on X, especially if you're tired of sifting through irrelevant posts. However, if you're working on a smaller project, deploying something this complex may be overkill. If you're looking to enhance user engagement through tailored content, this is worth a look, but be prepared for a steep learning curve.",
      "url": "https://github.com/yebeai/x-algorithm",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "xai-org/x-algorithm",
        "url": "https://github.com/xai-org/x-algorithm",
        "stars": 15756
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 20, 2026",
      "updatedAt": "January 20, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 79,
        "directories": {
          "(root)": 4,
          "candidate-pipeline": 9,
          "home-mixer": 44,
          "phoenix": 11,
          "thunder": 11
        },
        "languages": {
          "Markdown": 3,
          "Rust": 64,
          "Python": 8,
          "TOML": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "candidate-pipeline/lib.rs",
          "home-mixer/lib.rs",
          "home-mixer/main.rs",
          "thunder/lib.rs",
          "thunder/main.rs"
        ],
        "configFiles": [
          "phoenix/pyproject.toml"
        ],
        "dependencies": [
          "phoenix/pyproject.toml"
        ],
        "testFiles": [
          "phoenix/test_recsys_model.py",
          "phoenix/test_recsys_retrieval_model.py"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "phoenix/README.md"
        ],
        "fileTypes": {
          ".md": 3,
          ".rs": 64,
          ".py": 8,
          ".toml": 1,
          ".lock": 1
        }
      }
    },
    {
      "id": 1138105535,
      "name": "personalized-recommender-course",
      "displayName": "personalized recommender course",
      "description": "👕 Open-source course on architecting, building and deploying a real-time personalized recommender for H&M fashion articles.",
      "summary": "The Problem\nBuilding a personalized recommender system is no walk in the park. You need to manage data processing, model training, and deployment—all while ensuring it scales in real-time. For a brand like H&M, where fashion trends can change overnight, a fast and efficient system is crucial. Most tutorials don’t cover the intricacies of real-time deployment or MLOps practices, leaving many developers to figure it out themselves.\n\nWhat This Does\nThis repository, personalized-recommender-course, offers a hands-on course that guides you through architecting, building, and deploying a real-time recommender for H&M fashion articles. The INSTALLANDUSAGE.md file gets you set up quickly, and notebooks/1fpcomputingfeatures.ipynb dives into feature engineering using tools like Polars. You’ll also find notebooks/2tptrainingretrievalmodel.ipynb and notebooks/3tptrainingrankingmodel.ipynb which cover the nitty-gritty of training models. \n\nDeployment? No problem. The .github/workflows/mlpipelines.yaml file automates your CI/CD with GitHub Actions, so you can focus on refining your models rather than wrestling with deployment logistics. You’ll also learn to use KServe for serving your models in a Kubernetes cluster. \n\nReal-World Use\nImagine launching a new fashion line and needing to recommend items to users in real time. You’d start by running the code in notebooks/4ipcomputingitemembeddings.ipynb to create embeddings for your items. As users interact with your site, the recommender pulls from the latest data to make personalized suggestions, all thanks to the architecture outlined in assets/system_architecture.png. You can even tweak the model using LLM techniques, making recommendations feel almost intuitive.\n\nThe Bottom Line\nThis course is a solid resource for anyone looking to get their hands dirty with personalized recommenders, especially in a fast-paced domain like fashion. The structure is clear, and the GitHub Actions integration is a nice touch that saves you from a lot of headaches. Just be aware that if you're working on a small-scale project, this might feel like overkill. Otherwise, dive in and start recommending those trendy outfits!",
      "url": "https://github.com/yebeai/personalized-recommender-course",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "decodingai-magazine/personalized-recommender-course",
        "url": "https://github.com/decodingai-magazine/personalized-recommender-course",
        "stars": 631
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 20, 2026",
      "updatedAt": "January 20, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 69,
        "directories": {
          ".devcontainer": 1,
          "(root)": 11,
          ".github": 5,
          "assets": 13,
          "notebooks": 7,
          "recsys": 31,
          "tools": 1
        },
        "languages": {
          "JSON": 1,
          "Markdown": 5,
          "YAML": 2,
          "TOML": 1,
          "Python": 32
        },
        "frameworks": [
          "Flask"
        ],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          ".env.example",
          "Makefile",
          "pyproject.toml",
          "recsys/hopsworks_integration/llm_ranker/requirements.txt"
        ],
        "dependencies": [
          "pyproject.toml",
          "recsys/hopsworks_integration/llm_ranker/requirements.txt"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".json": 1,
          ".example": 1,
          ".md": 5,
          ".yaml": 2,
          ".png": 13,
          ".ipynb": 7,
          ".txt": 2,
          ".toml": 1,
          ".py": 32,
          ".lock": 1
        }
      }
    },
    {
      "id": 1136954685,
      "name": "maptoposter",
      "displayName": "maptoposter",
      "description": "Transform your favorite cities into beautiful, minimalist designs. MapToPoster lets you create and export visually striking map posters with code.",
      "summary": "The Problem\nCity maps are often cluttered and unappealing. If you want to transform your favorite urban landscape into something that looks good on your wall, you either need design skills or a hefty budget for a graphic designer. Most options out there don’t give you the flexibility of customization, which is a total bummer for creative types.\n\nWhat This Does\nEnter MapToPoster, the Python script that turns cities into minimalist poster art. The main file, createmapposter.py, is your command center. You feed it a city and country along with some options, and it spits out a stylish map poster in PNG format. \n\nYou can pick from 17 themes stored in the themes/ directory, from featurebased to japaneseink. Want to see what your city looks like with a midnight blue vibe? Just run:\n\npython createmapposter.py --city \"Dubai\" --country \"UAE\" --theme \"midnightblue\"\n\nIf you’re unsure which theme to use, throw in the --list-themes option to see what's available. \n\nThe requirements.txt file ensures you have all the necessary libraries to get started. Just install them with a simple pip install -r requirements.txt, and you’re ready to roll.\n\nReal-World Use\nLet's say you’re planning an office renovation, and you want to feature city maps of your team members’ hometowns. Run this command for each city:\n\npython createmap_poster.py -c \"San Francisco\" -C \"USA\" -t sunset -d 10000\n\nIt’s a quick way to get unique, high-quality prints ready for framing. Customize the distance parameter to zoom in or out, tailoring the output to your needs.\n\nThe Bottom Line\nMapToPoster is a nifty tool for anyone looking to add a personal touch to their decor without the hassle of hiring a designer. It's straightforward and offers decent customization options. However, if you’re not comfortable with Python, this might not be your jam. Designers might find it limiting, but for hobbyists or anyone wanting a stylish map without the fuss, it's worth a shot.",
      "url": "https://github.com/yebeai/maptoposter",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "originalankur/maptoposter",
        "url": "https://github.com/originalankur/maptoposter",
        "stars": 11349
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 18, 2026",
      "updatedAt": "January 18, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 39,
        "directories": {
          "(root)": 5,
          "fonts": 3,
          "posters": 14,
          "themes": 17
        },
        "languages": {
          "Markdown": 1,
          "Python": 1,
          "JSON": 17
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [
          "requirements.txt"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".md": 1,
          ".py": 1,
          ".ttf": 3,
          ".png": 14,
          ".txt": 1,
          ".json": 17
        }
      }
    },
    {
      "id": 1136288505,
      "name": "nautilus_trader",
      "displayName": "nautilus trader",
      "description": "A high-performance algorithmic trading platform and event-driven backtester",
      "summary": "Algorithmic trading has revolutionized the financial landscape, enabling traders to execute complex strategies with precision and speed. However, many aspiring quantitative traders face significant hurdles in building and deploying their own trading systems, often getting lost in the complexities of backtesting, deployment, and real-time execution. The NautilusTrader project addresses these challenges head-on, offering an open-source, high-performance platform that simplifies the development and deployment of algorithmic trading strategies, making it accessible for both seasoned professionals and newcomers alike.\n\nAt its core, NautilusTrader is designed to facilitate the creation and execution of algorithmic trading strategies within a robust and performant environment. What sets it apart is its AI-first approach, allowing users to not only backtest strategies on historical data but also deploy them in live trading scenarios without making code changes. This is particularly appealing for traders who want to iterate quickly on their strategies and minimize the friction typically associated with transitioning from a backtesting to a live trading environment. The platform supports both Rust and Python, making it versatile for a wide range of developers and their preferred programming paradigms.\n\nDiving into the architecture of NautilusTrader, we see a well-organized file structure that reflects a commitment to maintainability and scalability. The .docker directory, for instance, contains multiple Dockerfiles, including DockerfileUbuntu, jupyterlab.dockerfile, and nautilus_trader.dockerfile, indicating a focus on containerization for easy deployment across various environments. The presence of GitHub actions in the .github/workflows folder facilitates continuous integration and delivery, ensuring that the codebase remains robust through automated testing and building processes. Additionally, with files like .env.example and .codecov.yml, the project emphasizes configuration management and code quality, essential aspects for any production-grade software.\n\nNautilusTrader can be especially beneficial in multiple use cases. For instance, a quantitative analyst could leverage the platform to backtest a multi-strategy portfolio against historical market data, quickly iterating on the performance of each strategy thanks to its event-driven architecture. Another scenario involves a hedge fund looking to deploy a new trading strategy across various exchanges simultaneously. NautilusTrader’s ability to facilitate live trading without code changes means that the fund can adapt its strategies in real-time, responding to market conditions without the typical downtime associated with deploying new code. Lastly, educators could use NautilusTrader as a teaching tool for students in financial engineering or data science programs, providing hands-on experience with a sophisticated trading platform.\n\nThe significance of NautilusTrader extends beyond its technical capabilities; it embodies a movement towards democratizing access to algorithmic trading. By providing a robust, open-source platform, it lowers the barrier to entry for traders who may not have the resources to develop proprietary trading systems from scratch. As algorithmic trading continues to evolve, platforms like NautilusTrader will play a crucial role in enabling a broader range of participants to engage in this dynamic field, ultimately fostering innovation and competition in the financial markets.",
      "url": "https://github.com/yebeai/nautilus_trader",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "nautechsystems/nautilus_trader",
        "url": "https://github.com/nautechsystems/nautilus_trader",
        "stars": 20391
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 17, 2026",
      "updatedAt": "January 17, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".cargo": 1,
          "(root)": 27,
          ".config": 1,
          ".docker": 5,
          ".github": 26,
          ".pre-commit-hooks": 15,
          ".supply-chain": 3,
          "assets": 7,
          "crates": 115
        },
        "languages": {
          "TOML": 11,
          "YAML": 24,
          "Shell": 16,
          "Docker": 2,
          "Markdown": 16,
          "Python": 1,
          "Rust": 72,
          "JSON": 33
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": "cargo",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "crates/adapters/architect_ax/src/lib.rs"
        ],
        "configFiles": [
          ".docker/DockerfileUbuntu",
          ".docker/docker-compose.yml",
          ".env.example",
          "Cargo.toml",
          "Makefile",
          "crates/Cargo.toml",
          "crates/adapters/architect_ax/Cargo.toml",
          "crates/adapters/binance/Cargo.toml"
        ],
        "dependencies": [
          "Cargo.toml",
          "crates/Cargo.toml",
          "crates/adapters/architect_ax/Cargo.toml",
          "crates/adapters/binance/Cargo.toml"
        ],
        "testFiles": [
          ".config/nextest.toml",
          ".github/actions/common-test-data/action.yml",
          ".pre-commit-hooks/check_testing_conventions.sh",
          "crates/adapters/architect_ax/examples/node_data_tester.rs",
          "crates/adapters/architect_ax/examples/node_exec_tester.rs",
          "crates/adapters/architect_ax/test_data/http_get_balances.json",
          "crates/adapters/architect_ax/test_data/http_get_instruments.json",
          "crates/adapters/architect_ax/test_data/http_get_positions.json",
          "crates/adapters/architect_ax/test_data/http_get_whoami.json",
          "crates/adapters/architect_ax/test_data/ws_cancel_rejected.json",
          "crates/adapters/architect_ax/test_data/ws_md_book_l1.json",
          "crates/adapters/architect_ax/test_data/ws_md_book_l1_captured.json",
          "crates/adapters/architect_ax/test_data/ws_md_book_l2.json",
          "crates/adapters/architect_ax/test_data/ws_md_book_l2_captured.json",
          "crates/adapters/architect_ax/test_data/ws_md_book_l3.json",
          "crates/adapters/architect_ax/test_data/ws_md_book_l3_captured.json",
          "crates/adapters/architect_ax/test_data/ws_md_candle.json",
          "crates/adapters/architect_ax/test_data/ws_md_heartbeat.json",
          "crates/adapters/architect_ax/test_data/ws_md_heartbeat_captured.json",
          "crates/adapters/architect_ax/test_data/ws_md_ticker.json",
          "crates/adapters/architect_ax/test_data/ws_md_ticker_captured.json",
          "crates/adapters/architect_ax/test_data/ws_md_trade.json",
          "crates/adapters/architect_ax/test_data/ws_md_trade_captured.json",
          "crates/adapters/architect_ax/test_data/ws_order_acknowledged.json",
          "crates/adapters/architect_ax/test_data/ws_order_cancel_response.json",
          "crates/adapters/architect_ax/test_data/ws_order_canceled.json",
          "crates/adapters/architect_ax/test_data/ws_order_done_for_day.json",
          "crates/adapters/architect_ax/test_data/ws_order_error_response.json",
          "crates/adapters/architect_ax/test_data/ws_order_expired.json",
          "crates/adapters/architect_ax/test_data/ws_order_filled.json",
          "crates/adapters/architect_ax/test_data/ws_order_heartbeat.json",
          "crates/adapters/architect_ax/test_data/ws_order_list_response.json",
          "crates/adapters/architect_ax/test_data/ws_order_list_response_with_orders.json",
          "crates/adapters/architect_ax/test_data/ws_order_open_orders_response.json",
          "crates/adapters/architect_ax/test_data/ws_order_partially_filled.json",
          "crates/adapters/architect_ax/test_data/ws_order_place_response.json",
          "crates/adapters/architect_ax/test_data/ws_order_rejected.json",
          "crates/adapters/architect_ax/test_data/ws_order_replaced.json",
          "crates/adapters/architect_ax/tests/http.rs",
          "crates/adapters/architect_ax/tests/websocket.rs",
          "crates/adapters/binance/examples/futures/node_data_tester.rs",
          "crates/adapters/binance/examples/futures/node_exec_tester.rs",
          "crates/adapters/binance/examples/spot/node_data_tester.rs",
          "crates/adapters/binance/examples/spot/node_exec_tester.rs"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "crates/adapters/architect_ax/LICENSE",
          "crates/adapters/architect_ax/README.md",
          "crates/adapters/binance/LICENSE",
          "crates/adapters/binance/README.md",
          "crates/adapters/binance/licenses/Apache-2.0-RealLogic-SBE.txt",
          "crates/adapters/binance/licenses/THIRD_PARTY_LICENSES.md",
          "crates/adapters/binance/src/common/sbe/README.md"
        ],
        "fileTypes": {
          ".toml": 11,
          ".yml": 22,
          ".sh": 16,
          ".dockerfile": 2,
          ".example": 1,
          ".md": 16,
          ".jsonc": 1,
          ".yaml": 2,
          ".lock": 2,
          ".png": 7,
          ".py": 1,
          ".rs": 72,
          ".json": 33,
          ".txt": 1
        }
      }
    },
    {
      "id": 1136286981,
      "name": "spectre",
      "displayName": "spectre",
      "description": "GPU-accelerated Factors analysis library and Backtester",
      "summary": "The Problem\nIn quantitative trading, speed is everything. When you're crunching data across thousands of assets, CPU processing can turn into a bottleneck, stretching your analysis into hours or even days. If you've ever waited for a backtest to finish, you know the pain. Enter GPU acceleration—a game changer that can cut those wait times down to a fraction.\n\nWhat This Does\nspectre is a GPU-accelerated library designed for performance in factors analysis and backtesting. The library is built on PyTorch, which means if you’re already familiar with deep learning, integrating models is a walk in the park. Check out the spectre/factors folder for various factor implementations like basic.py and technical.py—these are your tools for defining trading strategies.\n\nThe README.md provides a solid starting point, showcasing how to set up data loaders like YahooDownloader in spectre/data/yahoo.py for easy access to market data. Want to run some factors? Use the FactorEngine in spectre/factors/engine.py to add indicators like the SMA or EMA effortlessly.\n\nReal-World Use\nLet’s say you want to analyze historical price data from Yahoo Finance. You can start by downloading the data:\n\nfrom spectre.data import YahooDownloader\nYahooDownloader.ingest(startdate=\"2001\", saveto=\"./prices/yahoo\", symbols=None, skipexists=True)\n\nNext, load that data and run a factor analysis:\n\nfrom spectre import factors\nfrom spectre.data import ArrowLoader\n\nloader = ArrowLoader('./prices/yahoo/yahoo.feather')\nengine = factors.FactorEngine(loader)\nengine.tocuda()\nengine.add(factors.SMA(5), 'ma5')\ndf = engine.run('2019-01-11', '2019-01-15')\n\nNow you have a DataFrame with your moving averages, ready for further analysis or backtesting.\n\nThe Bottom Line\nspectre is a solid choice if you need speed and are working with large datasets. It's well-structured for both data ingestion and factor creation, making it easier to get started. But if your project is small or your data is limited, this might be overkill. The GPU acceleration is fantastic, but you’ll need compatible hardware to truly benefit.",
      "url": "https://github.com/yebeai/spectre",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Heerozh/spectre",
        "url": "https://github.com/Heerozh/spectre",
        "stars": 779
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 17, 2026",
      "updatedAt": "January 17, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 67,
        "directories": {
          "(root)": 6,
          "examples": 2,
          "spectre": 37,
          "tests": 22
        },
        "languages": {
          "Markdown": 1,
          "Python": 50
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "setup.py"
        ],
        "configFiles": [
          "requirements.txt",
          "setup.py"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [
          "spectre/__init__.py",
          "spectre/config.py",
          "spectre/data/__init__.py",
          "spectre/data/arrow.py",
          "spectre/data/csv.py",
          "spectre/data/dataloader.py",
          "spectre/data/iex.py",
          "spectre/data/memory.py",
          "spectre/data/quandl.py",
          "spectre/data/yahoo.py",
          "spectre/factors/__init__.py",
          "spectre/factors/basic.py",
          "spectre/factors/datafactor.py",
          "spectre/factors/engine.py",
          "spectre/factors/factor.py",
          "spectre/factors/feature.py",
          "spectre/factors/filter.py",
          "spectre/factors/label.py",
          "spectre/factors/multiprocessing.py",
          "spectre/factors/statistical.py",
          "spectre/factors/technical.py",
          "spectre/parallel/__init__.py",
          "spectre/parallel/algorithmic.py",
          "spectre/parallel/constants.py",
          "spectre/plotting/__init__.py",
          "spectre/plotting/chart.py",
          "spectre/plotting/factor_diagram.py",
          "spectre/plotting/returns_chart.py",
          "spectre/trading/__init__.py",
          "spectre/trading/algorithm.py",
          "spectre/trading/blotter.py",
          "spectre/trading/calendar.py",
          "spectre/trading/event.py",
          "spectre/trading/metric.py",
          "spectre/trading/portfolio.py",
          "spectre/trading/position.py",
          "spectre/trading/stopmodel.py",
          "tests/__init__.py",
          "tests/benchmarks_spectre.ipynb",
          "tests/benchmarks_zipline.ipynb",
          "tests/data/5mins/AAPL_2018.csv",
          "tests/data/5mins/AAPL_2019.csv",
          "tests/data/5mins/MSFT_2018.csv",
          "tests/data/5mins/MSFT_2019.csv",
          "tests/data/daily/AAPL.csv",
          "tests/data/daily/MSFT.csv",
          "tests/data/dividends/AAPL.csv",
          "tests/data/dividends/MSFT.csv",
          "tests/data/splits/AAPL.csv",
          "tests/data/splits/MSFT.csv",
          "tests/test_blotter.py",
          "tests/test_custom_factor.py",
          "tests/test_data_factor.py",
          "tests/test_data_loader.py",
          "tests/test_event.py",
          "tests/test_factor.py",
          "tests/test_metric.py",
          "tests/test_parallel_algo.py",
          "tests/test_trading_algorithm.py"
        ],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".md": 1,
          ".py": 50,
          ".txt": 1,
          ".ipynb": 2,
          ".csv": 10
        }
      }
    },
    {
      "id": 1136228839,
      "name": "MirageKit",
      "displayName": "MirageKit",
      "description": "Peer to Peer screen sharing framework from macOS to iPadOS, visionOS, and macOS",
      "summary": "In an era where remote collaboration is becoming the norm, the need for seamless screen sharing solutions is more critical than ever. Traditional remote desktop applications often introduce latency issues and cumbersome setup processes that can hinder productivity. Imagine a scenario where you need to collaborate on a complex project with colleagues scattered across various locations. What if you could share your screen effortlessly from your macOS device to an iPad or visionOS device, with low latency and high-quality video? This is precisely the problem MirageKit aims to solve—a peer-to-peer screen sharing framework designed specifically for Apple platforms that enables smooth and efficient window and desktop streaming.\n\nMirageKit stands out due to its robust architecture, which leverages the capabilities of Apple's frameworks to provide a seamless experience. Unlike other solutions, MirageKit operates using a macOS host service that captures windows or virtual displays while offering clients the ability to discover hosts and receive video streams over UDP. The inclusion of SwiftUI views for rendering streams across macOS, iOS, and visionOS adds a modern touch, making it accessible for developers looking to create visually appealing applications. The project is still in active development, which presents a unique opportunity for developers to contribute to and shape the future of this framework.\n\nDiving into the architecture, the file structure of MirageKit reveals an organized and modular design that adheres to best practices in software development. The Sources/MirageKit/Internal/Network directory, for instance, contains critical components like BonjourAdvertiser.swift and ConnectionManager.swift, which handle service discovery and network connections. This modularity allows for easier maintenance and scalability. Additionally, the Sources/MirageKit/Internal/Host directory is packed with classes such as AppStreamManager.swift and WindowCaptureEngine.swift, which facilitate the capture of application windows and the streaming of video data. The use of asynchronous programming with Swift's async/await pattern enhances the responsiveness of the application, particularly in networking operations, which are often a bottleneck in real-time applications.\n\nDevelopers can envision several use cases for MirageKit. For instance, a software development team could utilize it during code reviews, enabling one developer to share their development environment with remote team members for real-time feedback. Another scenario could involve educators using MirageKit to demonstrate software applications or programming tutorials on iPads while controlling the macOS host machine, providing an interactive learning experience. Additionally, game developers might find it useful for showcasing gameplay on different devices, allowing testers to experience the game in real-time on their preferred devices.\n\nIn summary, MirageKit represents a significant advancement in peer-to-peer screen sharing on Apple platforms. Its architectural decisions and modular file structure provide a solid foundation for developers looking to build collaborative applications. As remote work continues to gain traction, the demand for efficient and user-friendly screen sharing solutions will only grow. By adopting and contributing to projects like MirageKit, developers can not only enhance their own workflows but also play a part in shaping the future of remote collaboration tools.",
      "url": "https://github.com/yebeai/MirageKit",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "EthanLipnik/MirageKit",
        "url": "https://github.com/EthanLipnik/MirageKit",
        "stars": 486
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 17, 2026",
      "updatedAt": "January 17, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 80,
        "directories": {
          "(root)": 5,
          "Sources": 74,
          "Tests": 1
        },
        "languages": {
          "Markdown": 2,
          "Swift": 76
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [
          "Tests/MirageKitTests/MirageKitTests.swift"
        ],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".md": 2,
          ".swift": 76
        }
      }
    },
    {
      "id": 1136208924,
      "name": "feathr",
      "displayName": "feathr",
      "description": "Feathr – A scalable, unified data and AI engineering platform for enterprise",
      "summary": "In today’s data-driven landscape, organizations face the challenge of efficiently managing and utilizing vast amounts of data to drive business outcomes. The traditional methods of feature engineering often lead to bottlenecks, inconsistencies, and a lack of collaboration among data teams. This is especially true in enterprise environments where data is siloed across different departments, and the need for a unified approach to data and AI engineering becomes paramount. This is where Feathr comes into play, offering a robust solution designed to streamline the process of feature extraction and transformation in a scalable manner.\n\nFeathr is an open-source data and AI engineering platform that originated from years of production use at LinkedIn before being open-sourced in 2022. It serves as a feature store that allows organizations to define, register, and share features derived from raw data sources. What sets Feathr apart is its focus on point-in-time correctness, which is crucial in avoiding data leakage during AI model training. The platform supports both batch and streaming data, making it versatile for a variety of use cases. Additionally, it boasts a rich set of transformation APIs that are Pythonic and user-friendly, allowing data scientists to easily implement complex data transformations.\n\nFrom a technical perspective, the architecture of Feathr is designed for scalability and efficiency. The presence of multiple workflow files in the .github/workflows directory indicates a strong commitment to CI/CD practices, with workflows for code quality checks, security scanning, and automated publishing to various package repositories like Docker Hub and PyPI. The use of Dockerfiles (e.g., FeathrRegistry.Dockerfile and FeathrSandbox.Dockerfile) shows that the platform is containerized, allowing for easy deployment and testing in isolated environments. Furthermore, the inclusion of .husky/pre-commit ensures that code quality is maintained before changes are pushed, which is essential for collaborative development.\n\nFeathr is particularly beneficial in several scenarios. First, in a retail analytics context, data scientists can quickly define features such as customer behavior metrics (like purchase frequency or average basket size) using Feathr’s transformation APIs, enabling faster and more accurate predictive modeling. Second, in a financial services environment, compliance teams can leverage Feathr’s ability to register feature transformations to ensure that data used for regulatory reporting is consistent and correctly derived. Lastly, in the realm of machine learning operations (MLOps), teams can utilize Feathr’s built-in registry to share and reuse features across different models, significantly reducing redundancy and enhancing collaboration.\n\nThe implications of adopting a platform like Feathr extend beyond mere data management; they touch on the core of how organizations can leverage data as a strategic asset. By providing a unified framework for feature engineering, Feathr encourages best practices in data governance and collaboration among data teams, ultimately leading to better model performance and faster time to market. As enterprises continue to navigate the complexities of data and AI, tools like Feathr will play a pivotal role in enabling scalability, consistency, and efficiency in the data engineering process.",
      "url": "https://github.com/yebeai/feathr",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "feathr-ai/feathr",
        "url": "https://github.com/feathr-ai/feathr",
        "stars": 1926
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 17, 2026",
      "updatedAt": "January 17, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 11,
          ".github": 20,
          ".husky": 1,
          "deploy": 2,
          "docs": 159,
          "feathr-compute": 7
        },
        "languages": {
          "YAML": 18,
          "Markdown": 64,
          "Docker": 2,
          "Shell": 2,
          "JSON": 2,
          "Python": 2,
          "Java": 6
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": "gradle",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "Azure Pipelines",
        "entryPoints": [],
        "configFiles": [
          "build.gradle",
          "docs/how-to-guides/deployment/requirements.txt",
          "feathr-compute/build.gradle"
        ],
        "dependencies": [
          "build.gradle",
          "docs/how-to-guides/deployment/requirements.txt",
          "feathr-compute/build.gradle"
        ],
        "testFiles": [
          ".github/workflows/gradle-test.yml",
          ".github/workflows/pull_request_push_test.yml",
          "docs/dev_guide/cloud_integration_testing.md",
          "docs/dev_guide/dev_testing_guide.md",
          "docs/dev_guide/test_coverage_guide.md",
          "docs/how-to-guides/local-feature-testing.md",
          "docs/images/feathr-spark-udf-test.png",
          "docs/images/feathr_api_image_latest.png",
          "docs/images/feathr_api_image_latest_deployment.png",
          "docs/images/feathr_api_image_latest_options.png"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "docs/README.md",
          "docs/_config.yml",
          "docs/concepts/concepts.md",
          "docs/concepts/faq.md",
          "docs/concepts/feathr-capabilities.md",
          "docs/concepts/feathr-concepts-for-beginners.md",
          "docs/concepts/feathr-udfs.md",
          "docs/concepts/feature-definition.md",
          "docs/concepts/feature-registry.md",
          "docs/concepts/feature-store-comparison.md",
          "docs/concepts/get-offline-features.md",
          "docs/concepts/materializing-features.md",
          "docs/concepts/point-in-time-join.md",
          "docs/concepts/registry-access-control.md",
          "docs/design_docs/feature_registry_abstraction.md",
          "docs/dev_guide/aerospike_setup_guide.md",
          "docs/dev_guide/build-and-push-feathr-registry-docker-image.md",
          "docs/dev_guide/cloud_integration_testing.md",
          "docs/dev_guide/cloud_resource_provision.md",
          "docs/dev_guide/creating_bacpac_file.md",
          "docs/dev_guide/dev-guide.md",
          "docs/dev_guide/dev_testing_guide.md",
          "docs/dev_guide/doc_guide.md",
          "docs/dev_guide/feathr-core-code-structure.md",
          "docs/dev_guide/feathr_overall_release_guide.md",
          "docs/dev_guide/feature_data_maintenence_api.md",
          "docs/dev_guide/images/aerospike_aql.png",
          "docs/dev_guide/images/aerospike_aql_1.png",
          "docs/dev_guide/images/aerospike_crud.png",
          "docs/dev_guide/images/aerospike_crud_1.png",
          "docs/dev_guide/images/coverage_res.png",
          "docs/dev_guide/images/docker_port_mapping.png",
          "docs/dev_guide/images/intellij-setup.png",
          "docs/dev_guide/images/jupyterlab_browser.png",
          "docs/dev_guide/images/vscode_browser.png",
          "docs/dev_guide/new_contributor_guide.md",
          "docs/dev_guide/publish_to_maven.md",
          "docs/dev_guide/pull_request_guideline.md",
          "docs/dev_guide/python_dev_guide.md",
          "docs/dev_guide/python_package_release.md",
          "docs/dev_guide/scala_dev_guide.md",
          "docs/dev_guide/test_coverage_guide.md",
          "docs/dev_guide/update_python_docs.md",
          "docs/how-to-guides/azure-deployment-arm.md",
          "docs/how-to-guides/azure-deployment-cli.md",
          "docs/how-to-guides/azure_resource_provision.json",
          "docs/how-to-guides/azure_resource_provision.sh",
          "docs/how-to-guides/deployment-to-prod-best-practices.md",
          "docs/how-to-guides/deployment/deploy.json",
          "docs/how-to-guides/deployment/deployDataLakeStorage.bicep",
          "docs/how-to-guides/deployment/deployFeathr.ps1",
          "docs/how-to-guides/deployment/deployKV.bicep",
          "docs/how-to-guides/deployment/deployPurview.bicep",
          "docs/how-to-guides/deployment/deployRedis.bicep",
          "docs/how-to-guides/deployment/deployRoleAssignments.bicep",
          "docs/how-to-guides/deployment/deploySynapse.bicep",
          "docs/how-to-guides/deployment/main.bicep",
          "docs/how-to-guides/deployment/requirements.txt",
          "docs/how-to-guides/feathr-advanced-topic.md",
          "docs/how-to-guides/feathr-azure-machine-learning.md",
          "docs/how-to-guides/feathr-azure-sql-guidance.md",
          "docs/how-to-guides/feathr-configuration-and-env.md",
          "docs/how-to-guides/feathr-credential-passthru.md",
          "docs/how-to-guides/feathr-input-format.md",
          "docs/how-to-guides/feathr-job-configuration.md",
          "docs/how-to-guides/feathr-mlops.md",
          "docs/how-to-guides/feathr-registry-client-update.md",
          "docs/how-to-guides/feathr-snowflake-guide.md",
          "docs/how-to-guides/feathr-spark-udf-advanced.md",
          "docs/how-to-guides/how-to-guides.md",
          "docs/how-to-guides/how-to-use-azurekv.md",
          "docs/how-to-guides/jdbc-cosmos-notes.md",
          "docs/how-to-guides/local-feature-testing.md",
          "docs/how-to-guides/local-spark-provider.md",
          "docs/how-to-guides/manage-library-spark-platform.md",
          "docs/how-to-guides/model-inference-with-feathr.md",
          "docs/how-to-guides/online-transformation.md",
          "docs/how-to-guides/sparksql-source-notes.md",
          "docs/how-to-guides/streaming-source-ingestion.md",
          "docs/how-to-guides/troubleshoot-feature-definition.md",
          "docs/images/access-control-management.png",
          "docs/images/aml-authentication.png",
          "docs/images/aml-environment-switch.png",
          "docs/images/api-docs.png",
          "docs/images/app-service-url.png",
          "docs/images/architecture.png",
          "docs/images/arm-deploy-delete-rg.png",
          "docs/images/azcloud-powershell.png",
          "docs/images/azure-sql-db-compute-storage.png",
          "docs/images/azure-sql-db-hardware-configs.png",
          "docs/images/azure-sql-default-configs.png",
          "docs/images/bacpac-export.png",
          "docs/images/bacpac-sql-database.png",
          "docs/images/cognitive-search-enrichment-architecture.png",
          "docs/images/concept_illustration.jpg",
          "docs/images/conflicts-check-and-handle.png",
          "docs/images/databricks_quickstart1.png",
          "docs/images/databricks_quickstart2.png",
          "docs/images/eventhub_config.png",
          "docs/images/feathr-add-users.jpg",
          "docs/images/feathr-feature-materliazation-flow.png",
          "docs/images/feathr-get-offline-features-flow.png",
          "docs/images/feathr-rbac-role-initialization.png",
          "docs/images/feathr-sandbox-dev-experience.png",
          "docs/images/feathr-sandbox-edit-file.png",
          "docs/images/feathr-sandbox-lineage.png",
          "docs/images/feathr-sandbox-ui.png",
          "docs/images/feathr-sandbox.png",
          "docs/images/feathr-spark-udf-artifact.png",
          "docs/images/feathr-spark-udf-result.png",
          "docs/images/feathr-spark-udf-test.png",
          "docs/images/feathr-spark-udf-upload.png",
          "docs/images/feathr-ui-landingpage.png",
          "docs/images/feathr-ui.png",
          "docs/images/feathr-update.jpg",
          "docs/images/feathr_api_image_latest.png",
          "docs/images/feathr_api_image_latest_deployment.png",
          "docs/images/feathr_api_image_latest_options.png",
          "docs/images/feathr_logo.png",
          "docs/images/feathr_udf.jpg",
          "docs/images/feature-details.png",
          "docs/images/feature-summary.png",
          "docs/images/feature_flow.png",
          "docs/images/feature_store_producer_consumer.jpg",
          "docs/images/fraud-detection-visual.png",
          "docs/images/kafka-messages-monitor.png",
          "docs/images/observation_data.jpg",
          "docs/images/online_inference.jpg",
          "docs/images/point-in-time-join.png",
          "docs/images/product_recommendation.jpg",
          "docs/images/product_recommendation_advanced.jpg",
          "docs/images/product_recommendation_overview.png",
          "docs/images/purview-root-collection-permission.png",
          "docs/images/purview_permission_setting.png",
          "docs/images/registry_abstraction.png",
          "docs/images/spark-output.png",
          "docs/images/sql-query-editor-auth.png",
          "docs/images/sql-query-editor-open.png",
          "docs/images/sql-query-editor.png",
          "docs/images/sqldb-query-editor.png",
          "docs/quickstart_databricks.md",
          "docs/quickstart_local_sandbox.md",
          "docs/quickstart_synapse.md",
          "docs/release-announcements/v1.0.0.md",
          "docs/samples/azure_synapse/product_recommendation_demo.ipynb",
          "docs/samples/customer360/Customer360.ipynb",
          "docs/samples/customer360/Feature_engineering_c360.jpg",
          "docs/samples/customer360/customer360.csv",
          "docs/samples/databricks/databricks_quickstart_nyc_taxi_demo.ipynb",
          "docs/samples/document_intelligence_with_azure_cognitive_search_skills.ipynb",
          "docs/samples/feature_embedding.ipynb",
          "docs/samples/feature_naming_conflicts_samples.py",
          "docs/samples/fraud_detection_demo.ipynb",
          "docs/samples/local_quickstart_notebook.ipynb",
          "docs/samples/nyc_taxi_demo.ipynb",
          "docs/samples/product_recommendation_demo_advanced.ipynb",
          "docs/samples/time_partition_pattern_samples.py",
          "docs/talks/Feathr Community Talk – An Enterprise-Grade High Performance Feature Store.pdf",
          "docs/talks/Feathr Feature Store Talk.pdf"
        ],
        "fileTypes": {
          ".yaml": 4,
          ".md": 64,
          ".yml": 14,
          ".dockerfile": 2,
          ".gradle": 2,
          ".conf": 1,
          ".sh": 2,
          ".png": 60,
          ".json": 2,
          ".bicep": 7,
          ".ps1": 1,
          ".txt": 1,
          ".jpg": 10,
          ".ipynb": 9,
          ".csv": 1,
          ".py": 2,
          ".pdf": 2,
          ".java": 6
        }
      }
    },
    {
      "id": 1136191679,
      "name": "Personal_AI_Infrastructure",
      "displayName": "Personal AI Infrastructure",
      "description": "Personal AI Infrastructure for upgrading humans.",
      "summary": "In a world where artificial intelligence is increasingly seen as a tool for the elite, the Personal AI Infrastructure (PAI) project emerges as a revolutionary approach to democratizing access to AI capabilities. The challenge today is not just the availability of AI technologies but the ability for individuals to harness them effectively. Many people lack the technical prowess or resources to implement sophisticated AI solutions that could enhance their personal and professional lives. PAI aims to bridge this gap, providing a customizable and user-friendly framework that empowers anyone to leverage AI, regardless of their background.\n\nAt its core, PAI is an open-source platform designed to create a personal AI ecosystem tailored to individual users. This project is a fork of Daniel Miessler's original Personal AI Infrastructure, which boasts an impressive following of over 6,200 stars, indicating a strong interest in its mission. What sets PAI apart is its emphasis on customization and accessibility; it allows users to build their AI stacks using \"Packs\" and \"Bundles\" that are modular and easy to integrate. The README file outlines essential components, guiding users through the installation process while providing resources for further exploration. This approach not only caters to experienced developers but also invites novices to experiment with AI in a structured environment.\n\nDiving deeper into its architecture, PAI employs a variety of modern technologies that enhance its functionality. The presence of TypeScript in the file structure indicates a commitment to type safety and maintainability, which is crucial for building scalable applications. The use of .github/workflows files suggests a robust CI/CD pipeline that automates testing and deployment, ensuring that contributions from the community can be integrated smoothly. Additionally, the Bundles and Packs directories indicate a modular design pattern, allowing developers to create and share reusable components easily. For instance, the install.ts file within the Bundles/Official directory serves as a script for installation, streamlining the setup process and enhancing user experience. This architectural decision reflects best practices in software design, ensuring that the infrastructure is both extensible and maintainable.\n\nThe potential use cases for PAI are numerous and varied. For instance, a freelance content creator could utilize PAI to automate tasks related to research and writing, integrating Packs that analyze data and suggest content ideas based on trending topics. Similarly, a small business owner could implement PAI to create a personalized customer service agent that learns from interactions and improves over time, streamlining operations and enhancing customer satisfaction. Developers could also benefit from utilizing PAI as a sandbox for experimenting with AI algorithms, allowing them to test their ideas in a controlled environment before deployment in production systems.\n\nUltimately, the significance of PAI extends beyond just the individual components or features; it represents a shift in how we view and interact with AI technologies. By prioritizing accessibility and customization, PAI empowers users to take control of their AI experiences, breaking down barriers that have traditionally separated tech-savvy individuals from the broader population. In an era where AI has the potential to amplify human capabilities, PAI stands as a beacon of hope, ensuring that this extraordinary advantage is available to everyone, not just a select few. This democratization of AI is not merely a technological advancement; it is a movement toward a more equitable future where everyone can benefit from the power of artificial intelligence.",
      "url": "https://github.com/yebeai/Personal_AI_Infrastructure",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "danielmiessler/Personal_AI_Infrastructure",
        "url": "https://github.com/danielmiessler/Personal_AI_Infrastructure",
        "stars": 9269
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 17, 2026",
      "updatedAt": "January 17, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".claude": 1,
          "(root)": 10,
          ".github": 3,
          "Bundles": 5,
          "Packs": 181
        },
        "languages": {
          "Shell": 1,
          "YAML": 6,
          "JSON": 5,
          "Markdown": 141,
          "TypeScript": 25
        },
        "frameworks": [
          "React"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "Packs/pai-browser-skill/src/skills/Browser/index.ts"
        ],
        "configFiles": [
          ".env.example",
          "Packs/pai-agents-skill/src/skills/Agents/Tools/package.json",
          "Packs/pai-browser-skill/src/skills/Browser/package.json",
          "Packs/pai-browser-skill/src/skills/Browser/tsconfig.json"
        ],
        "dependencies": [
          "Packs/pai-agents-skill/src/skills/Agents/Tools/package.json",
          "Packs/pai-browser-skill/src/skills/Browser/package.json"
        ],
        "testFiles": [
          "Packs/pai-agents-skill/src/agents/Pentester.md",
          "Packs/pai-agents-skill/src/agents/QATester.md",
          "Packs/pai-agents-skill/src/skills/Agents/QATesterContext.md",
          "Packs/pai-browser-skill/src/skills/Browser/examples/comprehensive-test.ts"
        ],
        "docs": [
          "Bundles/Official/README.md",
          "Bundles/README.md",
          "LICENSE",
          "Packs/README.md",
          "Packs/pai-agents-skill/README.md",
          "Packs/pai-algorithm-skill/README.md",
          "Packs/pai-annualreports-skill/README.md",
          "Packs/pai-art-skill/README.md",
          "Packs/pai-brightdata-skill/README.md",
          "Packs/pai-browser-skill/README.md",
          "Packs/pai-browser-skill/src/skills/Browser/README.md",
          "Packs/pai-core-install/README.md",
          "Packs/pai-core-install/src/skills/CORE/USER/BANNER/README.md",
          "Packs/pai-core-install/src/skills/CORE/USER/PAISECURITYSYSTEM/README.md",
          "Packs/pai-core-install/src/skills/CORE/USER/README.md",
          "Packs/pai-core-install/src/skills/CORE/USER/SKILLCUSTOMIZATIONS/README.md",
          "Packs/pai-core-install/src/skills/CORE/USER/TERMINAL/README.md",
          "Packs/pai-core-install/src/skills/CORE/WORK/README.md",
          "Packs/pai-council-skill/README.md",
          "Packs/pai-createcli-skill/README.md",
          "Packs/pai-createskill-skill/README.md"
        ],
        "fileTypes": {
          ".sh": 1,
          ".example": 1,
          ".yml": 3,
          ".json": 5,
          ".md": 141,
          ".ts": 25,
          ".png": 17,
          ".yaml": 3,
          ".hbs": 1
        }
      }
    },
    {
      "id": 1136191349,
      "name": "liquid-audio",
      "displayName": "liquid audio",
      "description": "Liquid Audio - Speech-to-Speech audio models by Liquid AI",
      "summary": "The Problem\nEver tried having a real-time conversation with a machine, only to be met with awkward pauses and garbled responses? Traditional speech-to-speech systems often struggle with latency, making them feel more like a bad robot audition than a smooth chat. Liquid Audio tackles this by offering a lightweight solution that keeps the conversation flowing without the hiccups.\n\nWhat This Does\nLiquid Audio is built around the LFM2-Audio-1.5B model, which supports both interleaved and sequential generation modes. You can find the core functionality in src/liquidaudio/model/lfm2audio.py. When using LFM2AudioModel.generateinterleaved, you get a real-time output that alternates between text and audio, ideal for conversations. If you’re dealing with non-conversational tasks, switch to generatesequential, which handles things like speech-to-text without messing up your flow.\n\nThe setup is pretty straightforward. Install it using pip install liquid-audio, and if you want to play around with the demo, toss in pip install \"liquid-audio [demo]\". The demo can be launched from the terminal with liquid-audio-demo, giving you a local interface at http://localhost:7860. Want to see how it works? Check out src/liquidaudio/demo/chat.py for a basic chat implementation.\n\nReal-World Use\nPicture this: you’re building an app that lets users have multi-turn conversations with an AI assistant. You start with audio input, then switch to text for follow-ups. With Liquid Audio, you set your system prompt to “Respond with interleaved text and audio” and let the ChatState class handle the input transitions. The output is fluid, and you avoid the dreaded dead air that usually accompanies AI responses.\n\nfrom liquidaudio import LFM2AudioModel, LFM2AudioProcessor\n\nmodel = LFM2AudioModel()\nprocessor = LFM2AudioProcessor()\n\nGenerate interleaved responses\nfor output in model.generate_interleaved(inputs):\n    response = processor.decode(output)\n    print(response)\n\nThe Bottom Line\nLiquid Audio has potential, especially for developers looking to implement real-time speech interactions. The interleaved generation is a nice touch, but the whole setup might be overkill for simpler projects. If you’re diving into speech processing, give it a shot—it’s worth the time to explore. Just don’t expect it to replace your human friends anytime soon.",
      "url": "https://github.com/yebeai/liquid-audio",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Liquid4All/liquid-audio",
        "url": "https://github.com/Liquid4All/liquid-audio",
        "stars": 408
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 17, 2026",
      "updatedAt": "January 17, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 67,
        "directories": {
          ".github": 1,
          "(root)": 6,
          "assets": 2,
          "src": 58
        },
        "languages": {
          "YAML": 1,
          "Markdown": 1,
          "TOML": 1,
          "Python": 56
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "src/liquid_audio/moshi/server.py"
        ],
        "configFiles": [
          "pyproject.toml"
        ],
        "dependencies": [
          "pyproject.toml"
        ],
        "testFiles": [
          "src/liquid_audio/moshi/modules/conv_test.py",
          "src/liquid_audio/moshi/modules/seanet_test.py"
        ],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".yml": 1,
          ".md": 1,
          ".wav": 2,
          ".toml": 1,
          ".py": 56,
          ".typed": 2,
          ".lock": 1
        }
      }
    },
    {
      "id": 1136191053,
      "name": "cookbook",
      "displayName": "cookbook",
      "description": "Examples, end-2-end tutorials and apps built using Liquid AI Foundational Models (LFM) and the LEAP SDK",
      "summary": "As the demand for intelligent applications continues to surge, developers are increasingly challenged to integrate advanced AI capabilities into their projects without incurring the heavy costs and complexities typically associated with deploying such technologies. The Liquid AI Cookbook emerges as a valuable resource that addresses this challenge, providing a structured collection of examples, tutorials, and applications that leverage Liquid AI’s Foundational Models (LFM) and the LEAP SDK. This repository not only simplifies the process of incorporating AI into applications but also makes it accessible for a broader audience, from hobbyists to seasoned developers.\n\nAt its core, the Liquid AI Cookbook serves as a comprehensive guide designed around the principles of modularity and ease of use. The repository is a fork from Liquid4All's well-regarded cookbook, which has garnered substantial community support, indicated by its 1076 stars. This new iteration focuses on enhancing accessibility to Liquid AI’s open-weight models and SDK. By providing resources for customization, deployment, and application development, the Cookbook facilitates a hands-on approach to learning and integrating AI. The structured layout of the repository, with dedicated folders for different examples and tutorials, reinforces its intent to be an educational tool as much as it is a functional resource.\n\nDelving deeper into the architecture and technologies, the file structure reveals a thoughtful organization that caters to various use cases. For instance, the examples/audio-transcription-cli directory contains a well-defined workflow for real-time audio-to-text transcription. Key files such as transcribe.py, which likely contains the main transcription logic, and audio_preprocessing.py, responsible for preparing audio data, illustrate a modular approach that promotes code reusability and clarity. The presence of a Makefile in each example directory indicates a commitment to build automation, allowing developers to easily compile and execute the projects. Furthermore, assets such as GIFs in the media folder serve to visually communicate the functionalities, making it easier for users to grasp the workflows at a glance.\n\nDevelopers can leverage the Liquid AI Cookbook in several impactful scenarios. For example, a developer creating a mobile application that requires real-time transcription may utilize the audio-transcription-cli example as a starting point. By building upon this, they can customize the model to better suit their application's specific needs, whether that involves tweaking the underlying model or adapting the user interface. Additionally, the invoice-parser example provides a clear path for developers needing to automate data extraction from documents—an increasingly relevant task in various industries. By modifying this CLI tool, businesses can streamline their workflows and reduce manual data entry. Lastly, the Cookbook’s resources can empower data scientists looking to fine-tune LFM2 models for specific language tasks, as detailed in sections dedicated to model tuning.\n\nIn a landscape where AI integration can often feel daunting, the Liquid AI Cookbook stands out as a beacon of accessibility and practicality. By providing detailed examples and a clear path for customization, it democratizes the use of advanced AI technologies, enabling developers to craft intelligent solutions tailored to their unique challenges. This repository not only serves as a repository of code but also as a community-driven platform that fosters innovation and collaboration. As more developers engage with these resources, the potential for creativity and efficiency within the AI domain will undoubtedly expand, paving the way for a new generation of intelligent applications.",
      "url": "https://github.com/yebeai/cookbook",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Liquid4All/cookbook",
        "url": "https://github.com/Liquid4All/cookbook",
        "stars": 1251
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 17, 2026",
      "updatedAt": "January 17, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 157,
        "directories": {
          "(root)": 2,
          "examples": 155
        },
        "languages": {
          "Markdown": 11,
          "Python": 47,
          "Shell": 2,
          "TOML": 7,
          "YAML": 18
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "examples/invoice-parser/src/invoice_parser/main.py",
          "examples/lfm2-english-to-korean/main.py",
          "examples/voice-chat/src/voice_chat/server.py"
        ],
        "configFiles": [
          "examples/audio-transcription-cli/Makefile",
          "examples/audio-transcription-cli/pyproject.toml",
          "examples/browser-control/Makefile",
          "examples/browser-control/pyproject.toml",
          "examples/car-maker-identification/Makefile",
          "examples/car-maker-identification/pyproject.toml",
          "examples/invoice-parser/Makefile",
          "examples/invoice-parser/pyproject.toml",
          "examples/lfm2-english-to-korean/pyproject.toml",
          "examples/meeting-summarization/pyproject.toml",
          "examples/voice-chat/Makefile",
          "examples/voice-chat/pyproject.toml"
        ],
        "dependencies": [
          "examples/audio-transcription-cli/pyproject.toml",
          "examples/browser-control/pyproject.toml",
          "examples/car-maker-identification/pyproject.toml",
          "examples/invoice-parser/pyproject.toml",
          "examples/lfm2-english-to-korean/pyproject.toml",
          "examples/meeting-summarization/pyproject.toml",
          "examples/voice-chat/pyproject.toml"
        ],
        "testFiles": [
          "examples/browser-control/media/click_test.gif"
        ],
        "docs": [
          "README.md",
          "examples/audio-transcription-cli/README.md",
          "examples/browser-control/README.md",
          "examples/car-maker-identification/README.md",
          "examples/invoice-parser/README.md",
          "examples/leap-slogan-example-ios/README.md",
          "examples/lfm2-english-to-korean/README.md",
          "examples/meeting-summarization/README.md",
          "examples/vl-webgpu-demo/README.md",
          "examples/voice-chat/README.md"
        ],
        "fileTypes": {
          ".md": 11,
          ".py": 47,
          ".sh": 2,
          ".gif": 11,
          ".toml": 7,
          ".typed": 5,
          ".lock": 7,
          ".yaml": 18,
          ".jpg": 6,
          ".png": 21,
          ".webp": 2,
          ".ipynb": 2,
          ".txt": 4
        }
      }
    },
    {
      "id": 1136190068,
      "name": "square-ui",
      "displayName": "square ui",
      "description": "Collection of beautifully crafted open-source layouts UI built with shadcn/ui.",
      "summary": "In a world where user interface design can significantly impact user engagement and satisfaction, developers often face the daunting task of building visually appealing and functional layouts quickly. The challenge is not merely to make things look good but to create interfaces that are both aesthetically pleasing and highly usable across multiple devices and contexts. This is where Square UI comes into play, providing a robust collection of beautifully crafted, open-source layouts that can accelerate the development process while ensuring high-quality design standards.\n\nSquare UI is fundamentally a set of pre-designed UI layouts built with Next.js and shadcn/ui, targeting developers who are looking for a quick yet effective way to implement complex user interfaces. What sets this project apart is its emphasis on modularity and customization, allowing developers to pick and choose components that best fit their needs. Each template is designed with modern web standards in mind, making it not only a repository of layouts but a resource for best practices in UI/UX design. The inclusion of templates that utilize both Radix UI and Base UI provides flexibility for developers with varying preferences for design systems, thereby broadening its appeal.\n\nDiving into the architecture, we see that Square UI employs a clear and organized file structure, which is critical for maintainability and scalability. The separation of concerns is evident with dedicated directories for different functionalities, such as home/mdx for Markdown transformations and home/public/registry for various UI component data. The presence of configuration files like next.config.mjs, postcss.config.js, and .eslintrc.json indicates a well-thought-out setup that adheres to industry standards. Furthermore, the use of TypeScript in home/mdx-components.tsx suggests a commitment to type safety, reducing runtime errors and improving code quality. This robust architecture allows developers to easily extend or modify the existing components, fitting them into larger applications without significant overhead.\n\nThe practical applications of Square UI are numerous. For instance, a startup looking to launch a rental property platform can leverage the \"Rentals\" template, which includes features like interactive maps and property filters, thus significantly reducing the time to market. Similarly, a developer building a modern bookmarks manager can utilize the \"Bookmarks\" template to quickly integrate collections, tags, and favorites, focusing their efforts on backend functionality instead of UI design. Lastly, for businesses needing an HR dashboard, the \"Dashboard 3\" template provides a ready-made solution that includes financial charts and employee lists, permitting developers to customize it further to meet specific organizational needs.\n\nUltimately, Square UI is not just another repository of UI components; it represents a significant shift towards making high-quality design accessible to developers of all skill levels. The project stands as a testament to the power of open-source collaboration, allowing developers to leverage the hard work of others while contributing back to the community. For those looking to streamline their UI development process without compromising on quality, Square UI is an invaluable resource worth exploring. Its thoughtful architecture and extensive collection of templates embody a practical approach to modern web development, ensuring that developers can deliver polished, user-friendly interfaces in less time.",
      "url": "https://github.com/yebeai/square-ui",
      "language": null,
      "stars": 1,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "ln-dev7/square-ui",
        "url": "https://github.com/ln-dev7/square-ui",
        "stars": 4845
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 17, 2026",
      "updatedAt": "January 17, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".github": 1,
          "(root)": 3,
          "home": 83,
          "templates-baseui": 113
        },
        "languages": {
          "YAML": 3,
          "Markdown": 4,
          "JSON": 34,
          "TSX": 94,
          "JavaScript": 3,
          "CSS": 5,
          "TypeScript": 11
        },
        "frameworks": [
          "React",
          "Next.js"
        ],
        "packageManager": "pnpm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [
          "home/.env.example",
          "home/.eslintrc.json",
          "home/next.config.mjs",
          "home/package.json",
          "home/tsconfig.json",
          "templates-baseui/bookmarks/next.config.ts",
          "templates-baseui/bookmarks/package.json",
          "templates-baseui/bookmarks/tsconfig.json",
          "templates-baseui/calendar/next.config.ts",
          "templates-baseui/calendar/package.json",
          "templates-baseui/calendar/tsconfig.json"
        ],
        "dependencies": [
          "home/package-lock.json",
          "home/package.json",
          "templates-baseui/bookmarks/package.json",
          "templates-baseui/calendar/package.json"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE.md",
          "README.md",
          "home/README.md",
          "home/scripts/README.md"
        ],
        "fileTypes": {
          ".yml": 1,
          ".md": 4,
          ".example": 1,
          ".json": 34,
          ".tsx": 94,
          ".mjs": 8,
          ".js": 3,
          ".png": 25,
          ".ico": 3,
          ".svg": 2,
          ".mdx": 1,
          ".woff2": 1,
          ".css": 5,
          ".ts": 11,
          ".yaml": 2
        }
      }
    },
    {
      "id": 1136188602,
      "name": "neural-os",
      "displayName": "neural os",
      "description": "No description available",
      "summary": "As the complexity of user interfaces continues to grow, providing intuitive interactions becomes crucial for enhancing user experience. Traditional operating systems rely heavily on predefined graphical user interfaces (GUIs) that can limit flexibility and adaptability. Imagine a system that can dynamically generate a GUI based on user behavior, learning from interactions over time to create a more personalized and efficient experience. This is where NeuralOS, a groundbreaking project aimed at simulating operating systems using neural generative models, comes into play. By predicting screen frames directly from user inputs, it opens new avenues for human-computer interaction.\n\nNeuralOS leverages state-of-the-art neural network architectures to simulate GUIs in a way that traditional systems have not. The repository builds on the foundation established by latent diffusion models, enabling the generation of realistic desktop images by combining a recurrent neural network (RNN) with a diffusion-based renderer. This unique approach allows the system not only to track the state of the computer but also to render images that accurately reflect user interactions. The training data, sourced from extensive recordings of Ubuntu XFCE sessions, encompasses both random and realistic interactions, providing a diverse dataset that enhances the model's learning capabilities.\n\nA closer examination of the file structure offers insights into the architecture and technologies employed in NeuralOS. The presence of the autoencoder/ directory suggests a focus on dimensionality reduction, essential for handling high-resolution image data efficiently. The various configuration files, such as configkl4lr4.5e6loadacc1512384mar10keyboardinit16contmar15acc1_cont1e6.yaml, hint at a meticulous approach to fine-tuning the autoencoder's performance, especially as it reduces image resolutions from 512×384 to 64×48. The process of generating and processing training data is encapsulated in the data/ directory, with scripts for both data collection and aggregation, showcasing a comprehensive pipeline that ensures the model has the necessary inputs to learn effectively. \n\nThe potential applications for NeuralOS are vast and varied. For instance, game developers could utilize this technology to create more immersive environments where the GUI adapts to player behavior in real-time, enhancing engagement and gameplay. Similarly, software developers working on accessibility tools could leverage NeuralOS to build adaptive interfaces that cater to individual user needs, dynamically adjusting based on user interactions to improve usability for those with disabilities. Furthermore, the research community could benefit from NeuralOS as a platform to explore new paradigms in human-computer interaction and interface design, pushing the boundaries of how users engage with technology.\n\nIn conclusion, NeuralOS represents a significant leap forward in the realm of operating systems and user interface design. By simulating GUIs through advanced neural models, it not only addresses current limitations in adaptability but also paves the way for innovative applications across various domains. As we continue to explore the implications of such technologies, the importance of fostering flexible, generative user interfaces cannot be overstated. Projects like NeuralOS challenge the status quo and invite developers to rethink the relationship between users and their digital environments.",
      "url": "https://github.com/yebeai/neural-os",
      "language": null,
      "stars": 1,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "yuntian-group/neural-os",
        "url": "https://github.com/yuntian-group/neural-os",
        "stars": 156
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1531482615713-2afd69097998?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 17, 2026",
      "updatedAt": "January 17, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 5,
          "autoencoder": 77,
          "computer": 118
        },
        "languages": {
          "Markdown": 2,
          "Python": 47,
          "YAML": 130,
          "Shell": 16
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "autoencoder/main.py"
        ],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [
          "autoencoder/test.py"
        ],
        "docs": [
          "README.md",
          "autoencoder/readme.md"
        ],
        "fileTypes": {
          ".md": 2,
          ".py": 47,
          ".yaml": 130,
          ".slurm": 1,
          ".sh": 16,
          ".swp": 2
        }
      }
    },
    {
      "id": 1136170147,
      "name": "fast-alpr",
      "displayName": "fast alpr",
      "description": "Fast Automatic License Plate Recognition (ALPR) framework.",
      "summary": "In an era where vehicle identification and security are paramount, the need for efficient and reliable Automatic License Plate Recognition (ALPR) systems is more pressing than ever. Whether for law enforcement monitoring, toll collection, or parking management, the ability to accurately read license plates in real-time can significantly enhance operational efficiencies. However, many existing solutions struggle with speed and adaptability, making it challenging for developers to integrate ALPR capabilities into their applications seamlessly.\n\nFastALPR emerges as a high-performance, customizable framework designed to address these challenges. Unlike conventional ALPR systems, FastALPR allows developers to leverage advanced ONNX models while also offering the flexibility to swap in their own models as needed. This adaptability is crucial, as it caters to a variety of use cases and hardware configurations. The framework not only supports fast and efficient license plate detection but also integrates Optical Character Recognition (OCR) through the fast-plate-ocr library, ensuring high accuracy. FastALPR’s unique proposition lies in its combination of speed, accuracy, and customization, making it a robust choice for developers looking to implement ALPR functionality without getting bogged down by complexity.\n\nDiving deeper into the architecture, the project employs a modular design evident from its file structure. The core functionality resides in the fastalpr directory, where files like alpr.py, defaultdetector.py, and default_ocr.py encapsulate the essential components of the ALPR process. This modularity allows developers to easily extend or replace specific components without having to navigate through monolithic code. The presence of a Makefile indicates a focus on build automation, while the comprehensive set of GitHub workflows, including ci.yaml and codeql-analysis.yaml, highlights a commitment to continuous integration and code quality. Furthermore, the structured documentation found in the docs directory, including installation guides and customization options, demonstrates an understanding of developer needs, making it easier for them to onboard and contribute to the project.\n\nDevelopers can leverage FastALPR in a multitude of scenarios. For instance, a parking management system can use FastALPR to automate entry and exit logging, enhancing user experience while maintaining security. In law enforcement, the framework could be integrated into surveillance systems for real-time vehicle tracking, helping to identify stolen vehicles or track suspects. Moreover, logistics companies can utilize FastALPR to streamline their fleet management operations by monitoring vehicle compliance with regulations, ensuring that all vehicles are properly licensed and documented.\n\nThe significance of FastALPR extends beyond its immediate technical capabilities; it represents a shift towards open-source solutions that prioritize flexibility and performance. By offering a customizable framework built on robust technologies, it empowers developers to create tailored solutions that meet specific operational needs. In a landscape where the demand for efficient ALPR systems continues to grow, FastALPR stands out not just as a tool, but as a catalyst for innovation in vehicle identification technology.",
      "url": "https://github.com/yebeai/fast-alpr",
      "language": null,
      "stars": 1,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "ankandrew/fast-alpr",
        "url": "https://github.com/ankandrew/fast-alpr",
        "stars": 417
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1542831371-29b0f74f9713?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 17, 2026",
      "updatedAt": "January 17, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 35,
        "directories": {
          "(root)": 9,
          ".github": 8,
          "assets": 5,
          "docs": 6,
          "fast_alpr": 5,
          "test": 2
        },
        "languages": {
          "JSON": 1,
          "YAML": 9,
          "Markdown": 7,
          "Python": 7,
          "TOML": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          "Makefile",
          "pyproject.toml"
        ],
        "dependencies": [
          "pyproject.toml"
        ],
        "testFiles": [
          ".github/workflows/test.yaml",
          "assets/test_image.png",
          "test/__init__.py",
          "test/test_alpr.py"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "docs/contributing.md",
          "docs/custom_models.md",
          "docs/index.md",
          "docs/installation.md",
          "docs/quick_start.md",
          "docs/reference.md"
        ],
        "fileTypes": {
          ".json": 1,
          ".yaml": 8,
          ".md": 7,
          ".gif": 2,
          ".png": 2,
          ".webp": 1,
          ".py": 7,
          ".yml": 1,
          ".toml": 1,
          ".lock": 1
        }
      }
    },
    {
      "id": 1136168479,
      "name": "onchainkit",
      "displayName": "onchainkit",
      "description": "React components and TypeScript utilities to help you build top-tier onchain apps.",
      "summary": "The Problem\nBuilding on-chain applications can be a drag. You often end up reinventing the wheel for basic UI components and TypeScript utilities, wasting time on boilerplate instead of focusing on what actually matters—your app’s functionality. You need a solid toolkit that gives you the essentials without the fluff.\n\nWhat This Does\nEnter OnchainKit. This repository offers a set of React components and TypeScript utilities designed to make your life easier when developing on-chain apps. The README.md provides a quickstart guide, allowing you to bootstrap an example project with a single command: npm create onchain. \n\nThe monorepo structure is a bonus. It’s organized with pnpm workspaces, meaning you can run scripts in specific packages using pnpm [-F | --filter] <package-name> <script-name> or execute them across the board with pnpm run <script-name>. For instance, if you want to fire up the playground to test your components, you just run pnpm f:play dev:watch, and voilà, you’re good to go at http://localhost:3000.\n\nReal-World Use\nImagine you're building a decentralized finance (DeFi) app. You need a wallet connection component and a transaction history UI. Instead of searching through a stack of libraries or crafting components from scratch, you pull in OnchainKit's ready-to-use components. Want to run tests? Just hit pnpm run test, and you're on your way. The integration is straightforward, letting you focus on business logic rather than UI headaches.\n\nThe Bottom Line\nOnchainKit is a solid pick for developers diving into on-chain applications. It offers the essentials without unnecessary complexity. However, if you're working on a small project or a prototype, this may feel like overkill. For teams wanting to build and iterate quickly on robust applications, though, this toolkit is a win.",
      "url": "https://github.com/yebeai/onchainkit",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "coinbase/onchainkit",
        "url": "https://github.com/coinbase/onchainkit",
        "stars": 1020
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 17, 2026",
      "updatedAt": "January 17, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".changeset": 3,
          ".github": 20,
          "(root)": 11,
          "assets": 1,
          "examples": 34,
          "packages": 131
        },
        "languages": {
          "Markdown": 15,
          "JSON": 14,
          "JavaScript": 8,
          "YAML": 19,
          "TypeScript": 70,
          "TSX": 49,
          "CSS": 3,
          "HTML": 1
        },
        "frameworks": [
          "React",
          "Next.js",
          "Express",
          "Tailwind"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "packages/create-onchain/src/cli.ts",
          "packages/miniapp-manifest-generator/index.html",
          "packages/miniapp-manifest-generator/src/App.tsx",
          "packages/onchainkit/.storybook/main.ts",
          "packages/onchainkit/src/api/index.ts"
        ],
        "configFiles": [
          ".prettierrc",
          "examples/minikit-example/.prettierrc",
          "examples/minikit-example/next.config.ts",
          "examples/minikit-example/package.json",
          "examples/minikit-example/tsconfig.json",
          "package.json",
          "packages/create-onchain/package.json",
          "packages/create-onchain/tsconfig.json",
          "packages/miniapp-manifest-generator/package.json",
          "packages/miniapp-manifest-generator/tailwind.config.js",
          "packages/miniapp-manifest-generator/tsconfig.json",
          "packages/miniapp-manifest-generator/vite.config.ts",
          "packages/onchainkit/package.json"
        ],
        "dependencies": [
          "examples/minikit-example/package.json",
          "package.json",
          "packages/create-onchain/package.json",
          "packages/miniapp-manifest-generator/package.json",
          "packages/onchainkit/package.json"
        ],
        "testFiles": [
          ".github/workflows/cli-test.yml",
          ".github/workflows/miniapp-manifest-test.yml",
          ".github/workflows/test.yml",
          "packages/create-onchain/scripts/publish-prerelease.test.ts",
          "packages/create-onchain/src/analytics.test.ts",
          "packages/create-onchain/src/cli.test.ts",
          "packages/create-onchain/src/minikit.test.ts",
          "packages/create-onchain/src/onchainkit.test.ts",
          "packages/create-onchain/src/utils.test.ts",
          "packages/create-onchain/vitest.config.ts",
          "packages/miniapp-manifest-generator/scripts/copyBuild.test.ts",
          "packages/miniapp-manifest-generator/src/components/Page.test.tsx",
          "packages/miniapp-manifest-generator/src/components/Step.test.tsx",
          "packages/miniapp-manifest-generator/src/components/Success.test.tsx",
          "packages/miniapp-manifest-generator/src/components/steps/Connect.test.tsx",
          "packages/miniapp-manifest-generator/src/components/steps/Domain.test.tsx",
          "packages/miniapp-manifest-generator/src/components/steps/Sign.test.tsx",
          "packages/miniapp-manifest-generator/src/hooks/useFid.test.tsx",
          "packages/miniapp-manifest-generator/src/hooks/useSignManifest.test.tsx",
          "packages/miniapp-manifest-generator/src/hooks/useValidateManifest.test.tsx",
          "packages/miniapp-manifest-generator/src/utilities/base64.test.ts",
          "packages/miniapp-manifest-generator/src/utilities/validateUrl.test.ts",
          "packages/miniapp-manifest-generator/vitest.config.ts",
          "packages/miniapp-manifest-generator/vitest.setup.ts",
          "packages/onchainkit/plugins/__tests__/babel-prefix-react-classnames.test.ts",
          "packages/onchainkit/plugins/__tests__/postcss-prefix-classnames.test.ts",
          "packages/onchainkit/scripts/get-next-version.test.ts",
          "packages/onchainkit/scripts/publish-prerelease.test.ts",
          "packages/onchainkit/scripts/validate-build.test.ts",
          "packages/onchainkit/src/DefaultOnchainKitProviders.test.tsx",
          "packages/onchainkit/src/OnchainKitProvider.test.tsx",
          "packages/onchainkit/src/OnchainKitProviderBoundary.test.tsx",
          "packages/onchainkit/src/api/buildMintTransaction.test.ts",
          "packages/onchainkit/src/api/buildPayTransaction.test.ts",
          "packages/onchainkit/src/api/buildSendTransaction.test.ts",
          "packages/onchainkit/src/api/buildSwapTransaction.test.ts",
          "packages/onchainkit/src/api/getMintDetails.test.ts",
          "packages/onchainkit/src/api/getPortfolios.test.ts",
          "packages/onchainkit/src/api/getPriceQuote.test.ts",
          "packages/onchainkit/src/api/getSwapQuote.test.ts",
          "packages/onchainkit/src/api/getTokenDetails.test.ts",
          "packages/onchainkit/src/api/getTokens.test.ts",
          "packages/onchainkit/src/api/utils/buildErrorStruct.test.ts",
          "packages/onchainkit/src/api/utils/getAPIParamsForToken.test.ts",
          "packages/onchainkit/src/api/utils/getPayErrorMessage.test.ts",
          "packages/onchainkit/src/api/utils/getSwapTransaction.test.ts",
          "packages/onchainkit/src/appchain/bridge/components/AppchainBridge.test.tsx",
          "packages/onchainkit/src/appchain/bridge/components/AppchainBridgeAddressInput.test.tsx",
          "packages/onchainkit/src/appchain/bridge/components/AppchainBridgeInput.test.tsx",
          "packages/onchainkit/src/appchain/bridge/components/AppchainBridgeProvider.test.tsx",
          "packages/onchainkit/src/appchain/bridge/components/AppchainBridgeResumeTransaction.test.tsx"
        ],
        "docs": [
          ".changeset/README.md",
          "LICENSE.md",
          "README.md",
          "alpha-upgrade-guide.md",
          "examples/minikit-example/README.md",
          "packages/create-onchain/CHANGELOG.md",
          "packages/create-onchain/README.md",
          "packages/miniapp-manifest-generator/README.md",
          "packages/onchainkit/CHANGELOG.md",
          "packages/onchainkit/CONTRIBUTING.md",
          "packages/onchainkit/README.md"
        ],
        "fileTypes": {
          ".md": 15,
          ".json": 14,
          ".js": 8,
          ".yml": 19,
          ".png": 6,
          ".mjs": 3,
          ".ts": 70,
          ".tsx": 49,
          ".ico": 1,
          ".css": 3,
          ".cjs": 1,
          ".svg": 1,
          ".html": 1
        }
      }
    },
    {
      "id": 1136147379,
      "name": "map",
      "displayName": "map",
      "description": "An open-source job-data + geospatial visualization platform for tech roles.",
      "summary": "In an increasingly competitive job market, especially within the tech industry, candidates often struggle to find suitable opportunities that align with their skills and aspirations. Traditional job search platforms frequently lack the geospatial context that can help job seekers visualize opportunities in relation to their preferred locations. This is where the open-source project known as \"map\" comes into play. By providing an interactive, dark-mode map that visualizes job openings from top tech companies around the world, this platform addresses a significant pain point for both job seekers and employers. \n\nThe \"map\" project is designed to streamline the job search experience through a user-friendly interface that integrates geospatial data with job listings from companies like OpenAI, Google, and Microsoft. Built using modern web technologies such as Next.js, React, and TypeScript, it leverages Mapbox GL for powerful map rendering capabilities. What sets this project apart is not only its focus on visualizing job opportunities but also its built-in AI assistant, which enhances the user experience by allowing candidates to query job listings and receive tailored suggestions based on their preferences. This unique feature could significantly reduce the time spent searching for jobs and improve the relevance of the listings presented to users.\n\nTaking a closer look at the architecture and file structure of the project reveals a thoughtful approach to development. The repository contains essential files like next.config.ts and package.json, which are standard for any Next.js application. The src/app/api directory highlights the backend capabilities, where various routes are defined for handling alerts and job inquiries, showcasing a RESTful design pattern. The public directory is populated with CSV files and icons, indicating a commitment to a rich user interface and data-driven functionality. The presence of drizzle.config.ts suggests that the project might also incorporate some form of data management or state handling, potentially enhancing the responsiveness and performance of the application.\n\nDevelopers can leverage this platform in a variety of scenarios. For instance, a startup looking to attract tech talent can use the \"map\" to visually pinpoint their job postings against competitors, making it easier for potential applicants to discover opportunities in their desired regions. Additionally, a developer or data scientist interested in analyzing job market trends can utilize the underlying data structure, accessing the CSV files to extract insights about job availability and requirements across different tech hubs. Furthermore, companies seeking to enhance their recruitment strategies can contribute by suggesting their own job listings, thereby enriching the platform with diverse opportunities.\n\nUltimately, the \"map\" project highlights the intersection of technology and job searching, providing a solution that is not only innovative but also practical. In a landscape where traditional job boards often fall short, this open-source initiative empowers both job seekers and employers by harnessing the power of geospatial visualization and AI. As the project continues to evolve, it has the potential to redefine how tech roles are discovered and engaged with, making it a significant contribution to the open-source community and the job market at large.",
      "url": "https://github.com/yebeai/map",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "kalil0321/map",
        "url": "https://github.com/kalil0321/map",
        "stars": 19
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 17, 2026",
      "updatedAt": "January 17, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 97,
        "directories": {
          "(root)": 11,
          "assets": 1,
          "public": 14,
          "src": 71
        },
        "languages": {
          "Markdown": 1,
          "TypeScript": 31,
          "JSON": 3,
          "TSX": 35,
          "CSS": 2
        },
        "frameworks": [
          "React",
          "Next.js"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [
          "next.config.ts",
          "package.json",
          "tsconfig.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".md": 1,
          ".svg": 5,
          ".ts": 31,
          ".example": 1,
          ".mjs": 2,
          ".json": 3,
          ".csv": 1,
          ".ico": 2,
          ".png": 11,
          ".jpeg": 1,
          ".tsx": 35,
          ".css": 2
        }
      }
    },
    {
      "id": 1135904947,
      "name": "OpenScreen",
      "displayName": "OpenScreen",
      "description": "Desktop application for screen sharing over the network",
      "summary": "In today's increasingly remote work environment, the need for effective screen-sharing solutions has never been more critical. Consider the scenario where a software developer needs to showcase a new feature to a team member located halfway across the world. Traditional conferencing tools may suffice, but they often come with limitations—either in terms of quality, control, or ease of use. OpenScreen emerges as a compelling solution by addressing these pain points with a desktop application specifically designed for seamless screen sharing over the network.\n\nOpenScreen is a desktop application aimed at providing a straightforward yet powerful means of screen sharing. What sets it apart is its emphasis on flexibility: users can share their entire screen or select specific application windows, making it adaptable for various use cases, whether for technical demonstrations, remote support, or collaborative brainstorming sessions. The ability to toggle cursor visibility and adjust the quality and frames per second (FPS) further enhances the user experience, allowing for a tailored presentation depending on network conditions or audience needs. This level of control is particularly valuable in professional settings where clarity and responsiveness can make all the difference.\n\nFrom a technical perspective, OpenScreen is built primarily using C# and the .NET Framework 4.7.2, showcasing a well-organized architecture. The file structure reveals a separation of concerns that indicates thoughtful design. For instance, the OpenScreen.Core folder contains various classes dedicated to handling different functionalities, such as MjpegStream.cs, which manages the MJPEG stream for video transmission, and Screenshot.cs, which encapsulates methods for capturing and processing screenshots. The Server folder includes essential components like StreamingServer.cs and ServerSocketExtension.cs, which suggest a robust implementation for managing network communications. This modular structure not only promotes maintainability but also allows for future enhancements, such as support for additional protocols or video codecs.\n\nDevelopers can leverage OpenScreen in several scenarios. For example, a tech support team could utilize the application to guide users through troubleshooting steps by sharing their screen in real time, providing a hands-on experience without needing third-party tools. Additionally, educators could employ OpenScreen to demonstrate coding techniques or software usage to students remotely, ensuring an interactive learning environment. Lastly, product teams could use it for showcasing new features during sprint reviews or stakeholder meetings, allowing for immediate feedback and discussions.\n\nIn conclusion, OpenScreen represents a timely solution to the challenges of remote collaboration, particularly in the tech community. By combining flexibility, ease of use, and a strong architectural foundation, it caters to the diverse needs of today’s developers and teams. As open-source projects continue to evolve in this space, OpenScreen stands out as one to watch, offering a platform for contributions and enhancements that could shape the future of screen-sharing technology. Embracing such tools not only streamlines workflows but also fosters a culture of collaboration that is indispensable in the modern workplace.",
      "url": "https://github.com/yebeai/OpenScreen",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "MrKonstantinSh/OpenScreen",
        "url": "https://github.com/MrKonstantinSh/OpenScreen",
        "stars": 96
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 16, 2026",
      "updatedAt": "January 16, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 36,
        "directories": {
          "(root)": 4,
          "Images": 3,
          "OpenScreen.Core": 14,
          "OpenScreen.Installer": 1,
          "OpenScreen": 14
        },
        "languages": {
          "C#": 19,
          "Markdown": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".png": 2,
          ".ico": 3,
          ".cs": 19,
          ".csproj": 2,
          ".vdproj": 1,
          ".sln": 1,
          ".config": 1,
          ".xaml": 2,
          ".resx": 1,
          ".settings": 1,
          ".md": 1
        }
      }
    },
    {
      "id": 1135902079,
      "name": "Autonomous-LLM-Agents",
      "displayName": "Autonomous LLM Agents",
      "description": "MCP-Zero: Active Tool Discovery for Autonomous LLM Agents",
      "summary": "In an increasingly automated world, the need for systems that can intelligently discover and utilize tools on demand has never been more pressing. Consider a scenario where a developer needs to build an application that interacts with numerous APIs across various domains, from finance to weather. Manually sifting through documentation and understanding the capabilities of each available tool can be time-consuming and error-prone. This is where MCP-Zero steps in, providing a framework for active tool discovery that empowers autonomous LLM (Large Language Model) agents to efficiently identify and use the right tools based on context.\n\nMCP-Zero is an innovative initiative aimed at enhancing the capabilities of LLMs by enabling them to autonomously discover and deploy tools tailored to specific tasks. The project is built on the premise that LLMs can be more effective when they can dynamically interact with external APIs and services rather than relying solely on pre-trained knowledge. What sets MCP-Zero apart is its focus on active tool discovery, allowing agents to construct toolchains based on contextual queries. The repository includes a comprehensive set of experiments, tools, and datasets that facilitate the application of this methodology in real-world situations.\n\nDelving into the technical architecture of MCP-Zero, the repository's structure organizes its functionalities into distinct modules, each serving a specific purpose. The MCP-zero directory contains essential scripts like matcher.py, which implements similarity matching algorithms crucial for identifying relevant tools based on user queries. The experimentapibank.py and experimentmcptools.py files showcase how different datasets can be leveraged to evaluate the performance of the tool discovery mechanism. The prompt structures found in the prompt_guide directory are key for guiding the LLM in generating meaningful queries, and the reformatter.py script ensures that tool descriptions are correctly formatted for processing. This modular design not only promotes code reusability but also simplifies the integration of new functionalities.\n\nMCP-Zero has several practical applications that developers can leverage. For instance, a developer building a chatbot for customer service could use MCP-Zero to autonomously discover and interact with various backend APIs, providing real-time responses to customer queries without hardcoding API calls. Another scenario could involve data scientists using MCP-Zero to automate the selection of machine learning tools based on user-defined criteria, streamlining the experimentation process when evaluating different models. Additionally, in the realm of IoT, autonomous agents powered by MCP-Zero could discover the most appropriate tools to interact with various devices based on real-time data, enhancing operational efficiency.\n\nThe implications of MCP-Zero extend beyond mere convenience; they signify a pivotal shift toward more intelligent and adaptable software systems. By enabling LLMs to actively discover and utilize tools, developers can create applications that not only respond to user needs but also evolve over time. The ability to dynamically construct toolchains based on contextual understanding opens up new avenues for automation and efficiency, making it essential for developers to explore and adopt such technologies in their projects. As MCP-Zero continues to evolve, it stands as a testament to the potential of autonomous agents in transforming the landscape of software development.",
      "url": "https://github.com/yebeai/Autonomous-LLM-Agents",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "0xSojalSec/Autonomous-LLM-Agents",
        "url": "https://github.com/0xSojalSec/Autonomous-LLM-Agents",
        "stars": 11
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 16, 2026",
      "updatedAt": "January 16, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 24,
        "directories": {
          "(root)": 4,
          "MCP-tools": 4,
          "MCP-zero": 14,
          "assets": 2
        },
        "languages": {
          "Python": 8,
          "Shell": 1,
          "Markdown": 2
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [
          "requirements.txt"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [
          "MCP-zero/test_cases.jsonl",
          "MCP-zero/test_matcher.py"
        ],
        "docs": [
          "LICENSE",
          "MCP-zero/prompt_guide/system_ours_apibank.prompt",
          "MCP-zero/prompt_guide/system_ours_apibank_icl.prompt",
          "MCP-zero/prompt_guide/system_ours_mcptools.prompt",
          "MCP-zero/prompt_guide/system_vanilla.prompt",
          "MCP-zero/prompt_guide/user_query_with_server.prompt",
          "MCP-zero/prompt_guide/user_query_without_server.prompt",
          "README.md"
        ],
        "fileTypes": {
          ".py": 8,
          ".sh": 1,
          ".prompt": 7,
          ".md": 2,
          ".jsonl": 1,
          ".png": 2,
          ".txt": 1
        }
      }
    },
    {
      "id": 1135853604,
      "name": "copilot-sdk",
      "displayName": "copilot sdk",
      "description": "Multi-platform SDK for integrating GitHub Copilot Agent into apps and services",
      "summary": "The Problem\nIntegrating GitHub Copilot into your applications can be a pain. You either end up rolling your own solution or spending too much time wrestling with API calls. The copilot-sdk aims to smooth out this experience by providing language-specific SDKs that allow you to interact with the Copilot CLI easily, without reinventing the wheel.\n\nWhat This Does\nThis repository offers multiple SDKs for different programming languages, including Node.js, Python, Go, and .NET. Each SDK is located in its respective folder, like ./nodejs/ or ./dotnet/, where you can find installation instructions and usage examples in their README.md files.\n\nFor example, if you're using the .NET SDK, you can add it to your project with dotnet add package GitHub.Copilot.SDK. The SDK manages the lifecycle of the Copilot CLI process automatically, so you don't have to include boilerplate code to handle that. You can even connect to an external CLI server if your use case requires it, which is documented in the individual SDK docs.\n\nReal-World Use\nImagine you’re building an app that needs to provide code suggestions based on user input. With the Node.js SDK, you can set up a basic integration like this:\n\nconst { CopilotClient } = require('@github/copilot-sdk');\n\nconst client = new CopilotClient();\nclient.start(); // Starts the Copilot CLI automatically\n\nclient.onSuggestion((suggestion) => {\n    console.log('Suggested Code:', suggestion);\n});\n\nThis snippet sets up the Copilot client and listens for code suggestions. You can adapt this for your specific needs, which saves you from diving deep into JSON-RPC calls.\n\nThe Bottom Line\nThe copilot-sdk is a solid choice if you want to integrate GitHub Copilot into your applications without losing your sanity. The multi-language support is a plus, but be cautious if you're just prototyping or working on small projects—this might feel like overkill. Still, if you’re building something that genuinely benefits from AI-assisted coding, this SDK could make your life a lot easier.",
      "url": "https://github.com/yebeai/copilot-sdk",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "github/copilot-sdk",
        "url": "https://github.com/github/copilot-sdk",
        "stars": 7416
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 16, 2026",
      "updatedAt": "January 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 193,
        "directories": {
          ".devcontainer": 1,
          "(root)": 9,
          ".github": 14,
          ".vscode": 2,
          "dotnet": 20,
          "go": 23,
          "nodejs": 32,
          "python": 28,
          "test": 64
        },
        "languages": {
          "JSON": 12,
          "YAML": 60,
          "Markdown": 14,
          "C#": 15,
          "Go": 17,
          "Shell": 1,
          "TypeScript": 28,
          "JavaScript": 3,
          "Python": 23,
          "TOML": 1
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "nodejs/src/index.ts",
          "python/setup.py",
          "test/harness/server.ts"
        ],
        "configFiles": [
          "go/go.mod",
          "nodejs/.prettierrc.json",
          "nodejs/package.json",
          "nodejs/tsconfig.json",
          "python/pyproject.toml",
          "python/setup.py",
          "test/harness/package.json",
          "test/harness/tsconfig.json"
        ],
        "dependencies": [
          "go/go.mod",
          "nodejs/package-lock.json",
          "nodejs/package.json",
          "python/pyproject.toml",
          "test/harness/package-lock.json",
          "test/harness/package.json"
        ],
        "testFiles": [
          ".github/workflows/sdk-e2e-tests.yml",
          "dotnet/test/ClientTests.cs",
          "dotnet/test/GitHub.Copilot.SDK.Test.csproj",
          "dotnet/test/Harness/CapiProxy.cs",
          "dotnet/test/Harness/E2ETestBase.cs",
          "dotnet/test/Harness/E2ETestContext.cs",
          "dotnet/test/Harness/E2ETestFixture.cs",
          "dotnet/test/Harness/TestHelper.cs",
          "dotnet/test/McpAndAgentsTests.cs",
          "dotnet/test/PermissionTests.cs",
          "dotnet/test/SessionTests.cs",
          "dotnet/test/ToolsTests.cs",
          "go/client_test.go",
          "go/definetool_test.go",
          "go/e2e/client_test.go",
          "go/e2e/mcp_and_agents_test.go",
          "go/e2e/permissions_test.go",
          "go/e2e/session_test.go",
          "go/e2e/testharness/context.go",
          "go/e2e/testharness/helper.go",
          "go/e2e/testharness/proxy.go",
          "go/e2e/tools_test.go",
          "go/test.sh",
          "nodejs/test/client.test.ts",
          "nodejs/test/e2e/client.test.ts",
          "nodejs/test/e2e/harness/CapiProxy.ts",
          "nodejs/test/e2e/harness/sdkTestContext.ts",
          "nodejs/test/e2e/harness/sdkTestHelper.ts",
          "nodejs/test/e2e/mcp-and-agents.test.ts",
          "nodejs/test/e2e/permissions.test.ts",
          "nodejs/test/e2e/session.test.ts",
          "nodejs/test/e2e/tools.test.ts",
          "nodejs/vitest.config.ts",
          "python/e2e/conftest.py",
          "python/e2e/test_client.py",
          "python/e2e/test_mcp_and_agents.py",
          "python/e2e/test_permissions.py",
          "python/e2e/test_session.py",
          "python/e2e/test_tools.py",
          "python/e2e/test_tools_unit.py",
          "python/e2e/testharness/__init__.py",
          "python/e2e/testharness/context.py",
          "python/e2e/testharness/helper.py",
          "python/e2e/testharness/proxy.py",
          "python/test-requirements.txt",
          "python/test_client.py",
          "test/harness/.gitignore",
          "test/harness/capturingHttpProxy.test.ts",
          "test/harness/capturingHttpProxy.ts",
          "test/harness/package-lock.json",
          "test/harness/package.json",
          "test/harness/replayingCapiProxy.test.ts",
          "test/harness/replayingCapiProxy.ts",
          "test/harness/server.ts",
          "test/harness/tsconfig.json",
          "test/harness/util.ts",
          "test/harness/vitest.config.ts",
          "test/snapshots/ask/should_invoke_onevent_callback_for_each_event.yaml",
          "test/snapshots/ask/should_return_assistant_message_content.yaml",
          "test/snapshots/combinedconfiguration/accept_mcp_servers_and_custom_agents.yaml",
          "test/snapshots/customagents/accept_custom_agent_config_on_create.yaml",
          "test/snapshots/customagents/accept_custom_agent_config_on_resume.yaml",
          "test/snapshots/mcp-and-agents/should_accept_both_mcp_servers_and_custom_agents.yaml",
          "test/snapshots/mcp-and-agents/should_accept_custom_agent_configuration_on_session_create.yaml",
          "test/snapshots/mcp-and-agents/should_accept_custom_agent_configuration_on_session_resume.yaml",
          "test/snapshots/mcp-and-agents/should_accept_mcp_server_configuration_on_session_create.yaml",
          "test/snapshots/mcp-and-agents/should_accept_mcp_server_configuration_on_session_resume.yaml",
          "test/snapshots/mcp_and_agents/accept_custom_agent_config_on_create.yaml",
          "test/snapshots/mcp_and_agents/accept_custom_agent_config_on_resume.yaml",
          "test/snapshots/mcp_and_agents/accept_mcp_server_config_on_create.yaml",
          "test/snapshots/mcp_and_agents/accept_mcp_server_config_on_resume.yaml",
          "test/snapshots/mcp_and_agents/accept_mcp_servers_and_custom_agents.yaml",
          "test/snapshots/mcpservers/accept_mcp_server_config_on_create.yaml",
          "test/snapshots/mcpservers/accept_mcp_server_config_on_resume.yaml",
          "test/snapshots/permissions/async_permission_handler.yaml",
          "test/snapshots/permissions/deny_permission.yaml",
          "test/snapshots/permissions/permission_handler_errors.yaml",
          "test/snapshots/permissions/permission_handler_for_shell_commands.yaml",
          "test/snapshots/permissions/permission_handler_for_write_operations.yaml",
          "test/snapshots/permissions/resume_session_with_permission_handler.yaml",
          "test/snapshots/permissions/should_deny_permission_when_handler_returns_denied.yaml",
          "test/snapshots/permissions/should_handle_async_permission_handler.yaml",
          "test/snapshots/permissions/should_handle_permission_handler_errors_gracefully.yaml",
          "test/snapshots/permissions/should_invoke_permission_handler_for_shell_commands.yaml",
          "test/snapshots/permissions/should_invoke_permission_handler_for_write_operations.yaml",
          "test/snapshots/permissions/should_receive_toolcallid_in_permission_requests.yaml",
          "test/snapshots/permissions/should_resume_session_with_permission_handler.yaml",
          "test/snapshots/permissions/should_work_without_permission_handler__default_behavior_.yaml",
          "test/snapshots/permissions/tool_call_id_in_permission_requests.yaml",
          "test/snapshots/permissions/without_permission_handler.yaml",
          "test/snapshots/query/should_stream_events_and_return_assistant_message.yaml",
          "test/snapshots/query/should_support_resume_option_for_multi_turn_conversations.yaml",
          "test/snapshots/session/send_returns_immediately_while_events_stream_in_background.yaml",
          "test/snapshots/session/sendandwait_blocks_until_session_idle_and_returns_final_assistant_message.yaml",
          "test/snapshots/session/should_abort_a_session.yaml",
          "test/snapshots/session/should_create_a_session_with_appended_systemmessage_config.yaml",
          "test/snapshots/session/should_create_a_session_with_availabletools.yaml",
          "test/snapshots/session/should_create_a_session_with_excludedtools.yaml",
          "test/snapshots/session/should_create_a_session_with_replaced_systemmessage_config.yaml",
          "test/snapshots/session/should_create_session_with_custom_tool.yaml",
          "test/snapshots/session/should_have_stateful_conversation.yaml",
          "test/snapshots/session/should_pass_streaming_option_to_session_creation.yaml",
          "test/snapshots/session/should_receive_session_events.yaml",
          "test/snapshots/session/should_receive_streaming_delta_events_when_streaming_is_enabled.yaml",
          "test/snapshots/session/should_resume_a_session_using_a_new_client.yaml",
          "test/snapshots/session/should_resume_a_session_using_the_same_client.yaml",
          "test/snapshots/tools/can_receive_and_return_complex_types.yaml",
          "test/snapshots/tools/handles_tool_calling_errors.yaml",
          "test/snapshots/tools/invokes_built_in_tools.yaml",
          "test/snapshots/tools/invokes_custom_tool.yaml"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "dotnet/README.md",
          "go/README.md",
          "nodejs/README.md",
          "python/README.md"
        ],
        "fileTypes": {
          ".json": 12,
          ".yml": 6,
          ".md": 14,
          ".yaml": 54,
          ".sln": 1,
          ".cs": 15,
          ".csproj": 2,
          ".go": 17,
          ".mod": 1,
          ".sum": 1,
          ".sh": 1,
          ".ts": 28,
          ".js": 3,
          ".py": 23,
          ".toml": 1,
          ".txt": 1,
          ".lock": 1
        }
      }
    },
    {
      "id": 1135847047,
      "name": "grok-1",
      "displayName": "grok 1",
      "description": "Grok open release",
      "summary": "The Problem\nTraining large language models is a pain. You need massive datasets, high-performance hardware, and, let’s be real, a PhD in deep learning. Grok-1 steps in to make things a bit simpler by providing an open-weights model, so you don’t have to start from scratch.\n\nWhat This Does\nThe run.py script in this repo is your entry point for testing the Grok-1 model. You’ll need to download the weights first and put the ckpt-0 directory in the checkpoints folder. Once that’s done, just pip install -r requirements.txt and you’re ready to fire it up. The script loads the model and samples from it based on your input.\n\nGrok-1 is built on a Mixture of Experts (MoE) architecture, featuring a whopping 314 billion parameters and 64 layers. You’ll find the model specifics in model.py, which outlines how the layers and attention heads are configured. The implementation isn’t optimized for efficiency, but it’s set up that way to keep things straightforward while you validate the model's correctness.\n\nReal-World Use\nImagine you want to generate text based on a prompt. After setting up your environment and ensuring you have a GPU that won't cry for mercy, you can run:\n\npython run.py --input \"What is the future of AI?\"\n\nThis will load your model, utilize the Mixture of Experts setup, and sample text based on your input. Just be prepared for the fact that if you're not running on a decent machine, you might hit a wall.\n\nThe Bottom Line\nGrok-1 is a solid option if you’re looking to experiment with large language models without the hassle of training one yourself. The setup is straightforward, but don’t expect top-tier performance right out of the box—the MoE layer implementation isn’t the most efficient. If you’re a researcher or developer looking to play with large-scale models, this is worth a shot. For hobbyists or smaller projects? Probably overkill.",
      "url": "https://github.com/yebeai/grok-1",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "xai-org/grok-1",
        "url": "https://github.com/xai-org/grok-1",
        "stars": 51518
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 16, 2026",
      "updatedAt": "January 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 12,
        "directories": {
          "(root)": 11,
          "checkpoints": 1
        },
        "languages": {
          "Markdown": 3,
          "Python": 4,
          "TOML": 1
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [
          "pyproject.toml",
          "requirements.txt"
        ],
        "dependencies": [
          "pyproject.toml",
          "requirements.txt"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE.txt",
          "README.md",
          "checkpoints/README.md"
        ],
        "fileTypes": {
          ".md": 3,
          ".txt": 2,
          ".py": 4,
          ".toml": 1,
          ".model": 1
        }
      }
    },
    {
      "id": 1135844803,
      "name": "open-researcher",
      "displayName": "open researcher",
      "description": "🔥 Visual AI research assistant that displays real-time thinking, provides split-view analysis, and automatic citations using Claude and Firecrawl",
      "summary": "The Problem\nResearching online is a mess. You sift through endless tabs, trying to find credible information and remember where you saw that one quote. It’s exhausting and time-consuming, especially when you need to cite everything properly. This repo tackles that chaos head-on.\n\nWhat This Does\nWelcome to open-researcher, an AI-powered tool that combines the scraping prowess of Firecrawl with the analytical skills of Claude. The app is structured cleanly, with API routes in app/api/, including check-env/route.ts to ensure everything's ready to roll. The main functionality lives in app/open-researcher/open-researcher-content.tsx, where you'll find the chat interface and the split-view layout that lets you see search results alongside your conversation with the AI.\n\nYou get real-time web scraping with app/api/scrape/route.ts, which pulls in current information that you can analyze on-the-fly. Plus, the automatic citation generator means you won't lose track of sources while you're digging through content. Just ask your questions, and watch the AI fetch the info for you.\n\nReal-World Use\nImagine you're knee-deep in a research paper about climate change. You start typing a query in the chat interface, and the AI instantly pulls up relevant articles. While you’re reading, you ask a follow-up question, and it not only refines the search but spits out citations that you can click to access original sources. It saves you from the \"where did I find this?\" panic when you're compiling your bibliography.\n\nStart the app and do some research\nnpm run dev\nOpen your browser to http://localhost:3000\n\nThe Bottom Line\nopen-researcher has solid potential for anyone who regularly needs to gather and analyze information. If you're a student or researcher, it could save you hours of hunting for sources. Just know that it might feel a bit overkill if you’re only looking for quick facts. The integration with Firecrawl and Claude is a nice touch, but if you only need basic search capabilities, there are simpler solutions out there.",
      "url": "https://github.com/yebeai/open-researcher",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "firecrawl/open-researcher",
        "url": "https://github.com/firecrawl/open-researcher",
        "stars": 616
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 16, 2026",
      "updatedAt": "January 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 83,
        "directories": {
          "(root)": 11,
          "app": 10,
          "components": 54,
          "lib": 2,
          "public": 6
        },
        "languages": {
          "Markdown": 1,
          "TypeScript": 8,
          "CSS": 1,
          "TSX": 58,
          "JSON": 3,
          "YAML": 1
        },
        "frameworks": [
          "React",
          "Next.js",
          "Tailwind"
        ],
        "packageManager": "pnpm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [
          "next.config.ts",
          "package.json",
          "tailwind.config.ts",
          "tsconfig.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [
          "components/ui/aspect-ratio.tsx"
        ],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".example": 1,
          ".md": 1,
          ".ts": 8,
          ".ico": 1,
          ".css": 1,
          ".tsx": 58,
          ".mjs": 2,
          ".json": 3,
          ".yaml": 1,
          ".svg": 5,
          ".png": 1
        }
      }
    },
    {
      "id": 1135831037,
      "name": "toon",
      "displayName": "toon",
      "description": "🎒 Token-Oriented Object Notation (TOON) – Compact, human-readable, schema-aware JSON for LLM prompts. Spec, benchmarks, TypeScript SDK.",
      "summary": "The Problem\nLarge Language Models (LLMs) are great for interpreting data, but they’re also expensive when it comes to token usage. Standard JSON can be a token hog. If you’re feeding complex or nested data to an LLM, you’re essentially throwing money into a black hole. The pain point? You need a way to reduce the token count without losing structure or meaning.\n\nWhat This Does\nEnter Token-Oriented Object Notation (TOON). It’s a compact representation of JSON that keeps the human-readable aspect while slashing the token count. The README.md explains that TOON merges the indentation style of YAML with a CSV-like format for uniform arrays, making it friendlier for LLMs. \n\nFor example, the SPEC.md file outlines the format's specifications, showing how TOON structures data efficiently. The benchmarks directory contains scripts like accuracy-benchmark.ts that validate TOON’s effectiveness against traditional formats. If you want to see how TOON performs, check out results/token-efficiency.md for comparisons that might just convince you to switch.\n\nReal-World Use\nLet’s say you’re working on an LLM project that requires hiking data for a chatbot. Instead of verbose JSON, you could represent the same data in TOON like so:\n\ncontext: task: Our favorite hikes together, location: Boulder, season: spring_2025\nfriends: [ana, luis, sam]\nhikes: \nid: 1, name: Blue Lake Trail, distanceKm: 7.5, elevationGain: 320, companion: ana, wasSunny: true\nid: 2, name: Ridge Overlook, distanceKm: 9.2, elevationGain: 540, companion: luis, wasSunny: false\nid: 3, name: Wildflower Loop, distanceKm: 5.1, elevationGain: 180, companion: sam, wasSunny: true\n\nBy using TOON, your data keeps its structure while also being more token-efficient, saving you money and making parsing easier for the model.\n\nThe Bottom Line\nTOON is a practical solution for anyone dealing with LLMs and large datasets. It’s not for every project—if you’re just doing simple JSON stuff, it might be overkill. But if you want to save on tokens while keeping your data structured, give TOON a shot. It’s like putting your JSON on a diet—without sacrificing the flavor.",
      "url": "https://github.com/yebeai/toon",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "toon-format/toon",
        "url": "https://github.com/toon-format/toon",
        "stars": 22895
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1531482615713-2afd69097998?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 16, 2026",
      "updatedAt": "January 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 125,
        "directories": {
          "(root)": 13,
          ".github": 5,
          ".vscode": 2,
          "benchmarks": 32,
          "docs": 30,
          "packages": 43
        },
        "languages": {
          "YAML": 6,
          "JSON": 9,
          "Markdown": 20,
          "TypeScript": 66,
          "Vue": 2,
          "CSS": 2,
          "TOML": 1
        },
        "frameworks": [
          "React",
          "Vue"
        ],
        "packageManager": "pnpm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "benchmarks/src/questions/index.ts",
          "docs/.vitepress/theme/index.ts",
          "packages/cli/src/index.ts",
          "packages/toon/src/index.ts"
        ],
        "configFiles": [
          "benchmarks/.env.example",
          "benchmarks/package.json",
          "docs/package.json",
          "package.json",
          "packages/cli/package.json",
          "packages/toon/package.json",
          "tsconfig.json"
        ],
        "dependencies": [
          "benchmarks/package.json",
          "docs/package.json",
          "package.json",
          "packages/cli/package.json",
          "packages/toon/package.json"
        ],
        "testFiles": [
          "SPEC.md",
          "docs/reference/spec.md",
          "packages/cli/test/index.test.ts",
          "packages/cli/test/json-from-events.test.ts",
          "packages/cli/test/json-stringify-stream.test.ts",
          "packages/cli/test/utils.ts",
          "packages/toon/test/decode.test.ts",
          "packages/toon/test/decodeStream.test.ts",
          "packages/toon/test/decodeStreamAsync.test.ts",
          "packages/toon/test/encode.test.ts",
          "packages/toon/test/encodeLines.test.ts",
          "packages/toon/test/normalization.test.ts",
          "packages/toon/test/replacer.test.ts",
          "packages/toon/test/types.ts"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "benchmarks/README.md",
          "docs/.vitepress/config.ts",
          "docs/.vitepress/meta.ts",
          "docs/.vitepress/theme/components/PlaygroundLayout.vue",
          "docs/.vitepress/theme/components/VPInput.vue",
          "docs/.vitepress/theme/index.ts",
          "docs/.vitepress/theme/overrides.css",
          "docs/.vitepress/theme/vars.css",
          "docs/cli/index.md",
          "docs/ecosystem/implementations.md",
          "docs/ecosystem/tools-and-playgrounds.md",
          "docs/guide/benchmarks.md",
          "docs/guide/format-overview.md",
          "docs/guide/getting-started.md",
          "docs/guide/llm-prompts.md",
          "docs/index.md",
          "docs/package.json",
          "docs/playground.md",
          "docs/public/favicon.ico",
          "docs/public/favicon.svg",
          "docs/public/logo-index-dark.svg",
          "docs/public/logo-index-light.svg",
          "docs/public/logo.svg",
          "docs/public/og.png",
          "docs/public/twitter.png",
          "docs/reference/api.md",
          "docs/reference/efficiency-formalization.md",
          "docs/reference/spec.md",
          "docs/reference/syntax-cheatsheet.md",
          "docs/uno.config.ts",
          "docs/wrangler.toml",
          "packages/cli/README.md",
          "packages/toon/README.md"
        ],
        "fileTypes": {
          ".png": 3,
          ".yml": 4,
          ".json": 9,
          ".md": 20,
          ".ts": 66,
          ".example": 1,
          ".5-flash": 1,
          ".vue": 2,
          ".css": 2,
          ".ico": 1,
          ".svg": 4,
          ".toml": 1,
          ".mjs": 2,
          ".yaml": 2
        }
      }
    },
    {
      "id": 1135827323,
      "name": "credit-ocr-system",
      "displayName": "credit ocr system",
      "description": "No description available",
      "summary": "The Problem\nLoan processing is a tedious mess. Loan officers spend hours sifting through 15-20 page applications, manually picking out the relevant financial data. Talk about a productivity killer. With loads of documents to process and human error lurking around every corner, it’s no wonder financial institutions are looking for a better way.\n\nWhat This Does\nEnter the credit-ocr-system, a tool designed to automate the entire document processing workflow. It employs OCR to extract data from PDFs and scanned documents, which is all laid out in the notebooks/2-ocr-based-text-extraction/02ocrtextextraction.ipynb. From there, it uses local AI models housed in Ollama to validate extracted information, ensuring that the data is not just collected but also accurate.\n\nIn addition, the architecture leverages PostgreSQL for storing metadata and extracted data, as outlined in database/schemas/schema.sql. The system orchestrates background tasks using Celery, enabling asynchronous processing without blocking the main workflow. You can check out the whole structure in the compose.yml file, which ties together all your services for easy deployment.\n\nReal-World Use\nImagine a loan officer uploading a document to the system. The process kicks off with the document landing in the DMS, which is managed by Azurite for blob storage. Next, EasyOCR leaps into action, extracting text and generating bounding boxes to visualize the OCR results. The officer can then review the extracted data alongside confidence scores, all generated in real-time. This setup can cut down processing time from hours to mere minutes while maintaining accuracy.\n\nSample code to trigger OCR processing\ndef processloanapplication(filepath):\n    uploaddocument(filepath)  # Upload to DMS\n    ocrresults = runocr(filepath)  # Trigger OCR\n    validatedata(ocr_results)  # Validate against business rules\n\nThe Bottom Line\nThis repository is a solid pick for teams ready to ditch the manual grind of loan processing. It’s well-structured with clear notebooks for each step, but don’t expect it to be a lightweight solution. If you’re a small operation, this might feel like overkill. However, for larger organizations handling tons of loan applications, this could be the ticket to efficiency.",
      "url": "https://github.com/yebeai/credit-ocr-system",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "markuskuehnle/credit-ocr-system",
        "url": "https://github.com/markuskuehnle/credit-ocr-system",
        "stars": 226
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 16, 2026",
      "updatedAt": "January 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 90,
        "directories": {
          "(root)": 11,
          "config": 2,
          "data": 1,
          "database": 2,
          "docs": 10,
          "notebooks": 18,
          "src": 37,
          "tests": 9
        },
        "languages": {
          "Markdown": 12,
          "YAML": 1,
          "SQL": 1,
          "TOML": 1,
          "Python": 46,
          "HTML": 1
        },
        "frameworks": [
          "Flask",
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "src/api/main.py",
          "src/api/templates/index.html"
        ],
        "configFiles": [
          "Dockerfile",
          "pyproject.toml"
        ],
        "dependencies": [
          "pyproject.toml"
        ],
        "testFiles": [
          "tests/__init__.py",
          "tests/conftest.py",
          "tests/test_api.py",
          "tests/test_api_simple.py",
          "tests/test_dms_integration.py",
          "tests/test_integrated_pipeline.py",
          "tests/test_notebook04_integration.py",
          "tests/test_notebook04_workflow.py",
          "tests/test_simple_workflow.py"
        ],
        "docs": [
          "README.md",
          "database/README.md",
          "docs/imgs/2-ocr-text-extraction-2.png",
          "docs/imgs/2-ocr-text-extraction-3.png",
          "docs/imgs/2-ocr-text-extraction.png",
          "docs/imgs/3-llm-field-extraction-2.png",
          "docs/imgs/3-llm-field-extraction.png",
          "docs/imgs/4-function-integration.png",
          "docs/imgs/6-data-flow-architecture.png",
          "docs/imgs/7-fast-api-service-architecture.png",
          "docs/imgs/9-application-ui.png",
          "docs/imgs/architecture.png",
          "notebooks/1-setup/README.md",
          "notebooks/2-ocr-based-text-extraction/README.md",
          "notebooks/3-llm-field-extraction/README.md",
          "notebooks/4-function-integration/README.md",
          "notebooks/5-dms-upload/README.md",
          "notebooks/6-document-processing-status/README.md",
          "notebooks/7-async-processing/README.md",
          "notebooks/8-api-service/README.md",
          "notebooks/9-application-setup/README.md",
          "src/api/README.md"
        ],
        "fileTypes": {
          ".template": 1,
          ".md": 12,
          ".yml": 1,
          ".conf": 2,
          ".pdf": 1,
          ".sql": 1,
          ".png": 10,
          ".ipynb": 9,
          ".toml": 1,
          ".py": 46,
          ".html": 1,
          ".lock": 1
        }
      }
    },
    {
      "id": 1135738362,
      "name": "AgenticTrading",
      "displayName": "AgenticTrading",
      "description": "No description available",
      "summary": "In the fast-paced world of financial markets, the reliance on traditional algorithmic trading frameworks often poses significant limitations. These systems, characterized by static modules and rigid data flows, can struggle to adapt to the ever-changing market conditions. The challenge lies in creating a trading environment that not only reacts to data but also learns from it, enabling a more agile and responsive trading strategy. With the growing complexity of financial instruments and the increasing volume of data, the need for a more sophisticated approach to trading has never been more critical.\n\nEnter the AgenticTrading project, which reimagines algorithmic trading through a multi-agent ecosystem. This framework distinguishes itself by utilizing autonomous agents that embody various components of the trading process, enhancing flexibility and adaptability. Unlike traditional models that operate on a fixed set of rules, AgenticTrading leverages a FinAgent Orchestrator that dynamically composes agents into execution graphs, allowing for real-time decision-making. The architecture facilitates continuous learning, where agents can adapt their strategies based on historical context and performance logs. This approach not only optimizes performance but also fosters an interconnected trading environment where agents can communicate and collaborate effectively.\n\nDelving into the technical architecture of AgenticTrading reveals a well-structured system built around specialized agent pools. The FinAgents directory contains essential components such as the DAG Planner Agent, located in FinAgents/agentpools/alphaagentpool, which generates directed acyclic graphs from high-level queries, allowing for complex task decomposition. The orchestrator, which executes these DAGs, is supported by a Memory Agent that retains historical context, stored in a Neo4j database, enabling agents to learn and adapt over time. The use of Python, as indicated by the presence of requirements.txt files in each agent pool, ensures that developers can easily set up and modify the agents to fit their specific trading strategies. The organization of the repository, with dedicated folders for each agent pool and clear README documentation, demonstrates an emphasis on modularity and ease of use.\n\nThe practical applications of AgenticTrading are vast. For example, a hedge fund could implement this framework to create a dynamic execution model that continuously optimizes trading strategies based on real-time data feeds. By utilizing the alphasignalagent.py found in FinAgents/agentpools/alphaagentdemo, traders can develop algorithms that generate alpha signals while learning from past trades, significantly enhancing their decision-making capability. Another scenario is in the development of a portfolio management tool that employs the Portfolio Construction Agent Pool, allowing asset managers to adjust their portfolios dynamically in response to changing market conditions. The system's ability to maintain contextual continuity through the Memory Agent further ensures that all agents operate with the latest information, minimizing the risk of outdated strategies.\n\nUltimately, the importance of the AgenticTrading framework lies in its potential to revolutionize how trading systems are designed and operate. By shifting from a model-centric approach to a system-centric one, where the focus is on holistic performance feedback and adaptability, AgenticTrading offers a compelling solution to the limitations of traditional algorithmic trading systems. The project's open-source nature invites collaboration and innovation, enabling developers to contribute to and enhance the framework, ensuring it evolves alongside the demands of modern financial markets. As the trading landscape continues to advance, frameworks like AgenticTrading will be at the forefront, driving the next generation of intelligent trading systems.",
      "url": "https://github.com/yebeai/AgenticTrading",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Open-Finance-Lab/AgenticTrading",
        "url": "https://github.com/Open-Finance-Lab/AgenticTrading",
        "stars": 88
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 16, 2026",
      "updatedAt": "January 16, 2026",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 3,
          ".vscode": 1,
          "FinAgents": 196
        },
        "languages": {
          "JSON": 9,
          "Python": 86,
          "Markdown": 5,
          "YAML": 5
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [
          "FinAgents/agent_pools/alpha_agent_demo/requirements.txt"
        ],
        "dependencies": [
          "FinAgents/agent_pools/alpha_agent_demo/requirements.txt"
        ],
        "testFiles": [
          "FinAgents/agent_pools/alpha_agent_demo/TEST_RESULTS.md",
          "FinAgents/agent_pools/alpha_agent_demo/test_with_real_data.py",
          "FinAgents/agent_pools/alpha_agent_pool/agents/theory_driven/btc_qlib_backtest_results.png"
        ],
        "docs": [
          "FinAgents/agent_pools/alpha_agent_demo/README.md",
          "FinAgents/agent_pools/alpha_agent_pool/README.md",
          "FinAgents/agent_pools/alpha_agent_pool/qlib_local/README.md"
        ],
        "fileTypes": {
          ".json": 9,
          ".py": 86,
          ".md": 5,
          ".txt": 1,
          ".png": 1,
          ".yaml": 5,
          ".bak": 1,
          ".csv": 78
        }
      }
    },
    {
      "id": 1135654047,
      "name": "agentic-internet",
      "displayName": "agentic internet",
      "description": "AgenticInternet is an innovative project focused on empowering agents to autonomously browse, interact, and collaborate across the web. Our goal is to create an intelligent assistant capable of executing complex online workflows, enhancing productivity and creativity for end-users and organizations.",
      "summary": "The Problem\nIn a world flooded with information, manually browsing the web for relevant content is a colossal time sink. Whether you’re trying to keep up with the latest news or gather research data, doing it all yourself is tedious. Enter Agentic Internet, which aims to automate these tasks and let agents take over the grunt work.\n\nWhat This Does\nAgentic Internet is designed for autonomous web interactions. You can find it in the agenticinternet folder, where it houses everything from agent logic to utility functions. The agents directory contains various agent implementations, such as basicagent.py for simple tasks and internetagent.py for more complex browsing. Need to run a search? The searchorchestrator.py has you covered, managing how agents query multiple sources and aggregate results.\n\nFor setup, just clone the repo and run uv sync. If you prefer pip, install it with pip install -e .. Remember to configure your API keys in a .env file for features like SerpAPI or OpenAI models. The cli.py provides a command-line interface for interaction, making it easy to run commands without diving deep into the code.\n\nReal-World Use\nImagine you want to gather the latest AI news and summarize it. You can do this with just a few lines of code:\n\nfrom agentic_internet import InternetAgent\n\nagent = InternetAgent()\nresult = agent.run(\"Search for the latest AI news and summarize the top 3 stories\")\nprint(result)\n\nThis snippet creates an agent that autonomously fetches and summarizes the news for you. Need to chat with the agent for more details? Just call agent.chat().\n\nThe Bottom Line\nAgentic Internet is a powerful tool for anyone drowning in data and needing a digital assistant. It’s not for small projects or one-off tasks—this is enterprise-level automation. The modular design is a plus, allowing customization, but it can feel overwhelming if you just need something simple. If you're looking to offload your web-browsing woes, give this a shot; just be ready to configure a few API keys first.",
      "url": "https://github.com/yebeai/agentic-internet",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "AgenticInternet/agentic-internet",
        "url": "https://github.com/AgenticInternet/agentic-internet",
        "stars": 34
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1607799279861-4dd421887fb3?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 16, 2026",
      "updatedAt": "January 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 49,
        "directories": {
          "(root)": 10,
          "agentic_internet": 25,
          "docs": 2,
          "images": 1,
          "specs": 9,
          "tests": 2
        },
        "languages": {
          "Markdown": 13,
          "Python": 30,
          "TOML": 1
        },
        "frameworks": [
          "Django"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "agentic_internet/__main__.py",
          "agentic_internet/cli.py",
          "main.py"
        ],
        "configFiles": [
          ".env.example",
          "pyproject.toml"
        ],
        "dependencies": [
          "pyproject.toml"
        ],
        "testFiles": [
          "agentic_internet/agents/specialized_agents.py",
          "specs/.what-is-this.md",
          "specs/2025-08-30_20-45Z-update-cli-based-on-current-updates.md",
          "specs/AUTHORS.md",
          "specs/CLI_ENHANCEMENTS.md",
          "specs/FEATURES.md",
          "specs/README_SCIM.md",
          "specs/Readme.md",
          "specs/datasetcard_template.md",
          "specs/modelcard_template.md",
          "test_agent.py",
          "test_simple_agent.py",
          "tests/__init__.py",
          "tests/test_mcp_integration.py"
        ],
        "docs": [
          "LICENSE.md",
          "README.md",
          "docs/MCP_INTEGRATION.md",
          "docs/MCP_README_SNIPPET.md",
          "specs/README_SCIM.md",
          "specs/Readme.md"
        ],
        "fileTypes": {
          ".example": 1,
          ".md": 13,
          ".py": 30,
          ".png": 1,
          ".toml": 1,
          ".lock": 1
        }
      }
    },
    {
      "id": 1135653643,
      "name": "MathVizAI",
      "displayName": "MathVizAI",
      "description": "A complete end-to-end system that takes mathematical problems and automatically generates polished educational videos",
      "summary": "The Problem\nEducators and content creators often struggle to produce high-quality educational videos that effectively explain complex mathematical concepts. Traditional video creation is time-consuming and requires expertise in both math and video editing. The gap between understanding a math problem and conveying that understanding visually can be frustrating.\n\nWhat This Does\nEnter MathVizAI. This system takes a mathematical problem and churns out a polished educational video complete with visualizations and narration. The heart of the operation lies in the PipelineOrchestrator, which manages several agents like the Solver Agent, Evaluator Agent, and Visual Developer Agent. Each agent specializes in its task, ensuring a streamlined process.\n\nFor example, the Visual Developer Agent uses a Retrieval-Augmented Generation (RAG) approach to pull from a curated Golden Set of high-quality Manim animations found in the golden_set folder. It runs a \"Reasoning + Acting\" loop, searching through the VectorStore for proven code snippets to minimize syntax errors. This way, the agent isn’t just generating code on a whim; it’s building on established, working examples.\n\nReal-World Use\nImagine you want to create a video explaining the Taylor Series. You simply input the problem, and MathVizAI does the heavy lifting. It runs through the config.py to handle settings, generates the script via the Script Agent, and then produces the video using the Manim scripts stored in the assets folder. You can check out a sample output in Sample/TaylorSeries.mp4 to see how it all comes together.\n\nThe Bottom Line\nMathVizAI is a decent attempt at automating educational video creation, especially if you're dealing with complex math topics. However, it’s overkill for simpler concepts where traditional video editing tools would suffice. If you’re a math educator or content creator with a penchant for automation, this could be a time-saver. Just be ready to tweak things if you hit a snag—automation isn’t foolproof.",
      "url": "https://github.com/yebeai/MathVizAI",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "anirudhsengar/MathVizAI",
        "url": "https://github.com/anirudhsengar/MathVizAI",
        "stars": 31
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 16, 2026",
      "updatedAt": "January 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 94,
        "directories": {
          "(root)": 10,
          "Sample": 2,
          "VectorStore": 4,
          "assets": 7,
          "golden_set": 51,
          "pipeline": 10,
          "src": 1,
          "system_prompts": 4,
          "utils": 5
        },
        "languages": {
          "Markdown": 1,
          "JSON": 2,
          "Shell": 2,
          "Python": 74
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "main.py"
        ],
        "configFiles": [
          ".env.example",
          "requirements.txt"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".example": 1,
          ".md": 1,
          ".mp4": 4,
          ".faiss": 2,
          ".json": 2,
          ".sh": 2,
          ".py": 74,
          ".png": 1,
          ".txt": 5
        }
      }
    },
    {
      "id": 1135629383,
      "name": "AI-ML-Book-References",
      "displayName": "AI ML Book References",
      "description": "This repository is for all those AI enthusiastics who actually loves to read books and learn.",
      "summary": "The Problem\nFinding quality resources for AI and machine learning can feel like searching for a needle in a haystack. With endless lists of books and resources out there, it’s easy to waste time sifting through outdated or irrelevant material. You want something structured and curated that actually helps you learn, rather than just a random assortment of titles.\n\nWhat This Does\nThe AI-ML-Book-References repository tackles this issue head-on. It’s a straightforward collection of essential AI and ML books, neatly organized in a table format within README.md. Each entry includes key details like authors, topic areas, and a direct link to a PDF version, so you can dive straight into the material without hunting around. \n\nThe repository also includes a LICENSE file, ensuring you know what you can and can’t do with the content. Plus, there’s a FUNDING.yml file, which is a nice touch if you’re interested in supporting the project (though I wouldn’t hold my breath for any crowdfunding here, given the 0 stars). \n\nReal-World Use\nImagine you’re ramping up on machine learning. You check out this repo and find Designing Machine Learning Systems by Chip Huyen. Click the PDF link, and voilà! You've got a solid resource at your fingertips. You could also use it as a reference list for a book club or a study group, making it easy to share valuable resources with others in the field. \n\nFor example, if you’re stuck on a practical problem, you could consult the Hands-On Machine Learning book from the list and follow along with the code examples. No need to dig through Google for hours.\n\nThe Bottom Line\nThis repo is a handy toolbox for anyone serious about learning AI and ML. It’s not flashy, but it gets the job done by offering a curated list of books that cover various levels of expertise. On the downside, the lack of tags and no active community engagement (zero stars and forks) could limit its growth. Still, if you want a straightforward reference without the fluff, this is worth adding to your bookmarks.",
      "url": "https://github.com/yebeai/AI-ML-Book-References",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Ramakm/AI-ML-Book-References",
        "url": "https://github.com/Ramakm/AI-ML-Book-References",
        "stars": 354
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 16, 2026",
      "updatedAt": "January 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 4,
        "directories": {
          ".github": 1,
          "(root)": 3
        },
        "languages": {
          "YAML": 1,
          "Markdown": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".yml": 1,
          ".md": 1,
          ".png": 1
        }
      }
    },
    {
      "id": 1135617894,
      "name": "crawlee",
      "displayName": "crawlee",
      "description": "Crawlee—A web scraping and browser automation library for Node.js to build reliable crawlers. In JavaScript and TypeScript. Extract data for AI, LLMs, RAG, or GPTs. Download HTML, PDF, JPG, PNG, and other files from websites. Works with Puppeteer, Playwright, Cheerio, JSDOM, and raw HTTP. Both headful and headless mode. With proxy rotation.",
      "summary": "The Problem\nWeb scraping is a pain. You need to extract data from various websites without getting blocked by anti-bot measures. Building a reliable crawler that can handle dynamic content, while still being easy to configure, is no small feat. If you've ever been frustrated by your scrapers getting throttled or banned, you know the struggle. \n\nWhat This Does\nCrawlee is here to save your sanity. Found in the README.md, it highlights that this library works with various tools like Puppeteer and Playwright, making it versatile for different scraping needs. You can set it up using the Crawlee CLI with a simple command: \n\nnpx crawlee create my-crawler\n\nThis initializes your project with boilerplate code, so you don’t have to start from scratch. The requestHandler function in PlaywrightCrawler lets you define how to process each page you scrape. Just look at src/crawlers/PlaywrightCrawler.js to see how it manages requests and responses.\n\nReal-World Use\nImagine you're trying to gather product prices from an e-commerce site. You can set up a crawler like this:\n\nimport { PlaywrightCrawler, Dataset } from 'crawlee';\n\nconst crawler = new PlaywrightCrawler({\n    async requestHandler({ request, page, enqueueLinks, log }) {\n        const price = await page.$eval('.product-price', el => el.innerText);\n        log.info(Price of product at ${request.loadedUrl} is '${price}');\n        await Dataset.pushData({ price, url: request.loadedUrl });\n        await enqueueLinks();\n    },\n});\n\nIn this snippet, you grab the product price and log it, while also enqueuing additional links for scraping. Easy peasy.\n\nThe Bottom Line\nCrawlee is solid for medium to large projects where you need a reliable scraping solution. It’s overkill for simple tasks, but if you’re dealing with complex sites and want to avoid getting banned, it’s worth a look. Just be prepared to dive into the docs; the initial setup can feel a bit overwhelming. For quick-and-dirty scrapers, stick to simpler libraries.",
      "url": "https://github.com/yebeai/crawlee",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "apify/crawlee",
        "url": "https://github.com/apify/crawlee",
        "stars": 21915
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 16, 2026",
      "updatedAt": "January 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 13,
          ".github": 11,
          ".husky": 1,
          "docs": 173,
          "packages": 2
        },
        "languages": {
          "YAML": 12,
          "Markdown": 14,
          "JSON": 5,
          "TypeScript": 97
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "yarn",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          "docs/package.json",
          "docs/tsconfig.json",
          "package.json"
        ],
        "dependencies": [
          "docs/package.json",
          "docs/yarn.lock",
          "package.json"
        ],
        "testFiles": [
          ".github/workflows/test-ci.yml",
          ".github/workflows/test-e2e.yml",
          "docs/guides/proxy_management_inspection_cheerio.ts",
          "docs/guides/proxy_management_inspection_http.ts",
          "docs/guides/proxy_management_inspection_jsdom.ts",
          "docs/guides/proxy_management_inspection_playwright.ts",
          "docs/guides/proxy_management_inspection_puppeteer.ts"
        ],
        "docs": [
          "CHANGELOG.md",
          "CONTRIBUTING.md",
          "LICENSE.md",
          "README.md",
          "docs/deployment/apify_platform.mdx",
          "docs/deployment/apify_platform_init_exit.ts",
          "docs/deployment/apify_platform_main.ts",
          "docs/deployment/aws-browsers.md",
          "docs/deployment/aws-cheerio.md",
          "docs/deployment/gcp-browsers.md",
          "docs/deployment/gcp-cheerio.md",
          "docs/examples/accept_user_input.mdx",
          "docs/examples/accept_user_input.ts",
          "docs/examples/add_data_to_dataset.mdx",
          "docs/examples/add_data_to_dataset.ts",
          "docs/examples/basic_crawler.mdx",
          "docs/examples/basic_crawler.ts",
          "docs/examples/cheerio_crawler.mdx",
          "docs/examples/cheerio_crawler.ts",
          "docs/examples/crawl_all_links.mdx",
          "docs/examples/crawl_all_links_cheerio.ts",
          "docs/examples/crawl_all_links_playwright.ts",
          "docs/examples/crawl_all_links_puppeteer.ts",
          "docs/examples/crawl_multiple_urls.mdx",
          "docs/examples/crawl_multiple_urls_cheerio.ts",
          "docs/examples/crawl_multiple_urls_playwright.ts",
          "docs/examples/crawl_multiple_urls_puppeteer.ts",
          "docs/examples/crawl_relative_links.mdx",
          "docs/examples/crawl_relative_links_all.ts",
          "docs/examples/crawl_relative_links_same_domain.ts",
          "docs/examples/crawl_relative_links_same_hostname.ts",
          "docs/examples/crawl_single_url.mdx",
          "docs/examples/crawl_single_url.ts",
          "docs/examples/crawl_sitemap.mdx",
          "docs/examples/crawl_sitemap_cheerio.ts",
          "docs/examples/crawl_sitemap_playwright.ts",
          "docs/examples/crawl_sitemap_puppeteer.ts",
          "docs/examples/crawl_some_links.mdx",
          "docs/examples/crawl_some_links.ts",
          "docs/examples/crawler-plugins/index.mdx",
          "docs/examples/crawler-plugins/playwright-extra.ts",
          "docs/examples/crawler-plugins/puppeteer-extra.ts",
          "docs/examples/export_entire_dataset.mdx",
          "docs/examples/export_entire_dataset.ts",
          "docs/examples/file_download.mdx",
          "docs/examples/file_download.ts",
          "docs/examples/file_download_stream.mdx",
          "docs/examples/file_download_stream.ts",
          "docs/examples/forms.mdx",
          "docs/examples/forms.ts",
          "docs/examples/http_crawler.mdx",
          "docs/examples/http_crawler.ts",
          "docs/examples/jsdom_crawler.mdx",
          "docs/examples/jsdom_crawler.ts",
          "docs/examples/jsdom_crawler_react.ts",
          "docs/examples/map.ts",
          "docs/examples/map_and_reduce.mdx",
          "docs/examples/playwright_crawler.mdx",
          "docs/examples/playwright_crawler.ts",
          "docs/examples/playwright_crawler_firefox.mdx",
          "docs/examples/playwright_crawler_firefox.ts",
          "docs/examples/puppeteer_capture_screenshot.mdx",
          "docs/examples/puppeteer_crawler.mdx",
          "docs/examples/puppeteer_crawler.ts",
          "docs/examples/puppeteer_crawler_crawler_utils_snapshot.ts",
          "docs/examples/puppeteer_crawler_page_screenshot.ts",
          "docs/examples/puppeteer_crawler_utils_snapshot.ts",
          "docs/examples/puppeteer_page_screenshot.ts",
          "docs/examples/puppeteer_recursive_crawl.mdx",
          "docs/examples/puppeteer_recursive_crawl.ts",
          "docs/examples/reduce.ts",
          "docs/examples/skip-navigation.mdx",
          "docs/examples/skip-navigation.ts",
          "docs/experiments/request_locking.mdx",
          "docs/experiments/systemInfoV2.mdx",
          "docs/guides/avoid_blocking.mdx",
          "docs/guides/avoid_blocking_camoufox.ts",
          "docs/guides/avoid_blocking_playwright.ts",
          "docs/guides/avoid_blocking_playwright_fingerprints_off.ts",
          "docs/guides/avoid_blocking_puppeteer.ts",
          "docs/guides/avoid_blocking_puppeteer_fingerprints_off.ts",
          "docs/guides/cheerio_crawler.mdx",
          "docs/guides/configuration.mdx",
          "docs/guides/custom-http-client/custom-http-client.mdx",
          "docs/guides/custom-http-client/implementation.ts",
          "docs/guides/custom-http-client/usage.ts",
          "docs/guides/docker_browser_js.txt",
          "docs/guides/docker_browser_ts.txt",
          "docs/guides/docker_images.mdx",
          "docs/guides/docker_node_js.txt",
          "docs/guides/docker_node_ts.txt",
          "docs/guides/got_scraping.mdx",
          "docs/guides/http-clients.mdx",
          "docs/guides/http-clients/cheerio-got-scraping-example.ts",
          "docs/guides/http-clients/cheerio-impit-example.ts",
          "docs/guides/javascript-rendering-playwright-no-wait.ts",
          "docs/guides/javascript-rendering-playwright.ts",
          "docs/guides/javascript-rendering-puppeteer-no-wait.ts",
          "docs/guides/javascript-rendering-puppeteer.ts",
          "docs/guides/javascript-rendering.mdx",
          "docs/guides/jsdom_crawler.mdx",
          "docs/guides/motivation.mdx",
          "docs/guides/parallel-scraping/adapted-routes.mjs",
          "docs/guides/parallel-scraping/modified-detail-route.mjs",
          "docs/guides/parallel-scraping/parallel-scraper.mjs",
          "docs/guides/parallel-scraping/parallel-scraping.mdx",
          "docs/guides/parallel-scraping/shared.mjs",
          "docs/guides/proxy_management.mdx",
          "docs/guides/proxy_management_inspection_cheerio.ts",
          "docs/guides/proxy_management_inspection_http.ts",
          "docs/guides/proxy_management_inspection_jsdom.ts",
          "docs/guides/proxy_management_inspection_playwright.ts",
          "docs/guides/proxy_management_inspection_puppeteer.ts",
          "docs/guides/proxy_management_integration_cheerio.ts",
          "docs/guides/proxy_management_integration_http.ts",
          "docs/guides/proxy_management_integration_jsdom.ts",
          "docs/guides/proxy_management_integration_playwright.ts",
          "docs/guides/proxy_management_integration_puppeteer.ts",
          "docs/guides/proxy_management_session_cheerio.ts",
          "docs/guides/proxy_management_session_http.ts",
          "docs/guides/proxy_management_session_jsdom.ts",
          "docs/guides/proxy_management_session_playwright.ts",
          "docs/guides/proxy_management_session_puppeteer.ts",
          "docs/guides/proxy_management_session_standalone.ts",
          "docs/guides/request_storage.mdx",
          "docs/guides/request_storage_queue_basic.ts",
          "docs/guides/request_storage_queue_crawler.ts",
          "docs/guides/request_storage_queue_crawler_explicit.ts",
          "docs/guides/request_storage_queue_list.ts",
          "docs/guides/request_storage_queue_only.ts",
          "docs/guides/result_storage.mdx",
          "docs/guides/running-in-web-server/running-in-web-server.mdx",
          "docs/guides/running-in-web-server/web-server.mjs",
          "docs/guides/scaling_crawlers.mdx",
          "docs/guides/scaling_crawlers_autoscaledPoolOptions.ts",
          "docs/guides/scaling_crawlers_maxRequestsPerMinute.ts",
          "docs/guides/scaling_crawlers_minMaxConcurrency.ts",
          "docs/guides/session_management.mdx",
          "docs/guides/session_management_basic.ts",
          "docs/guides/session_management_cheerio.ts",
          "docs/guides/session_management_http.ts",
          "docs/guides/session_management_jsdom.ts",
          "docs/guides/session_management_playwright.ts",
          "docs/guides/session_management_puppeteer.ts",
          "docs/guides/session_management_standalone.ts",
          "docs/guides/typescript_project.mdx",
          "docs/introduction/01-setting-up.mdx",
          "docs/introduction/02-first-crawler.mdx",
          "docs/introduction/03-adding-urls.mdx",
          "docs/introduction/03-filter-el.ts",
          "docs/introduction/03-filter-without-el.ts",
          "docs/introduction/03-find-el.ts",
          "docs/introduction/03-find-without-el.ts",
          "docs/introduction/04-pw-w-cheerio.ts",
          "docs/introduction/04-pw.ts",
          "docs/introduction/04-real-world-project.mdx",
          "docs/introduction/05-crawling.mdx",
          "docs/introduction/06-example.ts",
          "docs/introduction/06-scraping.mdx",
          "docs/introduction/07-example.ts",
          "docs/introduction/07-saving-data.mdx",
          "docs/introduction/08-refactoring.mdx",
          "docs/introduction/09-deployment.mdx",
          "docs/introduction/index.mdx",
          "docs/package.json",
          "docs/quick-start/headful_playwright.ts",
          "docs/quick-start/headful_puppeteer.ts",
          "docs/quick-start/index.mdx",
          "docs/quick-start/quick_start_cheerio.ts",
          "docs/quick-start/quick_start_cheerio.txt",
          "docs/quick-start/quick_start_playwright.ts",
          "docs/quick-start/quick_start_puppeteer.ts",
          "docs/tsconfig.json",
          "docs/upgrading/upgrading_v1.md",
          "docs/upgrading/upgrading_v2.md",
          "docs/upgrading/upgrading_v3.md",
          "docs/yarn.lock",
          "packages/basic-crawler/CHANGELOG.md"
        ],
        "fileTypes": {
          ".yml": 12,
          ".md": 14,
          ".json": 5,
          ".mdx": 56,
          ".ts": 97,
          ".txt": 5,
          ".mjs": 6,
          ".lock": 1
        }
      }
    },
    {
      "id": 1135615802,
      "name": "codeflow",
      "displayName": "codeflow",
      "description": "Visualise code",
      "summary": "The Problem\nEver tried diving into a new codebase and felt like you were staring at a wall of text? Figuring out how files are connected or who to ask about what can be a real headache. CodeFlow tackles this by visualizing your codebase architecture, so you don’t have to guess what’s going on.\n\nWhat This Does\nCodeFlow is like a GPS for your code. Just paste a GitHub URL, and it churns out an interactive dependency graph. You can see how files relate, click on nodes, and even zoom in for details. Run everything from your browser—no installation or complex setup. Just grab the index.html file from this repo and open it. That’s it.\n\nThe README.md outlines some killer features: a Blast Radius Analysis that answers the question, \"If I change this file, what breaks?\" and a Security Scanner that flags hardcoded secrets or vulnerabilities. You can also analyze private repos by pasting your GitHub personal access token, ensuring your sensitive data stays local.\n\nReal-World Use\nImagine you’re tasked with modifying a component in a large React app. You paste the repo URL into CodeFlow and instantly see which files depend on that component. The blast radius feature shows you exactly how many other files will be affected, letting you make better decisions before diving into the code. Plus, with the Code Ownership feature, you can easily identify who to consult for potential issues.\n\nThe Bottom Line\nCodeFlow is a solid tool for anyone grappling with large codebases. It’s particularly useful for teams that need to onboard new members quickly or for anyone trying to understand legacy code. It’s simple, effective, and does what it promises without any fluff. However, if you’re working on a small project, the overhead might not be worth it. Just open the index.html and start visualizing your code—it's that easy.",
      "url": "https://github.com/yebeai/codeflow",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "braedonsaunders/codeflow",
        "url": "https://github.com/braedonsaunders/codeflow",
        "stars": 557
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1531482615713-2afd69097998?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 16, 2026",
      "updatedAt": "January 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 3,
        "directories": {
          "(root)": 3
        },
        "languages": {
          "Markdown": 1,
          "HTML": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "index.html"
        ],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".md": 1,
          ".html": 1,
          ".png": 1
        }
      }
    },
    {
      "id": 1135581132,
      "name": "fastapi_mcp",
      "displayName": "fastapi mcp",
      "description": "Expose your FastAPI endpoints as Model Context Protocol (MCP) tools, with Auth!",
      "summary": "The Problem\nFor developers using FastAPI, exposing endpoints as tools for Model Context Protocol (MCP) can be a hassle. You might have to deal with additional boilerplate code, manage authentication manually, or wrestle with deployment configurations. It's tedious and can lead to messy code.\n\nWhat This Does\nEnter fastapimcp. This repo allows you to expose your FastAPI endpoints as MCP tools with minimal fuss. You just need to point it at your FastAPI app and it’s ready to go. The core functionality is set up in README.md, where you can see how to mount the MCP server with just a few lines of code:\n\nmcp = FastApiMCP(app)\nmcp.mount()\n\nThe configuration files, like .github/workflows/ci.yml for continuous integration, show that the developers are serious about maintaining a clean codebase. You don't need to reinvent the wheel for authentication either; it integrates with your existing FastAPI dependencies, making security a breeze.\n\nReal-World Use\nImagine you have a FastAPI application that serves user data. You want to expose this data as MCP tools for a frontend application, but you dread the extra work. With fastapimcp, you can integrate it in minutes. After mounting the MCP server, your endpoints are accessible at https://app.base.url/mcp, and they retain all the Swagger documentation you’re already using. This means your frontend devs can start using the endpoints without waiting for you to finish that tedious HTTP setup.\n\nThe Bottom Line\nfastapi_mcp is a handy tool for anyone who wants to expose FastAPI endpoints without the hassle. It’s a solid option if you’re dealing with larger applications where MCP can add real value. However, for small projects, this might be overkill. Just keep your expectations in check: while it simplifies integration, it also adds another layer of abstraction that you may not need.",
      "url": "https://github.com/yebeai/fastapi_mcp",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "AIGeniusInstitute/fastapi_mcp",
        "url": "https://github.com/AIGeniusInstitute/fastapi_mcp",
        "stars": 18
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1542831371-29b0f74f9713?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 16, 2026",
      "updatedAt": "January 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 84,
        "directories": {
          "(root)": 15,
          ".github": 8,
          "docs": 16,
          "examples": 16,
          "fastapi_mcp": 12,
          "tests": 17
        },
        "languages": {
          "Markdown": 9,
          "YAML": 5,
          "JSON": 1,
          "Python": 44,
          "TOML": 1
        },
        "frameworks": [
          "Flask",
          "FastAPI"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "examples/shared/setup.py",
          "fastapi_mcp/server.py"
        ],
        "configFiles": [
          "examples/shared/setup.py",
          "pyproject.toml"
        ],
        "dependencies": [
          "pyproject.toml"
        ],
        "testFiles": [
          "pytest.ini",
          "tests/__init__.py",
          "tests/conftest.py",
          "tests/fixtures/complex_app.py",
          "tests/fixtures/conftest.py",
          "tests/fixtures/example_data.py",
          "tests/fixtures/simple_app.py",
          "tests/fixtures/types.py",
          "tests/test_basic_functionality.py",
          "tests/test_configuration.py",
          "tests/test_http_real_transport.py",
          "tests/test_mcp_complex_app.py",
          "tests/test_mcp_execute_api_tool.py",
          "tests/test_mcp_simple_app.py",
          "tests/test_openapi_conversion.py",
          "tests/test_sse_mock_transport.py",
          "tests/test_sse_real_transport.py",
          "tests/test_types_validation.py"
        ],
        "docs": [
          "CHANGELOG.md",
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "README_zh-CN.md",
          "docs/advanced/asgi.mdx",
          "docs/advanced/auth.mdx",
          "docs/advanced/deploy.mdx",
          "docs/advanced/refresh.mdx",
          "docs/advanced/transport.mdx",
          "docs/configurations/customization.mdx",
          "docs/configurations/tool-naming.mdx",
          "docs/docs.json",
          "docs/getting-started/FAQ.mdx",
          "docs/getting-started/best-practices.mdx",
          "docs/getting-started/installation.mdx",
          "docs/getting-started/quickstart.mdx",
          "docs/getting-started/welcome.mdx",
          "docs/media/dark_logo.png",
          "docs/media/favicon.png",
          "docs/media/light_logo.png",
          "examples/README.md"
        ],
        "fileTypes": {
          ".md": 9,
          ".yml": 4,
          ".yaml": 1,
          ".in": 1,
          ".mdx": 12,
          ".json": 1,
          ".png": 3,
          ".py": 44,
          ".ini": 2,
          ".toml": 1,
          ".lock": 1
        }
      }
    },
    {
      "id": 1135521052,
      "name": "pagesource",
      "displayName": "pagesource",
      "description": "CLI to download websites' actual JS/CSS/assets (not flattened HTML)",
      "summary": "The Problem\nWhen you want to download a webpage, you're usually stuck with a flattened HTML file. Good luck trying to figure out where all the CSS and JavaScript came from. It’s like trying to find a needle in a haystack, except the haystack is a jumbled mess of files, and you’re on a deadline.\n\nWhat This Does\nEnter pagesource, a CLI tool that captures everything a webpage loads—think of it as the browser's DevTools on steroids. It saves all resources like HTML, CSS, JS, and images while preserving the original directory structure. You run pagesource https://example.com, and voilà, it dumps everything into ./pagesource_output/example.com/, keeping the hierarchy intact. \n\nNeed external resources from CDNs? Just toss in the --include-external flag, and it’ll organize those into their own directories. Check out src/pagesource/cli.py for the command-line magic that handles all this under the hood, while src/pagesource/downloader.py manages the nitty-gritty of fetching these assets.\n\nReal-World Use\nImagine you’re tasked with archiving a website for a client. You run:\n\npagesource https://example.com -o ./archive --wait 5 --include-external\n\nNow you have a neat archive folder with everything you need. You can inspect the index.html, dive into assets/css/style.css, or peek at cdn.example.com/libs/library.js without jumping through hoops. It’s a lifesaver if you’re dealing with single-page applications (SPAs) that load content dynamically.\n\nThe Bottom Line\npagesource can save you a ton of headaches if you frequently download web assets. It’s straightforward and does its job without unnecessary fluff. Just be aware that if you’re only looking to grab a simple webpage, this might feel like overkill. But for developers working with complex sites or needing to archive resources for audits, it’s a solid tool to have in your kit.",
      "url": "https://github.com/yebeai/pagesource",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "timf34/pagesource",
        "url": "https://github.com/timf34/pagesource",
        "stars": 319
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1607799279861-4dd421887fb3?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 16, 2026",
      "updatedAt": "January 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 15,
        "directories": {
          "(root)": 4,
          "assets": 1,
          "src": 10
        },
        "languages": {
          "Markdown": 1,
          "TOML": 1,
          "Python": 5
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "src/pagesource/cli.py"
        ],
        "configFiles": [
          "pyproject.toml"
        ],
        "dependencies": [
          "pyproject.toml"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".md": 1,
          ".png": 1,
          ".toml": 1,
          ".py": 5,
          ".pyc": 5
        }
      }
    },
    {
      "id": 1135518406,
      "name": "ekphos",
      "displayName": "ekphos",
      "description": "A lightweight, fast, terminal-based markdown research tool inspired by Obsidian",
      "summary": "The Problem\nResearching and organizing markdown notes can be a pain, especially when you're stuck in the terminal. You want something lightweight that doesn't bog you down with unnecessary features. Most markdown editors are either too bloated or just plain slow. If you’re like me, you want a tool that gets out of your way and lets you focus on your research.\n\nWhat This Does\nEnter ekphos—a terminal-based markdown research tool that’s as fast as your caffeine-fueled typing. The core of the app is in src/main.rs, where the execution begins. It handles everything from configuration loading to rendering markdown. Speaking of configuration, the src/config.rs file is where you can tweak your settings. Just note: if you mess up, you can always run ekphos --reset to revert to defaults.\n\nThe editor is where the magic happens. In the src/editor directory, you’ll find files like buffer.rs and cursor.rs, which manage your text input and navigation. If you’re a keyboard warrior, you’ll appreciate how fluid the experience is. Plus, the UI components live in src/ui, meaning you can customize how things look without diving too deep into the core logic.\n\nReal-World Use\nImagine you’re knee-deep in research for a paper. You launch ekphos, and within seconds, you're editing your notes. You start typing markdown, and it renders inline images if your terminal supports it. Need to reference something from another note? Just use the command palette—no mouse required. Your workflow becomes faster, and you can get back to your actual research instead of fiddling with the editor.\n\nThe Bottom Line\nekphos is a solid choice for anyone who lives in the terminal and needs a lightweight markdown tool. It has the potential to be really efficient, but the documentation could use some work since it's still in early development. If you’re looking for a no-frills way to manage markdown notes without the overhead of a full-fledged GUI application, give it a shot. Just don’t expect it to be perfect right out of the gate.",
      "url": "https://github.com/yebeai/ekphos",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "hanebox/ekphos",
        "url": "https://github.com/hanebox/ekphos",
        "stars": 840
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 16, 2026",
      "updatedAt": "January 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 49,
        "directories": {
          "(root)": 9,
          "examples": 1,
          "src": 37,
          "themes": 2
        },
        "languages": {
          "TOML": 3,
          "Markdown": 2,
          "YAML": 1,
          "Rust": 36
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": "cargo",
        "hasDocker": true,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "src/main.rs"
        ],
        "configFiles": [
          "Cargo.toml",
          "Dockerfile",
          "Makefile",
          "docker-compose.yml"
        ],
        "dependencies": [
          "Cargo.toml"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md",
          "src/editor/README.md"
        ],
        "fileTypes": {
          ".lock": 1,
          ".toml": 3,
          ".md": 2,
          ".yml": 1,
          ".png": 1,
          ".nix": 1,
          ".rs": 36
        }
      }
    },
    {
      "id": 1135471072,
      "name": "TradeMaster",
      "displayName": "TradeMaster",
      "description": "TradeMaster is an open-source platform for quantitative trading empowered by reinforcement learning :fire: :zap: :rainbow:",
      "summary": "The Problem\nQuantitative trading can be a nightmare of complex algorithms and ever-changing market dynamics. Many platforms are bloated with features that don’t address the core issues traders face, like quickly testing and deploying reinforcement learning (RL) strategies. TradeMaster aims to cut through the noise and provide a streamlined, open-source solution.\n\nWhat This Does\nTradeMaster is designed for traders who want to build and evaluate RL-based algorithms without drowning in fluff. The structure is clear, with directories like configs/base/agents housing various trading algorithms. For example, deepscalper.py implements a deep reinforcement learning approach for algorithmic trading, while ddqn.py targets high-frequency trading strategies. \n\nThe configs/base/datasets directory contains datasets tailored for different trading strategies, like BTC.py for Bitcoin or AAPL.py for Apple stocks. This allows you to quickly plug in data without spending hours wrangling it.\n\nReal-World Use\nImagine you want to test a new trading strategy based on deep reinforcement learning. You'd start by configuring your environment with the Dockerfile, ensuring dependencies are sorted out. Then, you'd dive into deepscalper.py, tweaking the hyperparameters to fit your risk appetite. Once you have your model trained, you can easily evaluate it using the datasets in configs/base/datasets/algorithmictrading. \n\nHere’s a quick snippet to get you started:\n\nfrom configs.base.agents.algorithmictrading.deepscalper import DeepScalper\nstrategy = DeepScalper()\nstrategy.train(data='configs/base/datasets/algorithmic_trading/AAPL.py')\n\nThe Bottom Line\nTradeMaster is a solid choice for anyone looking to get serious about quantitative trading with RL. It’s structured well and offers the essential components for building and testing strategies without unnecessary clutter. However, if you don’t have a background in RL or quantitative finance, this might feel overwhelming. It’s not for the faint-hearted, but for developers ready to dive in, it packs a punch.",
      "url": "https://github.com/yebeai/TradeMaster",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "TradeMaster-NTU/TradeMaster",
        "url": "https://github.com/TradeMaster-NTU/TradeMaster",
        "stars": 2496
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 16, 2026",
      "updatedAt": "January 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 5,
          "configs": 173,
          "data": 22
        },
        "languages": {
          "Markdown": 1,
          "Python": 164,
          "JSON": 1
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [
          "Dockerfile"
        ],
        "dependencies": [],
        "testFiles": [
          "data/algorithmic_trading/BTC/Market_Dynamics_Model/BTC/test_labeled_slice_and_merge_model_3dynamics_minlength12_quantile_labeling.csv"
        ],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".md": 1,
          ".py": 164,
          ".txt": 9,
          ".json": 1,
          ".csv": 17,
          ".pdf": 1,
          ".png": 4
        }
      }
    },
    {
      "id": 1135456085,
      "name": "puter",
      "displayName": "puter",
      "description": "🌐 The Internet Computer! Free, Open-Source, and Self-Hostable.",
      "summary": "The Problem\nMost cloud storage solutions are either bloated with features you don’t need or lock you into their ecosystem. If you want a personal cloud that respects your privacy while still providing flexibility, you’re often stuck with limited options or hefty subscription fees.\n\nWhat This Does\nEnter Puter, an open-source internet operating system that lets you self-host your own cloud environment. The repository structure is ready to roll with a Dockerfile for containerization and a docker-compose.yml for easy orchestration. You can dive into doc/self-hosters/instructions.md for detailed self-hosting guidance or check out README.md for quick setup instructions.\n\nPuter supports multiple deployment options. You can launch it locally using simple npm commands or via Docker for a more isolated setup. The git clone command gets your local dev environment up and running with just a few lines. If you prefer Docker, the provided commands show you how to set up your config and data directories.\n\nReal-World Use\nImagine you want to move away from Google Drive but still need a place to store all your files and apps. After cloning the repo, you run the Docker command:\n\ndocker run --rm -p 4100:4100 -v pwd/puter/config:/etc/puter -v pwd/puter/data:/var/puter ghcr.io/heyputer/puter\n\nNow, you can access your new personal cloud at http://puter.localhost:4100. It's like having your own Dropbox without the corporate oversight, and you can customize it to fit your needs.\n\nThe Bottom Line\nPuter is solid for anyone wanting a self-hosted cloud solution. The installation process is straightforward, especially if you’re familiar with Docker. On the downside, it's a bit overkill if you're just looking for a simple file storage solution without the hassle of maintaining your own server. But if you’re into devops or want to learn about cloud computing, this is a great playground.",
      "url": "https://github.com/yebeai/puter",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "HeyPuter/puter",
        "url": "https://github.com/HeyPuter/puter",
        "stars": 39704
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 16, 2026",
      "updatedAt": "January 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 23,
          ".github": 5,
          ".husky": 1,
          ".idx": 2,
          "doc": 82,
          "eslint": 4,
          "extensions": 45,
          "mod_packages": 1,
          "mods": 13,
          "scripts": 1,
          "src": 23
        },
        "languages": {
          "YAML": 6,
          "Markdown": 104,
          "JavaScript": 39,
          "TypeScript": 9,
          "JSON": 19,
          "TOML": 1,
          "Shell": 1
        },
        "frameworks": [
          "React",
          "Docker"
        ],
        "packageManager": "npm",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "extensions/extensionController/src/index.ts",
          "extensions/metering/main.ts",
          "extensions/puterfs/main.js",
          "extensions/whoami/main.js",
          "mods/mods_available/example/main.js",
          "mods/mods_available/kdmod/gui/main.js"
        ],
        "configFiles": [
          ".env.example",
          "Dockerfile",
          "docker-compose.yml",
          "extensions/app-telemetry/package.json",
          "extensions/app-telemetry/tsconfig.json",
          "extensions/extensionController/package.json",
          "extensions/extensionController/tsconfig.json",
          "extensions/hellodriver/package.json",
          "extensions/metering/package.json",
          "extensions/metering/tsconfig.json",
          "extensions/puterfs/package.json",
          "extensions/tsconfig.json",
          "extensions/whoami/package.json",
          "mod_packages/testex/package.json",
          "mods/mods_available/example/package.json",
          "mods/mods_available/kdmod/package.json",
          "package.json"
        ],
        "dependencies": [
          "extensions/app-telemetry/package.json",
          "extensions/extensionController/package.json",
          "extensions/hellodriver/package.json",
          "extensions/metering/package.json",
          "extensions/puterfs/package.json",
          "extensions/whoami/package.json",
          "mod_packages/testex/package.json",
          "mods/mods_available/example/package.json",
          "mods/mods_available/kdmod/package.json",
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [
          ".github/workflows/test.yml",
          "doc/contributors/email_testing.md",
          "doc/test/playwright-test.md",
          "doc/testing_with_email.md",
          "mod_packages/testex/package.json",
          "mods/mods_available/kdmod/ShareTestService.js",
          "mods/mods_available/kdmod/data/sharetest_scenarios.js",
          "mods/mods_available/testex.js"
        ],
        "docs": [
          "CHANGELOG.md",
          "CONTRIBUTING.md",
          "LICENSE.txt",
          "README.md",
          "doc/AI.md",
          "doc/File Structure.drawio",
          "doc/File Structure.drawio.png",
          "doc/README.md",
          "doc/RFCS/20250826_captcha_cloudflare_turnstile.md",
          "doc/api/README.md",
          "doc/api/concepts/share-link.md",
          "doc/api/drivers.md",
          "doc/api/group.md",
          "doc/api/notifications.md",
          "doc/api/share.md",
          "doc/api/type-tagged.md",
          "doc/api/types/app-share.md",
          "doc/api/types/file-share.md",
          "doc/contributors/comment_prefixes.md",
          "doc/contributors/email_testing.md",
          "doc/contributors/extensions.md",
          "doc/contributors/extensions/README.md",
          "doc/contributors/extensions/definitions.md",
          "doc/contributors/extensions/events.json.js",
          "doc/contributors/extensions/events.md",
          "doc/contributors/extensions/gen.js",
          "doc/contributors/extensions/manual_overrides.json.js",
          "doc/contributors/image.png",
          "doc/contributors/structure.md",
          "doc/contributors/vscode.md",
          "doc/devlog.md",
          "doc/devmeta/track-comments.md",
          "doc/docmeta.md",
          "doc/i18n/README.ar.md",
          "doc/i18n/README.bn.md",
          "doc/i18n/README.da.md",
          "doc/i18n/README.de.md",
          "doc/i18n/README.en.md",
          "doc/i18n/README.es.md",
          "doc/i18n/README.fa.md",
          "doc/i18n/README.fi.md",
          "doc/i18n/README.fr.md",
          "doc/i18n/README.he.md",
          "doc/i18n/README.hi.md",
          "doc/i18n/README.hu.md",
          "doc/i18n/README.hy.md",
          "doc/i18n/README.id.md",
          "doc/i18n/README.it.md",
          "doc/i18n/README.jp.md",
          "doc/i18n/README.ko.md",
          "doc/i18n/README.ml.md",
          "doc/i18n/README.my.md",
          "doc/i18n/README.nl.md",
          "doc/i18n/README.od.md",
          "doc/i18n/README.pa.md",
          "doc/i18n/README.pl.md",
          "doc/i18n/README.pt.md",
          "doc/i18n/README.ro.md",
          "doc/i18n/README.ru.md",
          "doc/i18n/README.sv.md",
          "doc/i18n/README.ta.md",
          "doc/i18n/README.te.md",
          "doc/i18n/README.th.md",
          "doc/i18n/README.tr.md",
          "doc/i18n/README.ua.md",
          "doc/i18n/README.ur.md",
          "doc/i18n/README.vi.md",
          "doc/i18n/README.zh.md",
          "doc/license_header.txt",
          "doc/planning/2025-10-21_puter-fs-extension.md",
          "doc/planning/alternatives-to-$.md",
          "doc/planning/micro-modules.md",
          "doc/prod.md",
          "doc/self-hosters/config-vals.json.js",
          "doc/self-hosters/config.md",
          "doc/self-hosters/config_values.md",
          "doc/self-hosters/domains.md",
          "doc/self-hosters/first-run-issues.md",
          "doc/self-hosters/gen.js",
          "doc/self-hosters/instructions.md",
          "doc/self-hosters/support.md",
          "doc/test/playwright-test.md",
          "doc/testing_with_email.md",
          "doc/uncategorized/README.md",
          "doc/uncategorized/es6-note.md",
          "doc/uncategorized/puter-mods.md",
          "extensions/README.md",
          "mods/README.md",
          "mods/mods_available/kdmod/README.md",
          "src/backend/CONTRIBUTING.md",
          "src/backend/README.md",
          "src/backend/doc/A-and-A/auth.md",
          "src/backend/doc/A-and-A/permission.md",
          "src/backend/doc/Kernel.md",
          "src/backend/doc/README.md",
          "src/backend/doc/assets/puter-backend-map.drawio.png",
          "src/backend/doc/contributors/boot-sequence.md",
          "src/backend/doc/contributors/coding-style.md",
          "src/backend/doc/contributors/modules.md",
          "src/backend/doc/contributors/structure.md",
          "src/backend/doc/dev_socket.md",
          "src/backend/doc/extensions/README.md",
          "src/backend/doc/extensions/builtins/data.md",
          "src/backend/doc/extensions/pages/core-devs.md",
          "src/backend/doc/extensions/pages/drivers.md",
          "src/backend/doc/extensions/pages/import-and-export.md",
          "src/backend/doc/extensions/pages/runtime-modules.md",
          "src/backend/doc/features/batch-and-symlinks.md",
          "src/backend/doc/features/protected-apps.md",
          "src/backend/doc/features/service-scripts.md",
          "src/backend/doc/howto_make_driver.md"
        ],
        "fileTypes": {
          ".example": 1,
          ".yml": 5,
          ".yaml": 1,
          ".nix": 1,
          ".png": 4,
          ".md": 104,
          ".txt": 2,
          ".drawio": 1,
          ".js": 39,
          ".ts": 9,
          ".json": 19,
          ".toml": 1,
          ".sh": 1
        }
      }
    },
    {
      "id": 1135452329,
      "name": "awesome-agent-learning",
      "displayName": "awesome agent learning",
      "description": "Guides, courses & reading lists for learning to build autonomous LLM agents",
      "summary": "The Problem\nLearning to build autonomous AI agents can feel like navigating a maze blindfolded. You have endless resources, but finding what’s actually useful is a pain. With the rapid evolution of LLMs, you need focused guidance to keep up without drowning in irrelevant theory.\n\nWhat This Does\nThe awesome-agent-learning repo is your curated cheat sheet for diving into AI agents. The main file, README.md, lays out a well-structured collection of resources, from foundational courses to conceptual guides. Want to get your hands dirty? Check out the Foundational Courses section for links to actual courses, including the hands-on Hugging Face's AI Agents Course, which walks you through using popular frameworks. \n\nIf you want to contribute, the contributing.md file has your back, detailing how to add your favorite resources without making a mess. And don’t forget the eye-catching image in assets/ai-agent-learning.png — because who doesn’t love a good visual to complement their learning?\n\nReal-World Use\nImagine you’re tasked with building an AI agent for customer service. You start with the Advanced Large Language Model Agents course to grasp the underlying principles and then pivot to Microsoft's AI Agents for Beginners for practical lessons. You pick up code snippets along the way, which you can adapt for your project. By the end, you’ve got a working agent ready to deploy, thanks to the structured resources at your fingertips.\n\nThe Bottom Line\nThis repo is a solid starting point for anyone wanting to build AI agents. It's not overloaded with unnecessary fluff, and the resource curation is decent. However, with zero stars, it’s clear that it’s still under the radar. If you’re serious about diving into AI agents, grab the links and get to work; just be prepared to cross-reference with other trusted materials.",
      "url": "https://github.com/yebeai/awesome-agent-learning",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "artnitolog/awesome-agent-learning",
        "url": "https://github.com/artnitolog/awesome-agent-learning",
        "stars": 101
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 16, 2026",
      "updatedAt": "January 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 4,
        "directories": {
          "(root)": 3,
          "assets": 1
        },
        "languages": {
          "Markdown": 2
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md",
          "contributing.md"
        ],
        "fileTypes": {
          ".md": 2,
          ".png": 1
        }
      }
    },
    {
      "id": 1135451962,
      "name": "VibeWorkflowPlatform",
      "displayName": "VibeWorkflowPlatform",
      "description": "Vibe Workflow Platform for Non-technical Creators.",
      "summary": "The Problem\nNon-technical creators often find themselves stuck in a loop of repetitive tasks. They want to automate workflows but face technical barriers that require extensive coding knowledge. This can lead to frustration and wasted time, especially when tools like n8n feel like they require a PhD in engineering to use. \n\nWhat This Does\nEnter the Vibe Workflow Platform. This repo, a fork of the AIGeniusInstitute's project, provides a user-friendly interface for building workflows without writing a single line of code. You can check out the .cursor/rules/ directory, which contains a bunch of markdown files detailing coding guidelines and project structure—essentially a playbook for keeping everything organized.\n\nThe real magic happens in the visual canvas. The README highlights features like the Intervenable Agent, where you can visualize each step of your workflow and intervene in real-time. No more \"black box\" executions leaving you to guess what's gone wrong. You can modify and restart processes right on the canvas, making it user-friendly for those who aren’t deep into code.\n\nReal-World Use\nImagine you’re a content creator who spends hours manually sharing posts across platforms. With Refly.ai, you describe the task using the Workflow Copilot, and it crafts a multi-step automation for you. You drag and drop a couple of Agents, and voilà—your posts are scheduled automatically without needing to mess with complex API calls. It’s like having a personal assistant that actually gets your vibe.\n\nThe Bottom Line\nRefly.ai is a solid choice for non-techies wanting to automate their workflows without the headache of learning to code. The visual interface is a big win, but it’s still early days—no stars yet on this repo, so expect some rough edges. If you're a creator who wants to get things done quickly and easily, give it a shot. Just don’t expect it to handle enterprise-level complexity; it’s more like a friendly neighborhood sidekick.",
      "url": "https://github.com/yebeai/VibeWorkflowPlatform",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "AIGeniusInstitute/VibeWorkflowPlatform",
        "url": "https://github.com/AIGeniusInstitute/VibeWorkflowPlatform",
        "stars": 11
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 16, 2026",
      "updatedAt": "January 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".cursor": 14,
          "(root)": 11,
          ".github": 30,
          ".husky": 1,
          ".vscode": 2,
          "apps": 142
        },
        "languages": {
          "Markdown": 10,
          "YAML": 27,
          "JSON": 4,
          "TypeScript": 129,
          "JavaScript": 1
        },
        "frameworks": [
          "React",
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "apps/api/src/index.ts",
          "apps/api/src/main.ts",
          "apps/api/src/modules/common/fulltext-search/index.ts",
          "apps/api/src/modules/common/object-storage/index.ts",
          "apps/api/src/modules/common/vector-search/index.ts"
        ],
        "configFiles": [
          "apps/api/.env.example",
          "apps/api/Dockerfile",
          "apps/api/jest.config.ts",
          "apps/api/package.json"
        ],
        "dependencies": [
          "apps/api/package.json"
        ],
        "testFiles": [
          ".cursor/rules/10-testing-guidelines.mdc",
          ".github/workflows/deploy-test.yml",
          "apps/api/src/modules/action/action.controller.spec.ts",
          "apps/api/src/modules/action/action.service.spec.ts",
          "apps/api/src/modules/app.controller.spec.ts",
          "apps/api/src/modules/auth/auth.controller.spec.ts",
          "apps/api/src/modules/auth/auth.service.spec.ts",
          "apps/api/src/modules/canvas/canvas.controller.spec.ts",
          "apps/api/src/modules/canvas/canvas.service.spec.ts",
          "apps/api/src/modules/code-artifact/code-artifact.controller.spec.ts",
          "apps/api/src/modules/code-artifact/code-artifact.service.spec.ts",
          "apps/api/src/modules/collab/collab.service.spec.ts",
          "apps/api/src/modules/event/event.service.spec.ts",
          "apps/api/src/modules/knowledge/knowledge.controller.spec.ts"
        ],
        "docs": [
          ".cursor/rules/03-typescript-guidelines.mdc",
          ".cursor/rules/08-contributing-guidelines.mdc",
          ".cursor/rules/09-i18n-guidelines.mdc",
          ".cursor/rules/10-testing-guidelines.mdc",
          ".cursor/rules/16-language-guidelines.mdc",
          "CONTRIBUTING.md",
          "CONTRIBUTING_CN.md",
          "LICENSE",
          "README.md",
          "apps/api/README.md",
          "apps/api/src/modules/common/vector-search/README.md",
          "apps/api/src/modules/common/vector-search/backend/README.md"
        ],
        "fileTypes": {
          ".mdc": 14,
          ".md": 10,
          ".yml": 27,
          ".json": 4,
          ".development": 1,
          ".example": 1,
          ".ts": 129,
          ".prisma": 1,
          ".js": 1
        }
      }
    },
    {
      "id": 1135450976,
      "name": "BoldWallet",
      "displayName": "BoldWallet",
      "description": "Your Superior Bitcoin Wallet",
      "summary": "The Problem\nWhen it comes to Bitcoin wallets, security is often compromised by the need for seed phrases, which can be lost, stolen, or forgotten. Users face a trade-off between convenience and security, leaving many vulnerable. BoldWallet aims to eliminate this issue with a seedless approach using Threshold Signatures.\n\nWhat This Does\nBoldWallet's architecture is pretty straightforward but effective. It leverages a Threshold Signature Scheme (TSS), meaning you can set up and sign transactions without the hassle of seed phrases. The core logic is in App.tsx, which serves as the entry point for the React Native app, handling user interactions and managing wallets.\n\nIn the BBMTLib folder, you'll find scripts like keygen.sh and spend-bitcoin.sh, which are crucial for key generation and transaction signing. The flexibility of using multiple devices (up to three) for key generation means that you can securely operate without risking a single point of failure. For example, spend-bitcoin.sh allows you to create and sign transactions securely across devices, ensuring that no single device can access your funds alone.\n\nReal-World Use\nImagine you want to send Bitcoin to a friend without worrying about losing your seed phrase. You fire up the BoldWallet app, pair two devices via local WiFi or a Nostr relay, and initiate the transaction. Use the send-bitcoin function from the app; it prompts you to select the devices for signing, confirming the transaction securely. The whole process is done offline if you prefer, which is a great privacy boost.\n\nThe Bottom Line\nBoldWallet is an impressive solution for those who want security without the headache of seed phrases. Its multi-device approach is a strong fit for tech-savvy users who prioritize security. However, if you're not comfortable with the command line or Docker setup (docker/scripts/), it can feel overwhelming. The app's simplicity is great, but the underlying complexity may deter some users. In short, if you’re a Bitcoin enthusiast who values security and is willing to dive into a bit of tech, BoldWallet is worth checking out.",
      "url": "https://github.com/yebeai/BoldWallet",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "BoldBitcoinWallet/BoldWallet",
        "url": "https://github.com/BoldBitcoinWallet/BoldWallet",
        "stars": 19
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 16, 2026",
      "updatedAt": "January 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 13,
          ".github": 1,
          "BBMTLib": 48,
          "__tests__": 1,
          "android": 73,
          "assets": 64
        },
        "languages": {
          "JavaScript": 2,
          "YAML": 1,
          "TSX": 2,
          "Markdown": 8,
          "Shell": 15,
          "Go": 24,
          "Kotlin": 5,
          "Java": 1,
          "JSON": 1
        },
        "frameworks": [
          "React",
          "Express",
          "Rails",
          "Docker"
        ],
        "packageManager": "gradle",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "App.tsx",
          "BBMTLib/scripts/main.go",
          "BBMTLib/tss/cmd/bold-spend/README.md",
          "BBMTLib/tss/cmd/bold-spend/main.go",
          "BBMTLib/tss/cmd/nostr-keygen/main.go",
          "BBMTLib/tss/cmd/nostr-keysign/main.go"
        ],
        "configFiles": [
          ".eslintrc.js",
          ".prettierrc.js",
          "BBMTLib/go.mod",
          "Dockerfile",
          "Gemfile",
          "Gemfile.lock",
          "android/app/CMakeLists.txt",
          "android/app/build.gradle",
          "android/build.gradle"
        ],
        "dependencies": [
          "BBMTLib/go.mod",
          "Gemfile",
          "android/app/build.gradle",
          "android/build.gradle"
        ],
        "testFiles": [
          ".github/workflows/bbmtlib-test.yml",
          "BBMTLib/scripts/README-CI-TESTING.md",
          "BBMTLib/scripts/TESTING.md",
          "BBMTLib/scripts/test-all.sh",
          "BBMTLib/scripts/test-ci-local.sh",
          "BBMTLib/scripts/test-websocket-connection.sh",
          "__tests__/App.test.tsx",
          "assets/testnet-icon.png"
        ],
        "docs": [
          "BBMTLib/LICENSE",
          "BBMTLib/README.md",
          "BBMTLib/scripts/README-CI-TESTING.md",
          "BBMTLib/tss/cmd/bold-spend/README.md",
          "CHANGELOG.md",
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".js": 2,
          ".yml": 1,
          ".tsx": 2,
          ".md": 8,
          ".sh": 15,
          ".mod": 1,
          ".sum": 1,
          ".go": 24,
          ".lock": 1,
          ".txt": 3,
          ".gradle": 3,
          ".keystore": 1,
          ".jar": 2,
          ".aar": 1,
          ".pro": 1,
          ".xml": 12,
          ".png": 68,
          ".kt": 5,
          ".java": 1,
          ".webp": 30,
          ".so": 1,
          ".properties": 2,
          ".docker-linux": 1,
          ".bat": 1,
          ".json": 1
        }
      }
    },
    {
      "id": 1135450615,
      "name": "whatseerr",
      "displayName": "whatseerr",
      "description": "WhatsApp bot for Seerr that allows users to search and request media via WhatsApp messages",
      "summary": "The Problem\nEver tried to find a specific movie or show while juggling WhatsApp messages? Yeah, it's a pain. You end up scrolling through endless chats or switching apps, losing track of what you wanted to watch. Whatseerr tackles this by letting you search and request media directly through WhatsApp. No more app-switching; just send a quick message and get back to your day.\n\nWhat This Does\nWhatseerr is a WhatsApp bot for Seerr, built to streamline the media request process. It's structured cleanly with a few key files: cli.js handles the command line interface, while lib/api-message-extractor.js parses incoming WhatsApp messages. The lib/commands folder contains various command handlers—like search-command.js, which does the heavy lifting of searching Seerr for your requested media.\n\nConfiguration is done through config/config.example.json, which you’ll need to rename to config.json after setting it up. It’s straightforward—just fill in your Seerr and WAHA API keys, and map WhatsApp numbers to user IDs. That’s it; you’re good to go.\n\nReal-World Use\nLet’s say you’re at work and remember you wanted to watch The Matrix. Instead of firing up Seerr or a streaming service, just text your WhatsApp bot: r The Matrix. The bot searches Seerr, finds the results, and sends them back to you. Reply with the number of the one you want, and it submits the request. Simple, right? You can also request 4K content with r4k <title> if you’ve got that enabled.\n\nThe Bottom Line\nWhatseerr is a neat solution for anyone who uses Seerr and WhatsApp a lot. Its setup is pretty straightforward, especially if you’re comfortable with Docker. However, if you’re a casual user who doesn’t need a full bot setup, this might feel like overkill. But for power users or those managing groups, it’s a solid tool that cuts down on the hassle of media requests.",
      "url": "https://github.com/yebeai/whatseerr",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "SuFxGIT/whatseerr",
        "url": "https://github.com/SuFxGIT/whatseerr",
        "stars": 23
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 16, 2026",
      "updatedAt": "January 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 53,
        "directories": {
          "(root)": 13,
          ".github": 1,
          "config": 1,
          "lib": 35,
          "screenshots": 2,
          "templates": 1
        },
        "languages": {
          "YAML": 2,
          "Markdown": 3,
          "JavaScript": 37,
          "JSON": 3
        },
        "frameworks": [
          "React",
          "Express",
          "Docker"
        ],
        "packageManager": "npm",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "cli.js",
          "lib/commands/index.js",
          "lib/middleware/index.js",
          "lib/server.js"
        ],
        "configFiles": [
          "Dockerfile",
          "docker-compose.yml",
          "package.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".yml": 2,
          ".md": 3,
          ".js": 37,
          ".json": 3,
          ".png": 3,
          ".xml": 1
        }
      }
    },
    {
      "id": 1135450276,
      "name": "awesome-agentic-patterns",
      "displayName": "awesome agentic patterns",
      "description": "Visual card-based snippets for 99 AI agent design patterns. Fork of awesome-agentic-patterns.",
      "summary": "The Problem\nDesigning AI agents can feel like assembling IKEA furniture without instructions. You have a million pieces, and good luck figuring out how they fit together. Many tutorials are just shiny demos, while real-world applications can bury useful patterns under layers of complexity. This repository aims to cut through that noise.\n\nWhat This Does\nThe awesome-agentic-patterns repo provides a visual, card-based format for 99 AI agent design patterns, making it easier to grasp complex concepts at a glance. Check out the docs/patterns/ folder where each pattern gets its own file, like action-selector-pattern.md and agent-assisted-scaffolding.md. You’ll find ASCII art and Mermaid diagrams that visually break down these patterns. Plus, there’s bilingual support in English and Korean, making it accessible to a broader audience.\n\nIf you want to propose a new pattern, just follow the template in .github/ISSUETEMPLATE/newpattern_proposal.md. And if you’re feeling fancy, you can even deploy updates using the workflow defined in .github/workflows/deploy-pages.yml.\n\nReal-World Use\nImagine you’re building an AI-powered customer support agent. You can pull from patterns like feedback-loops to implement a self-healing retry mechanism. In practical terms, you’d check out docs/patterns/agent-driven-research.md to see how to structure your agent’s learning process. The repo helps you avoid reinventing the wheel by using proven methods that other teams have successfully implemented.\n\nThe Bottom Line\nThis repo is a valuable resource for anyone designing AI agents. The card-based format is a breath of fresh air compared to dense documentation. However, if you're just tinkering with AI for a small project, this might feel like overkill. But if you're serious about building robust agents, dive in—these patterns can save you a ton of headaches.",
      "url": "https://github.com/yebeai/awesome-agentic-patterns",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "esc5221/awesome-agentic-patterns",
        "url": "https://github.com/esc5221/awesome-agentic-patterns",
        "stars": 94
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 16, 2026",
      "updatedAt": "January 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".claude": 3,
          ".github": 2,
          "(root)": 18,
          ".vscode": 1,
          "docs": 112,
          "overrides": 3,
          "pattern-snippets": 61
        },
        "languages": {
          "Markdown": 121,
          "JSON": 45,
          "YAML": 2,
          "JavaScript": 4,
          "HTML": 19,
          "Shell": 1
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "index.js",
          "pattern-snippets/index.html"
        ],
        "configFiles": [
          "Makefile",
          "package.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [
          "docs/patterns/spec-as-test-feedback-loop.md",
          "docs/patterns/specification-driven-agent-development.md",
          "docs/patterns/spectrum-of-control-blended-initiative.md",
          "docs/patterns/structured-output-specification.md"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "docs/CNAME",
          "docs/CONTRIBUTING.md",
          "docs/LICENSE",
          "docs/TEMPLATE.md",
          "docs/agentic-patterns.jpeg",
          "docs/patterns/TEMPLATE.md",
          "docs/patterns/abstracted-code-representation-for-review.md",
          "docs/patterns/action-selector-pattern.md",
          "docs/patterns/agent-assisted-scaffolding.md",
          "docs/patterns/agent-driven-research.md",
          "docs/patterns/agent-first-tooling-and-logging.md",
          "docs/patterns/agent-friendly-workflow-design.md",
          "docs/patterns/agent-powered-codebase-qa-onboarding.md",
          "docs/patterns/agent-reinforcement-fine-tuning.md",
          "docs/patterns/agent-sdk-for-programmatic-control.md",
          "docs/patterns/agentic-search-over-vector-embeddings.md",
          "docs/patterns/ai-accelerated-learning-and-skill-development.md",
          "docs/patterns/ai-assisted-code-review-verification.md",
          "docs/patterns/anti-reward-hacking-grader-design.md",
          "docs/patterns/asynchronous-coding-agent-pipeline.md",
          "docs/patterns/autonomous-workflow-agent-architecture.md",
          "docs/patterns/autonomous-workflow-agent-architecture.png",
          "docs/patterns/background-agent-ci.md",
          "docs/patterns/chain-of-thought-monitoring-interruption.md",
          "docs/patterns/cli-first-skill-design.md",
          "docs/patterns/cli-native-agent-orchestration.md",
          "docs/patterns/code-first-tool-interface-pattern.md",
          "docs/patterns/code-over-api-pattern.md",
          "docs/patterns/code-then-execute-pattern.md",
          "docs/patterns/coding-agent-ci-feedback-loop.md",
          "docs/patterns/compounding-engineering-pattern.md",
          "docs/patterns/context-minimization-pattern.md",
          "docs/patterns/context-window-anxiety-management.md",
          "docs/patterns/continuous-autonomous-task-loop-pattern.md",
          "docs/patterns/criticgpt-style-evaluation.md",
          "docs/patterns/curated-code-context-window.md",
          "docs/patterns/curated-file-context-window.md",
          "docs/patterns/democratization-of-tooling-via-agents.md",
          "docs/patterns/deterministic-security-scanning-build-loop.md",
          "docs/patterns/discrete-phase-separation.md",
          "docs/patterns/disposable-scaffolding-over-durable-features.md",
          "docs/patterns/distributed-execution-cloud-workers.md",
          "docs/patterns/dogfooding-with-rapid-iteration-for-agent-improvement.md",
          "docs/patterns/dual-llm-pattern.md",
          "docs/patterns/dual-use-tool-design.md",
          "docs/patterns/dynamic-code-injection-on-demand-file-fetch.md",
          "docs/patterns/dynamic-context-injection.md",
          "docs/patterns/egress-lockdown-no-exfiltration-channel.md",
          "docs/patterns/episodic-memory-retrieval-injection.md",
          "docs/patterns/explicit-posterior-sampling-planner.md",
          "docs/patterns/extended-coherence-work-sessions.md",
          "docs/patterns/feature-list-as-immutable-contract.md",
          "docs/patterns/filesystem-based-agent-state.md",
          "docs/patterns/graph-of-thoughts.md",
          "docs/patterns/human-in-loop-approval-framework.md",
          "docs/patterns/inference-healed-code-review-reward.md",
          "docs/patterns/inference-time-scaling.md",
          "docs/patterns/initializer-maintainer-dual-agent.md",
          "docs/patterns/inversion-of-control.md",
          "docs/patterns/isolated-vm-per-rl-rollout.md",
          "docs/patterns/iterative-multi-agent-brainstorming.md",
          "docs/patterns/language-agent-tree-search-lats.md",
          "docs/patterns/latent-demand-product-discovery.md",
          "docs/patterns/layered-configuration-context.md",
          "docs/patterns/lethal-trifecta-threat-model.md",
          "docs/patterns/llm-friendly-api-design.md",
          "docs/patterns/llm-map-reduce-pattern.md",
          "docs/patterns/memory-synthesis-from-execution-logs.md",
          "docs/patterns/merged-code-language-skill-model.md",
          "docs/patterns/multi-model-orchestration-for-complex-edits.md",
          "docs/patterns/multi-platform-communication-aggregation.md",
          "docs/patterns/no-token-limit-magic.md",
          "docs/patterns/opponent-processor-multi-agent-debate.md",
          "docs/patterns/oracle-and-worker-multi-model.md",
          "docs/patterns/parallel-tool-call-learning.md",
          "docs/patterns/parallel-tool-execution.md",
          "docs/patterns/patch-steering-via-prompted-tool-selection.md",
          "docs/patterns/pii-tokenization.md",
          "docs/patterns/plan-then-execute-pattern.md",
          "docs/patterns/proactive-agent-state-externalization.md",
          "docs/patterns/proactive-trigger-vocabulary.md",
          "docs/patterns/progressive-autonomy-with-model-evolution.md",
          "docs/patterns/progressive-complexity-escalation.md",
          "docs/patterns/progressive-tool-discovery.md",
          "docs/patterns/reflection.md",
          "docs/patterns/rich-feedback-loops.md",
          "docs/patterns/rlaif-reinforcement-learning-from-ai-feedback.md",
          "docs/patterns/seamless-background-to-foreground-handoff.md",
          "docs/patterns/self-critique-evaluator-loop.md",
          "docs/patterns/self-discover-reasoning-structures.md",
          "docs/patterns/self-rewriting-meta-prompt-loop.md",
          "docs/patterns/shell-command-contextualization.md",
          "docs/patterns/skill-library-evolution.md",
          "docs/patterns/spec-as-test-feedback-loop.md",
          "docs/patterns/specification-driven-agent-development.md",
          "docs/patterns/spectrum-of-control-blended-initiative.md",
          "docs/patterns/stop-hook-auto-continue-pattern.md",
          "docs/patterns/structured-output-specification.md",
          "docs/patterns/sub-agent-spawning.md",
          "docs/patterns/subagent-compilation-checker.md",
          "docs/patterns/swarm-migration-pattern.md",
          "docs/patterns/team-shared-agent-configuration.md",
          "docs/patterns/three-stage-perception-architecture.md",
          "docs/patterns/tool-capability-compartmentalization.md",
          "docs/patterns/tool-use-incentivization-via-reward-shaping.md",
          "docs/patterns/tool-use-steering-via-prompting.md",
          "docs/patterns/tree-of-thought-reasoning.md",
          "docs/patterns/variance-based-rl-sample-selection.md",
          "docs/patterns/verbose-reasoning-transparency.md",
          "docs/patterns/versioned-constitution-governance.md",
          "docs/patterns/virtual-machine-operator-agent.md",
          "docs/patterns/visual-ai-multimodal-integration.md"
        ],
        "fileTypes": {
          ".md": 121,
          ".json": 45,
          ".yml": 1,
          ".jpeg": 2,
          ".png": 1,
          ".js": 4,
          ".yaml": 1,
          ".html": 19,
          ".sh": 1
        }
      }
    },
    {
      "id": 1135450037,
      "name": "Neoflow",
      "displayName": "Neoflow",
      "description": "Neoflow is an open-source whiteboard application designed for seamless collaboration and creativity. It combines simplicity with advanced features, making it perfect for teams, designers, and creative minds.",
      "summary": "The Problem\nIn today's remote work environment, teams often struggle to collaborate effectively on creative projects. Traditional tools fall short on flexibility, and whiteboard options can be clunky or costly. Neoflow aims to eliminate these hassles, offering a straightforward, free solution that doesn't skimp on features.\n\nWhat This Does\nNeoflow is built on the tldraw engine, providing a canvas for real-time collaboration. The structure of the repo is clear; for instance, the API routes are neatly organized under the app/api/ directory. You’ll find app/api/chat/route.ts, which likely handles chat functionality, and app/api/user/route.ts, managing user-related operations. The use of NextAuth in app/api/auth/[...nextauth]/route.ts suggests solid authentication handling, making it easier to manage user logins.\n\nInstallation is straightforward. After cloning the repo and running npm --force i, you're just a npm run dev away from opening the app at http://localhost:3000. It’s almost too easy—just make sure you configure your .env file correctly.\n\nReal-World Use\nImagine you’re working on a design project with your team. You can create a shared whiteboard space where everyone can draw, comment, and brainstorm ideas simultaneously. For example, you could use the app/api/team/project/route.ts to manage team projects, allowing users to create, update, or delete project boards on the fly. This is especially handy for agile teams who need to pivot quickly based on feedback.\n\nThe Bottom Line\nNeoflow is a solid choice for teams looking for a free and uncomplicated whiteboard tool. The integration of AI features and real-time collaboration makes it appealing, though the lack of stars suggests it might still be under the radar. If you're a designer or part of a small team needing a collaborative space, give Neoflow a shot. Just be ready to refine it as you go—like any open-source project, it's not perfect out of the box.",
      "url": "https://github.com/yebeai/Neoflow",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "kiraaziz/Neoflow",
        "url": "https://github.com/kiraaziz/Neoflow",
        "stars": 243
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 16, 2026",
      "updatedAt": "January 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 140,
        "directories": {
          "(root)": 11,
          "app": 44,
          "components": 67,
          "lib": 3,
          "prisma": 1,
          "public": 14
        },
        "languages": {
          "Markdown": 4,
          "TypeScript": 23,
          "JSX": 84,
          "JSON": 4,
          "JavaScript": 6,
          "CSS": 1,
          "HTML": 1
        },
        "frameworks": [
          "React",
          "Next.js",
          "Tailwind"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [
          ".env.example",
          "next.config.js",
          "package.json",
          "tailwind.config.js",
          "tsconfig.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".example": 1,
          ".md": 4,
          ".ts": 23,
          ".jsx": 84,
          ".json": 4,
          ".js": 6,
          ".css": 1,
          ".prisma": 1,
          ".jpg": 1,
          ".svg": 11,
          ".html": 1,
          ".webp": 1,
          ".txt": 1
        }
      }
    },
    {
      "id": 1135447763,
      "name": "soccerdata",
      "displayName": "soccerdata",
      "description": "⛏⚽ Scrape soccer data from Club Elo, ESPN, FBref, Football-Data.co.uk, FotMob, Sofascore, SoFIFA, Understat and WhoScored. ",
      "summary": "The Problem\nScraping soccer data can be a headache. With countless websites offering stats, manually pulling this data isn’t just tedious—it’s inefficient. If you want up-to-date game schedules, player stats, or historical data, you need a reliable solution that can handle the messy world of web scraping without breaking every time a site updates its layout.\n\nWhat This Does\nEnter soccerdata. This repo is a collection of scrapers designed to pull data from numerous sources like Club Elo, ESPN, FBref, and more. Each scraper outputs data as Pandas DataFrames, which means you won’t be stuck cleaning column names or dealing with inconsistent identifiers. \n\nCheck out the docs/datasources/ directory for example Jupyter notebooks that illustrate how to use each data source. For instance, docs/datasources/FBref.ipynb shows you how to get the latest team season stats or match schedules without losing your sanity. The caching mechanism is a nice touch—data is only downloaded when necessary, keeping your local storage tidy.\n\nReal-World Use\nImagine you’re building a web app that tracks player performance in real-time. You can set up a scraper like this:\n\nimport soccerdata as sd\n\nCreate a scraper for the 2020/21 Premier League\nfbref = sd.FBref('ENG-Premier League', '2021')\n\nFetch data\ngames = fbref.readschedule()\nteamstats = fbref.readteamseasonstats(stattype=\"passing\")\n\nNow you have the latest game schedules and team stats in your DataFrame, ready for analysis or visualization. No more manual downloads or formatting nightmares.\n\nThe Bottom Line\nsoccerdata is a solid choice if you need to scrape soccer data efficiently. It’s well-structured, with clear examples and a sensible caching approach. Just keep in mind that web scraping can break when sites change their layouts, so you might need to tweak things now and then. This is not for small, one-off projects; it's for those who are serious about soccer data and are ready to dive into the world of scraping.",
      "url": "https://github.com/yebeai/soccerdata",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "probberechts/soccerdata",
        "url": "https://github.com/probberechts/soccerdata",
        "stars": 1575
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1531482615713-2afd69097998?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 16, 2026",
      "updatedAt": "January 16, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 91,
        "directories": {
          ".dvc": 2,
          ".github": 9,
          "(root)": 10,
          "docs": 41,
          "soccerdata": 12,
          "tests": 17
        },
        "languages": {
          "Markdown": 2,
          "YAML": 8,
          "JSON": 3,
          "reStructuredText": 25,
          "CSS": 1,
          "Python": 27,
          "TOML": 1
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          "Makefile",
          "docs/requirements.txt",
          "pyproject.toml",
          "requirements.txt"
        ],
        "dependencies": [
          "docs/requirements.txt",
          "pyproject.toml",
          "requirements.txt"
        ],
        "testFiles": [
          "tests/__init__.py",
          "tests/appdata/config/league_dict.json",
          "tests/appdata/config/teamname_replacements.json",
          "tests/appdata/data.dvc",
          "tests/conftest.py",
          "tests/test_ClubElo.py",
          "tests/test_ESPN.py",
          "tests/test_FBref.py",
          "tests/test_FotMob.py",
          "tests/test_Integration.py",
          "tests/test_MatchHistory.py",
          "tests/test_SoFIFA.py",
          "tests/test_Sofascore.py",
          "tests/test_Understat.py",
          "tests/test_Whoscored.py",
          "tests/test_common.py",
          "tests/test_config.py"
        ],
        "docs": [
          "CONTRIBUTING.rst",
          "LICENSE.rst",
          "README.rst",
          "docs/_static/artwork.ai",
          "docs/_static/default.css",
          "docs/_static/favicon.ico",
          "docs/_static/logo.png",
          "docs/_static/logo2.png",
          "docs/conf.py",
          "docs/contributing.rst",
          "docs/datasources/ClubElo.ipynb",
          "docs/datasources/ESPN.ipynb",
          "docs/datasources/FBref.ipynb",
          "docs/datasources/FotMob.ipynb",
          "docs/datasources/MatchHistory.ipynb",
          "docs/datasources/SoFIFA.ipynb",
          "docs/datasources/Sofascore.ipynb",
          "docs/datasources/Understat.ipynb",
          "docs/datasources/WhoScored.ipynb",
          "docs/datasources/index.rst",
          "docs/examples/ClubElo - Evolution of current top teams.ipynb",
          "docs/examples/MatchHistory - Home advantage.ipynb",
          "docs/examples/index.rst",
          "docs/faq.rst",
          "docs/howto/custom-leagues.rst",
          "docs/howto/index.rst",
          "docs/howto/proxy.rst",
          "docs/index.rst",
          "docs/intro.rst",
          "docs/license.rst",
          "docs/output.csv",
          "docs/reference/base.rst",
          "docs/reference/clubelo.rst",
          "docs/reference/espn.rst",
          "docs/reference/fbref.rst",
          "docs/reference/fotmob.rst",
          "docs/reference/index.rst",
          "docs/reference/matchhistory.rst",
          "docs/reference/sofascore.rst",
          "docs/reference/sofifa.rst",
          "docs/reference/understat.rst",
          "docs/reference/utils.rst",
          "docs/reference/whoscored.rst",
          "docs/requirements.txt"
        ],
        "fileTypes": {
          ".md": 2,
          ".yml": 7,
          ".json": 3,
          ".yaml": 1,
          ".rst": 25,
          ".ai": 1,
          ".css": 1,
          ".ico": 1,
          ".png": 2,
          ".py": 27,
          ".ipynb": 11,
          ".csv": 1,
          ".txt": 2,
          ".toml": 1,
          ".dvc": 1,
          ".lock": 1
        }
      }
    },
    {
      "id": 1135137980,
      "name": "maplibre-gl-lidar",
      "displayName": "maplibre gl lidar",
      "description": "A MapLibre plugin for visualizing LiDAR Point Cloud",
      "summary": "The Problem\nVisualizing LiDAR point clouds can be a nightmare. You often end up juggling between large datasets and clunky visualization tools that can't handle the data's complexity. If you've ever tried to make sense of point clouds without a decent viewer, you know the struggle. It's a pain to sift through raw data and decipher what's actually useful.\n\nWhat This Does\nEnter maplibre-gl-lidar, a plugin that brings some sanity to the chaos. This repo is a fork of opengeos/maplibre-gl-lidar, which means you're getting a solid base with a few added tweaks. The core files like src/lib/adapters/LidarLayerAdapter.ts handle the heavy lifting for loading and rendering LAS/LAZ point clouds efficiently. Features like dynamic COPC streaming allow you to visualize massive datasets without crashing your browser.\n\nThe examples folder is your playground. Want to see how it all fits together? Check out examples/basic/main.ts for a straightforward implementation. You can also explore examples/react/main.tsx if you're working with React. Both provide a practical way to get started and demonstrate the API's capabilities.\n\nReal-World Use\nImagine you're tasked with visualizing a large LiDAR dataset for a new development project. You can quickly set up a basic viewer using the following snippet:\n\nconst lidarControl = new LidarControl({\n  title: \"LiDAR Viewer\",\n  collapsed: true,\n  pointSize: 2,\n  colorScheme: \"elevation\",\n});\n\nmap.addControl(lidarControl, \"top-right\");\nlidarControl.loadPointCloud(\"https://s3.amazonaws.com/hobu-lidar/autzen-classified.copc.laz\");\n\nWith just a few lines of code, you can load and explore the point cloud right in your browser. Plus, the interactive GUI lets you toggle classifications or adjust point sizes on-the-fly.\n\nThe Bottom Line\nmaplibre-gl-lidar is a solid choice for anyone needing to visualize LiDAR data without diving into a rabbit hole of complexity. It’s well-structured, and the examples make it easy to get going. However, if you only need to display small datasets, this might be overkill. For larger projects where performance and interactivity matter, this plugin shines.",
      "url": "https://github.com/yebeai/maplibre-gl-lidar",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "opengeos/maplibre-gl-lidar",
        "url": "https://github.com/opengeos/maplibre-gl-lidar",
        "stars": 149
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1542831371-29b0f74f9713?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 69,
        "directories": {
          ".github": 5,
          "(root)": 14,
          "examples": 6,
          "public": 3,
          "src": 37,
          "tests": 2,
          "viewer": 2
        },
        "languages": {
          "YAML": 6,
          "Markdown": 1,
          "HTML": 5,
          "TypeScript": 41,
          "TSX": 2,
          "JSON": 4,
          "CSS": 2,
          "JavaScript": 1
        },
        "frameworks": [
          "React",
          "Docker"
        ],
        "packageManager": "npm",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "examples/basic/index.html",
          "examples/basic/main.ts",
          "examples/ept/index.html",
          "examples/ept/main.ts",
          "examples/react/index.html",
          "index.html",
          "src/index.ts",
          "src/lib/adapters/index.ts",
          "src/lib/colorizers/index.ts",
          "src/lib/gui/index.ts",
          "src/lib/hooks/index.ts",
          "src/lib/layers/index.ts",
          "src/lib/loaders/index.ts",
          "src/lib/utils/index.ts",
          "viewer/index.html",
          "viewer/main.ts"
        ],
        "configFiles": [
          "Dockerfile",
          "package.json",
          "tsconfig.json",
          "vite.config.ts"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [
          "tests/helpers.test.ts",
          "tests/setup.ts",
          "vitest.config.ts"
        ],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".yml": 5,
          ".yaml": 1,
          ".md": 1,
          ".html": 5,
          ".ts": 41,
          ".tsx": 2,
          ".json": 4,
          ".wasm": 3,
          ".css": 2,
          ".js": 1
        }
      }
    },
    {
      "id": 1135131603,
      "name": "Acontext",
      "displayName": "Acontext",
      "description": "Data platform for context engineering. Context data platform that stores, observes and learns. Join the community❤️: https://discord.acontext.io",
      "summary": "The Problem\nBuilding AI agents that can handle substantial user loads isn't child's play. When you're dealing with databases that mainly consist of LLM messages, you're staring down a performance nightmare. Poor schema design can quickly turn your valuable data into a bottleneck, leading to slow queries and high costs. \n\nWhat This Does\nEnter Acontext, the context data platform that's all about efficient context storage and retrieval. It utilizes a mix of PostgreSQL, Redis, and S3, ensuring you can store everything from ChatGPT messages to files without breaking a sweat. Check out the AGENTS.md file for a detailed overview of how Acontext handles different types of data.\n\nLong-running agents often require constant context management, and Acontext simplifies that with built-in context editing methods. It's not just about storage; it's about easy access. Look into the README.md for a breakdown of the core features like unified message storage, task tracking, and the experience agent that learns from successful runs. \n\nReal-World Use\nImagine you're rolling out a new AI assistant for 100,000 users. You'd start by setting up your context storage using Acontext. In your code, you’d use the unified message storage feature to handle incoming messages across various LLMs. For instance, in your main agent logic, you might have:\n\nfrom acontext import Context\n\ncontext = Context()\ncontext.savemessage(userid, chat_message)\n\nAs your agent interacts with users, you'd track performance metrics directly through the platform, allowing you to tweak and improve your agent based on real user data.\n\nThe Bottom Line\nAcontext packs a punch for those building complex AI agents. It’s got the tools to manage context effectively and offers insights into agent performance that you'd otherwise miss. On the downside, if you're working on a small-scale project, this might feel like overkill. Use Acontext if you need robust context handling for larger applications; otherwise, you might want to stick with simpler solutions.",
      "url": "https://github.com/yebeai/Acontext",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "memodb-io/Acontext",
        "url": "https://github.com/memodb-io/Acontext",
        "stars": 3071
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1607799279861-4dd421887fb3?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".github": 22,
          "(root)": 8,
          "assets": 8,
          "charts": 20,
          "docs": 51,
          "onboard": 4,
          "readme": 8,
          "src": 79
        },
        "languages": {
          "Markdown": 20,
          "YAML": 32,
          "JSON": 2,
          "Python": 47,
          "TypeScript": 2,
          "Go": 19,
          "Shell": 1,
          "TOML": 1
        },
        "frameworks": [
          "Docker",
          "Kubernetes"
        ],
        "packageManager": "go modules",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "src/client/acontext-cli/cmd/create.go",
          "src/client/acontext-cli/cmd/create_test.go",
          "src/client/acontext-cli/cmd/docker.go",
          "src/client/acontext-cli/cmd/upgrade.go",
          "src/client/acontext-cli/main.go"
        ],
        "configFiles": [
          "src/client/acontext-cli/Makefile",
          "src/client/acontext-cli/go.mod",
          "src/client/acontext-cli/internal/docker/docker-compose.yaml",
          "src/client/acontext-py/pyproject.toml"
        ],
        "dependencies": [
          "src/client/acontext-cli/go.mod",
          "src/client/acontext-py/pyproject.toml"
        ],
        "testFiles": [
          ".github/workflows/api-test.yaml",
          ".github/workflows/cli-test.yaml",
          ".github/workflows/client-test-py.yaml",
          ".github/workflows/client-test-ts.yaml",
          ".github/workflows/core-test.yaml",
          "docs/store/messages/special/anthropic.mdx",
          "src/client/acontext-cli/cmd/create_test.go",
          "src/client/acontext-cli/internal/config/templates_test.go",
          "src/client/acontext-cli/internal/docker/env_test.go",
          "src/client/acontext-cli/internal/git/init_test.go",
          "src/client/acontext-cli/internal/template/downloader_test.go",
          "src/client/acontext-cli/internal/version/version_test.go",
          "src/client/acontext-py/tests/test_agent_tools.py",
          "src/client/acontext-py/tests/test_async_client.py",
          "src/client/acontext-py/tests/test_client.py"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "docs/api-reference/introduction.mdx",
          "docs/api-reference/openapi.json",
          "docs/chore/async_python.mdx",
          "docs/chore/badge.mdx",
          "docs/chore/per-user.mdx",
          "docs/docs.json",
          "docs/engineering/cache.mdx",
          "docs/engineering/editing.mdx",
          "docs/engineering/whatis.mdx",
          "docs/favicon.svg",
          "docs/images/acontext_data_flow.png",
          "docs/images/context_editing.png",
          "docs/images/dashboard/BI.png",
          "docs/images/dashboard/artifact_viewer.png",
          "docs/images/dashboard/message_viewer.png",
          "docs/images/dashboard/session_task_viewer.png",
          "docs/images/dashboard/skill_viewer.png",
          "docs/images/dashboard/task_viewer.png",
          "docs/images/dashboard/traces_viewer.png",
          "docs/index.mdx",
          "docs/integrations/agno.mdx",
          "docs/integrations/ai-sdk.mdx",
          "docs/integrations/intro.mdx",
          "docs/integrations/openai-python.mdx",
          "docs/integrations/openai-typescript.mdx",
          "docs/integrations/openai_agent.mdx",
          "docs/learn/advance/design-complex.mdx",
          "docs/learn/advance/experience-agent.mdx",
          "docs/learn/advance/wait-user.mdx",
          "docs/learn/search-skills.mdx",
          "docs/learn/skill-space.mdx",
          "docs/learn/tool.mdx",
          "docs/llm_quick.mdx",
          "docs/logo/dark.svg",
          "docs/logo/light.svg",
          "docs/observe/agent_tasks.mdx",
          "docs/observe/buffer.mdx",
          "docs/observe/dashboard.mdx",
          "docs/observe/disable_tasks.mdx",
          "docs/observe/traces.mdx",
          "docs/quick.mdx",
          "docs/sdk/disk_tools.mdx",
          "docs/sdk/skill_tools.mdx",
          "docs/settings/core.mdx",
          "docs/settings/local.mdx",
          "docs/settings/runtime.mdx",
          "docs/store/disk.mdx",
          "docs/store/messages/multi-modal.mdx",
          "docs/store/messages/multi-provider.mdx",
          "docs/store/messages/special/anthropic.mdx",
          "docs/store/skill.mdx",
          "readme/de/README.md",
          "readme/es/README.md",
          "readme/fr/README.md",
          "readme/ja/README.md",
          "readme/ko/README.md",
          "readme/pt/README.md",
          "readme/ru/README.md",
          "readme/zh/README.md",
          "src/client/acontext-cli/README.md",
          "src/client/acontext-py/README.md"
        ],
        "fileTypes": {
          ".txt": 2,
          ".md": 20,
          ".yml": 3,
          ".yaml": 29,
          ".png": 13,
          ".jpg": 1,
          ".svg": 5,
          ".gif": 1,
          ".lock": 2,
          ".tgz": 3,
          ".tpl": 1,
          ".mdx": 37,
          ".json": 2,
          ".py": 47,
          ".ts": 2,
          ".go": 19,
          ".mod": 1,
          ".sum": 1,
          ".sh": 1,
          ".toml": 1,
          ".typed": 1
        }
      }
    },
    {
      "id": 1135128731,
      "name": "vscode",
      "displayName": "vscode",
      "description": "Visual Studio Code",
      "summary": "The Problem\nDevelopers often find themselves juggling multiple tools for coding, debugging, and version control, leading to a disjointed workflow. Visual Studio Code (VS Code) aims to address this mess by integrating essential features into a single, lightweight interface. But, if you're starting from scratch, setting it up can be a pain without guidance.\n\nWhat This Does\nThe vscode repo serves as the open-source version of Visual Studio Code, where Microsoft and the community collaborate. It's packed with the tools you need to build, debug, and extend your coding experience. Inside the .devcontainer directory, you’ll find Dockerfile and devcontainer.json, which are essential for setting up a consistent development environment. This makes it easy to run your projects in the cloud or on local machines without the typical dependency hell.\n\nFor linting and enforcing coding standards, check out the .eslint-plugin-local folder. It contains a bunch of custom ESLint rules, like code-no-any-casts.ts, which prevents you from using any in TypeScript, keeping your codebase clean and maintainable.\n\nReal-World Use\nImagine you're working on a team project where everyone has different setups. You can clone the repository, use the install-vscode.sh script in .devcontainer to get your environment right, and start coding without worrying about mismatched Node versions or missing dependencies. Want to ensure no one is using any types in TypeScript? Just run ESLint with the custom rules from .eslint-plugin-local, and you're golden.\n\nThe Bottom Line\nThis repo is a solid choice for anyone looking to contribute to or customize their VS Code experience. It’s particularly beneficial for teams and open-source contributors who need a uniform environment. However, if you're just dabbling in coding or working on small projects, the overhead might be overkill. Stick to the standard VS Code for quick setups and save this for when you're ready to dive deeper.",
      "url": "https://github.com/yebeai/vscode",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "microsoft/vscode",
        "url": "https://github.com/microsoft/vscode",
        "stars": 182123
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".config": 3,
          ".devcontainer": 6,
          "(root)": 18,
          ".eslint-plugin-local": 47,
          ".github": 61,
          ".vscode": 48,
          "build": 17
        },
        "languages": {
          "YAML": 26,
          "Markdown": 39,
          "JSON": 23,
          "Shell": 3,
          "TypeScript": 63,
          "JavaScript": 1
        },
        "frameworks": [
          "React",
          "Express",
          "Docker"
        ],
        "packageManager": "npm",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          ".eslint-plugin-local/index.ts"
        ],
        "configFiles": [
          ".devcontainer/Dockerfile",
          ".eslint-plugin-local/package.json",
          ".eslint-plugin-local/tsconfig.json",
          ".vscode/extensions/vscode-selfhost-import-aid/package.json",
          ".vscode/extensions/vscode-selfhost-import-aid/tsconfig.json",
          ".vscode/extensions/vscode-selfhost-test-provider/package.json",
          ".vscode/extensions/vscode-selfhost-test-provider/tsconfig.json"
        ],
        "dependencies": [
          ".eslint-plugin-local/package.json",
          ".vscode/extensions/vscode-selfhost-import-aid/package-lock.json",
          ".vscode/extensions/vscode-selfhost-import-aid/package.json",
          ".vscode/extensions/vscode-selfhost-test-provider/package-lock.json",
          ".vscode/extensions/vscode-selfhost-test-provider/package.json"
        ],
        "testFiles": [
          ".eslint-plugin-local/code-ensure-no-disposables-leak-in-test.ts",
          ".eslint-plugin-local/code-no-test-async-suite.ts",
          ".eslint-plugin-local/code-no-test-only.ts",
          ".eslint-plugin-local/tests/code-no-observable-get-in-reactive-context-test.ts",
          ".eslint-plugin-local/tests/code-no-reader-after-await-test.ts",
          ".github/workflows/pr-darwin-test.yml",
          ".github/workflows/pr-linux-cli-test.yml",
          ".github/workflows/pr-linux-test.yml",
          ".github/workflows/pr-win32-test.yml",
          ".vscode-test.js",
          ".vscode/extensions/vscode-selfhost-test-provider/.vscode/launch.json",
          ".vscode/extensions/vscode-selfhost-test-provider/.vscode/settings.json",
          ".vscode/extensions/vscode-selfhost-test-provider/icon.png",
          ".vscode/extensions/vscode-selfhost-test-provider/package-lock.json",
          ".vscode/extensions/vscode-selfhost-test-provider/package.json",
          ".vscode/extensions/vscode-selfhost-test-provider/src/coverageProvider.ts",
          ".vscode/extensions/vscode-selfhost-test-provider/src/debounce.ts",
          ".vscode/extensions/vscode-selfhost-test-provider/src/extension.ts",
          ".vscode/extensions/vscode-selfhost-test-provider/src/failingDeepStrictEqualAssertFixer.ts",
          ".vscode/extensions/vscode-selfhost-test-provider/src/failureTracker.ts",
          ".vscode/extensions/vscode-selfhost-test-provider/src/importGraph.ts",
          ".vscode/extensions/vscode-selfhost-test-provider/src/memoize.ts",
          ".vscode/extensions/vscode-selfhost-test-provider/src/metadata.ts",
          ".vscode/extensions/vscode-selfhost-test-provider/src/snapshot.ts",
          ".vscode/extensions/vscode-selfhost-test-provider/src/sourceUtils.ts",
          ".vscode/extensions/vscode-selfhost-test-provider/src/stackTraceParser.ts",
          ".vscode/extensions/vscode-selfhost-test-provider/src/streamSplitter.ts",
          ".vscode/extensions/vscode-selfhost-test-provider/src/testOutputScanner.ts",
          ".vscode/extensions/vscode-selfhost-test-provider/src/testTree.ts",
          ".vscode/extensions/vscode-selfhost-test-provider/src/v8CoverageWrangling.test.ts",
          ".vscode/extensions/vscode-selfhost-test-provider/src/v8CoverageWrangling.ts",
          ".vscode/extensions/vscode-selfhost-test-provider/src/vscodeTestRunner.ts",
          ".vscode/extensions/vscode-selfhost-test-provider/tsconfig.json"
        ],
        "docs": [
          ".devcontainer/README.md",
          ".eslint-plugin-local/README.md",
          ".vscode/cglicenses.schema.json",
          "CONTRIBUTING.md",
          "LICENSE.txt",
          "README.md"
        ],
        "fileTypes": {
          ".yml": 26,
          ".winget": 1,
          ".md": 39,
          ".json": 23,
          ".sh": 3,
          ".ts": 63,
          ".svg": 6,
          ".js": 1,
          ".png": 1,
          ".github-issues": 10,
          ".code-search": 2,
          ".code-snippets": 1,
          ".txt": 2,
          ".darwin": 1,
          ".linux": 1,
          ".win32": 1
        }
      }
    },
    {
      "id": 1135128135,
      "name": "json-render",
      "displayName": "json render",
      "description": "AI → JSON → UI",
      "summary": "The Problem\nIntegrating AI-generated content into existing UI frameworks can be a nightmare. You want users to build dashboards or widgets from simple prompts, but how do you ensure they don’t create chaos? Traditional methods often lead to unpredictable outputs that don’t match your UI components, making it a real headache for developers and users alike.\n\nWhat This Does\nEnter json-render, which wraps AI-generated JSON in a safe, predictable environment. You define a catalog of components using createCatalog in apps/web/app/api/generate/route.ts, giving the AI a constrained vocabulary. This means users can only generate UI elements you’ve explicitly defined—no accidental chaos. \n\nThe setup is straightforward. Define your components and actions in a schema, then register how they render. For instance, in apps/web/app/docs/actions/page.tsx, you can specify that a Card should display a title and children. When users prompt the AI, it generates JSON that strictly adheres to your defined schema, ensuring that outputs are consistently valid.\n\nReal-World Use\nImagine a sales dashboard where users want to visualize revenue data. With json-render, you set up a simple React component like this:\n\nconst registry = {\n  Metric: ({ element }) => {\n    const value = useDataValue(element.props.valuePath);\n    return <div className=\"metric\">{format(value)}</div>;\n  },\n};\n\nUsers hit enter after typing “Show me my revenue,” and the AI generates JSON that maps directly to your Metric component. You get a safe and predictable rendering of their request—no more guessing what the AI might spit out.\n\nThe Bottom Line\njson-render is a solid tool for projects where user-generated UI is a requirement. It enforces structure, making sure your app remains stable while allowing flexibility. However, if you’re working on small projects or static UIs, this might feel like overkill. But for larger applications needing user interactivity, it’s a worthwhile addition to your toolkit.",
      "url": "https://github.com/yebeai/json-render",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "vercel-labs/json-render",
        "url": "https://github.com/vercel-labs/json-render",
        "stars": 11501
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 164,
        "directories": {
          ".github": 1,
          "(root)": 10,
          ".husky": 1,
          "apps": 78,
          "examples": 29,
          "packages": 45
        },
        "languages": {
          "YAML": 3,
          "Markdown": 6,
          "TypeScript": 26,
          "TSX": 89,
          "CSS": 2,
          "JSON": 18,
          "JavaScript": 7
        },
        "frameworks": [
          "React",
          "Next.js"
        ],
        "packageManager": "pnpm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "apps/web/components/demo/index.ts",
          "examples/dashboard/components/ui/index.ts",
          "packages/core/src/index.ts",
          "packages/react/src/index.ts"
        ],
        "configFiles": [
          "apps/web/.env.example",
          "apps/web/next.config.js",
          "apps/web/package.json",
          "apps/web/tsconfig.json",
          "examples/dashboard/.env.example",
          "examples/dashboard/next.config.js",
          "examples/dashboard/package.json",
          "examples/dashboard/tsconfig.json",
          "package.json",
          "packages/core/package.json",
          "packages/core/tsconfig.json",
          "packages/eslint-config/package.json",
          "packages/react/package.json",
          "packages/react/tsconfig.json",
          "packages/typescript-config/package.json",
          "packages/ui/package.json",
          "packages/ui/tsconfig.json"
        ],
        "dependencies": [
          "apps/web/package.json",
          "examples/dashboard/package.json",
          "package.json",
          "packages/core/package.json",
          "packages/eslint-config/package.json",
          "packages/react/package.json",
          "packages/typescript-config/package.json",
          "packages/ui/package.json"
        ],
        "testFiles": [
          "packages/core/src/actions.test.ts",
          "packages/core/src/catalog.test.ts",
          "packages/core/src/types.test.ts",
          "packages/core/src/validation.test.ts",
          "packages/core/src/visibility.test.ts",
          "packages/react/src/contexts/data.test.tsx",
          "packages/react/src/contexts/visibility.test.tsx",
          "packages/react/src/hooks.test.ts",
          "packages/react/src/renderer.test.tsx",
          "vitest.config.ts"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "apps/web/README.md",
          "apps/web/app/docs/actions/page.tsx",
          "apps/web/app/docs/ai-sdk/page.tsx",
          "apps/web/app/docs/api/core/page.tsx",
          "apps/web/app/docs/api/react/page.tsx",
          "apps/web/app/docs/catalog/page.tsx",
          "apps/web/app/docs/components/page.tsx",
          "apps/web/app/docs/data-binding/page.tsx",
          "apps/web/app/docs/installation/page.tsx",
          "apps/web/app/docs/layout.tsx",
          "apps/web/app/docs/page.tsx",
          "apps/web/app/docs/quick-start/page.tsx",
          "apps/web/app/docs/streaming/page.tsx",
          "apps/web/app/docs/validation/page.tsx",
          "apps/web/app/docs/visibility/page.tsx",
          "packages/core/README.md",
          "packages/eslint-config/README.md",
          "packages/react/README.md"
        ],
        "fileTypes": {
          ".yml": 1,
          ".md": 6,
          ".example": 2,
          ".ts": 26,
          ".tsx": 89,
          ".ico": 1,
          ".woff": 2,
          ".css": 2,
          ".json": 18,
          ".js": 7,
          ".mjs": 2,
          ".ttf": 1,
          ".yaml": 2
        }
      }
    },
    {
      "id": 1135124688,
      "name": "neonize",
      "displayName": "neonize",
      "description": "whatsapp automation library, written in python",
      "summary": "The Problem\nAutomating WhatsApp interactions can be a real headache. If you've ever tried to manage messages, media, or group operations without a solid library, you know the frustration. You end up writing boilerplate code for handling events and managing connections, which is time-consuming and error-prone.\n\nWhat This Does\nEnter Neonize, a Python library that makes WhatsApp automation a breeze. Built on top of the Whatsmeow Go library, it provides a clean API for sending messages, handling media, and managing group chats. The client.py file is your entry point for initializing and managing your bot. With the NewClient class, you can easily set up your bot and register event handlers like onconnected.\n\nThe project structure is convenient, with documentation neatly organized in the docs directory. You’ll find everything from installation steps in docs/getting-started/authentication.md to API references in docs/api-reference/client.md. It’s well-structured enough that you won’t need a treasure map to find what you need.\n\nReal-World Use\nImagine you need a bot that sends a daily message to a group at 9 AM. With Neonize, you could set up a simple script like this:\n\nfrom neonize.client import NewClient\nfrom neonize.events import MessageEv, ConnectedEv, event\n\nclient = NewClient(\"DailyReminderBot\")\n\n@client.event\ndef onconnected(client: NewClient, event: ConnectedEv):\n    print(\"🎉 Bot connected successfully!\")\n\n@client.event\ndef onmessage(client: NewClient, event: MessageEv):\n    if event.message == \"Send daily reminder\":\n        client.sendtext(\"Good morning! Don't forget to check your tasks!\")\n\nclient.run()\n\nWith just a few lines, you have a bot that listens for a specific trigger and responds accordingly. \n\nThe Bottom Line\nNeonize is a solid choice for anyone looking to automate WhatsApp tasks, especially if you're already in the Python ecosystem. The performance benefits from the Go backend are noticeable, and the API is straightforward. However, if your needs are simple—like sending a few messages here and there—this might be overkill. If you’re serious about WhatsApp automation, give it a shot. Just don’t expect it to do your laundry—yet.",
      "url": "https://github.com/yebeai/neonize",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "krypton-byte/neonize",
        "url": "https://github.com/krypton-byte/neonize",
        "stars": 335
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".github": 6,
          "(root)": 7,
          ".vscode": 1,
          "assets": 3,
          "docs": 22,
          "examples": 6,
          "goneonize": 72,
          "neonize": 83
        },
        "languages": {
          "YAML": 8,
          "JSON": 1,
          "Markdown": 23,
          "Shell": 1,
          "Python": 56,
          "Protocol Buffers": 56,
          "Go": 9,
          "C/C++ Header": 2,
          "C": 1
        },
        "frameworks": [],
        "packageManager": "go modules",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "goneonize/main.go"
        ],
        "configFiles": [
          "goneonize/go.mod"
        ],
        "dependencies": [
          "goneonize/go.mod"
        ],
        "testFiles": [
          "docs/development/testing.md"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "docs/.gitignore",
          "docs/README.md",
          "docs/api-reference/async-client.md",
          "docs/api-reference/client.md",
          "docs/api-reference/index.md",
          "docs/async/index.md",
          "docs/changelog.md",
          "docs/development/building.md",
          "docs/development/contributing.md",
          "docs/development/index.md",
          "docs/development/testing.md",
          "docs/examples/index.md",
          "docs/faq.md",
          "docs/getting-started/authentication.md",
          "docs/getting-started/index.md",
          "docs/getting-started/installation.md",
          "docs/getting-started/quickstart.md",
          "docs/index.md",
          "docs/user-guide/client-configuration.md",
          "docs/user-guide/index.md",
          "docs/user-guide/receiving-messages.md",
          "docs/user-guide/sending-messages.md"
        ],
        "fileTypes": {
          ".yml": 6,
          ".yaml": 2,
          ".json": 1,
          ".md": 23,
          ".png": 2,
          ".jpg": 1,
          ".sh": 1,
          ".py": 56,
          ".proto": 56,
          ".go": 9,
          ".mod": 1,
          ".sum": 1,
          ".h": 2,
          ".c": 1,
          ".pyi": 34
        }
      }
    },
    {
      "id": 1134830400,
      "name": "eigent",
      "displayName": "eigent",
      "description": "Eigent: The Open Source Cowork Desktop to Unlock Your Exceptional Productivity.",
      "summary": "The Problem\nIn today's world, managing workflows can feel like herding cats. Teams struggle with disjointed tools and processes, leading to wasted time and frustration. If you've ever felt bogged down by repetitive tasks or a lack of coordination among team members, you know the pain.\n\nWhat This Does\nEigent aims to tackle these challenges head-on. This open-source cowork desktop application allows users to build and manage a custom AI workforce that automates complex workflows. The backend folder contains the core logic for the local server, which means you can run everything on your own machine without worrying about data privacy. The README.md provides detailed instructions on how to set it up, whether you want a local or cloud-connected experience. \n\nThe .github directory is packed with templates for issues and pull requests, making it easier for contributors to engage with the project. If you’re looking to enhance your productivity and take control of your workflows, Eigent provides the tools to do just that.\n\nReal-World Use\nImagine you’re a project manager juggling multiple tasks across different teams. With Eigent, you can set up a multi-agent workflow where different agents handle various aspects of the project simultaneously. For instance, you might have one agent gathering data from APIs while another processes that data and a third generates reports. You could execute this by configuring the agents in your local backend server and triggering their activities via the API. Here’s a quick snippet to illustrate:\n\n// Pseudo-code for triggering agents\nconst agents = [\"dataCollector\", \"dataProcessor\", \"reportGenerator\"];\nagents.forEach(agent => {\n    fetch(http://localhost:3000/start/${agent})\n        .then(response => response.json())\n        .then(data => console.log(${agent} started:, data));\n});\n\nThe Bottom Line\nEigent is a solid choice for teams tired of the usual chaos. It offers a straightforward way to automate tasks and improve collaboration. However, if you’re a solo developer or working on a small project, this might be overkill. Overall, it's worth checking out if you're looking to ramp up your productivity with a bit of AI muscle behind you.",
      "url": "https://github.com/yebeai/eigent",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "eigent-ai/eigent",
        "url": "https://github.com/eigent-ai/eigent",
        "stars": 12726
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 14,
          ".github": 12,
          ".vscode": 5,
          "backend": 93,
          "build": 4,
          "config": 2,
          "docs": 16,
          "electron": 15,
          "package": 39
        },
        "languages": {
          "YAML": 11,
          "Markdown": 19,
          "JSON": 12,
          "Python": 81,
          "TOML": 1,
          "TypeScript": 15,
          "HTML": 1,
          "JavaScript": 18
        },
        "frameworks": [
          "React"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "backend/cli.py",
          "backend/main.py",
          "electron/main/index.ts",
          "electron/preload/index.ts",
          "index.html"
        ],
        "configFiles": [
          "backend/pyproject.toml",
          "package.json"
        ],
        "dependencies": [
          "backend/pyproject.toml",
          "package.json"
        ],
        "testFiles": [
          "backend/tests/conftest.py",
          "backend/tests/unit/controller/test_chat_controller.py",
          "backend/tests/unit/controller/test_model_controller.py",
          "backend/tests/unit/controller/test_task_controller.py",
          "backend/tests/unit/controller/test_tool_controller.py",
          "backend/tests/unit/service/test_chat_service.py",
          "backend/tests/unit/service/test_task.py",
          "backend/tests/unit/utils/test_agent.py",
          "backend/tests/unit/utils/test_single_agent_worker.py",
          "backend/tests/unit/utils/test_terminal_toolkit.py",
          "backend/tests/unit/utils/test_workforce.py"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "README_CN.md",
          "backend/README.md",
          "docs/core/concepts.md",
          "docs/core/models/gemini.md",
          "docs/core/models/local-model.md",
          "docs/core/tools.md",
          "docs/core/workers.md",
          "docs/core/workforce.md",
          "docs/docs.json",
          "docs/get_started/installation.md",
          "docs/get_started/quick_start.md",
          "docs/get_started/welcome.md",
          "docs/images/gemini_1.png",
          "docs/images/gemini_2.png",
          "docs/images/gemini_3.png",
          "docs/images/gemini_4.png",
          "docs/troubleshooting/bug.md",
          "docs/troubleshooting/support.md",
          "package/@stackframe/react/CHANGELOG.md",
          "package/@stackframe/react/LICENSE",
          "package/@stackframe/react/README.md"
        ],
        "fileTypes": {
          ".development": 1,
          ".yml": 11,
          ".md": 19,
          ".mjs": 1,
          ".json": 12,
          ".py": 81,
          ".cfg": 1,
          ".po": 2,
          ".pot": 1,
          ".toml": 1,
          ".lock": 1,
          ".icns": 1,
          ".ico": 1,
          ".png": 5,
          ".nsh": 1,
          ".cjs": 1,
          ".ts": 15,
          ".plist": 1,
          ".html": 1,
          ".js": 18,
          ".map": 18
        }
      }
    },
    {
      "id": 1134819106,
      "name": "lemon-chat",
      "displayName": "lemon chat",
      "description": "No description available",
      "summary": "The Problem\nIn a world drowning in chat applications, finding a self-hosted solution that offers both privacy and flexibility is like searching for a unicorn. Most chat applications are either bloated with features you’ll never use or they snoop on your data. Lemon Chat tackles this by enabling users to run their own lightweight chat server, giving control back to the people.\n\nWhat This Does\nLemon Chat is structured to be simple yet effective. At its core, the server runs a lightweight C application that you can build with windowsbuildscript.bat or linuxbuildscript.sh. It supports real-time communication through WebSocket for text and images, alongside WebRTC for audio, which keeps your IP address safe. \n\nThe client-side is just a single client.html file. You can run it directly in a browser or package it into an executable using Electron. It’s all laid out in the client/android/app/ directory, which contains the necessary files for an Android app if you want to go that route. The configuration is straightforward enough that you don’t need to download additional C/C++ libraries—everything's included in the repository.\n\nReal-World Use\nImagine you're setting up a small community chat for a hobby group. You clone the repo, run the appropriate build script, and you’re up and running. Using the client.html, your friends can connect through their browsers without any installation fuss. You can even customize settings like user roles and channel management using the ChatSettings.java file. Want to add a custom theme? Just tweak the relevant drawable XML files under client/android/app/src/main/res/drawable/.\n\nIf you're feeling adventurous, you can embed client.html into a website using Apache and stunnel, as outlined in the README. This opens up your chat to a wider audience without sacrificing security.\n\nThe Bottom Line\nLemon Chat is a solid choice for anyone tired of corporate chat apps that invade your privacy. It’s lightweight and relatively easy to set up, but it might be overkill if you’re just looking for a quick chat solution with friends. Developers who want control over their data and a customizable chat experience will find this project useful, but those who want a no-fuss option might want to stick to established platforms.",
      "url": "https://github.com/yebeai/lemon-chat",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "azc5OQ/lemon-chat",
        "url": "https://github.com/azc5OQ/lemon-chat",
        "stars": 13
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 5,
          "client": 61,
          "example": 3,
          "server-source-code": 131
        },
        "languages": {
          "Markdown": 7,
          "Java": 9,
          "HTML": 3,
          "TOML": 1,
          "YAML": 2,
          "Swift": 1,
          "C++": 12
        },
        "frameworks": [],
        "packageManager": "gradle",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "Travis CI",
        "entryPoints": [
          "server-source-code/libdatachannel/deps/json/tests/abi/main.cpp",
          "server-source-code/libdatachannel/deps/json/tests/cmake_add_subdirectory/project/main.cpp",
          "server-source-code/libdatachannel/deps/json/tests/cmake_fetch_content/project/main.cpp"
        ],
        "configFiles": [
          "client/android/app/build.gradle",
          "client/android/build.gradle",
          "server-source-code/libdatachannel/CMakeLists.txt",
          "server-source-code/libdatachannel/deps/json/CMakeLists.txt",
          "server-source-code/libdatachannel/deps/json/tests/CMakeLists.txt",
          "server-source-code/libdatachannel/deps/json/tests/abi/CMakeLists.txt",
          "server-source-code/libdatachannel/deps/json/tests/abi/config/CMakeLists.txt",
          "server-source-code/libdatachannel/deps/json/tests/abi/diag/CMakeLists.txt",
          "server-source-code/libdatachannel/deps/json/tests/abi/inline_ns/CMakeLists.txt",
          "server-source-code/libdatachannel/deps/json/tests/benchmarks/CMakeLists.txt",
          "server-source-code/libdatachannel/deps/json/tests/cmake_add_subdirectory/CMakeLists.txt",
          "server-source-code/libdatachannel/deps/json/tests/cmake_add_subdirectory/project/CMakeLists.txt",
          "server-source-code/libdatachannel/deps/json/tests/cmake_fetch_content/CMakeLists.txt",
          "server-source-code/libdatachannel/deps/json/tests/cmake_fetch_content/project/CMakeLists.txt",
          "server-source-code/libdatachannel/deps/json/tests/cmake_fetch_content2/CMakeLists.txt"
        ],
        "dependencies": [
          "client/android/app/build.gradle",
          "client/android/build.gradle"
        ],
        "testFiles": [
          "client/android/app/src/androidTest/java/com/example/lemonchat/ExampleInstrumentedTest.java",
          "client/android/app/src/test/java/com/example/lemonchat/ExampleUnitTest.java",
          "example/test1.PNG",
          "server-source-code/libdatachannel/deps/json/cmake/download_test_data.cmake",
          "server-source-code/libdatachannel/deps/json/cmake/test.cmake",
          "server-source-code/libdatachannel/deps/json/tests/CMakeLists.txt",
          "server-source-code/libdatachannel/deps/json/tests/abi/CMakeLists.txt",
          "server-source-code/libdatachannel/deps/json/tests/abi/config/CMakeLists.txt",
          "server-source-code/libdatachannel/deps/json/tests/abi/config/config.hpp",
          "server-source-code/libdatachannel/deps/json/tests/abi/config/custom.cpp",
          "server-source-code/libdatachannel/deps/json/tests/abi/config/default.cpp",
          "server-source-code/libdatachannel/deps/json/tests/abi/config/noversion.cpp",
          "server-source-code/libdatachannel/deps/json/tests/abi/diag/CMakeLists.txt",
          "server-source-code/libdatachannel/deps/json/tests/abi/diag/diag.cpp",
          "server-source-code/libdatachannel/deps/json/tests/abi/diag/diag.hpp",
          "server-source-code/libdatachannel/deps/json/tests/abi/diag/diag_off.cpp",
          "server-source-code/libdatachannel/deps/json/tests/abi/diag/diag_on.cpp",
          "server-source-code/libdatachannel/deps/json/tests/abi/include/nlohmann/json_v3_10_5.hpp",
          "server-source-code/libdatachannel/deps/json/tests/abi/inline_ns/CMakeLists.txt",
          "server-source-code/libdatachannel/deps/json/tests/abi/inline_ns/use_current.cpp",
          "server-source-code/libdatachannel/deps/json/tests/abi/inline_ns/use_v3_10_5.cpp",
          "server-source-code/libdatachannel/deps/json/tests/abi/main.cpp",
          "server-source-code/libdatachannel/deps/json/tests/benchmarks/CMakeLists.txt",
          "server-source-code/libdatachannel/deps/json/tests/benchmarks/src/benchmarks.cpp",
          "server-source-code/libdatachannel/deps/json/tests/cmake_add_subdirectory/CMakeLists.txt",
          "server-source-code/libdatachannel/deps/json/tests/cmake_add_subdirectory/project/CMakeLists.txt",
          "server-source-code/libdatachannel/deps/json/tests/cmake_add_subdirectory/project/main.cpp",
          "server-source-code/libdatachannel/deps/json/tests/cmake_fetch_content/CMakeLists.txt",
          "server-source-code/libdatachannel/deps/json/tests/cmake_fetch_content/project/CMakeLists.txt",
          "server-source-code/libdatachannel/deps/json/tests/cmake_fetch_content/project/main.cpp",
          "server-source-code/libdatachannel/deps/json/tests/cmake_fetch_content2/CMakeLists.txt"
        ],
        "docs": [
          "README.md",
          "client/android/README.md.txt",
          "server-source-code/libdatachannel/LICENSE",
          "server-source-code/libdatachannel/README.md",
          "server-source-code/libdatachannel/deps/json/ChangeLog.md",
          "server-source-code/libdatachannel/deps/json/LICENSE.MIT",
          "server-source-code/libdatachannel/deps/json/LICENSES/Apache-2.0.txt",
          "server-source-code/libdatachannel/deps/json/LICENSES/BSD-3-Clause.txt",
          "server-source-code/libdatachannel/deps/json/LICENSES/GPL-3.0-only.txt",
          "server-source-code/libdatachannel/deps/json/LICENSES/MIT.txt",
          "server-source-code/libdatachannel/deps/json/README.md"
        ],
        "fileTypes": {
          ".md": 7,
          ".txt": 21,
          ".gradle": 3,
          ".pro": 1,
          ".java": 9,
          ".xml": 21,
          ".html": 3,
          ".png": 4,
          ".webp": 15,
          ".properties": 3,
          ".toml": 1,
          ".jar": 1,
          ".bat": 1,
          ".mkv": 1,
          ".zip": 1,
          ".yml": 2,
          ".cmake": 20,
          ".in": 5,
          ".jinja2": 2,
          ".bazel": 2,
          ".cff": 1,
          ".mit": 1,
          ".swift": 1,
          ".hpp": 48,
          ".build": 1,
          ".natvis": 1,
          ".pc": 1,
          ".cpp": 12
        }
      }
    },
    {
      "id": 1134804505,
      "name": "Salon-Management-System",
      "displayName": "Salon Management System",
      "description": "This is a web-based application designed to help salon owners and managers manage their business operations more efficiently.",
      "summary": "The Problem\nRunning a salon involves juggling appointments, managing staff, and keeping track of inventory. Without proper tools, owners drown in chaos while trying to provide good service. Enter the need for a straightforward management system that keeps things organized and efficient.\n\nWhat This Does\nThe Salon Management System repository provides a web-based solution for salon owners. It’s built using HTML, CSS, PHP, and MySQL, allowing for a dynamic user experience. You can find all the core functionalities in mysalon/admin/. For instance, dash-index.php gives you a dashboard overview, while customer-list.php lets you manage customer profiles directly. Need to add services? Just hop into add-services.php.\n\nThe database structure is found in mysalon/Database/msmsdb.sql, which sets up the necessary tables for customers, services, and appointments. This is crucial if you want to hit the ground running. \n\nReal-World Use\nImagine you’re a salon owner preparing for a busy Saturday. You log into the admin panel using the credentials provided in the README. From dashboard.php, you can see today’s appointments, manage staff schedules, and check inventory levels before the rush hits. If a customer walks in needing an appointment, you can quickly use customer-enquiry.php to pull up their profile and book them in, all while keeping a cool demeanor. \n\nHere's a quick snippet on how you might fetch customer data from the database:\n\n$query = \"SELECT * FROM customers WHERE id = ?\";\n$stmt = $pdo->prepare($query);\n$stmt->execute([$customerId]);\n$customer = $stmt->fetch();\n\nThis shows how easy it is to pull information when you need it.\n\nThe Bottom Line\nThe Salon Management System is a decent starting point for salons looking to digitize their operations. It covers the basics like appointment scheduling and customer management without unnecessary fluff. However, if you're running a small shop, this might feel like overkill. Still, for medium to larger salons, it's a solid choice that could save time and hassle during peak hours.",
      "url": "https://github.com/yebeai/Salon-Management-System",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Abhisheksingh0303/Salon-Management-System",
        "url": "https://github.com/Abhisheksingh0303/Salon-Management-System",
        "stars": 36
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 170,
        "directories": {
          "(root)": 1,
          "my_salon": 169
        },
        "languages": {
          "Markdown": 1,
          "SQL": 1,
          "PHP": 58,
          "CSS": 10,
          "JavaScript": 20
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".md": 1,
          ".sql": 1,
          ".php": 58,
          ".css": 10,
          ".otf": 2,
          ".eot": 1,
          ".svg": 3,
          ".ttf": 1,
          ".woff": 4,
          ".woff2": 3,
          ".png": 24,
          ".js": 20,
          ".txt": 2,
          ".jpg": 38
        }
      }
    },
    {
      "id": 1134802136,
      "name": "BeautySmart",
      "displayName": "BeautySmart",
      "description": "System management to Salon/SPA  LARAVEL ",
      "summary": "The Problem\nManaging a salon or spa can feel like juggling flaming swords while riding a unicycle. Appointments, customer management, payments, and inventory—it's a lot to handle. If you're still using a mix of spreadsheets and sticky notes, it's time to modernize. You need a dedicated system to keep everything organized without losing your sanity.\n\nWhat This Does\nEnter the BeautySmart project, built on Laravel. This app is designed for salon and spa management, offering features like appointment booking, customer management, and inventory control—all in one place. Check out app/Http/Controllers/AppBeautySmart/AppBeautySmartController.php for the main controller that handles routing and logic for your beauty business.\n\nYou'll find CustomersController.php and ProductsController.php to manage customer data and product inventory. Need to send appointment reminders? The email and SMS features are built-in, so you can keep your clients informed without resorting to carrier pigeons. \n\nThe configuration is straightforward, and with the .env.example file, you can set your environment variables easily. Just rename it to .env and fill in your details.\n\nReal-World Use\nImagine a customer booking an appointment through your app. As soon as they select a service, the system checks staff availability and sends a confirmation email. Meanwhile, the daily_balance feature ensures you never lose track of your cash flow. You can see this in action in the app/Http/Controllers/PaymentsController.php, where all payment logic lives. \n\nYou can even manage loyalty points and promotions, which means your clients keep coming back for more—because who doesn't love rewards?\n\nThe Bottom Line\nBeautySmart is a solid option for salon and spa owners looking to ditch the chaos of manual management. It’s built with Laravel, so if you're familiar with it, you’ll appreciate the clean structure. On the downside, it’s still a work in progress with zero stars, so you might find some rough edges. If you're running a small shop, this might be overkill, but for larger operations, it could save you a ton of headaches.",
      "url": "https://github.com/yebeai/BeautySmart",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "IsaacMeirelles/BeautySmart",
        "url": "https://github.com/IsaacMeirelles/BeautySmart",
        "stars": 45
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 11,
          "app": 22,
          "public": 7,
          "resources": 15,
          "routes": 4,
          "storage": 8,
          "tests": 4,
          "vendor": 129
        },
        "languages": {
          "PHP": 136,
          "JSON": 11,
          "CSS": 1,
          "JavaScript": 3,
          "Markdown": 11,
          "Vue": 1,
          "SCSS": 2
        },
        "frameworks": [
          "React",
          "Vue",
          "Express",
          "Laravel"
        ],
        "packageManager": "composer",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "public/js/app.js",
          "resources/assets/js/app.js"
        ],
        "configFiles": [
          ".env.example",
          "package.json"
        ],
        "dependencies": [
          "composer.json",
          "package.json",
          "vendor/dnoegel/php-xdg-base-dir/composer.json",
          "vendor/doctrine/inflector/composer.json",
          "vendor/doctrine/instantiator/composer.json",
          "vendor/doctrine/lexer/composer.json",
          "vendor/egulias/email-validator/composer.json",
          "vendor/erusev/parsedown/composer.json",
          "vendor/fideloper/proxy/composer.json",
          "vendor/filp/whoops/composer.json"
        ],
        "testFiles": [
          "storage/framework/testing/.gitignore",
          "tests/CreatesApplication.php",
          "tests/Feature/ExampleTest.php",
          "tests/TestCase.php",
          "tests/Unit/ExampleTest.php",
          "vendor/dnoegel/php-xdg-base-dir/tests/XdgTest.php",
          "vendor/filp/whoops/src/Whoops/Exception/Inspector.php"
        ],
        "docs": [
          "readme.md",
          "vendor/composer/LICENSE",
          "vendor/dnoegel/php-xdg-base-dir/LICENSE",
          "vendor/dnoegel/php-xdg-base-dir/README.md",
          "vendor/doctrine/inflector/LICENSE",
          "vendor/doctrine/inflector/README.md",
          "vendor/doctrine/instantiator/CONTRIBUTING.md",
          "vendor/doctrine/instantiator/LICENSE",
          "vendor/doctrine/instantiator/README.md",
          "vendor/doctrine/lexer/LICENSE",
          "vendor/doctrine/lexer/README.md",
          "vendor/egulias/email-validator/LICENSE",
          "vendor/egulias/email-validator/README.md",
          "vendor/erusev/parsedown/LICENSE.txt",
          "vendor/erusev/parsedown/README.md",
          "vendor/fideloper/proxy/LICENSE.md",
          "vendor/filp/whoops/CHANGELOG.md",
          "vendor/filp/whoops/LICENSE.md"
        ],
        "fileTypes": {
          ".example": 1,
          ".php": 136,
          ".json": 11,
          ".lock": 2,
          ".xml": 1,
          ".css": 1,
          ".ico": 1,
          ".js": 3,
          ".txt": 2,
          ".config": 1,
          ".md": 11,
          ".vue": 1,
          ".scss": 2,
          ".bat": 3,
          ".dist": 2
        }
      }
    },
    {
      "id": 1134801873,
      "name": "CRM-laravel",
      "displayName": "CRM laravel",
      "description": "A Laravel based Booking + CRM system for a fictional salon called Salon Bliss. This project was developed as per the requirements of a Server Side Programming Module. ",
      "summary": "The Problem\nManaging bookings and customer relationships for a salon can be a logistical nightmare. Double bookings, missed appointments, and customer dissatisfaction can turn a thriving business into a chaotic mess. Salon Bliss needed a straightforward solution to keep everything organized and efficient.\n\nWhat This Does\nThis Laravel-based CRM and booking system tackles those pain points head-on. By leveraging the TALL stack (Tailwind CSS, Alpine.js, Laravel, Livewire), it provides a slick interface for both customers and admins. The app/Http/Controllers directory is packed with controllers like CartController.php and ManageService.php, which handle everything from managing appointments to tweaking service details.\n\nUser roles are managed through middleware, allowing for role-based access control. Check out app/Enums/UserRolesEnum.php for the specifics on user types. The Queued Jobs functionality, found in app/Http/Controllers/DisplayDeal.php, ensures that emails are sent out promptly without clogging the system. \n\nReal-World Use\nImagine a customer trying to book an appointment for a haircut. They log in, view available services via DisplayService.php, and pick a time slot. The system checks availability—thanks to the single appointment per time slot rule—and confirms the booking. If a new service pops up, the admin updates it in ManageService.php, and customers are notified via email, thanks to the queued jobs. \n\nHere’s a quick example of how you might handle a new booking in a controller:\n\npublic function bookAppointment(Request $request) {\n    // Validate and book the appointment\n    $validated = $request->validate([\n        'serviceid' => 'required|exists:services,id',\n        'userid' => 'required|exists:users,id',\n        'appointmenttime' => 'required|date|after:now',\n    ]);\n    Appointment::create($validated);\n    // Notify the user\n    SendBookingConfirmationJob::dispatch($validated['userid']);\n}\n\nThe Bottom Line\nSalon Bliss's CRM system is a solid choice if you're managing a small to medium salon. It’s feature-rich without being overwhelming, though it might feel like overkill for a one-person operation. If you're looking to get organized and improve customer interactions, this setup could save you a lot of headaches. Just be prepared to dive into some Laravel code to get the most out of it.",
      "url": "https://github.com/yebeai/CRM-laravel",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "sachintha-lk/CRM-laravel",
        "url": "https://github.com/sachintha-lk/CRM-laravel",
        "stars": 56
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".devcontainer": 3,
          "(root)": 17,
          "app": 72,
          "bootstrap": 2,
          "config": 18,
          "database": 25,
          "public": 27,
          "readme-assets": 22,
          "resources": 14
        },
        "languages": {
          "JSON": 6,
          "YAML": 2,
          "Markdown": 3,
          "PHP": 124,
          "Shell": 1,
          "JavaScript": 4,
          "CSS": 3
        },
        "frameworks": [
          "React",
          "Express",
          "Laravel",
          "Docker"
        ],
        "packageManager": "npm",
        "hasDocker": true,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "public/vendor/telescope/app.js",
          "resources/js/app.js"
        ],
        "configFiles": [
          ".devcontainer/Dockerfile",
          ".devcontainer/docker-compose.yml",
          ".env.example",
          "Dockerfile",
          "docker-compose.yml",
          "package.json"
        ],
        "dependencies": [
          "composer.json",
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "README.md",
          "readme-assets/screenshots/admin-dash-analytics.png",
          "readme-assets/screenshots/admin-location-day-schedule.png",
          "readme-assets/screenshots/analytics_recording.png",
          "readme-assets/screenshots/appointment_confirm_email_queue.png",
          "readme-assets/screenshots/cart.png",
          "readme-assets/screenshots/customer-analytics.png",
          "readme-assets/screenshots/customer-details-analytics.png",
          "readme-assets/screenshots/dashboard.png",
          "readme-assets/screenshots/homepage.png",
          "readme-assets/screenshots/locations-manage.png",
          "readme-assets/screenshots/logo-readme.png",
          "readme-assets/screenshots/manage-appointment-admin-view.png",
          "readme-assets/screenshots/manage-deals.png",
          "readme-assets/screenshots/manage-services.png",
          "readme-assets/screenshots/manage-users.png",
          "readme-assets/screenshots/new-service-email.png",
          "readme-assets/screenshots/new_service_promo_queue.png",
          "readme-assets/screenshots/queued_mail_appointment_confirm_email.png",
          "readme-assets/screenshots/service-analytics.png",
          "readme-assets/screenshots/services-page.png",
          "readme-assets/screenshots/view-a-service.png",
          "readme-assets/screenshots/view-appointment-customer.png"
        ],
        "fileTypes": {
          ".json": 6,
          ".yml": 2,
          ".example": 1,
          ".md": 3,
          ".pdf": 1,
          ".php": 124,
          ".lock": 1,
          ".sqlite": 1,
          ".sh": 1,
          ".xml": 1,
          ".js": 4,
          ".ico": 2,
          ".jpg": 14,
          ".png": 26,
          ".txt": 1,
          ".css": 3
        }
      }
    },
    {
      "id": 1134801521,
      "name": "Multi-Beauty-Salon-Web-Application-In-ReactJS-Firebase",
      "displayName": "Multi Beauty Salon Web Application In ReactJS Firebase",
      "description": "Introducing Your Ultimate Beauty Salon Management System – a next-gen platform to streamline and elevate salon operations! Whether you're a single salon or a multi-salon business, our system has everything you need to manage bookings, services, and customers effortlessly.",
      "summary": "The Problem\nManaging a beauty salon can be a logistical nightmare. Double bookings, inefficient service management, and poor customer data tracking can lead to frustrated clients and lost revenue. This repo tackles these pain points by providing a centralized system for salon management.\n\nWhat This Does\nThe Multi-Beauty-Salon-Web-Application-In-ReactJS-Firebase repo offers a full-fledged platform built with React.js and Firebase. You can manage bookings, services, and customers all from a single dashboard. The core files like src/App.js handle the main application logic, while server.js takes care of backend interactions. Want analytics? Check out the recommendation.json in mlmodelflask, which provides insights into customer preferences.\n\nThe file structure is straightforward. For instance, mlmodelAWS_Lambda/app.py encapsulates the logic for serving your machine learning model, while requirements.txt ensures you have the right dependencies. So, if you’re looking to add or modify features, you’ve got easy access to the necessary components.\n\nReal-World Use\nImagine a busy Saturday at your salon. A client walks in to book a last-minute appointment. Thanks to the real-time booking system in src/App.js, staff can quickly check availability without risking double bookings. Automated email confirmations (yep, that’s in there too) keep clients informed, which reduces no-shows. You can even track what services are most popular using the analytics features, allowing you to adjust marketing efforts and service offerings based on actual data.\n\nThe Bottom Line\nThis project is solid for medium to large salon operations but may feel overkill for a single salon. The React and Firebase combo is powerful, creating a responsive user experience. Just be prepared to dive into the code to tweak it to your needs. If you're managing multiple locations or scaling your business, this repo is worth checking out. If you're a one-person show, maybe stick to a simpler solution.",
      "url": "https://github.com/yebeai/Multi-Beauty-Salon-Web-Application-In-ReactJS-Firebase",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Zaibten/Multi-Beauty-Salon-Web-Application-In-ReactJS-Firebase",
        "url": "https://github.com/Zaibten/Multi-Beauty-Salon-Web-Application-In-ReactJS-Firebase",
        "stars": 1
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "AI Sakincare Recommandation": 45,
          "Admin Panel": 155
        },
        "languages": {
          "JSON": 10,
          "Python": 3,
          "Markdown": 7,
          "HTML": 1,
          "CSS": 6,
          "JavaScript": 20,
          "TypeScript": 98
        },
        "frameworks": [
          "React",
          "Flask",
          "Express"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "AI Sakincare Recommandation/mlmodel_AWS_Lambda/app.py",
          "AI Sakincare Recommandation/mlmodel_flask/app.py",
          "AI Sakincare Recommandation/public/index.html",
          "AI Sakincare Recommandation/server.js",
          "AI Sakincare Recommandation/src/App.js",
          "AI Sakincare Recommandation/src/index.js",
          "Admin Panel/index.js",
          "Admin Panel/node_modules/@fast-csv/format/build/src/formatter/index.js",
          "Admin Panel/node_modules/@fast-csv/format/build/src/index.js"
        ],
        "configFiles": [
          "AI Sakincare Recommandation/mlmodel_AWS_Lambda/requirements.txt",
          "AI Sakincare Recommandation/mlmodel_flask/requirements.txt",
          "AI Sakincare Recommandation/package.json",
          "Admin Panel/node_modules/@fast-csv/format/node_modules/@types/node/package.json",
          "Admin Panel/node_modules/@fast-csv/format/package.json"
        ],
        "dependencies": [
          "AI Sakincare Recommandation/mlmodel_AWS_Lambda/requirements.txt",
          "AI Sakincare Recommandation/mlmodel_flask/requirements.txt",
          "AI Sakincare Recommandation/package-lock.json",
          "AI Sakincare Recommandation/package.json",
          "Admin Panel/node_modules/@fast-csv/format/node_modules/@types/node/package.json",
          "Admin Panel/node_modules/@fast-csv/format/package.json"
        ],
        "testFiles": [
          "AI Sakincare Recommandation/src/App.test.js",
          "AI Sakincare Recommandation/src/setupTests.js",
          "Admin Panel/node_modules/@fast-csv/format/node_modules/@types/node/inspector.d.ts",
          "Admin Panel/node_modules/@fast-csv/format/node_modules/@types/node/ts4.8/inspector.d.ts"
        ],
        "docs": [
          "Admin Panel/node_modules/@fast-csv/format/CHANGELOG.md",
          "Admin Panel/node_modules/@fast-csv/format/LICENSE",
          "Admin Panel/node_modules/@fast-csv/format/README.md",
          "Admin Panel/node_modules/@fast-csv/format/node_modules/@types/node/LICENSE",
          "Admin Panel/node_modules/@fast-csv/format/node_modules/@types/node/README.md",
          "Admin Panel/node_modules/@fast-csv/parse/CHANGELOG.md",
          "Admin Panel/node_modules/@fast-csv/parse/LICENSE",
          "Admin Panel/node_modules/@fast-csv/parse/README.md"
        ],
        "fileTypes": {
          ".json": 10,
          ".py": 3,
          ".pkl": 2,
          ".md": 7,
          ".txt": 3,
          ".ipynb": 1,
          ".ico": 1,
          ".png": 4,
          ".html": 1,
          ".css": 6,
          ".js": 20,
          ".svg": 1,
          ".jpg": 2,
          ".jpeg": 2,
          ".xlsx": 1,
          ".cmd": 8,
          ".ps1": 8,
          ".ts": 98,
          ".map": 9
        }
      }
    },
    {
      "id": 1134801264,
      "name": "SEA-Salon",
      "displayName": "SEA Salon",
      "description": "salon management system website ",
      "summary": "The Problem\nManaging a salon can feel like herding cats. Appointments, services, and staff scheduling can quickly spiral out of control, especially as your clientele grows. Without a solid system in place, you risk double bookings, confused clients, and a chaotic work environment. \n\nWhat This Does\nEnter the SEA Salon Management System. This project provides a full-fledged web application to manage salon bookings, services, and staff. In the app/api/admin directory, you’ll find routes for managing branches, services, and stylists. For example, route.ts files handle CRUD operations, letting admins add or delete services with ease. \n\nUser authentication is managed through app/api/auth/[...nextauth]/route.ts, ensuring that only authorized personnel can access sensitive areas. The app allows clients to book appointments and select their preferred stylist, with real-time validation to avoid scheduling conflicts. Need to edit a branch or service? Just hit the appropriate route in the API, and you’re golden. \n\nReal-World Use\nImagine a busy Saturday morning at your salon. A client walks in wanting a last-minute appointment. With SEA Salon, you can quickly check the availability of stylists right from your admin panel, thanks to the app/api/booking/stylist/route.ts. If the stylist is booked, it alerts you immediately, allowing you to offer alternatives without breaking a sweat. The My Reservations page lets clients track their past bookings, reducing the number of \"Did I book that?\" questions.\n\nThe Bottom Line\nSEA Salon is a solid choice if you're looking to upgrade your salon management game. It uses NextJS for a smooth user experience, and the reliance on Prisma and PostgreSQL means you have a reliable backend. However, the requirement for page reloads after data changes is a pain point that needs addressing. Overall, if you’re managing a mid-sized salon and want to ditch the spreadsheets, this app is worth a shot.",
      "url": "https://github.com/yebeai/SEA-Salon",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Filbert88/SEA-Salon",
        "url": "https://github.com/Filbert88/SEA-Salon",
        "stars": 4
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1531482615713-2afd69097998?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 146,
        "directories": {
          "(root)": 9,
          "app": 52,
          "components": 43,
          "lib": 3,
          "prisma": 25,
          "public": 13,
          "types": 1
        },
        "languages": {
          "Markdown": 1,
          "CSS": 2,
          "TypeScript": 33,
          "TSX": 69,
          "JSON": 3,
          "SQL": 18,
          "TOML": 1
        },
        "frameworks": [
          "React",
          "Next.js",
          "Tailwind"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [
          ".env.example",
          "next.config.mjs",
          "package.json",
          "tailwind.config.ts",
          "tsconfig.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [
          "components/Dashboard/DeleteStylist.tsx",
          "prisma/seeds/test.ts"
        ],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".example": 1,
          ".md": 1,
          ".css": 2,
          ".ts": 33,
          ".tsx": 69,
          ".ico": 1,
          ".mjs": 2,
          ".json": 3,
          ".sql": 18,
          ".toml": 1,
          ".prisma": 1,
          ".jpg": 9,
          ".svg": 3,
          ".png": 1
        }
      }
    },
    {
      "id": 1134797367,
      "name": "ai-knowledge-graph",
      "displayName": "ai knowledge graph",
      "description": "AI Powered Knowledge Graph Generator",
      "summary": "The Problem\n\nProcessing unstructured text can feel like trying to find a needle in a haystack. You have all this information, but you need a way to extract meaningful relationships from it. Enter the ai-knowledge-graph repo—a tool that takes your messy text and turns it into a structured knowledge graph. You still have to deal with the raw data, but at least now you’ll have a visual representation of the relationships within it.\n\nWhat This Does\n\nThis system leverages a Large Language Model (LLM) to extract Subject-Predicate-Object (SPO) triplets from your text. It’s not rocket science, but it’s close enough. The magic happens in generate-graph.py, which orchestrates the extraction and visualization. You’ll want to tweak your settings in config.toml, especially the llm section where you can specify your model and API endpoint. \n\nAfter running the command:\n\npython generate-graph.py --input yourtextfile.txt --output knowledge_graph.html\n\nyou'll get an interactive HTML file that visualizes the relationships in your text. For those who prefer a more streamlined approach, you can also use uv, which is a decent way of running Python scripts if you don’t mind the extra dependencies.\n\nReal-World Use\n\nImagine you have a lengthy document on the Industrial Revolution. You throw it into the system via:\n\ngenerate-graph --input data/industrial-revolution.txt --output industrial-revolution-kg.html\n\nYou get back a shiny graph that shows entities like \"steam engine\" and \"factory\" and their connections. This isn’t just for show; it lets you quickly grasp complex relationships that might take hours to sort through manually.\n\nThe Bottom Line\n\nai-knowledge-graph is a solid tool for turning unstructured data into something digestible. It’s particularly useful for researchers or data scientists who need to analyze relationships in text but don’t want to reinvent the wheel. Just be aware: if your project is small or your text is straightforward, this might be overkill. But for larger datasets, it’s a lifesaver.",
      "url": "https://github.com/yebeai/ai-knowledge-graph",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "robert-mcdermott/ai-knowledge-graph",
        "url": "https://github.com/robert-mcdermott/ai-knowledge-graph",
        "stars": 1907
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1542831371-29b0f74f9713?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 26,
        "directories": {
          "(root)": 10,
          "data": 2,
          "docs": 1,
          "src": 13
        },
        "languages": {
          "Markdown": 1,
          "TOML": 2,
          "HTML": 2,
          "Python": 14
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "docs/index.html",
          "src/knowledge_graph/main.py"
        ],
        "configFiles": [
          "pyproject.toml",
          "requirements.txt"
        ],
        "dependencies": [
          "pyproject.toml",
          "requirements.txt"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md",
          "docs/index.html"
        ],
        "fileTypes": {
          ".md": 1,
          ".toml": 2,
          ".png": 1,
          ".txt": 2,
          ".html": 2,
          ".py": 14,
          ".lock": 1
        }
      }
    },
    {
      "id": 1134792760,
      "name": "midday",
      "displayName": "midday",
      "description": "Invoicing, Time tracking, File reconciliation, Storage, Financial Overview & your own Assistant made for Freelancers",
      "summary": "The Problem\nFreelancers are juggling a mess of tools to handle invoicing, time tracking, and file storage. The chaos of multiple platforms leads to wasted time and missed payments. You need a better way to manage your business without drowning in spreadsheets and disorganized files.\n\nWhat This Does\nEnter the midday repo. It’s designed for freelancers who want everything in one place. The structure reveals a thoughtful layout, with key features like time tracking and invoicing handled directly in the apps/api folder. The Dockerfile in apps/api/ ensures your local dev environment mirrors production, which is nice for avoiding those “it works on my machine” moments.\n\nThe real kicker here is the Magic Inbox, which lives in src/ai/agents/analytics.ts. It automates matching invoices to transactions, a lifesaver for keeping financials in check. You’re also getting a Vault for securely storing contracts, which beats digging through email attachments any day.\n\nReal-World Use\nImagine you’ve just wrapped up a project and need to invoice the client. You fire up the midday app, track the hours via the time tracking feature, and generate a beautiful invoice right from the app. No more copying and pasting into a Word document. The export feature then lets you download everything in a tidy CSV for your accountant. \n\nHere's a quick look at how you might initiate the time tracking in your code:\n\nconst startTracking = async (projectId: string) => {\n    await timeTracker.start(projectId);\n    console.log(Tracking started for project: ${projectId});\n};\n\nThe Bottom Line\nMidday makes sense for freelancers tired of switching between apps. It consolidates everything into one platform, but it might feel like overkill if you’re just starting out or only tracking a couple of projects. If you’re managing multiple clients and need a solid structure, this tool is worth checking out. Just be ready for some setup—it's not a plug-and-play solution.",
      "url": "https://github.com/yebeai/midday",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "midday-ai/midday",
        "url": "https://github.com/midday-ai/midday",
        "stars": 14056
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1607799279861-4dd421887fb3?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".github": 14,
          "(root)": 4,
          ".vscode": 2,
          "apps": 180
        },
        "languages": {
          "YAML": 15,
          "JSON": 3,
          "Markdown": 6,
          "TOML": 1,
          "TypeScript": 170
        },
        "frameworks": [
          "React",
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "apps/api/src/ai/agents/main.ts",
          "apps/api/src/index.ts",
          "apps/api/src/rest/middleware/index.ts",
          "apps/api/src/rest/routers/apps/fortnox/index.ts",
          "apps/api/src/rest/routers/apps/gmail/index.ts",
          "apps/api/src/rest/routers/apps/index.ts",
          "apps/api/src/rest/routers/apps/outlook/index.ts",
          "apps/api/src/rest/routers/apps/quickbooks/index.ts",
          "apps/api/src/rest/routers/apps/slack/index.ts",
          "apps/api/src/rest/routers/apps/xero/index.ts",
          "apps/api/src/rest/routers/files/index.ts",
          "apps/api/src/rest/routers/index.ts",
          "apps/api/src/rest/routers/webhooks/inbox/index.ts",
          "apps/api/src/rest/routers/webhooks/index.ts",
          "apps/api/src/rest/routers/webhooks/polar/index.ts",
          "apps/api/src/rest/routers/webhooks/stripe/index.ts",
          "apps/api/src/rest/routers/webhooks/whatsapp/index.ts"
        ],
        "configFiles": [
          "apps/api/Dockerfile",
          "apps/api/package.json"
        ],
        "dependencies": [
          "apps/api/package.json"
        ],
        "testFiles": [
          "apps/api/src/ai/artifacts/cash-flow-stress-test.ts",
          "apps/api/src/ai/tools/get-cash-flow-stress-test.ts"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "apps/api/README.md"
        ],
        "fileTypes": {
          ".yaml": 6,
          ".yml": 9,
          ".json": 3,
          ".md": 6,
          ".toml": 1,
          ".ts": 170
        }
      }
    },
    {
      "id": 1134792360,
      "name": "supermemory",
      "displayName": "supermemory",
      "description": "Memory engine and app that is extremely fast, scalable. The Memory API for the AI era.",
      "summary": "The Problem\nIn a world overflowing with information, keeping track of what matters can feel impossible. Traditional note-taking apps are often cluttered and lack smart integrations, leading to lost insights and disorganized content. Supermemory tackles this by providing a fast, scalable memory engine that makes saving and organizing information a breeze.\n\nWhat This Does\nSupermemory allows users to add memories from various sources—URLs, PDFs, or plain text—using a straightforward interface. You can interact with your saved content through a chat interface, making it feel like you’re conversing with your personal archive. Check out the apps/browser-extension/entrypoints/popup/App.tsx file to see how the chat feature is implemented, which uses React components to render the chat UI.\n\nThe app supports integrations with popular AI tools via the Supermemory MCP, found in the README.md. This means you can connect with tools like Claude or ChatGPT and enhance how you retrieve and interact with your stored memories. The browser extension, located in apps/browser-extension, allows you to save memories directly from your browsing sessions, integrating seamlessly with platforms like Twitter and ChatGPT.\n\nReal-World Use\nImagine you come across an insightful article on Medium. Instead of bookmarking it and losing it in the abyss of your browser, you can click the Supermemory extension, add a memory with one click, and categorize it. Later, when you want to retrieve that information, you simply open the app, type your question, and Supermemory digs through your collection to find relevant content. \n\nHere’s a quick example of how you might add a memory programmatically:\n\nasync function addMemory(content) {\n    const response = await fetch('/api/memory', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ memory: content }),\n    });\n    return response.json();\n}\n\nThe Bottom Line\nSupermemory is a solid solution for anyone overwhelmed by information overload. It’s especially useful for researchers, students, or anyone who regularly consumes content and wants to keep it organized. The browser extension is a nice touch, but if you don’t need an AI integration, this might be overkill. Just remember: with no stars yet, you’re jumping in early on a promising project that still needs some polish.",
      "url": "https://github.com/yebeai/supermemory",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "supermemoryai/supermemory",
        "url": "https://github.com/supermemoryai/supermemory",
        "stars": 16654
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".github": 3,
          "(root)": 5,
          "apps": 192
        },
        "languages": {
          "YAML": 3,
          "Markdown": 5,
          "TypeScript": 22,
          "CSS": 3,
          "TSX": 4,
          "HTML": 2,
          "JSON": 3,
          "Python": 1
        },
        "frameworks": [
          "React"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "apps/browser-extension/entrypoints/content/index.ts",
          "apps/browser-extension/entrypoints/popup/App.tsx",
          "apps/browser-extension/entrypoints/popup/index.html",
          "apps/browser-extension/entrypoints/welcome/index.html"
        ],
        "configFiles": [
          "apps/browser-extension/.env.example",
          "apps/browser-extension/package.json",
          "apps/browser-extension/tsconfig.json"
        ],
        "dependencies": [
          "apps/browser-extension/package.json"
        ],
        "testFiles": [],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "apps/browser-extension/README.md",
          "apps/docs/.cursor/rules/docs.mdc",
          "apps/docs/.gitignore",
          "apps/docs/README.md",
          "apps/docs/add-memories/examples/basic.mdx",
          "apps/docs/add-memories/examples/file-upload.mdx",
          "apps/docs/add-memories/overview.mdx",
          "apps/docs/add-memories/parameters.mdx",
          "apps/docs/ai-sdk/examples.mdx",
          "apps/docs/ai-sdk/infinite-chat.mdx",
          "apps/docs/ai-sdk/memory-tools.mdx",
          "apps/docs/ai-sdk/npm.mdx",
          "apps/docs/ai-sdk/overview.mdx",
          "apps/docs/ai-sdk/user-profiles.mdx",
          "apps/docs/analytics.mdx",
          "apps/docs/changelog/developer-platform.mdx",
          "apps/docs/changelog/overview.mdx",
          "apps/docs/connectors/github.mdx",
          "apps/docs/connectors/google-drive.mdx",
          "apps/docs/connectors/notion.mdx",
          "apps/docs/connectors/onedrive.mdx",
          "apps/docs/connectors/overview.mdx",
          "apps/docs/connectors/s3.mdx",
          "apps/docs/connectors/troubleshooting.mdx",
          "apps/docs/connectors/web-crawler.mdx",
          "apps/docs/cookbook/ai-sdk-integration.mdx",
          "apps/docs/cookbook/chat-with-gdrive.mdx",
          "apps/docs/cookbook/customer-support.mdx",
          "apps/docs/cookbook/document-qa.mdx",
          "apps/docs/cookbook/inf-chat-blog.mdx",
          "apps/docs/cookbook/overview.mdx",
          "apps/docs/cookbook/perplexity-supermemory.mdx",
          "apps/docs/cookbook/personal-assistant.mdx",
          "apps/docs/deployment/self-hosting.mdx",
          "apps/docs/docs.json",
          "apps/docs/favicon.png",
          "apps/docs/how-it-works.mdx",
          "apps/docs/images/232.png",
          "apps/docs/images/Screenshot 2025-06-19 at 3.50.20 PM.png",
          "apps/docs/images/Screenshot 2025-07-05 at 7.16.18 PM (2).png",
          "apps/docs/images/Screenshot 2025-07-05 at 7.16.18 PM (3).png",
          "apps/docs/images/Screenshot 2025-07-05 at 7.16.18 PM.png",
          "apps/docs/images/Screenshot 2025-07-05 at 7.16.22 PM (2).png",
          "apps/docs/images/Screenshot 2025-07-05 at 7.16.22 PM (3).png",
          "apps/docs/images/Screenshot 2025-07-05 at 7.16.22 PM.png",
          "apps/docs/images/add-gmail-node-zapier.png",
          "apps/docs/images/bearer-auth-add-n8n.png",
          "apps/docs/images/connectors-flow.png",
          "apps/docs/images/core-http-req.png",
          "apps/docs/images/create-api.png",
          "apps/docs/images/dev-platform-api-keys.png",
          "apps/docs/images/dev-platform-copy-key.png",
          "apps/docs/images/dev-platform-create-key.png",
          "apps/docs/images/dev-platform-login.png",
          "apps/docs/images/doc-to-memory-process.png",
          "apps/docs/images/gmail-content.png",
          "apps/docs/images/gmail-trigger.png",
          "apps/docs/images/graph-view.png",
          "apps/docs/images/hero-dark.svg",
          "apps/docs/images/hero-light.svg",
          "apps/docs/images/infinite-context.png",
          "apps/docs/images/make-zap.png",
          "apps/docs/images/map-content-to-gmail.png",
          "apps/docs/images/memories-inferred.png",
          "apps/docs/images/memory-graph.png",
          "apps/docs/images/opts/Connectors.png",
          "apps/docs/images/opts/Memory_API.png",
          "apps/docs/images/opts/Model_Enhancer.png",
          "apps/docs/images/opts/Supermemory_MCP.png",
          "apps/docs/images/overview-image.png",
          "apps/docs/images/pipeline.png",
          "apps/docs/images/process.png",
          "apps/docs/images/processing.png",
          "apps/docs/images/query-rewriting.png",
          "apps/docs/images/rerank.png",
          "apps/docs/images/sm-header.png",
          "apps/docs/images/static-dynamic-profile.png",
          "apps/docs/images/transparent-proxy.png",
          "apps/docs/images/zapier-output.png",
          "apps/docs/intro.mdx",
          "apps/docs/introduction.mdx",
          "apps/docs/list-memories/examples/basic.mdx",
          "apps/docs/list-memories/examples/filtering.mdx",
          "apps/docs/list-memories/examples/monitoring.mdx",
          "apps/docs/list-memories/examples/pagination.mdx",
          "apps/docs/list-memories/overview.mdx",
          "apps/docs/logo/dark.svg",
          "apps/docs/logo/light.svg",
          "apps/docs/memory-api/connectors/advanced/bring-your-own-key.mdx",
          "apps/docs/memory-api/connectors/creating-connection.mdx",
          "apps/docs/memory-api/connectors/google-drive.mdx",
          "apps/docs/memory-api/connectors/managing-resources.mdx",
          "apps/docs/memory-api/connectors/overview.mdx",
          "apps/docs/memory-api/creation/adding-memories.mdx",
          "apps/docs/memory-api/creation/status.mdx",
          "apps/docs/memory-api/features/auto-multi-modal.mdx",
          "apps/docs/memory-api/features/content-cleaner.mdx",
          "apps/docs/memory-api/features/filtering.mdx",
          "apps/docs/memory-api/features/query-rewriting.mdx",
          "apps/docs/memory-api/features/reranking.mdx",
          "apps/docs/memory-api/ingesting.mdx",
          "apps/docs/memory-api/introduction.mdx",
          "apps/docs/memory-api/overview.mdx",
          "apps/docs/memory-api/sdks/anthropic-claude-memory.mdx",
          "apps/docs/memory-api/sdks/native.mdx",
          "apps/docs/memory-api/sdks/openai-plugins.mdx",
          "apps/docs/memory-api/sdks/overview.mdx",
          "apps/docs/memory-api/sdks/python.mdx",
          "apps/docs/memory-api/sdks/supermemory-npm.mdx",
          "apps/docs/memory-api/sdks/supermemory-pypi.mdx",
          "apps/docs/memory-api/sdks/typescript.mdx",
          "apps/docs/memory-api/searching/searching-memories.mdx",
          "apps/docs/memory-api/track-progress.mdx",
          "apps/docs/memory-graph/api-reference.mdx",
          "apps/docs/memory-graph/examples.mdx",
          "apps/docs/memory-graph/installation.mdx",
          "apps/docs/memory-graph/npm.mdx",
          "apps/docs/memory-graph/overview.mdx",
          "apps/docs/memory-graph/quickstart.mdx",
          "apps/docs/memory-router/overview.mdx",
          "apps/docs/memory-router/usage.mdx",
          "apps/docs/memory-router/with-memory-api.mdx",
          "apps/docs/memory-vs-rag.mdx",
          "apps/docs/memorybench/architecture.mdx",
          "apps/docs/memorybench/cli.mdx",
          "apps/docs/memorybench/contributing.mdx",
          "apps/docs/memorybench/extend-benchmark.mdx",
          "apps/docs/memorybench/extend-provider.mdx",
          "apps/docs/memorybench/github.mdx",
          "apps/docs/memorybench/installation.mdx",
          "apps/docs/memorybench/integrations.mdx",
          "apps/docs/memorybench/overview.mdx",
          "apps/docs/memorybench/quickstart.mdx",
          "apps/docs/memorybench/supported-models.mdx",
          "apps/docs/migration/from-mem0.mdx",
          "apps/docs/migration/from-zep.mdx",
          "apps/docs/migration/mem0-migration-script.py"
        ],
        "fileTypes": {
          ".yml": 3,
          ".md": 5,
          ".example": 1,
          ".ts": 22,
          ".css": 3,
          ".tsx": 4,
          ".html": 2,
          ".ttf": 6,
          ".json": 3,
          ".svg": 5,
          ".png": 54,
          ".mdc": 1,
          ".mdx": 86,
          ".py": 1
        }
      }
    },
    {
      "id": 1134791393,
      "name": "FOSSBilling",
      "displayName": "FOSSBilling",
      "description": "Empower your hosting business with FOSSBilling, the free and open-source solution for efficient billing and client management.",
      "summary": "The Problem\n\nManaging billing and clients for a hosting business sucks. You cobble together spreadsheets, hack some WordPress plugin, or pay through the nose for proprietary software with more bugs than features. None of it fits, and you spend more time wrangling invoices than serving your customers.\n\nWhat This Does\n\nFOSSBilling gives you an open-source way out. It wrangles invoices, payments, and client data into one place, and you control the stack. The README.md spells out the basics, but the real action is under the hood. The .ddev/ folder handles your local dev environment (Docker, nginx configs, and even phpMyAdmin for poking the database), while config.yaml sorts project-level settings. The github/workflows/ci.yml and friends keep CI/CD humming, so you won’t ship broken code by accident. Security? There’s a SECURITY.md and automated scans (codeql.yml) so you can sleep at night.\n\nNeed to extend? The architecture is extension-friendly—add payment gateways or integrations without hacking core files. Translating for your global customers is paved by the Crowdin pipeline. And yes, the UI is actually usable on mobile, not just desktop.\n\nReal-World Use\n\nSay you run a small hosting shop. You set up FOSSBilling on your LAMP box. Tweak config.yaml to fit your domain. You add Stripe as a payment option (no, you don’t need a PhD in PHP). When a client signs up, FOSSBilling spits out invoices, sends reminders, and tracks payments. You poke around the database with phpmyadmin (thanks .ddev/), and when something breaks, you check CI logs from github/workflows/ci.yml before fixing and pushing. Want to localize for your Spanish clients? Crowdin integration means you don’t have to reinvent the wheel.\n\nThe Bottom Line\n\nFOSSBilling is a legit solution if you’re sick of SaaS lock-in or overpriced junk. It’s still beta—expect rough edges and some DIY fixes. If you run a hosting biz or sell subscriptions and want control (and don’t mind getting your hands dirty), this is worth a look. Small side projects? Probably overkill. But for real businesses, it’s a breath of fresh air.",
      "url": "https://github.com/yebeai/FOSSBilling",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "FOSSBilling/FOSSBilling",
        "url": "https://github.com/FOSSBilling/FOSSBilling",
        "stars": 1451
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".claude": 1,
          ".ddev": 7,
          "(root)": 20,
          ".gemini": 1,
          ".github": 17,
          ".qwen": 1,
          "data": 2,
          "frontend-build-utils": 5,
          "src": 146
        },
        "languages": {
          "Markdown": 9,
          "YAML": 16,
          "Shell": 1,
          "JSON": 8,
          "PHP": 120,
          "JavaScript": 3,
          "HTML": 5,
          "CSS": 1,
          "SQL": 2
        },
        "frameworks": [
          "React",
          "Laravel",
          "Docker"
        ],
        "packageManager": "npm",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "src/data/assets/gateways/index.html",
          "src/data/assets/index.html",
          "src/data/index.html",
          "src/data/log/index.html",
          "src/data/uploads/index.html"
        ],
        "configFiles": [
          ".ddev/docker-compose.phpmyadmin.yaml",
          ".ddev/docker-compose.phpmyadmin_norouter.yaml",
          "Dockerfile",
          "frontend-build-utils/package.json",
          "package.json"
        ],
        "dependencies": [
          "composer.json",
          "frontend-build-utils/package.json",
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [
          ".github/workflows/live-tests.yml"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "src/library/Model/ProductLicense.php",
          "src/library/Model/ServiceLicense.php"
        ],
        "fileTypes": {
          ".md": 9,
          ".yaml": 4,
          ".conf": 1,
          ".sh": 1,
          ".json": 8,
          ".yml": 12,
          ".php": 120,
          ".lock": 1,
          ".txt": 2,
          ".mjs": 3,
          ".js": 3,
          ".neon": 2,
          ".xml": 1,
          ".dist": 1,
          ".png": 9,
          ".html": 5,
          ".jpg": 1,
          ".css": 1,
          ".twig": 3,
          ".sql": 2,
          ".mmdb": 2
        }
      }
    },
    {
      "id": 1134790867,
      "name": "pocketbase",
      "displayName": "pocketbase",
      "description": "Open Source realtime backend in 1 file",
      "summary": "The Problem\nBuilding a backend from scratch is a pain. You have to set up a database, manage authentication, and create an API—all while juggling frameworks and libraries. If you just want something lightweight and functional without the bloat, you’re in for a headache. Enter PocketBase, which tries to simplify this mess by bundling everything into a single executable file.\n\nWhat This Does\nPocketBase gives you an embedded SQLite database with real-time subscriptions, a built-in admin dashboard, and a REST-ish API, all packed into one easy-to-use Go application. The core functionality is found in the apis folder, with files like collection.go for handling data collections and health.go for health checks. You can serve it up with a simple command—./pocketbase serve—after downloading the prebuilt executable from the Releases page.\n\nWhat’s cool is that if you want to add custom functionality, you can use the main.go example provided in examples/base/main.go. Just set up your routes in the OnServe function, and you're off to the races. Need to register a new API endpoint? Just throw in a few lines, and you're done.\n\nReal-World Use\nLet’s say you’re building a small app that needs user authentication and file uploads. You can set up your backend in minutes. After installing Go, create a new project with the following main.go:\n\npackage main\n\nimport (\n    \"log\"\n    \"github.com/pocketbase/pocketbase\"\n    \"github.com/pocketbase/pocketbase/core\"\n)\n\nfunc main() {\n    app := pocketbase.New()\n    app.OnServe().BindFunc(func(se core.ServeEvent) error {\n        se.Router.GET(\"/hello\", func(re core.RequestEvent) error {\n            return re.String(200, \"Hello world!\")\n        })\n        return se.Next()\n    })\n    if err := app.Start(); err != nil {\n        log.Fatal(err)\n    }\n}\n\nRun go run main.go serve, and you’ve got a backend that responds to GET /hello.\n\nThe Bottom Line\nPocketBase is a solid choice for small to medium projects that need a backend without the heavy lifting. The convenience of having everything in one file is a huge plus, but if your app grows complex, you might hit some limitations. It's perfect for prototypes or simple applications, but don’t expect it to handle enterprise-level demands just yet.",
      "url": "https://github.com/yebeai/pocketbase",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "pocketbase/pocketbase",
        "url": "https://github.com/pocketbase/pocketbase",
        "stars": 56428
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".github": 2,
          "(root)": 9,
          "apis": 73,
          "cmd": 3,
          "core": 113
        },
        "languages": {
          "Markdown": 7,
          "YAML": 2,
          "Go": 189
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "cmd/serve.go",
          "cmd/superuser.go",
          "cmd/superuser_test.go"
        ],
        "configFiles": [
          "Makefile"
        ],
        "dependencies": [],
        "testFiles": [
          "apis/backup_test.go",
          "apis/base_test.go",
          "apis/batch_test.go",
          "apis/collection_import_test.go",
          "apis/collection_test.go",
          "apis/cron_test.go",
          "apis/file_test.go",
          "apis/health_test.go",
          "apis/logs_test.go",
          "apis/middlewares_body_limit_test.go",
          "apis/middlewares_rate_limit_test.go",
          "apis/middlewares_test.go",
          "apis/realtime_test.go",
          "apis/record_auth_email_change_confirm_test.go",
          "apis/record_auth_email_change_request_test.go",
          "apis/record_auth_impersonate_test.go",
          "apis/record_auth_methods_test.go",
          "apis/record_auth_otp_request_test.go",
          "apis/record_auth_password_reset_confirm_test.go",
          "apis/record_auth_password_reset_request_test.go",
          "apis/record_auth_refresh_test.go",
          "apis/record_auth_verification_confirm_test.go",
          "apis/record_auth_verification_request_test.go",
          "apis/record_auth_with_oauth2_redirect_test.go",
          "apis/record_auth_with_oauth2_test.go",
          "apis/record_auth_with_otp_test.go",
          "apis/record_auth_with_password_test.go",
          "apis/record_crud_auth_origin_test.go",
          "apis/record_crud_external_auth_test.go",
          "apis/record_crud_mfa_test.go",
          "apis/record_crud_otp_test.go",
          "apis/record_crud_superuser_test.go",
          "apis/record_crud_test.go",
          "apis/record_helpers_test.go",
          "apis/settings_test.go",
          "cmd/superuser_test.go",
          "core/auth_origin_model_test.go",
          "core/auth_origin_query_test.go",
          "core/base_backup_test.go",
          "core/base_test.go",
          "core/collection_import_test.go",
          "core/collection_model_auth_options_test.go",
          "core/collection_model_test.go",
          "core/collection_model_view_options_test.go",
          "core/collection_query_test.go",
          "core/collection_record_table_sync_test.go",
          "core/collection_validate_test.go",
          "core/db_model_test.go",
          "core/db_retry_test.go",
          "core/db_table_test.go",
          "core/db_test.go",
          "core/db_tx_test.go",
          "core/event_request_batch_test.go",
          "core/event_request_test.go",
          "core/external_auth_model_test.go",
          "core/external_auth_query_test.go",
          "core/field_autodate_test.go",
          "core/field_bool_test.go",
          "core/field_date_test.go",
          "core/field_editor_test.go",
          "core/field_email_test.go",
          "core/field_file_test.go",
          "core/field_geo_point_test.go",
          "core/field_json_test.go",
          "core/field_number_test.go",
          "core/field_password_test.go",
          "core/field_relation_test.go",
          "core/field_select_test.go",
          "core/field_test.go",
          "core/field_text_test.go",
          "core/field_url_test.go",
          "core/fields_list_test.go",
          "core/log_printer_test.go",
          "core/log_query_test.go",
          "core/mfa_model_test.go",
          "core/mfa_query_test.go",
          "core/migrations_list_test.go",
          "core/migrations_runner_test.go",
          "core/otp_model_test.go",
          "core/otp_query_test.go",
          "core/record_field_resolver_test.go",
          "core/record_model_auth_test.go",
          "core/record_model_superusers_test.go",
          "core/record_model_test.go",
          "core/record_proxy_test.go",
          "core/record_query_expand_test.go",
          "core/record_query_test.go"
        ],
        "docs": [
          "CHANGELOG.md",
          "CHANGELOG_16_22.md",
          "CHANGELOG_8_15.md",
          "CONTRIBUTING.md",
          "LICENSE.md",
          "README.md"
        ],
        "fileTypes": {
          ".md": 7,
          ".yaml": 2,
          ".go": 189
        }
      }
    },
    {
      "id": 1134789760,
      "name": "QloApps",
      "displayName": "QloApps",
      "description": "QloApps is a Free and Open-source hotel management and reservation system to take a hotel business online. QloApps offers a Property Management System (PMS), a Booking Engine, and an attractive Hotel Website. Elevate hotel operations with QloApps to streamline processes and provide an enhanced experience for both hoteliers and guests.",
      "summary": "The Problem\n\nRunning a hotel isn’t just about fresh towels and grumpy guests—it's a nightmare of room inventory, bookings, payments, and a website that somehow never works right. Most hotel software is either expensive, locked down, or looks like it was built in 2002. QloApps tries to fix that by giving you an open-source system that actually covers the basics: property management, booking engine, and a usable website.\n\nWhat This Does\n\nQloApps is a PHP-based hotel management system. The guts are in folders like Adapter/ (factories, cache, database, etc.) and Core/Business/ (CMS, payment, stock managers—yes, hotels track \"stock\" too). Want to add a new payment option? Dive into Core/Business/Payment/CoreBusinessPaymentPaymentOption.php. Need to mess with room rates? Check out Adapter/AdapterProductPriceCalculator.php. The Core/Foundation/Database/ folder handles all the database glue, so you aren’t stuck rewriting CRUD for every new feature.\n\nYou get a basic website, booking engine, and PMS. The code is split so you can swap out adapters or core logic without nuking the whole thing. It’s not exactly Laravel, but it’s modular enough for most customizations.\n\nReal-World Use\n\nSay you run \"Bob's Boutique Hotel.\" Install QloApps (follow the README, or just use Docker if you hate manually setting up PHP). You log in, add your rooms, tweak pricing in the admin, and bookings show up in your dashboard. Want to add a custom notification when a VIP checks in? Extend Adapter/AdapterHookManager.php. Need to support a weird local payment gateway? Hack away in CoreBusinessPaymentPaymentOption.php. The workflow is: guests book on your slick site, data lands in MySQL, and you handle everything from inventory to payments in one place.\n\nThe Bottom Line\n\nQloApps is decent for small to mid-size hotels who want ownership and flexibility. It’s not pretty, and you’ll probably spend time reading PHP code, but at least you’re not locked into SaaS junk. If you want something plug-and-play, look elsewhere. If you want control and aren’t scared of code, give it a shot.",
      "url": "https://github.com/yebeai/QloApps",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Qloapps/QloApps",
        "url": "https://github.com/Qloapps/QloApps",
        "stars": 12473
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 7,
          "Adapter": 12,
          "Core": 19,
          "admin": 162
        },
        "languages": {
          "YAML": 1,
          "PHP": 51,
          "Markdown": 4,
          "CSS": 8,
          "LESS": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "Travis CI",
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "CHANGELOG.txt",
          "CONTRIBUTING.md",
          "LICENSE.md",
          "README.md",
          "admin/filemanager/LICENSE"
        ],
        "fileTypes": {
          ".yml": 1,
          ".php": 51,
          ".txt": 1,
          ".md": 4,
          ".css": 8,
          ".less": 1,
          ".png": 14,
          ".jpg": 113,
          ".ico": 2
        }
      }
    },
    {
      "id": 1134788719,
      "name": "Events",
      "displayName": "Events",
      "description": "Open-source event management and ticket selling platform — perfect for concerts, conferences, and everything in between 🎟️  If you find this project helpful, please consider giving us a star ⭐️ ",
      "summary": "The Problem\nEvent organizers are drowning in platforms that bleed them dry with per-ticket fees and lock them into their ecosystems. If you want control over your branding, data, and checkout experience, good luck finding something that doesn’t come with hidden fees or a convoluted setup.\n\nWhat This Does\nEnter Hi.Events, an open-source alternative to overpriced ticketing services like Eventbrite and Tickettailor. With this repo, you can manage ticket sales for anything from concerts to conferences without losing control of your data. Check out the Dockerfile.all-in-one if you want to get this up and running without dealing with the usual dependency hell.\n\nThe FEATURES.md file breaks down what you can expect. You get everything from tiered ticket types and promo codes to a customizable checkout experience. Want to see how many tickets are left? The real-time sales dashboard does that too. For the hands-on folks, the INSTALLWITHOUTDOCKER.md guides you through the installation process if Docker isn't your thing.\n\nReal-World Use\nImagine you're hosting a music festival. You want to offer early bird tickets and tiered pricing. With Hi.Events, you can set up promo codes and manage all ticket types effortlessly. Use the attendee management tools to check in guests with QR codes and keep track of sales data in real time. If you need to send out bulk messages to ticket holders, the built-in messaging feature has you covered.\n\nHere's a simple workflow to get started:\nClone the repo: git clone https://github.com/YourUsername/Events.git\nNavigate to your project directory and run the Docker container: docker-compose up -d\nCustomize your event through the beautifully designed dashboard.\n\nThe Bottom Line\nHi.Events is a solid option if you’re looking for a customizable ticketing solution without the corporate nonsense. The features are geared toward serious organizers, making it overkill for small events or casual meetups. However, if you need robust functionality without the fees, this is worth a look. Just don’t expect it to magically solve all your problems—setup will take some effort.",
      "url": "https://github.com/yebeai/Events",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "HiEventsDev/Hi.Events",
        "url": "https://github.com/HiEventsDev/Hi.Events",
        "stars": 3558
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".do": 1,
          "(root)": 22,
          ".github": 9,
          "backend": 168
        },
        "languages": {
          "YAML": 7,
          "Markdown": 22,
          "PHP": 160
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          "Dockerfile.all-in-one",
          "backend/.env.example",
          "backend/Dockerfile",
          "backend/Dockerfile.dev"
        ],
        "dependencies": [],
        "testFiles": [
          ".github/workflows/unit-tests.yml"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "README.de.md",
          "README.es.md",
          "README.fr.md",
          "README.hu.md",
          "README.it.md",
          "README.ja.md",
          "README.md",
          "README.nl.md",
          "README.pt.md",
          "README.tr.md",
          "README.vi.md",
          "README.zh-cn.md",
          "README.zh-hk.md",
          "backend/README.md"
        ],
        "fileTypes": {
          ".yaml": 1,
          ".yml": 6,
          ".md": 22,
          ".all-in-one": 1,
          ".example": 1,
          ".dev": 1,
          ".php": 160
        }
      }
    },
    {
      "id": 1134787997,
      "name": "crm",
      "displayName": "crm",
      "description": "Fully featured, open source CRM",
      "summary": "The Problem\n\nSales teams waste time wrangling clunky CRMs that feel like they were designed by accountants instead of actual users. Most open-source options are either bloated, confusing, or force you into \"enterprise\" nonsense before you can add your second teammate. You want something that actually helps you track leads, deals, and calls—without needing a full-time admin.\n\nWhat This Does\n\ncrm gives you a no-nonsense, open-source CRM built on the Frappe framework. You get the basics: leads, deals, Kanban boards, custom views, and call/email integration. The UI screenshots in .github/screenshots/ actually look usable (for once), and the repo's config lives in files like .devcontainer/devcontainer.json and .devcontainer/docker-compose.yml—so yes, you can run it locally without sacrificing a weekend. Automation and CI are set up with .github/workflows/ci.yml and .github/workflows/builds.yml, so you can deploy or test without yak-shaving.\n\nIntegrations? Twilio and Exotel are baked in. Look for helper scripts in .github/helper/ like install.sh and updatepotfile.sh if you want to hack on translations or setup. No mystery meat—everything is where you'd expect it.\n\nReal-World Use\n\nLet's say you run a scrappy SaaS and need to track inbound leads. Fire up the dev environment with docker-compose up (from .devcontainer/docker-compose.yml). Add leads, use the drag-and-drop Kanban to move them through stages, and log calls directly from the UI—Twilio handles dialing, and you see call logs update in real time (CallLog.png isn’t just marketing fluff).\n\nWant to tweak what columns show up on your lead list? Edit your custom view from the UI, no code needed. If you’re feeling brave, automate some workflow or set up CI for your fork using the provided GitHub Actions in .github/workflows/.\n\nThe Bottom Line\n\nFrappe CRM is actually usable, doesn’t nickel-and-dime you for basic features, and lets you self-host with minimal pain. The code’s clean, the structure makes sense, and you can extend it if you’re not allergic to Python. If you want Salesforce-level complexity, look elsewhere. If you just want to get sales done without the usual CRM headaches, try it.",
      "url": "https://github.com/yebeai/crm",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "frappe/crm",
        "url": "https://github.com/frappe/crm",
        "stars": 2380
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".devcontainer": 2,
          ".github": 20,
          "(root)": 6,
          ".vscode": 2,
          "crm": 170
        },
        "languages": {
          "JSON": 36,
          "YAML": 8,
          "Markdown": 3,
          "Shell": 2,
          "Python": 113,
          "JavaScript": 24
        },
        "frameworks": [
          "Django",
          "Flask",
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          ".devcontainer/docker-compose.yml"
        ],
        "dependencies": [],
        "testFiles": [
          "crm/fcrm/doctype/crm_call_log/test_crm_call_log.py",
          "crm/fcrm/doctype/crm_communication_status/test_crm_communication_status.py",
          "crm/fcrm/doctype/crm_dashboard/test_crm_dashboard.py",
          "crm/fcrm/doctype/crm_deal/test_crm_deal.py",
          "crm/fcrm/doctype/crm_deal_status/test_crm_deal_status.py",
          "crm/fcrm/doctype/crm_exotel_settings/test_crm_exotel_settings.py",
          "crm/fcrm/doctype/crm_fields_layout/test_crm_fields_layout.py",
          "crm/fcrm/doctype/crm_form_script/test_crm_form_script.py",
          "crm/fcrm/doctype/crm_global_settings/test_crm_global_settings.py",
          "crm/fcrm/doctype/crm_holiday_list/test_crm_holiday_list.py",
          "crm/fcrm/doctype/crm_industry/test_crm_industry.py",
          "crm/fcrm/doctype/crm_invitation/test_crm_invitation.py",
          "crm/fcrm/doctype/crm_lead/test_crm_lead.py",
          "crm/fcrm/doctype/crm_lead_source/test_crm_lead_source.py",
          "crm/fcrm/doctype/crm_lead_status/test_crm_lead_status.py",
          "crm/fcrm/doctype/crm_lost_reason/test_crm_lost_reason.py",
          "crm/fcrm/doctype/crm_notification/test_crm_notification.py",
          "crm/fcrm/doctype/crm_organization/test_crm_organization.py",
          "crm/fcrm/doctype/crm_product/test_crm_product.py",
          "crm/fcrm/doctype/crm_service_level_agreement/test_crm_service_level_agreement.py",
          "crm/fcrm/doctype/crm_service_level_priority/test_crm_service_level_priority.py",
          "crm/fcrm/doctype/crm_task/test_crm_task.py",
          "crm/fcrm/doctype/crm_telephony_agent/test_crm_telephony_agent.py",
          "crm/fcrm/doctype/crm_territory/test_crm_territory.py"
        ],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".json": 36,
          ".yml": 8,
          ".md": 3,
          ".png": 9,
          ".sh": 2,
          ".svg": 1,
          ".py": 113,
          ".js": 24
        }
      }
    },
    {
      "id": 1134786455,
      "name": "Awesome-AI-Agents-for-Healthcare",
      "displayName": "Awesome AI Agents for Healthcare",
      "description": "Latest Advances on Agentic AI & AI Agents for Healthcare",
      "summary": "The Problem\nHealthcare is drowning in data, and extracting actionable insights can feel like finding a needle in a haystack. Clinicians need tools that can sift through mountains of research and patient data, but traditional systems fall short. The gap between data availability and practical application is a pain point that nobody seems to address effectively.\n\nWhat This Does\nEnter the Awesome-AI-Agents-for-Healthcare repository, which is a curated collection of research papers, projects, and resources focused on AI agents tailored for healthcare. The README.md provides a solid overview of what’s included, from medical image analysis to patient dialogue systems. It’s not just a bunch of links; the repository is structured to help you navigate through topics like Doctor-facing Agents and Genomics & Biomarker Agents.\n\nYou’ll find visual aids like landscape.png, which lays out the entire conceptual framework, showing how these AI agents can integrate within the healthcare ecosystem. The statistics.png offers a snapshot of recent trends in the field, highlighting where the action is—spoiler: it’s in textual data and multi-agent systems.\n\nReal-World Use\nImagine you’re a clinician looking for the latest developments in AI-assisted radiology. You could dive into the Latest Papers section, filter for Radiology Agents, and quickly access papers that cover the latest algorithms and tools. You could even fork the repo and customize it to your specific needs if you want to build on the existing framework. \n\nFor a quick code snippet, if you were to analyze a new dataset, you could implement an agent that uses existing frameworks listed in the repo to automate the extraction of insights based on the latest research.\n\nThe Bottom Line\nThis repo is a solid resource for anyone in healthcare looking to integrate AI solutions. It’s got potential, but it’s still in its infancy with zero stars—meaning it’s not exactly blowing up yet. If you’re in research or a developer looking to dive into healthcare AI, keep an eye on it. Otherwise, it might be overkill for smaller projects.",
      "url": "https://github.com/yebeai/Awesome-AI-Agents-for-Healthcare",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "AgenticHealthAI/Awesome-AI-Agents-for-Healthcare",
        "url": "https://github.com/AgenticHealthAI/Awesome-AI-Agents-for-Healthcare",
        "stars": 661
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 3,
        "directories": {
          "(root)": 3
        },
        "languages": {
          "Markdown": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".md": 1,
          ".png": 2
        }
      }
    },
    {
      "id": 1134786081,
      "name": "tauri-plugin-aptabase",
      "displayName": "tauri plugin aptabase",
      "description": "Tauri Plugin for Aptabase: Open Source, Privacy-First and Simple Analytics for Mobile, Desktop and Web Apps",
      "summary": "The Problem\n\nTracking usage and events in desktop apps sucks. Google Analytics isn’t built for native code, and most solutions are either privacy nightmares or a pain to integrate. You want something simple that won’t creep out your users or force you to wire 18 different APIs together.\n\nWhat This Does\n\ntauri-plugin-aptabase bolts Aptabase analytics onto your Tauri app with minimal friction. Drop the dependency into your src-tauri/Cargo.toml, slap your app key into main.rs, and you’re ready to start tracking events. There’s zero magic: you call trackevent manually, so nothing gets sent unless you say so. Want JS bindings? Stick @aptabase/tauri into your package.json and fire events straight from your frontend.\n\nThe example in examples/helloworld/ shows the whole workflow: Rust setup in src-tauri/src/main.rs, events on startup and exit, guest-side JS calls, and a bunch of config files you’ll probably ignore unless you love staring at icons. You can even shove your app key in a .env file using dotenvymacro, so you don’t have secrets floating around in source.\n\nReal-World Use\n\nLet’s say you’re building a cross-platform desktop note app. In src-tauri/src/main.rs, you wire up:\n\ntauri::Builder::default()\n  .plugin(tauripluginaptabase::Builder::new(dotenv!(\"APTABASEKEY\")).build())\n  .run(tauri::generatecontext!())\n  .expect(\"error while running tauri application\");\n\nThen, every time a user creates a note, you call:\n\nimport { trackEvent } from \"@aptabase/tauri\";\ntrackEvent(\"note_created\", { length: note.length });\n\nThat’s it. No waiting for promises, no weird background thread hacks. You get privacy-first analytics in Aptabase, and your users don’t get secretly fingerprinted.\n\nThe Bottom Line\n\ntauri-plugin-aptabase is what app analytics should be: obvious, minimal, and not creepy. You control every event, setup isn’t a slog, and it plays nice with Rust and JS. If you want to slap some basic analytics into a Tauri app without selling your soul to Google, use it. If you’re building another CRUD admin panel, skip it—your boss won’t care.",
      "url": "https://github.com/yebeai/tauri-plugin-aptabase",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "aptabase/tauri-plugin-aptabase",
        "url": "https://github.com/aptabase/tauri-plugin-aptabase",
        "stars": 153
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 52,
        "directories": {
          "(root)": 8,
          "examples": 30,
          "permissions": 3,
          "src": 6,
          "webview-dist": 2,
          "webview-src": 3
        },
        "languages": {
          "Markdown": 3,
          "TOML": 4,
          "Rust": 10,
          "HTML": 1,
          "JSON": 11,
          "Svelte": 2,
          "JavaScript": 4,
          "CSS": 1,
          "TypeScript": 3
        },
        "frameworks": [
          "React",
          "Svelte"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "examples/helloworld/index.html",
          "examples/helloworld/src-tauri/src/lib.rs",
          "examples/helloworld/src-tauri/src/main.rs",
          "examples/helloworld/src/main.js",
          "src/lib.rs",
          "webview-dist/index.js",
          "webview-src/index.ts"
        ],
        "configFiles": [
          "Cargo.toml",
          "examples/helloworld/package.json",
          "examples/helloworld/src-tauri/Cargo.toml",
          "examples/helloworld/vite.config.js",
          "package.json",
          "webview-src/tsconfig.json"
        ],
        "dependencies": [
          "Cargo.toml",
          "examples/helloworld/package.json",
          "examples/helloworld/src-tauri/Cargo.toml",
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "CHANGELOG.md",
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".md": 3,
          ".toml": 4,
          ".rs": 10,
          ".html": 1,
          ".json": 11,
          ".svg": 3,
          ".png": 4,
          ".icns": 1,
          ".ico": 1,
          ".svelte": 2,
          ".js": 4,
          ".css": 1,
          ".ts": 3
        }
      }
    },
    {
      "id": 1134785756,
      "name": "modal-metabase",
      "displayName": "modal metabase",
      "description": "Run metabase on modal!",
      "summary": "The Problem\nIf you're neck-deep in machine learning and data engineering but still relying on spreadsheets or basic dashboards, you're missing out. You need a tool that can visualize your data effectively. Enter Metabase—a straightforward way to get insights without drowning in complexity. This repo lets you deploy Metabase on Modal, making it easier to connect your data sources and visualize results.\n\nWhat This Does\nThe modal-metabase repo simplifies the deployment of Metabase by providing a quick setup on Modal's infrastructure. You start with cloning the repo using git clone https://github.com/anthonycorletti/modal-metabase.git and then run bin/install to grab dependencies. The bin/deploy-modal script spins up your Metabase instance, letting you focus on analytics rather than server management.\n\nOnce deployed, you can access your Metabase app at https://YOURMODALPROFILE--modal-metabase-metabase.modal.run. The README warns that this setup isn’t meant for production workloads. You’ll need a separate database like PostgreSQL and to set the appropriate environment variables. Check out the README.md for those details.\n\nReal-World Use\nImagine you have a dataset from your latest machine learning project, and you want to visualize the results to present to stakeholders. After deploying Metabase, you can connect it to your PostgreSQL database and start creating dashboards in minutes. Use Metabase's intuitive UI to create queries without writing SQL—handy if you’re more of a data scientist than a database admin.\n\nHere’s a quick snippet for setting up your database connection in Metabase:\n\nIn Metabase, specify your PostgreSQL settings\nDATABASE_URL=postgres://user:password@your-db-host:5432/your-db\n\nThe Bottom Line\nThis repo is a neat solution for getting Metabase up and running quickly for testing and demos. It’s not production-ready, so don’t even think about using it for heavy workloads. If you need a proof of concept or a sandbox for your data visualization, this is worth a look. But for serious applications, prepare to do some heavy lifting elsewhere.",
      "url": "https://github.com/yebeai/modal-metabase",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "anthonycorletti/modal-metabase",
        "url": "https://github.com/anthonycorletti/modal-metabase",
        "stars": 4
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 11,
        "directories": {
          "(root)": 6,
          "app": 2,
          "assets": 1,
          "bin": 2
        },
        "languages": {
          "Markdown": 1,
          "Python": 2,
          "TOML": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "app/main.py"
        ],
        "configFiles": [
          "pyproject.toml"
        ],
        "dependencies": [
          "pyproject.toml"
        ],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".md": 1,
          ".py": 2,
          ".png": 1,
          ".toml": 1,
          ".lock": 1
        }
      }
    },
    {
      "id": 1134785523,
      "name": "daniels-home-office-portfolio",
      "displayName": "daniels home office portfolio",
      "description": "Life is too boring to have one personality, so let's have two",
      "summary": "The Problem\n\nMost portfolios are bland. You know the type: static grids, generic templates, and zero personality. If you want your site to actually show your creative chops (not just list them), you need something that looks and feels custom—ideally with some 3D, movement, and visual flair, without spending two months fighting WebGL or asset pipelines.\n\nWhat This Does\n\ndaniels-home-office-portfolio is a full-on interactive portfolio that mixes Blender assets and Three.js magic. The project lives in index.html and references a pile of assets in public/, like custom fonts (public/fonts/PlusJakartaSans-*) and a basis transcoder for compressed textures (public/basis/basis_transcoder.js). You’ll notice there’s a README.md with links to Blender files, YouTube tutorials, and asset credits—so you’re not guessing how it was built.\n\nThe codebase also handles some annoyances for you: splitting overlay effects in React (see the README update), integrating video textures with Drei’s useVideoTexture, and managing those WebAssembly transcoder bits so your 3D stuff loads fast. It’s not just a pretty face; it’s wired for performance and polish.\n\nReal-World Use\n\nSay you’ve made a scene in Blender and want it running in a browser. Grab the Blender files from the linked Drive, bake your textures (using tools like UVPACKMASTER3 or SimpleBake), export to the format you need, then drop assets in public/. Reference them in your Three.js code. Want custom fonts? Toss them in public/fonts/ and wire up your CSS. If you’re wrangling compressed textures, the basis transcoder setup means you don’t have to go hunting for weird loaders or hack together WASM nonsense.\n\nA typical snippet (not here, but you’d use it) in your React component:\n\nimport { useVideoTexture } from '@react-three/drei';\nconst texture = useVideoTexture(myVideoElement);\n\nNo fuss, no drama.\n\nThe Bottom Line\n\nIf you want a portfolio that actually stands out and you’re comfortable with React, Three.js, and Blender, this repo is gold. The structure’s solid, asset management is handled, and you get actual practical links—not just empty placeholders. Not for beginners or folks who want a “click and deploy” template, but if you want to flex your creative muscles, start here.",
      "url": "https://github.com/yebeai/daniels-home-office-portfolio",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "andrewwoan/daniels-home-office-portfolio",
        "url": "https://github.com/andrewwoan/daniels-home-office-portfolio",
        "stars": 62
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1531482615713-2afd69097998?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 119,
        "directories": {
          "(root)": 9,
          "public": 56,
          "src": 54
        },
        "languages": {
          "Markdown": 3,
          "JavaScript": 8,
          "HTML": 1,
          "JSON": 3,
          "JSX": 32,
          "SCSS": 18
        },
        "frameworks": [
          "React",
          "Express"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "index.html",
          "src/App.jsx"
        ],
        "configFiles": [
          "package.json",
          "vite.config.js"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE.md",
          "README.md",
          "public/basis/README.md"
        ],
        "fileTypes": {
          ".md": 3,
          ".js": 8,
          ".html": 1,
          ".json": 3,
          ".wasm": 1,
          ".woff": 14,
          ".woff2": 14,
          ".webp": 5,
          ".png": 4,
          ".ico": 1,
          ".svg": 1,
          ".webmanifest": 1,
          ".glb": 10,
          ".jsx": 32,
          ".mp4": 2,
          ".scss": 18
        }
      }
    },
    {
      "id": 1134785230,
      "name": "AionUi",
      "displayName": "AionUi",
      "description": "Free, local, open-source Cowork for Gemini CLI, Claude Code, Codex, Qwen Code, Goose Cli, Auggie, and more | 🌟 Star if you like it!",
      "summary": "The Problem\nIf you've ever juggled multiple command-line AI tools, you've probably faced the chaos of context-switching and disorganization. Trying to keep track of separate sessions, file outputs, and the constant back-and-forth with the terminal can feel like herding cats. Who has time for that? \n\nWhat This Does\nEnter AionUi, a local open-source solution that gives your command-line AI tools a much-needed graphical interface. It supports popular tools like Gemini CLI, Claude Code, and Codex, automatically detecting them and providing a unified workspace. The magic happens in the src directory, where the app’s core logic lives, integrating these tools into a single dashboard.\n\nYou’ll find file management features in specify/templates, where templates help auto-classify and organize your work. Need to rename a batch of files? AionUi’s got you covered with its one-click renaming feature—no more manual renaming hell.\n\nReal-World Use\nImagine you have outputs from Goose CLI and Codex, and you want to compile them into a report. With AionUi, you can easily view these results in the preview panel without flipping through multiple applications. The .github/workflows scripts can automate your CI/CD process, so every time you push changes, the app stays updated with the latest features and bug fixes. \n\nHere’s a simple workflow: after generating a report with Claude Code, you can instantly preview it in AionUi, tweak it in real-time, and export it—all without leaving the interface. This saves you from having to open multiple tabs and applications.\n\nThe Bottom Line\nAionUi is a solid tool for anyone heavily using command-line AI tools. It simplifies the interface and makes file management less of a headache. However, if you're just tinkering with one or two tools, this might feel like overkill. For developers and teams dealing with multiple AI outputs, it’s a step up from the command line, and it’s free. Plus, it’s open-source, so you can poke around the code if you feel adventurous.",
      "url": "https://github.com/yebeai/AionUi",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "iOfficeAI/AionUi",
        "url": "https://github.com/iOfficeAI/AionUi",
        "stars": 17250
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1542831371-29b0f74f9713?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 18,
          ".github": 12,
          ".husky": 2,
          ".specify": 5,
          ".vscode": 3,
          "assistant": 41,
          "config": 5,
          "docs": 2,
          "public": 1,
          "resources": 26,
          "scripts": 6,
          "skills": 79
        },
        "languages": {
          "JSON": 7,
          "Markdown": 42,
          "YAML": 11,
          "Python": 23,
          "JavaScript": 7,
          "TypeScript": 5,
          "HTML": 2,
          "CSS": 1
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "docs/index.html",
          "public/index.html"
        ],
        "configFiles": [
          ".eslintrc.json",
          ".prettierrc.json",
          "config/webpack/webpack.config.ts",
          "jest.config.js",
          "package.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [
          ".specify/memory/constitution.md",
          ".specify/templates/agent-file-template.md",
          ".specify/templates/plan-template.md",
          ".specify/templates/spec-template.md",
          ".specify/templates/tasks-template.md",
          "skills/pdf/scripts/check_bounding_boxes_test.py"
        ],
        "docs": [
          "LICENSE",
          "WEBUI_GUIDE.md",
          "assistant/ui-ux-pro-max/README.md",
          "assistant/ui-ux-pro-max/data/ux-guidelines.csv",
          "docs/index.html",
          "docs/style.css",
          "readme.md",
          "readme_ch.md",
          "readme_jp.md",
          "resources/aionui_readme_header_0807.png",
          "scripts/README.md",
          "skills/docx/LICENSE.txt",
          "skills/pdf/LICENSE.txt",
          "skills/pptx/LICENSE.txt"
        ],
        "fileTypes": {
          ".json": 7,
          ".md": 42,
          ".yml": 11,
          ".csv": 19,
          ".py": 23,
          ".js": 7,
          ".ts": 5,
          ".html": 2,
          ".css": 1,
          ".plist": 1,
          ".gif": 10,
          ".png": 13,
          ".svg": 1,
          ".icns": 1,
          ".ico": 1,
          ".txt": 3,
          ".xsd": 41,
          ".xml": 5
        }
      }
    },
    {
      "id": 1134784733,
      "name": "opencode",
      "displayName": "opencode",
      "description": "The open source coding agent.",
      "summary": "The Problem\n\nEveryone wants AI to write their code, but most tools either lock you into some proprietary platform or make you jump through hoops to get anything working locally. OpenCode cuts the fluff and actually gives you an agent you can run on your own machine—no vendor lock-in, no hidden fees, and no “please wait while we train your model” nonsense.\n\nWhat This Does\n\nOpenCode is an open source coding agent you can install with one command (curl -fsSL https://opencode.ai/install | bash) or via your favorite package manager. The repo is loaded with automation: check .github/workflows/ for CI/CD, auto-publishing, stale issue cleanup, and type checks. Want desktop? Grab the installer from the releases, or install via Homebrew (brew install --cask opencode-desktop). The install script respects your environment, letting you pick where binaries go—see how it prioritizes $OPENCODEINSTALLDIR, $XDGBINDIR, and falls back to $HOME/bin or $HOME/.opencode/bin.\n\nTwo agents ship with OpenCode: build for hands-on code generation and editing, and plan for read-only analysis. Switch between them with Tab. There’s also a hidden general subagent for gnarlier tasks—summoning it is as easy as typing @general. All this is spelled out in the README and docs, so you’re not left guessing.\n\nReal-World Use\n\nSay you’re knee-deep in a legacy project and want to refactor a bunch of spaghetti without nuking anything. Fire up OpenCode, use the plan agent to poke around and get suggestions—it won’t touch files unless you say so. When you’re ready to make changes, switch to build, and let it generate code, edit files, or run shell commands. Example:  \n\nopencode plan\n\"How do I untangle these circular imports?\"\nAgent analyzes, gives you a safe plan, asks before running anything risky\n\nWant to install on a shared dev box? Set your install path like:\n\nOPENCODEINSTALLDIR=/usr/local/bin curl -fsSL https://opencode.ai/install | bash\n\nNo weird paths, no mystery configs.\n\nThe Bottom Line\n\nOpenCode is legit if you want an AI coding agent that actually respects your environment and doesn’t get in your way. The workflow files are overkill for tiny projects, but if you care about automation and platform support, it delivers. If you want cloud magic, look elsewhere. If you want a local, open source agent you can hack on, this is the one.",
      "url": "https://github.com/yebeai/opencode",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "anomalyco/opencode",
        "url": "https://github.com/anomalyco/opencode",
        "stars": 112393
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1607799279861-4dd421887fb3?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 18,
          ".github": 29,
          ".husky": 1,
          ".opencode": 16,
          ".vscode": 2,
          "github": 10,
          "infra": 5,
          "logs": 2,
          "nix": 10,
          "packages": 107
        },
        "languages": {
          "YAML": 28,
          "Markdown": 23,
          "TypeScript": 37,
          "JSON": 12,
          "TOML": 2,
          "Shell": 1,
          "HTML": 1,
          "JavaScript": 2,
          "TSX": 46,
          "CSS": 2
        },
        "frameworks": [
          "React"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "github/index.ts",
          "infra/app.ts",
          "packages/app/index.html",
          "packages/app/src/app.tsx",
          "packages/app/src/components/session/index.ts",
          "packages/app/src/index.ts",
          "packages/app/src/utils/index.ts",
          "packages/console/app/src/app.tsx"
        ],
        "configFiles": [
          "github/package.json",
          "github/tsconfig.json",
          "package.json",
          "packages/app/package.json",
          "packages/app/tsconfig.json",
          "packages/app/vite.config.ts",
          "packages/console/app/package.json"
        ],
        "dependencies": [
          "github/package.json",
          "package.json",
          "packages/app/package.json",
          "packages/console/app/package.json"
        ],
        "testFiles": [
          ".github/workflows/test.yml",
          ".opencode/skill/test-skill/SKILL.md",
          "packages/app/src/addons/serialize.test.ts",
          "packages/app/src/context/layout-scroll.test.ts"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "README.zh-CN.md",
          "README.zh-TW.md",
          "STYLE_GUIDE.md",
          "github/README.md",
          "packages/app/README.md",
          "packages/console/app/README.md"
        ],
        "fileTypes": {
          ".yml": 28,
          ".md": 23,
          ".ts": 37,
          ".jsonc": 1,
          ".json": 12,
          ".txt": 3,
          ".lock": 3,
          ".toml": 2,
          ".nix": 4,
          ".log": 1,
          ".sh": 1,
          ".html": 1,
          ".png": 13,
          ".ico": 2,
          ".svg": 2,
          ".js": 2,
          ".webmanifest": 2,
          ".tsx": 46,
          ".css": 2,
          ".zip": 1
        }
      }
    },
    {
      "id": 1134784407,
      "name": "expo-ecommerce",
      "displayName": "expo ecommerce",
      "description": "No description available",
      "summary": "The Problem\nBuilding a full-stack e-commerce application is a headache. You need a mobile app for customers, an admin dashboard to manage products and orders, and a backend API to tie everything together. Doing this from scratch can take ages, and let's be honest, most starter templates leave out critical parts, making you reinvent the wheel.\n\nWhat This Does\nEnter the expo-ecommerce repo. It’s a full-stack setup that includes a mobile app, an admin dashboard, and a backend API. The admin folder has everything you need for the dashboard, including components like Navbar.jsx and DashboardLayout.jsx for a solid structure. You get secure authentication with Clerk, Stripe for payments, and a REST API powered by Node.js and Express in the backend folder.\n\nConfiguration is straightforward, too, as seen in the .env setup. You specify your database URL, Clerk keys, and Stripe secrets right there. Just run npm install in the backend and admin directories, and you're off to the races. The vite.config.js in the admin folder ensures hot module reloading, so you can actually develop without wanting to throw your laptop out the window.\n\nReal-World Use\nImagine you’re launching a new online store. With this repo, you can have a mobile app up and running in no time. Just configure your .env files and run the backend with npm run dev. Then, head over to the admin directory, run npm run dev, and you’ve got a dashboard to manage your products, view customer orders, and analyze stats—all within minutes. Plus, you can integrate Sentry for monitoring errors and keeping an eye on performance.\n\nThe Bottom Line\nThis repo is a solid starting point for anyone looking to build a full-stack e-commerce app without starting from scratch. The architecture is sensible, and it saves you a ton of time by covering essential features out of the box. Just be aware that if you're building a tiny project, this setup might be overkill. Otherwise, if you want to dive into e-commerce development, this is a repository worth checking out.",
      "url": "https://github.com/yebeai/expo-ecommerce",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "burakorkmez/expo-ecommerce",
        "url": "https://github.com/burakorkmez/expo-ecommerce",
        "stars": 351
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 122,
        "directories": {
          "(root)": 3,
          "admin": 24,
          "backend": 29,
          "mobile": 66
        },
        "languages": {
          "Markdown": 3,
          "JavaScript": 36,
          "HTML": 1,
          "JSON": 11,
          "JSX": 11,
          "CSS": 2,
          "TSX": 23,
          "TypeScript": 12
        },
        "frameworks": [
          "React",
          "Express",
          "Tailwind"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "admin/index.html",
          "admin/src/App.jsx",
          "backend/src/seeds/index.js",
          "backend/src/server.js",
          "mobile/app/(auth)/index.tsx",
          "mobile/app/(tabs)/index.tsx",
          "mobile/types/index.ts"
        ],
        "configFiles": [
          "admin/package.json",
          "admin/vite.config.js",
          "backend/package.json",
          "mobile/package.json",
          "mobile/tailwind.config.js",
          "mobile/tsconfig.json",
          "package.json"
        ],
        "dependencies": [
          "admin/package-lock.json",
          "admin/package.json",
          "backend/package-lock.json",
          "backend/package.json",
          "mobile/package-lock.json",
          "mobile/package.json",
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "README.md",
          "admin/README.md",
          "admin/public/screenshot-for-readme.png",
          "mobile/README.md"
        ],
        "fileTypes": {
          ".md": 3,
          ".js": 36,
          ".html": 1,
          ".json": 11,
          ".png": 19,
          ".svg": 1,
          ".jsx": 11,
          ".css": 2,
          ".tsx": 23,
          ".ts": 12
        }
      }
    },
    {
      "id": 1134783968,
      "name": "LLMs-local",
      "displayName": "LLMs local",
      "description": " list of awesome platforms, tools, and resources   run for LLMs locally",
      "summary": "The Problem\n\nRunning LLMs locally is a nightmare if you're new: random repos, half-baked guides, hardware confusion, and every tool claims to be \"the future.\" You just want a straight list of what's actually useful, not another marketing pitch or dead-end GitHub link.\n\nWhat This Does\n\nLLMs-local is basically a curated cheat sheet jammed into a single README.md. It's not code, it's a directory: links to inference platforms (like LM Studio, jan), engines (ollama, llama.cpp), GUIs, model providers, and every random tool you didn't know existed. The file is broken down with actual categories—e.g., \"Inference platforms,\" \"Agent Frameworks,\" \"Retrieval-Augmented Generation\"—so you can skip the fluff and find what you need fast.\n\nYou want to run something like llama.cpp? Scroll down to \"Inference engines,\" click the link, and you're off. Need a GUI, or want benchmarks for your local setup? The README has those too. No annoying install scripts or weird folder structure; it's just one file, all links, all signal, no noise.\n\nReal-World Use\n\nSay you're hacking on a side project and want to run a local LLM for code generation. You hit the \"Inference platforms\" section, grab LM Studio or jan, and get a desktop app up in minutes. Or maybe you want raw speed—jump to \"Inference engines,\" pick vllm or llama.cpp, and start benchmarking. If you're feeling masochistic and want to build an agent, the \"Agent Frameworks\" section points you at the right repos. It's basically a menu for the LLM ecosystem, minus the sales pitches.\n\nThe Bottom Line\n\nLLMs-local is a solid shortcut if you hate digging through Google and Reddit for \"best local LLM tools.\" There's no magic sauce here—just links and categories. If you already know what you're doing, you'll find it handy. If you're lost, it'll save you hours. Would be nice to see actual config examples someday, but for now this is about as efficient as it gets.",
      "url": "https://github.com/yebeai/LLMs-local",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "0xSojalSec/LLMs-local",
        "url": "https://github.com/0xSojalSec/LLMs-local",
        "stars": 610
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 1,
        "directories": {
          "(root)": 1
        },
        "languages": {
          "Markdown": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".md": 1
        }
      }
    },
    {
      "id": 1134783708,
      "name": "faceswap",
      "displayName": "faceswap",
      "description": "Industry leading face manipulation platform",
      "summary": "The Problem\nFace manipulation tools are everywhere, but most are either too complex or lack flexibility. Developers need something that simplifies the process without sacrificing power. If you're tired of wrestling with convoluted APIs or endless configurations, welcome to facefusion.\n\nWhat This Does\nfacefusion is an industry-leading face manipulation platform that allows you to run various commands for face editing and processing. The main entry point is facefusion.py, where you can execute commands like run, benchmark, or even job-submit. Want to automate downloads? Just use force-download. \n\nThe file structure is straightforward. For example, facefusion/appcontext.py handles the application context, while facefusion/facedetector.py focuses on detecting faces in images. Each module is neatly organized, making it easy to jump in and modify or extend functionality. \n\nReal-World Use\nImagine you're working on a project that requires batch processing of images for a deepfake application. You could use the command line like this:\n\npython facefusion.py batch-run --input-dir /path/to/images --output-dir /path/to/output\n\nThis runs the program in batch mode, processing all images in the specified directory and saving the results where you want them. Combine this with the job-list command to manage ongoing tasks and you’ve got a pretty solid workflow.\n\nThe Bottom Line\nfacefusion packs a punch but isn't for the faint of heart. If you’re comfortable with the command line and need a face manipulation tool that doesn’t hold back, this is worth a look. Just be prepared to wrestle with some technical details along the way. If you don’t want to deal with the terminal, just stick to the installers. They’re not perfect, but they’ll save you some headaches.",
      "url": "https://github.com/yebeai/faceswap",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "allenk/facefusion",
        "url": "https://github.com/allenk/facefusion",
        "stars": 62
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 180,
        "directories": {
          "(root)": 11,
          ".github": 3,
          "facefusion": 126,
          "tests": 40
        },
        "languages": {
          "YAML": 2,
          "Markdown": 2,
          "Python": 167,
          "CSS": 1
        },
        "frameworks": [
          "Express"
        ],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          "requirements.txt"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [
          "tests/__init__.py",
          "tests/helper.py",
          "tests/test_audio.py",
          "tests/test_cli_age_modifier.py",
          "tests/test_cli_batch_runner.py",
          "tests/test_cli_expression_restorer.py",
          "tests/test_cli_face_debugger.py",
          "tests/test_cli_face_editor.py",
          "tests/test_cli_face_enhancer.py",
          "tests/test_cli_face_swapper.py",
          "tests/test_cli_frame_colorizer.py",
          "tests/test_cli_frame_enhancer.py",
          "tests/test_cli_job_manager.py",
          "tests/test_cli_job_runner.py",
          "tests/test_cli_lip_syncer.py",
          "tests/test_cli_output_scale.py",
          "tests/test_common_helper.py",
          "tests/test_config.py",
          "tests/test_curl_builder.py",
          "tests/test_download.py",
          "tests/test_execution.py",
          "tests/test_face_analyser.py",
          "tests/test_ffmpeg.py",
          "tests/test_ffmpeg_builder.py",
          "tests/test_filesystem.py",
          "tests/test_inference_manager.py",
          "tests/test_job_helper.py",
          "tests/test_job_list.py",
          "tests/test_job_manager.py",
          "tests/test_job_runner.py",
          "tests/test_json.py",
          "tests/test_memory.py",
          "tests/test_normalizer.py",
          "tests/test_process_manager.py",
          "tests/test_program_helper.py",
          "tests/test_state_manager.py",
          "tests/test_temp_helper.py",
          "tests/test_time_helper.py",
          "tests/test_vision.py",
          "tests/test_wording.py"
        ],
        "docs": [
          "LICENSE.md",
          "README.md"
        ],
        "fileTypes": {
          ".yml": 2,
          ".png": 1,
          ".md": 2,
          ".ico": 1,
          ".ini": 2,
          ".py": 167,
          ".css": 1,
          ".txt": 1
        }
      }
    },
    {
      "id": 1134783276,
      "name": "invoice-builder",
      "displayName": "invoice builder",
      "description": "Invoice and quotation builder desktop app with PDF export, designed for small businesses and freelancers. Create, manage, and export invoices and quotes easily using a local database in an Electron-based app.",
      "summary": "The Problem\n\nSick of SaaS invoicing platforms holding your data hostage, forcing logins, and nickel-and-diming you for features? If you just want something simple to generate invoices and quotes, control your data, and not worry about cloud outages or monthly fees, the options are slim. Most open-source tools either look like they were designed in 2005 or require a PhD in Docker to run.\n\nWhat This Does\n\ninvoice-builder is an Electron desktop app that lets you create, manage, and export invoices and quotes using a local database. Everything lives on your machine—no server, no cloud. The config is dead simple: pick a .env.* file for your environment, and your data is stored in a file you actually own. Want to tweak how invoices look? The index.html and PDF preview features let you preview and customize layouts before exporting.\n\nAll the boring stuff is covered: multi-currency, partial payments, business/client/item management. The app stores everything locally, so you can backup/restore using JSON or XLSX exports. The electron-builder.yml handles packaging for Windows, macOS, and Linux. You get live PDF previews, branding options, and translations baked right in. No hidden sync, no weird telemetry.\n\nReal-World Use\n\nSay you’re a freelancer. You open the app, create a new invoice for your client, add items, set tax/shipping/discounts, and pick the currency. Hit preview, tweak colors and logo size, export as PDF. Need a backup? Click export to JSON or XLSX and stash it somewhere safe. Here’s how simple it is:\n\n// Add a new client and invoice (pseudo-code)\ndb.clients.insert({ name: \"Acme Corp\", contact: \"alice@acme.com\" });\ndb.invoices.insert({\n  clientId: acmeId,\n  items: [{ name: \"Logo Design\", price: 500 }],\n  currency: \"USD\",\n  status: \"unpaid\"\n});\n\nNo server, no API keys, no nonsense. Just local files and a UI that doesn’t suck.\n\nThe Bottom Line\n\nIf you want a desktop invoicing tool that doesn’t require an account or a cloud subscription, invoice-builder is a solid pick. It’s not fancy, but it does what you need and keeps your data local. Great for freelancers and small shops. If you’re running a giant agency, maybe look elsewhere—but for solo work, this is refreshingly straightforward.",
      "url": "https://github.com/yebeai/invoice-builder",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "piratuks/invoice-builder",
        "url": "https://github.com/piratuks/invoice-builder",
        "stars": 223
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 24,
          ".github": 8,
          ".vscode": 1,
          "public": 1,
          "scripts": 2,
          "src": 164
        },
        "languages": {
          "Markdown": 15,
          "YAML": 3,
          "JSON": 6,
          "JavaScript": 3,
          "HTML": 1,
          "TypeScript": 56,
          "TSX": 39
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "index.html",
          "src/main/ipc/index.ts",
          "src/main/main.ts",
          "src/renderer/app/App.tsx",
          "src/renderer/i18n/index.ts",
          "src/renderer/mocks/server.ts",
          "src/renderer/pages/businesses/index.tsx",
          "src/renderer/pages/categories/index.tsx",
          "src/renderer/pages/clients/index.tsx",
          "src/renderer/pages/currencies/index.tsx"
        ],
        "configFiles": [
          ".prettierrc",
          "package.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [
          ".env.test.example",
          "setupTests.ts"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "LICENSE-DISCLAIMER.md",
          "README.md",
          "src/renderer/assets/roboto/README.txt"
        ],
        "fileTypes": {
          ".example": 3,
          ".md": 15,
          ".yml": 3,
          ".json": 6,
          ".js": 3,
          ".png": 10,
          ".html": 1,
          ".cjs": 1,
          ".ts": 56,
          ".icns": 1,
          ".tsx": 39,
          ".txt": 2,
          ".ttf": 56
        }
      }
    },
    {
      "id": 1134782394,
      "name": "iot-projects",
      "displayName": "iot projects",
      "description": "🤖 A curated list of awesome Internet of Things projects and resources.",
      "summary": "The Problem\nFinding reliable resources for IoT projects can feel like searching for a needle in a haystack. With a plethora of options out there, it’s easy to get lost in the noise. You need a curated list that actually points to useful tools and hardware without the fluff.\n\nWhat This Does\nThe iot-projects repository is your go-to compilation of Internet of Things resources. It’s forked from the popular awesome-iot, so you know there’s some pedigree behind it. The README.md file lays out a clear structure, categorizing resources into hardware, software, protocols, and more. You’ll find everything from Arduino to Raspberry Pi, all linked out to their respective sites. \n\nWant to contribute? Check out the CONTRIBUTING.md file for guidelines. It’s straightforward—just follow the format and keep it relevant. The .travis.yml file suggests that the repo might have CI in place, which is a nice touch. It’s like a safety net for maintaining the quality of the list as it grows.\n\nReal-World Use\nImagine you’re building a smart home device. You start in the Hardware section of the repo and find ESP32—it’s got Wi-Fi and Bluetooth, perfect for your needs. You click the link, read up on it, and you’re ready to go. Need a library? Jump to the Software section, grab a compatible library, and you’re halfway to making your device come alive. \n\nIf you want to add your own project, just fork the repo, update it, and submit a pull request. Easy as pie.\n\nThe Bottom Line\nThis repo is a solid, no-nonsense resource for anyone diving into IoT. It’s well-organized and gives you the essentials without drowning you in jargon. However, it’s still a bit barebones—zero stars means it’s likely not on many people’s radar yet. If you’re serious about IoT, contribute to it and help it grow. If you just need a quick reference, you might want to look elsewhere until it gains traction.",
      "url": "https://github.com/yebeai/iot-projects",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "HQarroum/awesome-iot",
        "url": "https://github.com/HQarroum/awesome-iot",
        "stars": 3858
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 5,
        "directories": {
          "(root)": 5
        },
        "languages": {
          "YAML": 1,
          "Markdown": 2
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "Travis CI",
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".yml": 1,
          ".md": 2,
          ".png": 1
        }
      }
    },
    {
      "id": 1134782014,
      "name": "codegraph-rust",
      "displayName": "codegraph rust",
      "description": "100% Rust implementation of code graphRAG with blazing fast AST+FastML parsing, surrealDB backend and advanced agentic code analysis tools through MCP for efficient code agent context management",
      "summary": "The Problem\n\nAI coding assistants are mostly fancy grep machines. They crawl through files one at a time, losing all context, burning tokens, and generally acting clueless about how your code actually fits together. If you've ever asked Copilot to explain a function, you know: it doesn't get architecture, just snippets.\n\nWhat This Does\n\ncodegraph-rust builds a real knowledge graph from your codebase—think AST parsing meets FastML, all wired up to SurrealDB for storage. The magic lives in files like Cargo.toml (dependencies), the Makefile (build automation), and the actual Rust code (not shown, but trust me—it's all Rust). It doesn't just make embeddings and call it a day. Instead, it maps out relationships: who calls what, where docs reference functions, and even cross-file module containment.\n\nIndexing is tiered. You pick between fast, balanced, and full modes. fast just grabs AST nodes and basic edges; balanced adds LSP, doc linking, and module relationships; full is everything—dataflow, architecture signals, you name it. If you're missing external tools (rust-analyzer for Rust, typescript-language-server for JS, etc.), it'll fail loudly and early. All that config happens via CLI flags (codegraph index --index-tier balanced), env vars, or config files.\n\nReal-World Use\n\nSay you’ve got a tangled Rust project and want to see everywhere a function is used, who calls it, and what modules it touches. After indexing (let’s say with codegraph index --index-tier full), you can query the graph—either via CLI or an agent—to get all relationships and documentation references. Here’s a typical flow:\n\ncodegraph index --index-tier balanced\n\nThen ask your AI assistant:\n\"Where does function foo get called, and what does it mutate?\"\n\nYou’ll get not just file matches, but a map of dependencies, callers, and even links to relevant docs in README.md or docs/.\n\nThe Bottom Line\n\ncodegraph-rust is serious overkill for tiny hobby projects, but if you’re wrangling a big Rust codebase and want your AI tools to actually understand context, this is worth a look. The setup is a bit involved (hello, LSP toolchain hell), but once indexed, you get way more than fuzzy search. If you’re tired of assistants acting dumb, this is the upgrade.",
      "url": "https://github.com/yebeai/codegraph-rust",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Jakedismo/codegraph-rust",
        "url": "https://github.com/Jakedismo/codegraph-rust",
        "stars": 149
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 12,
          ".github": 18,
          "config": 3,
          "crates": 167
        },
        "languages": {
          "Markdown": 11,
          "YAML": 15,
          "TOML": 14,
          "Rust": 151,
          "SQL": 1
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "cargo",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "crates/codegraph-ai/src/lib.rs",
          "crates/codegraph-concurrent/src/lib.rs",
          "crates/codegraph-core/src/lib.rs",
          "crates/codegraph-graph/src/lib.rs",
          "crates/codegraph-mcp-autoagents/src/lib.rs",
          "crates/codegraph-mcp-core/src/lib.rs",
          "crates/codegraph-mcp-daemon/src/lib.rs",
          "crates/codegraph-mcp-rig/src/lib.rs",
          "crates/codegraph-mcp-server/src/lib.rs",
          "crates/codegraph-mcp-tools/src/lib.rs"
        ],
        "configFiles": [
          ".env.example",
          "Cargo.toml",
          "Makefile",
          "crates/codegraph-ai/Cargo.toml",
          "crates/codegraph-concurrent/Cargo.toml",
          "crates/codegraph-core/Cargo.toml",
          "crates/codegraph-graph/Cargo.toml",
          "crates/codegraph-mcp-autoagents/Cargo.toml",
          "crates/codegraph-mcp-core/Cargo.toml",
          "crates/codegraph-mcp-daemon/Cargo.toml",
          "crates/codegraph-mcp-rig/Cargo.toml",
          "crates/codegraph-mcp-server/Cargo.toml",
          "crates/codegraph-mcp-tools/Cargo.toml",
          "crates/codegraph-mcp/Cargo.toml"
        ],
        "dependencies": [
          "Cargo.toml",
          "crates/codegraph-ai/Cargo.toml",
          "crates/codegraph-concurrent/Cargo.toml",
          "crates/codegraph-core/Cargo.toml",
          "crates/codegraph-graph/Cargo.toml",
          "crates/codegraph-mcp-autoagents/Cargo.toml",
          "crates/codegraph-mcp-core/Cargo.toml",
          "crates/codegraph-mcp-daemon/Cargo.toml",
          "crates/codegraph-mcp-rig/Cargo.toml",
          "crates/codegraph-mcp-server/Cargo.toml",
          "crates/codegraph-mcp-tools/Cargo.toml",
          "crates/codegraph-mcp/Cargo.toml"
        ],
        "testFiles": [
          "crates/codegraph-core/src/integration/memory_tests.rs",
          "crates/codegraph-core/tests/config_integration_test.rs",
          "crates/codegraph-graph/src/bin/surreal_smoke_test.rs",
          "crates/codegraph-graph/src/tests.rs",
          "crates/codegraph-graph/tests/schema_indexes_test.rs",
          "crates/codegraph-graph/tests/semantic_search_nodes_via_chunks_test.rs",
          "crates/codegraph-mcp-server/tests/http_server_integration.rs",
          "crates/codegraph-mcp-server/tests/semantic_question_prompts_test.rs"
        ],
        "docs": [
          "CHANGELOG.md",
          "CONTRIBUTING.md",
          "README.md",
          "config/README.md",
          "crates/codegraph-concurrent/README.md",
          "crates/codegraph-graph/README.md"
        ],
        "fileTypes": {
          ".security": 1,
          ".example": 2,
          ".md": 11,
          ".yml": 15,
          ".codegraph": 1,
          ".lock": 1,
          ".toml": 14,
          ".rs": 151,
          ".sql": 1
        }
      }
    },
    {
      "id": 1134781734,
      "name": "admin-dashboard",
      "displayName": "admin dashboard",
      "description": "Free and open-source admin dashboard template built with Tailwind CSS and Flowbite",
      "summary": "The Problem\nBuilding an admin dashboard from scratch can suck up a lot of time and resources, especially if you're just looking for a solid UI. You want to focus on your application logic, not reinventing the wheel with every table and chart.\n\nWhat This Does\nEnter the admin-dashboard repo, a free and open-source template built with Tailwind CSS and Flowbite. It packs a punch with 15 example pages, including CRUD layouts for products and users, authentication pages like sign-in.html, and even error pages (404.html, 500.html). The config.yml file manages your site's configuration, while the data/products.json and data/users.json files hold the dummy data you'll need to test your layouts.\n\nThe structure is pretty straightforward. You've got your layouts in layouts/_default, where you can tweak the dashboard.html to fit your needs. The sidebar and stacked layouts in content/layouts give you options for how to display content, and the playground folder is a neat little sandbox for experimenting with components.\n\nReal-World Use\nImagine you're building an e-commerce app. You want a dashboard to manage products and users without spending days on design. Clone the repo, modify data/products.json to add some items, and you can immediately see them in the product management page (content/crud/products.html). Want to add a new feature? Just drop in a new chart component from Flowbite, and you’re good to go.\n\nHere's a quick snippet to help you get started with the authentication flow:\n\n<!-- Sign In Form -->\n<form action=\"/login\" method=\"POST\">\n    <input type=\"text\" name=\"username\" placeholder=\"Username\" required>\n    <input type=\"password\" name=\"password\" placeholder=\"Password\" required>\n    <button type=\"submit\">Sign In</button>\n</form>\n\nThe Bottom Line\nThis template is a solid choice if you want to skip the UI headache and get straight to the fun stuff. It's well-built, but if you're working on a tiny app, this might be overkill. If you're in the market for a quick start with a good design foundation, give it a shot. Just be ready to dive into the Flowbite docs if you want to customize components.",
      "url": "https://github.com/yebeai/admin-dashboard",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "themesberg/flowbite-admin-dashboard",
        "url": "https://github.com/themesberg/flowbite-admin-dashboard",
        "stars": 2809
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 8,
          "content": 17,
          "data": 3,
          "layouts": 26,
          "src": 6,
          "static": 140
        },
        "languages": {
          "Markdown": 1,
          "YAML": 1,
          "HTML": 42,
          "JSON": 5,
          "JavaScript": 6,
          "CSS": 1
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "src/index.js"
        ],
        "configFiles": [
          "package.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".lock": 1,
          ".md": 1,
          ".yml": 1,
          ".html": 42,
          ".json": 5,
          ".xml": 2,
          ".js": 6,
          ".css": 1,
          ".png": 23,
          ".ico": 1,
          ".jpg": 10,
          ".svg": 104
        }
      }
    },
    {
      "id": 1134780546,
      "name": "meetai",
      "displayName": "meetai",
      "description": "Meet.AI is a powerful, full-stack AI platform designed to help users create, manage, and interact with custom AI agents in seconds. From secure authentication to AI-powered meeting assistants, Meet.AI blends advanced technologies into an intuitive, production-ready app.",
      "summary": "The Problem\n\nWrangling custom AI agents for meetings usually means duct-taping a bunch of APIs, fighting with flaky auth, and praying your database migrations don’t nuke production. Most “AI assistant” tools are either half-baked, or bloated with features you never asked for. If you want something fast, secure, and not ugly, good luck.\n\nWhat This Does\n\nmeetai gives you a full-stack playground for spinning up custom AI meeting agents. The src/app folder is where all the Next.js App Router magic happens—API endpoints, routes, and server logic. Authentication isn’t an afterthought: auth-schema.ts and better-auth.config.ts set up passwordless magic links, social logins, and 2FA (actual TOTP, not some SMS hack). Database schema and migrations live in drizzle/, and yes, it uses Drizzle ORM with PostgreSQL so you aren’t stuck writing raw SQL or dealing with Prisma’s “surprise migrations.”\n\nPayments and subscriptions? You get Polar integration out of the box. Background jobs (think: meeting processing, summaries) run via inngest/. AI is powered by OpenAI’s GPT-4o, and the chat/video is handled using Stream.io APIs. Styling isn’t an afterthought either—Tailwind CSS all the way.\n\nReal-World Use\n\nLet’s say you want to run a meeting and have an AI transcribe and summarize it, then chat with the agent about the results. Fire up the dev server with npm run dev. Create your agent via the UI (backed by /src/modules/agents). Join a call; the real-time assistant kicks in, transcribes via GPT-4o, and stores results using Drizzle. Want to add 2FA for your account? Tweak better-auth.config.ts, and the UI will show TOTP setup. Payments? It’s handled in /src/modules/payments with Polar, so you can slap on usage limits and premium tiers without hunting for Stripe docs.\n\nThe Bottom Line\n\nIf you’re sick of Frankensteining your own AI meeting bot, meetai does the heavy lifting. The stack is modern, but not excessively hipster—Next.js, Drizzle, tRPC, etc. It’s overkill for solo projects or tiny teams, but if you want production-ready features without reinventing the wheel, this is worth a weekend. Just don’t expect a plug-and-play Slack integration out of the box.",
      "url": "https://github.com/yebeai/meetai",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "AppajiDheeraj/meetai",
        "url": "https://github.com/AppajiDheeraj/meetai",
        "stars": 24
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 11,
          "drizzle": 7,
          "public": 25,
          "src": 157
        },
        "languages": {
          "Markdown": 1,
          "TypeScript": 41,
          "JSON": 7,
          "SQL": 3,
          "TSX": 118,
          "CSS": 1
        },
        "frameworks": [
          "React",
          "Next.js"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "src/db/index.ts",
          "src/lib/email/index.ts"
        ],
        "configFiles": [
          "next.config.ts",
          "package.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [
          "src/components/ui/aspect-ratio.tsx"
        ],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".md": 1,
          ".ts": 41,
          ".json": 7,
          ".sql": 3,
          ".mjs": 2,
          ".svg": 21,
          ".txt": 2,
          ".png": 2,
          ".tsx": 118,
          ".ico": 1,
          ".css": 1
        }
      }
    },
    {
      "id": 1134780318,
      "name": "whatomate",
      "displayName": "whatomate",
      "description": "Whatomate is an open-source WhatsApp integration",
      "summary": "The Problem\nManaging communications for a business can quickly spiral into chaos, especially if you’re trying to juggle multiple clients and channels. Traditional messaging systems often lack the capability for real-time interaction, multi-tenancy, or effective automation. This is where WhatsApp, with its massive user base, becomes a potential goldmine—if you can effectively integrate it into your operations.\n\nWhat This Does\nWhatomate steps in as an open-source solution to bridge the gap between businesses and WhatsApp’s messaging capabilities. The core of its functionality lies in the cmd/whatomate/main.go file, where the server is kicked off, and all the heavy lifting happens. It supports multi-tenancy, allowing you to manage multiple organizations with isolated data. You also get role-based access control—check out how permissions are managed in the backend.\n\nThe configuration is straightforward. You set it up using the config.example.toml file, which you copy and modify to fit your needs. Want to scale? Use docker/docker-compose.yml to spin up containers effortlessly. The deployment scripts in .github/workflows/ make it easy to automate deployments and tests, so you can focus more on features rather than deployment headaches.\n\nReal-World Use\nImagine you're running a marketing agency handling campaigns for several clients simultaneously. Each client needs tailored messaging and analytics. With Whatomate, you can set up multiple accounts, manage chatbots for auto-replies, and track campaign performance through the built-in analytics dashboard. You'd simply configure the config.toml file for each client and use the CLI to manage your workers. A quick command like ./whatomate server -workers=4 can spin up the necessary workers for handling high loads during peak campaign times.\n\nThe Bottom Line\nWhatomate is great for businesses looking to integrate WhatsApp into their operations without the overhead of commercial solutions. It's feature-rich and offers a lot of flexibility with its multi-tenant architecture and automation capabilities. However, if you’re a small shop or just need basic messaging, this might be overkill. You can get started without breaking the bank, but be prepared to invest some time in setup and maintenance. If you can navigate Go and Docker, this repo is worth a look.",
      "url": "https://github.com/yebeai/whatomate",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "shridarpatil/whatomate",
        "url": "https://github.com/shridarpatil/whatomate",
        "stars": 916
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".github": 6,
          "(root)": 6,
          "cmd": 1,
          "docker": 3,
          "docs": 50,
          "frontend": 134
        },
        "languages": {
          "Markdown": 3,
          "YAML": 6,
          "Go": 1,
          "TOML": 1,
          "JSON": 6,
          "TypeScript": 42,
          "CSS": 2,
          "HTML": 1,
          "Vue": 83
        },
        "frameworks": [
          "React",
          "Vue",
          "Docker"
        ],
        "packageManager": "npm",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "cmd/whatomate/main.go",
          "frontend/e2e/helpers/index.ts",
          "frontend/e2e/pages/index.ts",
          "frontend/index.html",
          "frontend/src/components/ui/accordion/index.ts",
          "frontend/src/components/ui/alert-dialog/index.ts",
          "frontend/src/components/ui/alert/index.ts",
          "frontend/src/components/ui/aspect-ratio/index.ts",
          "frontend/src/components/ui/avatar/index.ts",
          "frontend/src/components/ui/badge/index.ts",
          "frontend/src/components/ui/breadcrumb/index.ts",
          "frontend/src/components/ui/button/index.ts",
          "frontend/src/components/ui/calendar/index.ts",
          "frontend/src/components/ui/card/index.ts",
          "frontend/src/components/ui/checkbox/index.ts",
          "frontend/src/components/ui/collapsible/index.ts",
          "frontend/src/components/ui/command/index.ts"
        ],
        "configFiles": [
          "Makefile",
          "docker/Dockerfile",
          "docker/Dockerfile.goreleaser",
          "docker/docker-compose.yml",
          "docs/package.json",
          "docs/tsconfig.json",
          "frontend/.env.example",
          "frontend/Dockerfile",
          "frontend/package.json"
        ],
        "dependencies": [
          "docs/package-lock.json",
          "docs/package.json",
          "frontend/package-lock.json",
          "frontend/package.json"
        ],
        "testFiles": [
          ".github/workflows/e2e-tests.yml",
          ".github/workflows/test.yml",
          "frontend/e2e/tests/analytics/analytics.spec.ts",
          "frontend/e2e/tests/auth/login.spec.ts",
          "frontend/e2e/tests/auth/register.spec.ts",
          "frontend/e2e/tests/campaigns/campaigns.spec.ts",
          "frontend/e2e/tests/chatbot/ai-contexts.spec.ts",
          "frontend/e2e/tests/chatbot/keywords.spec.ts",
          "frontend/e2e/tests/dashboard/dashboard.spec.ts",
          "frontend/e2e/tests/flows/flows.spec.ts",
          "frontend/e2e/tests/settings/api-keys.spec.ts",
          "frontend/e2e/tests/settings/canned-responses.spec.ts",
          "frontend/e2e/tests/settings/custom-actions.spec.ts",
          "frontend/e2e/tests/settings/teams.spec.ts",
          "frontend/e2e/tests/settings/users.spec.ts",
          "frontend/e2e/tests/settings/webhooks.spec.ts",
          "frontend/src/components/ui/aspect-ratio/AspectRatio.vue",
          "frontend/src/components/ui/aspect-ratio/index.ts"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "docs/.gitignore",
          "docs/astro.config.mjs",
          "docs/package-lock.json",
          "docs/package.json",
          "docs/public/images/01-dashboard.png",
          "docs/public/images/02-chatbot-settings.png",
          "docs/public/images/03-keyword-rules.png",
          "docs/public/images/04-keyword-rule-editor.png",
          "docs/public/images/05-ai-contexts.png",
          "docs/public/images/06-ai-context-editor.png",
          "docs/public/images/07-conversation-flows.png",
          "docs/public/images/08-conversation-flow-builder.png",
          "docs/public/images/09-whatsapp-flows.png",
          "docs/public/images/10-whatsapp-flow-builder.png",
          "docs/public/images/11-templates.png",
          "docs/public/images/12-template-editor.png",
          "docs/public/images/13-campaigns.png",
          "docs/public/images/14-campaign-details.png",
          "docs/public/images/15-settings.png",
          "docs/public/images/16-account-settings.png",
          "docs/src/assets/logo-dark.svg",
          "docs/src/assets/logo-light.svg",
          "docs/src/content.config.ts",
          "docs/src/content/docs/api-reference/accounts.mdx",
          "docs/src/content/docs/api-reference/analytics.mdx",
          "docs/src/content/docs/api-reference/api-keys.mdx",
          "docs/src/content/docs/api-reference/authentication.mdx",
          "docs/src/content/docs/api-reference/campaigns.mdx",
          "docs/src/content/docs/api-reference/canned-responses.mdx",
          "docs/src/content/docs/api-reference/chatbot.mdx",
          "docs/src/content/docs/api-reference/contacts.mdx",
          "docs/src/content/docs/api-reference/flows.mdx",
          "docs/src/content/docs/api-reference/messages.mdx",
          "docs/src/content/docs/api-reference/overview.mdx",
          "docs/src/content/docs/api-reference/teams.mdx",
          "docs/src/content/docs/api-reference/templates.mdx",
          "docs/src/content/docs/api-reference/users.mdx",
          "docs/src/content/docs/api-reference/webhooks.mdx",
          "docs/src/content/docs/features/campaigns.mdx",
          "docs/src/content/docs/features/canned-responses.mdx",
          "docs/src/content/docs/features/chatbot.mdx",
          "docs/src/content/docs/features/dashboard.mdx",
          "docs/src/content/docs/features/templates.mdx",
          "docs/src/content/docs/features/whatsapp-flows.mdx",
          "docs/src/content/docs/getting-started/configuration.mdx",
          "docs/src/content/docs/getting-started/introduction.mdx",
          "docs/src/content/docs/getting-started/quickstart.mdx",
          "docs/src/content/docs/index.mdx",
          "docs/src/styles/custom.css",
          "docs/tsconfig.json"
        ],
        "fileTypes": {
          ".md": 3,
          ".yml": 6,
          ".go": 1,
          ".toml": 1,
          ".goreleaser": 1,
          ".mjs": 1,
          ".json": 6,
          ".png": 16,
          ".svg": 3,
          ".ts": 42,
          ".mdx": 25,
          ".css": 2,
          ".example": 1,
          ".html": 1,
          ".cjs": 1,
          ".mp3": 1,
          ".vue": 83
        }
      }
    },
    {
      "id": 1134780004,
      "name": "aikit",
      "displayName": "aikit",
      "description": "A comprehensive, SDK-agnostic UI library built on Atomic Design principles. Create beautiful, accessible AI chat experiences with full TypeScript support, theming, and extensive customization options.",
      "summary": "The Problem\n\nBuilding AI chat UIs sucks. You’re either duct-taping random UI kits together or writing the same chat bubble boilerplate for the 50th time. Accessibility? Usually an afterthought. And if you want to swap out your AI backend, good luck—most chat UIs are glued to one SDK.\n\nWhat This Does\n\naikit gives you a bunch of prebuilt React components for AI chats, organized by Atomic Design. You get everything from tiny atoms like ActionButton and Alert in src/components/atoms, up to full-blown chat layouts in src/components/templates and src/components/pages. There’s a clear hierarchy, so you’re not hunting through spaghetti code.\n\nIt’s SDK-agnostic; check out the ChatContainer in the docs and demo. You wire up your own AI backend—just pass messages and chats as props. The src/hooks folder has utilities for customizing behavior, and theming is handled via CSS variables in src/themes. No wrestling with ugly overrides.\n\nReal-World Use\n\nSay you want a Slack-style AI chat in your product. Install @gravity-ui/aikit, drop the ChatContainer into your app, and hook up your message logic. Here’s how it looks:\n\nimport { ChatContainer } from '@gravity-ui/aikit';\n\nfunction App() {\n    // your state, handlers, etc\n    return (\n        <ChatContainer\n            chats={chats}\n            activeChat={activeChat}\n            messages={messages}\n            onSendMessage={mySendHandler}\n            onSelectChat={setActiveChat}\n            // ...other props\n        />\n    );\n}\n\nWant custom message types or theming? Register your own in src/types, tweak CSS variables, or dig into the src/components/organisms. No need to rewrite everything.\n\nThe Bottom Line\n\naikit is legit if you need a flexible, accessible AI chat UI and don’t want to reinvent the wheel. The Atomic Design thing keeps it sane for bigger apps, but it’s probably overkill for tiny side projects. If you care about accessibility and swapping AI backends, use it. If you just want a quick chatbot for your landing page, stick to something simpler.",
      "url": "https://github.com/yebeai/aikit",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "gravity-ui/aikit",
        "url": "https://github.com/gravity-ui/aikit",
        "stars": 145
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1531482615713-2afd69097998?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 21,
          ".github": 5,
          ".husky": 2,
          ".storybook": 8,
          "build-utils": 1,
          "docs": 13,
          "playwright": 9,
          "src": 141
        },
        "languages": {
          "YAML": 5,
          "JavaScript": 4,
          "TSX": 52,
          "TypeScript": 16,
          "JSON": 5,
          "Markdown": 25,
          "HTML": 1,
          "SCSS": 12,
          "Shell": 1
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          ".storybook/main.ts",
          "playwright/core/index.ts",
          "playwright/index.html",
          "playwright/index.tsx",
          "src/components/atoms/ActionButton/index.ts",
          "src/components/atoms/Alert/index.tsx",
          "src/components/atoms/ChatDate/i18n/index.ts",
          "src/components/atoms/ChatDate/index.ts",
          "src/components/atoms/ContextIndicator/index.tsx",
          "src/components/atoms/ContextItem/index.tsx",
          "src/components/atoms/DiffStat/index.tsx",
          "src/components/atoms/Disclaimer/index.ts",
          "src/components/atoms/InlineCitation/index.ts",
          "src/components/atoms/IntersectionContainer/index.ts",
          "src/components/atoms/Loader/index.ts",
          "src/components/atoms/MarkdownRenderer/index.ts",
          "src/components/atoms/MessageBalloon/index.tsx",
          "src/components/atoms/Shimmer/index.tsx"
        ],
        "configFiles": [
          ".eslintrc",
          ".prettierrc.js",
          ".storybook/tsconfig.json",
          "jest.config.js",
          "package.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [
          "docs/TESTING.md",
          "src/components/atoms/ActionButton/__tests__/ActionButton.visual.spec.tsx",
          "src/components/atoms/ActionButton/__tests__/__snapshots__/ActionButton-should-render-button-without-tooltip-chromium.png",
          "src/components/atoms/ActionButton/__tests__/__snapshots__/ActionButton-should-render-default-button-without-hover-chromium.png",
          "src/components/atoms/ActionButton/__tests__/__snapshots__/ActionButton-should-render-default-with-tooltip-on-hover-chromium.png",
          "src/components/atoms/ActionButton/__tests__/__snapshots__/ActionButton-should-render-without-tooltip-on-hover-chromium.png",
          "src/components/atoms/ActionButton/__tests__/helpersPlaywright.tsx",
          "src/components/atoms/Alert/__tests__/Alert.visual.spec.tsx",
          "src/components/atoms/Alert/__tests__/__snapshots__/Alert-should-correct-render-custom-icon-chromium.png",
          "src/components/atoms/Alert/__tests__/__snapshots__/Alert-should-correct-render-with-long-text-chromium.png",
          "src/components/atoms/Alert/__tests__/__snapshots__/Alert-should-render-action-button-chromium.png",
          "src/components/atoms/Alert/__tests__/__snapshots__/Alert-should-render-collapsible-content-chromium.png",
          "src/components/atoms/Alert/__tests__/__snapshots__/Alert-should-render-different-variant-chromium.png",
          "src/components/atoms/Alert/__tests__/helpersPlaywright.tsx",
          "src/components/atoms/ChatDate/__tests__/ChatDate.visual.spec.tsx",
          "src/components/atoms/ChatDate/__tests__/__snapshots__/ChatDate-should-render-different-date-types-chromium.png",
          "src/components/atoms/ChatDate/__tests__/__snapshots__/ChatDate-should-render-different-formats-chromium.png",
          "src/components/atoms/ChatDate/__tests__/__snapshots__/ChatDate-should-render-invalid-date-chromium.png",
          "src/components/atoms/ChatDate/__tests__/__snapshots__/ChatDate-should-render-recent-dates-chromium.png",
          "src/components/atoms/ChatDate/__tests__/__snapshots__/ChatDate-should-render-with-custom-format-and-time-chromium.png",
          "src/components/atoms/ChatDate/__tests__/__snapshots__/ChatDate-should-render-with-custom-format-chromium.png",
          "src/components/atoms/ChatDate/__tests__/__snapshots__/ChatDate-should-render-with-custom-style-chromium.png",
          "src/components/atoms/ChatDate/__tests__/__snapshots__/ChatDate-should-render-with-date-object-chromium.png",
          "src/components/atoms/ChatDate/__tests__/__snapshots__/ChatDate-should-render-with-date-string-chromium.png",
          "src/components/atoms/ChatDate/__tests__/__snapshots__/ChatDate-should-render-with-time-chromium.png",
          "src/components/atoms/ChatDate/__tests__/__snapshots__/ChatDate-should-render-with-timestamp-chromium.png",
          "src/components/atoms/ChatDate/__tests__/helpersPlaywright.tsx",
          "src/components/atoms/ContextIndicator/__tests__/ContextIndicator.visual.spec.tsx",
          "src/components/atoms/ContextIndicator/__tests__/__snapshots__/ContextIndicator-should-render-all-reversed-variants-chromium.png",
          "src/components/atoms/ContextIndicator/__tests__/__snapshots__/ContextIndicator-should-render-all-states-chromium.png",
          "src/components/atoms/ContextIndicator/__tests__/__snapshots__/ContextIndicator-should-render-empty-state-chromium.png",
          "src/components/atoms/ContextIndicator/__tests__/__snapshots__/ContextIndicator-should-render-full-state-chromium.png",
          "src/components/atoms/ContextIndicator/__tests__/__snapshots__/ContextIndicator-should-render-half-state-chromium.png",
          "src/components/atoms/ContextIndicator/__tests__/__snapshots__/ContextIndicator-should-render-playground-variant-chromium.png",
          "src/components/atoms/ContextIndicator/__tests__/__snapshots__/ContextIndicator-should-render-quarter-state-chromium.png",
          "src/components/atoms/ContextIndicator/__tests__/__snapshots__/ContextIndicator-should-render-three-quarters-state-chromium.png",
          "src/components/atoms/ContextIndicator/__tests__/__snapshots__/ContextIndicator-should-render-vertical-with-number-chromium.png",
          "src/components/atoms/ContextIndicator/__tests__/__snapshots__/ContextIndicator-should-render-with-gray-colors-chromium.png",
          "src/components/atoms/ContextIndicator/__tests__/__snapshots__/ContextIndicator-should-render-with-number-at-half-chromium.png",
          "src/components/atoms/ContextIndicator/__tests__/__snapshots__/ContextIndicator-should-render-with-number-chromium.png",
          "src/components/atoms/ContextIndicator/__tests__/__snapshots__/ContextIndicator-should-render-with-vertical-orientation-chromium.png",
          "src/components/atoms/ContextIndicator/__tests__/helpersPlaywright.tsx",
          "src/components/atoms/ContextItem/__tests__/ContextItem.visual.spec.tsx",
          "src/components/atoms/ContextItem/__tests__/__snapshots__/ContextItem-should-render-playground-variant-chromium.png",
          "src/components/atoms/ContextItem/__tests__/__snapshots__/ContextItem-should-render-without-remove-button-chromium.png",
          "src/components/atoms/ContextItem/__tests__/helpersPlaywright.tsx",
          "src/components/atoms/DiffStat/__tests__/DiffStat.visual.spec.tsx",
          "src/components/atoms/DiffStat/__tests__/__snapshots__/DiffStat-should-render-all-lengths-variants-chromium.png",
          "src/components/atoms/DiffStat/__tests__/__snapshots__/DiffStat-should-render-playground-variant-chromium.png",
          "src/components/atoms/DiffStat/__tests__/helpersPlaywright.tsx",
          "src/components/atoms/Disclaimer/__tests__/Disclaimer.visual.spec.tsx",
          "src/components/atoms/Disclaimer/__tests__/__snapshots__/Disclaimer-should-render-with-caption-variant-chromium.png",
          "src/components/atoms/Disclaimer/__tests__/__snapshots__/Disclaimer-should-render-with-children-chromium.png",
          "src/components/atoms/Disclaimer/__tests__/__snapshots__/Disclaimer-should-render-with-text-and-children-chromium.png",
          "src/components/atoms/Disclaimer/__tests__/__snapshots__/Disclaimer-should-render-with-text-chromium.png",
          "src/components/atoms/Disclaimer/__tests__/helpersPlaywright.tsx",
          "src/components/atoms/Loader/__tests__/Loader.visual.spec.tsx",
          "src/components/atoms/Loader/__tests__/__snapshots__/Loader-should-render-all-sizes-chromium.png",
          "src/components/atoms/Loader/__tests__/__snapshots__/Loader-should-render-loading-view-chromium.png",
          "src/components/atoms/Loader/__tests__/__snapshots__/Loader-should-render-streaming-view-chromium.png",
          "src/components/atoms/Loader/__tests__/helpersPlaywright.tsx",
          "src/components/atoms/MarkdownRenderer/__tests__/MarkdownRenderer.visual.spec.tsx",
          "src/components/atoms/MarkdownRenderer/__tests__/__snapshots__/MarkdownRenderer-should-render-basic-markdown-chromium.png",
          "src/components/atoms/MarkdownRenderer/__tests__/__snapshots__/MarkdownRenderer-should-render-with-transform-options-and-custom-plugin-chromium.png",
          "src/components/atoms/MarkdownRenderer/__tests__/helpersPlaywright.tsx",
          "src/components/atoms/MessageBalloon/__tests__/MessageBallojn.visual.spec.tsx",
          "src/components/atoms/MessageBalloon/__tests__/__snapshots__/MessageBalloon-should-render-user-message-chromium.png",
          "src/components/atoms/MessageBalloon/__tests__/helpersPlaywright.tsx",
          "src/components/atoms/Shimmer/__tests__/Shimmer.visual.spec.tsx",
          "src/components/atoms/Shimmer/__tests__/__snapshots__/Shimmer-should-render-text-state-chromium.png",
          "src/components/atoms/Shimmer/__tests__/helpersPlaywright.tsx"
        ],
        "docs": [
          "CHANGELOG.md",
          "CONTRIBUTING.md",
          "LICENSE",
          "README-ru.md",
          "README.md",
          "docs/ARCHITECTURE.md",
          "docs/GETTING_STARTED.md",
          "docs/PLAYWRIGHT.md",
          "docs/PROJECT_STRUCTURE.md",
          "docs/README.md",
          "docs/TESTING.md",
          "docs/assets/aikit_cover.png",
          "docs/assets/globe_dark.svg",
          "docs/assets/globe_light.svg",
          "docs/assets/storybook_dark.svg",
          "docs/assets/storybook_light.svg",
          "docs/assets/telegram_dark.svg",
          "docs/assets/telegram_light.svg",
          "playwright/README.md",
          "src/components/atoms/ActionButton/README.md",
          "src/components/atoms/Alert/README.md",
          "src/components/atoms/ChatDate/README.md",
          "src/components/atoms/ContextIndicator/README.md",
          "src/components/atoms/ContextItem/README.md",
          "src/components/atoms/DiffStat/README.md",
          "src/components/atoms/Disclaimer/README.md",
          "src/components/atoms/IntersectionContainer/README.md",
          "src/components/atoms/Loader/README.md",
          "src/components/atoms/MarkdownRenderer/README.md",
          "src/components/atoms/MessageBalloon/README.md",
          "src/components/atoms/Shimmer/README.md",
          "src/components/atoms/SubmitButton/README.md"
        ],
        "fileTypes": {
          ".yml": 5,
          ".js": 4,
          ".tsx": 52,
          ".ts": 16,
          ".json": 5,
          ".md": 25,
          ".png": 49,
          ".svg": 6,
          ".html": 1,
          ".scss": 12,
          ".sh": 1,
          ".mdx": 12
        }
      }
    },
    {
      "id": 1134778666,
      "name": "react-native-starter",
      "displayName": "react native starter",
      "description": "🚀A powerful react native starter template that bootstraps development of your mobile application ",
      "summary": "The Problem\nDeveloping a mobile application from scratch can feel like a never-ending cycle of boilerplate code and configuration hell. It’s like trying to assemble IKEA furniture without the instructions. You end up with a mess that barely resembles what you wanted. A solid starter template can save you time and sanity, especially when you just want to focus on building features.\n\nWhat This Does\nEnter react-native-starter. This repo is a free template that kickstarts your mobile app development with a bunch of ready-to-use components. You get a basic structure without the fluff. The main entry point is App.js, where you can start building your screens. You have a modular architecture in place, making it easy to scale as your app grows. \n\nThe android/app/build.gradle file handles the Android-specific configurations, while the fonts under android/app/src/main/assets/fonts/ give your app a polished look right out of the box. Want to implement authentication? It’s got that covered with ready-made components for login and signup.\n\nReal-World Use\nImagine you’re building a social media app. You clone the repo with:\n\ngit clone https://github.com/flatlogic/react-native-starter.git\ncd react-native-starter\nyarn install\n\nThen, you fire up the app on your device with:\n\nyarn run:android\n\nVoila! You’ve got a baseline app with a profile page, calendar integration, and even analytics setup. You can focus on implementing your unique features instead of wrestling with setup.\n\nThe Bottom Line\nreact-native-starter is a solid choice for developers looking to jump into mobile app development without the overhead of starting from scratch. It’s feature-rich and free, which is great. On the flip side, if you’re building something small or simple, this might be overkill. But if you need a strong foundation, this template has your back. Just don’t forget to read the fine print—it's still a template, not a magic wand.",
      "url": "https://github.com/yebeai/react-native-starter",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "flatlogic/react-native-starter",
        "url": "https://github.com/flatlogic/react-native-starter",
        "stars": 2510
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1542831371-29b0f74f9713?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 15, 2026",
      "updatedAt": "January 15, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".bundle": 1,
          "(root)": 21,
          "android": 37,
          "assets": 100,
          "generators": 5,
          "ios": 20,
          "src": 16
        },
        "languages": {
          "YAML": 1,
          "JavaScript": 25,
          "Markdown": 2,
          "Kotlin": 2,
          "JSON": 6,
          "Shell": 1,
          "C/C++ Header": 1
        },
        "frameworks": [
          "React",
          "Express",
          "Rails"
        ],
        "packageManager": "gradle",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "Travis CI",
        "entryPoints": [
          "App.js",
          "index.js",
          "src/components/index.js"
        ],
        "configFiles": [
          ".eslintrc",
          ".prettierrc",
          "Gemfile",
          "android/app/build.gradle",
          "android/build.gradle",
          "jest.config.js",
          "package.json"
        ],
        "dependencies": [
          "Gemfile",
          "android/app/build.gradle",
          "android/build.gradle",
          "package.json"
        ],
        "testFiles": [
          "generators/component/Component.spec.js.hbs",
          "ios/ReactNativeStarterTests/Info.plist",
          "ios/ReactNativeStarterTests/ReactNativeStarterTests.m",
          "src/components/__tests__/example.spec.js"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "changelog.md"
        ],
        "fileTypes": {
          ".yml": 1,
          ".js": 25,
          ".md": 2,
          ".gradle": 3,
          ".keystore": 1,
          ".pro": 1,
          ".xml": 5,
          ".ttf": 18,
          ".kt": 2,
          ".png": 96,
          ".properties": 2,
          ".jar": 1,
          ".bat": 1,
          ".json": 6,
          ".svg": 1,
          ".jpg": 2,
          ".jpeg": 2,
          ".sh": 1,
          ".hbs": 5,
          ".env": 1,
          ".storyboard": 2,
          ".lock": 1,
          ".pbxproj": 1,
          ".xcscheme": 2,
          ".xcworkspacedata": 1,
          ".plist": 3,
          ".h": 1,
          ".mm": 1,
          ".xib": 1,
          ".m": 2
        }
      }
    },
    {
      "id": 1134563577,
      "name": "seedbox-lite",
      "displayName": "seedbox lite",
      "description": "A light-weight torrent media center at one place.",
      "summary": "The Problem\n\nTrying to stream torrents like you would on Netflix sucks. Most “seedbox” apps make you wait for the whole file to download, or they’re bloated nightmares to set up. If all you want is to watch a TV show instantly, not run a full-blown media server, you’re out of luck.\n\nWhat This Does\n\nseedbox-lite cuts the nonsense and gives you a lightweight torrent streamer. The client/ folder is a React front-end that looks and feels like Netflix but is actually just a smart video player. The back-end (hidden in the main repo, likely in bridge.js and whatever’s in server/ if you pull from upstream) handles torrent downloads and fires HTTP range requests so you can start watching before the file finishes. Config is dead simple—check out .env.example and .env.production—so you’re not digging through endless YAML. Docker? Yep, just run docker-compose and you’re live. PM2 support for Node nerds who hate containers. Mobile actually works, including native fullscreen on Safari and Chrome (seriously, check out the WebKit APIs referenced).\n\nReal-World Use\n\nSay you want to binge some obscure anime that’s only on torrent sites. Clone the repo, run docker-compose up -d, and drop a .torrent file or magnet link into the UI. The React client (client/index.html and client/package.json) shows download progress, lets you seek, and even loads subtitles if they’re in the torrent. No Plex, no “scan library” nonsense. Password protection is built-in, so you don’t have to worry about randoms snooping.\n\nThe Bottom Line\n\nIf you want instant torrent streaming without spinning up a media center monstrosity, seedbox-lite is legit. Setup is fast, the UI is slick, and it actually works on your phone. Downsides? Not for huge libraries or advanced users—this is “hit play and watch,” not “organize your entire collection.” Perfect for people who just want to stream torrents, not manage them.",
      "url": "https://github.com/yebeai/seedbox-lite",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "hotheadhacker/seedbox-lite",
        "url": "https://github.com/hotheadhacker/seedbox-lite",
        "stars": 4488
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1607799279861-4dd421887fb3?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 14, 2026",
      "updatedAt": "January 14, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 116,
        "directories": {
          "(root)": 21,
          "client": 69,
          "nginx": 1,
          "public": 3,
          "screenshots": 4,
          "server": 18
        },
        "languages": {
          "Markdown": 8,
          "JavaScript": 29,
          "Shell": 4,
          "HTML": 2,
          "JSON": 6,
          "CSS": 16,
          "JSX": 20,
          "YAML": 3
        },
        "frameworks": [
          "React",
          "Express",
          "Docker"
        ],
        "packageManager": "npm",
        "hasDocker": true,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "client/index.html",
          "client/server.js",
          "client/src/App.jsx",
          "public/app.js",
          "public/index.html",
          "server.js",
          "server/index.js"
        ],
        "configFiles": [
          ".env.example",
          "client/.env.example",
          "client/Dockerfile",
          "client/Dockerfile.dev",
          "client/package.json",
          "client/vite.config.js",
          "docker-compose.override.yml",
          "docker-compose.prod.yml",
          "docker-compose.yml",
          "package.json",
          "server/Dockerfile",
          "server/package.json"
        ],
        "dependencies": [
          "client/package-lock.json",
          "client/package.json",
          "package.json",
          "server/package-lock.json",
          "server/package.json"
        ],
        "testFiles": [
          "server/test-cors.sh"
        ],
        "docs": [
          "DEPLOYMENT_GUIDE.md",
          "LICENSE",
          "README.md",
          "client/README.md"
        ],
        "fileTypes": {
          ".docker": 2,
          ".example": 2,
          ".production": 3,
          ".md": 8,
          ".js": 29,
          ".dev": 1,
          ".sh": 4,
          ".cjs": 1,
          ".html": 2,
          ".conf": 2,
          ".json": 6,
          ".svg": 3,
          ".css": 16,
          ".jsx": 20,
          ".backup": 2,
          ".append": 2,
          ".yml": 3,
          ".png": 4
        }
      }
    },
    {
      "id": 1134563092,
      "name": "claude-code-router",
      "displayName": "claude code router",
      "description": "Use Claude Code as the foundation for coding infrastructure, allowing you to decide how to interact with the model while enjoying updates from Anthropic.",
      "summary": "The Problem\nManaging multiple AI models for coding tasks can be a headache. You might need one model for background tasks and another for complex reasoning. Switching between these can slow you down, especially when you’re knee-deep in code. If you’re juggling different providers or models, it can quickly become a mess.\n\nWhat This Does\nEnter claude-code-router, a neat solution that organizes your interactions with various AI models. The core functionality lies in the model routing feature, allowing you to direct requests based on specific needs. You can customize how requests and responses are transformed using the transformers defined in your configuration file. \n\nThe configuration lives in ~/.claude-code-router/config.json, where you can set optional parameters like PROXYURL, LOG, and APIKEY. For instance, if you want to log all your API requests, you can simply set \"LOG\": true. Need to authenticate your requests? Just pop your key in the APIKEY section. \n\nReal-World Use\nImagine you’re working on a feature that requires heavy reasoning capabilities while also needing quick responses from a simple model for background tasks. With claude-code-router, you can use the /model command to switch between models on-the-fly. \n\nHere's how you might do it in your terminal:\n\nccr model set reasoning\nNow all requests are routed to the reasoning model\n\nOr if you want to log everything and route requests through a proxy:\n\n{\n  \"PROXYURL\": \"http://127.0.0.1:7890\",\n  \"LOG\": true,\n  \"APIKEY\": \"your-secret-key\"\n}\n\nThe Bottom Line\nclaude-code-router is a solid tool if you find yourself frequently switching between models or providers. The setup is straightforward, and it’s easy to manage your configurations. However, if you’re working on small projects or don’t need multiple models, this might be overkill. If you’re a developer looking to maintain flexibility while working with AI, definitely give this a shot.",
      "url": "https://github.com/yebeai/claude-code-router",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "musistudio/claude-code-router",
        "url": "https://github.com/musistudio/claude-code-router",
        "stars": 28551
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 14, 2026",
      "updatedAt": "January 14, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".github": 2,
          "(root)": 8,
          "blog": 24,
          "docs": 126,
          "examples": 4,
          "packages": 36
        },
        "languages": {
          "YAML": 2,
          "Markdown": 91,
          "JavaScript": 3,
          "TypeScript": 36,
          "JSON": 20,
          "CSS": 2,
          "TSX": 2
        },
        "frameworks": [
          "React",
          "Tailwind"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "docs/src/pages/index.tsx",
          "packages/cli/src/cli.ts",
          "packages/cli/src/utils/index.ts",
          "packages/cli/src/utils/preset/index.ts",
          "packages/core/src/plugins/index.ts",
          "packages/core/src/plugins/output/index.ts"
        ],
        "configFiles": [
          "docs/package.json",
          "docs/tailwind.config.js",
          "docs/tsconfig.json",
          "package.json",
          "packages/cli/package.json",
          "packages/cli/tsconfig.json",
          "packages/core/package.json"
        ],
        "dependencies": [
          "docs/package.json",
          "package.json",
          "packages/cli/package.json",
          "packages/core/package.json"
        ],
        "testFiles": [
          "blog/en/progressive-disclosure-of-agent-tools-from-the-perspective-of-cli-tool-style.md",
          "blog/images/chrome-inspect.png",
          "docs/static/blog-images/chrome-inspect.png"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "README_zh.md",
          "docs/.gitignore",
          "docs/README.md",
          "docs/blog/2025-02-25-project-motivation.md",
          "docs/blog/2025-11-18-glm-reasoning.md",
          "docs/blog/2025-11-18-router-exploration.md",
          "docs/docs/cli/commands/model.md",
          "docs/docs/cli/commands/other.md",
          "docs/docs/cli/commands/preset.md",
          "docs/docs/cli/commands/start.md",
          "docs/docs/cli/commands/status.md",
          "docs/docs/cli/commands/statusline.md",
          "docs/docs/cli/config/basic.md",
          "docs/docs/cli/config/project-level.md",
          "docs/docs/cli/installation.md",
          "docs/docs/cli/intro.md",
          "docs/docs/cli/quick-start.md",
          "docs/docs/presets/intro.md",
          "docs/docs/server/advanced/custom-router.md",
          "docs/docs/server/api/config-api.md",
          "docs/docs/server/api/logs-api.md",
          "docs/docs/server/api/messages-api.md",
          "docs/docs/server/api/overview.md",
          "docs/docs/server/config/basic.md",
          "docs/docs/server/config/providers.md",
          "docs/docs/server/config/routing.md",
          "docs/docs/server/config/transformers.md",
          "docs/docs/server/deployment.md",
          "docs/docs/server/intro.md",
          "docs/docusaurus.config.ts",
          "docs/i18n/en/code.json",
          "docs/i18n/en/docusaurus-plugin-content-blog/options.json",
          "docs/i18n/en/docusaurus-plugin-content-docs/current.json",
          "docs/i18n/en/docusaurus-theme-classic/footer.json",
          "docs/i18n/en/docusaurus-theme-classic/navbar.json",
          "docs/i18n/zh-CN/code.json",
          "docs/i18n/zh-CN/docusaurus-plugin-content-blog/2025-02-25-project-motivation.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-blog/2025-11-18-glm-reasoning.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-blog/2025-11-18-router-exploration.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-blog/options.json",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs.backup.20260101_205603/advanced/custom-router.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs.backup.20260101_205603/advanced/preset-format.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs.backup.20260101_205603/advanced/presets.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs.backup.20260101_205603/cli/commands/preset.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs.backup.20260101_205603/cli/commands/statusline.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs.backup.20260101_205603/cli/config/basic.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs.backup.20260101_205603/cli/config/project-level.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs.backup.20260101_205603/cli/intro.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs.backup.20260101_205603/cli/model.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs.backup.20260101_205603/cli/other-commands.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs.backup.20260101_205603/cli/start.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs.backup.20260101_205603/cli/status.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs.backup.20260101_205603/config/basic.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs.backup.20260101_205603/config/providers.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs.backup.20260101_205603/config/routing.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs.backup.20260101_205603/config/transformers.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs.backup.20260101_205603/current.json",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs.backup.20260101_205603/installation.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs.backup.20260101_205603/intro.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs.backup.20260101_205603/quick-start.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs.backup.20260101_205603/server/api/config-api.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs.backup.20260101_205603/server/api/logs-api.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs.backup.20260101_205603/server/api/messages-api.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs.backup.20260101_205603/server/api/overview.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs.backup.20260101_205603/server/deployment.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs.backup.20260101_205603/server/intro.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs/current.json",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs/current/cli/commands/model.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs/current/cli/commands/other.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs/current/cli/commands/preset.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs/current/cli/commands/start.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs/current/cli/commands/status.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs/current/cli/commands/statusline.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs/current/cli/config/basic.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs/current/cli/config/project-level.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs/current/cli/installation.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs/current/cli/intro.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs/current/cli/quick-start.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs/current/presets/intro.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs/current/server/advanced/custom-router.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs/current/server/advanced/preset-format.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs/current/server/api/config-api.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs/current/server/api/logs-api.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs/current/server/api/messages-api.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs/current/server/api/overview.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs/current/server/config/basic.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs/current/server/config/providers.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs/current/server/config/routing.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs/current/server/config/transformers.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs/current/server/deployment.md",
          "docs/i18n/zh-CN/docusaurus-plugin-content-docs/current/server/intro.md",
          "docs/i18n/zh-CN/docusaurus-theme-classic/footer.json",
          "docs/i18n/zh-CN/docusaurus-theme-classic/navbar.json",
          "docs/package.json",
          "docs/postcss.config.js",
          "docs/sidebars.ts",
          "docs/src/components/HomepageFeatures.module.css",
          "docs/src/components/HomepageFeatures.tsx",
          "docs/src/css-modules.d.ts",
          "docs/src/css/custom.css",
          "docs/src/docusaurus.d.ts",
          "docs/src/pages/index.tsx",
          "docs/static/blog-images/alipay.jpg",
          "docs/static/blog-images/chrome-devtools.png",
          "docs/static/blog-images/chrome-inspect.png",
          "docs/static/blog-images/claude-code-router-img.png",
          "docs/static/blog-images/claude-code.png",
          "docs/static/blog-images/models.gif",
          "docs/static/blog-images/roadmap.svg",
          "docs/static/blog-images/search.png",
          "docs/static/blog-images/sponsors/glm-en.jpg",
          "docs/static/blog-images/sponsors/glm-zh.jpg",
          "docs/static/blog-images/statusline-config.png",
          "docs/static/blog-images/statusline.png",
          "docs/static/blog-images/ui.png",
          "docs/static/blog-images/webstorm-formate-file.png",
          "docs/static/blog-images/wechat.jpg",
          "docs/static/blog-images/wechat_group.jpg",
          "docs/static/img/ccr.svg",
          "docs/static/img/docusaurus-social-card.jpg",
          "docs/static/img/favicon.ico",
          "docs/static/img/logo.svg",
          "docs/static/img/undraw_docusaurus_mountain.svg",
          "docs/static/img/undraw_docusaurus_react.svg",
          "docs/static/img/undraw_docusaurus_tree.svg",
          "docs/tailwind.config.js",
          "docs/tsconfig.json",
          "examples/README.md"
        ],
        "fileTypes": {
          ".yml": 2,
          ".md": 91,
          ".jpg": 11,
          ".png": 18,
          ".gif": 2,
          ".svg": 7,
          ".js": 3,
          ".ts": 36,
          ".json": 20,
          ".css": 2,
          ".tsx": 2,
          ".ico": 1
        }
      }
    },
    {
      "id": 1134499482,
      "name": "ralph-wiggum",
      "displayName": "ralph wiggum",
      "description": "Ralph Wiggum: Autonomous AI coding with spec-driven development. Point your AI agent here to get started.",
      "summary": "The Problem\n\nAI code assistants are great at writing snippets, but they suck at building whole features reliably. You ask for “user authentication,” and get a half-baked login form with zero tests and missing routes. The real pain is wrangling the bot into actually finishing a feature to spec, not just dumping code in random files.\n\nWhat This Does\n\nralph-wiggum turns your AI agent into a project grunt that actually follows specs. It sets up a bunch of markdown templates (see templates/constitution-template.md, templates/spec-template.md), adds scripts like scripts/ralph-loop.sh, and wires in slash commands for Cursor and Codex. The AI gets a constitution file (.specify/memory/constitution.md) with your project’s rules, then uses /speckit.specify to create feature specs and /speckit.implement to force itself to build them. Everything runs in loops until the acceptance criteria pass—no more “good enough” code dumps.\n\nYou also get an AGENTS.md to tell future AI agents how to behave. The repo doesn’t care if you’re using Claude, Codex CLI, or Cursor; it sets up all the commands and scripts so the bot can work with whatever you’ve got.\n\nReal-World Use\n\nSay you want to add OAuth login. You run /speckit.specify Add user authentication with OAuth and let the AI generate a spec in templates/spec-template.md. Then /speckit.implement kicks off, and the bot builds the feature, checks its own work, and iterates until your acceptance criteria are actually met. The loop script (scripts/ralph-loop.sh) keeps the bot honest—no half-done features, and you get a <promise>DONE</promise> when it’s really finished.\n\nThe Bottom Line\n\nralph-wiggum is great if you’re tired of AI assistants flaking out mid-feature. It’s a bit heavy for tiny projects—setting up constitutions and templates just to add a button is overkill. But if you want your AI to work like a junior dev who actually reads specs and finishes the job, this repo is worth a shot. Just don’t expect magic; you still have to write clear specs and check the output.",
      "url": "https://github.com/yebeai/ralph-wiggum",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "fstandhartinger/ralph-wiggum",
        "url": "https://github.com/fstandhartinger/ralph-wiggum",
        "stars": 178
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 14, 2026",
      "updatedAt": "January 14, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 18,
        "directories": {
          ".claude": 1,
          ".cursor": 2,
          "(root)": 6,
          "codex-prompts": 2,
          "scripts": 4,
          "templates": 3
        },
        "languages": {
          "Markdown": 13,
          "Shell": 4
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [
          ".cursor/commands/speckit.implement.md",
          ".cursor/commands/speckit.specify.md",
          "codex-prompts/ralph-spec.md",
          "templates/spec-template.md"
        ],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".md": 13,
          ".sh": 4
        }
      }
    },
    {
      "id": 1134497985,
      "name": "ralph-wiggum-marketer",
      "displayName": "ralph wiggum marketer",
      "description": "A Claude Code Plugin that provides an autonomous AI copywriter.",
      "summary": "The Problem\nContent creation is a slog. Marketing teams are constantly juggling deadlines, endless drafts, and revisions while trying to maintain a coherent brand voice. The process can be draining, and often leaves you wondering why you’re not just paying a freelance writer. Enter ralph-wiggum-marketer, which promises to automate the writing grind—if it works as advertised.\n\nWhat This Does\nThis plugin is built around the Ralph Wiggum pattern, which is a fancy way of saying it iterates through writing tasks while you catch some Z's. The core functionality resides in the commands/ralph-marketer.md, which kicks off the autonomous writing loop. It pulls from inputs like scripts/ralph/prd.json for tasks and scripts/ralph/progress.txt for learnings, allowing it to prioritize and manage content effectively.\n\nThe hooks/stop-hook.sh lets you halt the process if things go sideways, while commands/ralph-status.md keeps you updated on progress. Basically, you give it the requirements, and it churns out drafts like a caffeinated intern.\n\nReal-World Use\nImagine you're a content manager for a SaaS product. You fire up the plugin with /ralph-init, set your PRD in scripts/ralph/prd.json, and let Ralph take over. While you grab lunch, it reads through the tasks, checks what's been done, and starts writing. You can check its status anytime with /ralph-status to see if it’s on track or if you need to intervene. If you’re not happy with the quality, just cancel it with /ralph-cancel and try again later.\n\nStart the autonomous loop\n/ralph-marketer\n\nThe Bottom Line\nThis plugin could save your sanity if you’re drowning in content creation. On the flip side, it’s not foolproof. The quality of the output depends heavily on the input you provide. If you’re a solo developer or a small team, this might be overkill for your needs. However, for larger teams or agencies that produce a ton of content, ralph-wiggum-marketer might just become your new best friend—or at least a less annoying colleague.",
      "url": "https://github.com/yebeai/ralph-wiggum-marketer",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "muratcankoylan/ralph-wiggum-marketer",
        "url": "https://github.com/muratcankoylan/ralph-wiggum-marketer",
        "stars": 673
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 14, 2026",
      "updatedAt": "January 14, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 24,
        "directories": {
          ".claude-plugin": 2,
          "(root)": 5,
          "commands": 4,
          "hooks": 2,
          "scripts": 6,
          "skills": 1,
          "templates": 4
        },
        "languages": {
          "JSON": 7,
          "Markdown": 8,
          "Shell": 1,
          "JavaScript": 6
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [
          "package.json",
          "templates/package.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json",
          "templates/package.json"
        ],
        "testFiles": [
          "scripts/src/test.js"
        ],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".json": 7,
          ".md": 8,
          ".sh": 1,
          ".js": 6,
          ".txt": 1
        }
      }
    },
    {
      "id": 1134497452,
      "name": "agent-browser",
      "displayName": "agent browser",
      "description": "Browser automation CLI for AI agents",
      "summary": "The Problem\n\nAutomating browsers for AI agents sucks. You’re either wrestling with flaky Python scripts, waiting ages for Selenium, or duct-taping Playwright into something it was never meant to be. And if you want a CLI that actually speaks “AI agent,” good luck—most tools expect humans, not bots.\n\nWhat This Does\n\nagent-browser is a CLI built (primarily) in Rust for speed, with a fallback to Node.js if you’re allergic to compiling things. It sits between your AI agent and the browser, translating simple shell commands into real actions. The core logic lives in cli/src/main.rs and splits out commands in cli/src/commands.rs—so no magic, just actual code you can read.\n\nYou get all the usual suspects: click, fill, screenshot, etc. But the killer feature is the semantic locators and “snapshot” command. Instead of CSS selectors, your agent can grab elements by ARIA role, label, or even accessibility refs (@e2). It’s meant for machines, not humans. The install process is painless (bin/agent-browser), and there’s a proper Docker setup in docker/ if you want to run this somewhere weird.\n\nReal-World Use\n\nSay your AI needs to fill out a form. You’d run:\n\nagent-browser open example.com\nagent-browser snapshot\nagent-browser fill @e3 \"test@example.com\"\nagent-browser click @e2\n\nAll refs come from the previous snapshot, so your agent doesn’t need to guess selectors. If you’re old-school, you can still do agent-browser click \"#submit\", but why suffer?\n\nThe Bottom Line\n\nagent-browser is fast, predictable, and actually designed for AI workflows. If your agent needs to wrangle the browser, this is way better than hacking together Selenium or Playwright scripts. The docs are decent, the commands make sense, and you don’t have to fight with selectors. If you just need one-off automation, maybe overkill. But for agent devs or anyone building LLM pipelines, it’s the right tool for the job.",
      "url": "https://github.com/yebeai/agent-browser",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "vercel-labs/agent-browser",
        "url": "https://github.com/vercel-labs/agent-browser",
        "stars": 16448
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 14, 2026",
      "updatedAt": "January 14, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 62,
        "directories": {
          ".github": 1,
          "(root)": 9,
          ".husky": 1,
          "bin": 2,
          "cli": 8,
          "docker": 2,
          "docs": 23,
          "scripts": 4,
          "skills": 1,
          "src": 10,
          "test": 1
        },
        "languages": {
          "YAML": 4,
          "Markdown": 3,
          "TOML": 1,
          "Rust": 6,
          "TypeScript": 13,
          "JSON": 4,
          "TSX": 14,
          "CSS": 1,
          "Shell": 1,
          "JavaScript": 3
        },
        "frameworks": [
          "React",
          "Next.js",
          "Docker"
        ],
        "packageManager": "pnpm",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "cli/src/main.rs"
        ],
        "configFiles": [
          ".prettierrc",
          "cli/Cargo.toml",
          "docker/Dockerfile.build",
          "docker/docker-compose.yml",
          "docs/next.config.ts",
          "docs/package.json",
          "docs/tsconfig.json",
          "package.json",
          "tsconfig.json"
        ],
        "dependencies": [
          "cli/Cargo.toml",
          "docs/package.json",
          "package.json"
        ],
        "testFiles": [
          "src/actions.test.ts",
          "src/browser.test.ts",
          "src/protocol.test.ts",
          "test/serverless.test.ts",
          "vitest.config.ts"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "docs/.gitignore",
          "docs/eslint.config.mjs",
          "docs/next.config.ts",
          "docs/package.json",
          "docs/pnpm-lock.yaml",
          "docs/postcss.config.mjs",
          "docs/src/app/agent-mode/page.tsx",
          "docs/src/app/cdp-mode/page.tsx",
          "docs/src/app/commands/page.tsx",
          "docs/src/app/favicon.ico",
          "docs/src/app/globals.css",
          "docs/src/app/installation/page.tsx",
          "docs/src/app/layout.tsx",
          "docs/src/app/page.tsx",
          "docs/src/app/quick-start/page.tsx",
          "docs/src/app/selectors/page.tsx",
          "docs/src/app/sessions/page.tsx",
          "docs/src/app/snapshots/page.tsx",
          "docs/src/app/streaming/page.tsx",
          "docs/src/components/code-block.tsx",
          "docs/src/components/copy-button.tsx",
          "docs/src/components/sidebar.tsx",
          "docs/tsconfig.json"
        ],
        "fileTypes": {
          ".yml": 2,
          ".md": 3,
          ".cmd": 1,
          ".lock": 1,
          ".toml": 1,
          ".rs": 6,
          ".build": 1,
          ".mjs": 2,
          ".ts": 13,
          ".json": 4,
          ".yaml": 2,
          ".tsx": 14,
          ".ico": 1,
          ".css": 1,
          ".sh": 1,
          ".js": 3
        }
      }
    },
    {
      "id": 1134496112,
      "name": "agent-skills",
      "displayName": "agent skills",
      "description": "No description available",
      "summary": "The Problem\nDeploying a web application can be a hassle. You’ve coded your heart out, but now you’re stuck navigating authentication hurdles and deployment setups. If you're using Vercel, why not skip the tedious parts? Enter the vercel-deploy-claimable skill.\n\nWhat This Does\nThe vercel-deploy-claimable skill simplifies your deployment process. With the scripts/deploy.sh script, it packages your project into a tarball, detects your framework (Next.js, Astro, or whatever), and uploads it to Vercel without needing you to authenticate. No more fiddling with settings just to get your app live. \n\nMeanwhile, the skills/react-best-practices folder holds over 40 performance optimization rules for React and Next.js. If you're writing new components or reviewing existing code, the SKILL.md file contains prioritized guidelines that can turbocharge your app's performance.\n\nReal-World Use\nImagine you’ve just finished building a shiny new Next.js app. You run the command:\n\nnpx add-skill vercel-labs/agent-skills\n\nYou then invoke the skill with:\n\nDeploy my app\n\nBoom! You get a response with a preview URL and a claim URL, letting you push the app live without the usual headaches. Now, while your app is uploading, you can check the references/react-performance-guidelines.md for optimization tips on the fly. \n\nThe Bottom Line\nThis repo has a solid deployment approach for Vercel users and great performance guidelines for React devs. If you’re constantly deploying apps and need a quick way to optimize them, this is worth checking out. Just be aware that if your project is small or simple, this might feel like overkill. But for serious projects? It’s a no-brainer.",
      "url": "https://github.com/yebeai/agent-skills",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "vercel-labs/agent-skills",
        "url": "https://github.com/vercel-labs/agent-skills",
        "stars": 21432
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 14, 2026",
      "updatedAt": "January 14, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 56,
        "directories": {
          "(root)": 4,
          "skills": 52
        },
        "languages": {
          "Markdown": 52,
          "Shell": 1
        },
        "frameworks": [
          "React"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [
          "skills/react-best-practices/references/rules/advanced-use-latest.md"
        ],
        "docs": [
          "README.md",
          "skills/react-best-practices/references/react-performance-guidelines.md",
          "skills/vercel-design-guidelines.zip",
          "skills/vercel-design-guidelines/SKILL.md"
        ],
        "fileTypes": {
          ".md": 52,
          ".zip": 2,
          ".sh": 1
        }
      }
    },
    {
      "id": 1134495140,
      "name": "Hozn-RealEstate-Fullstack",
      "displayName": "Hozn RealEstate Fullstack",
      "description": "🚀 Hozn - Real Estate Fullstack is a Website complete real estate platform built with React, Next.js, TypeScript, Express, and PostgreSQL. ",
      "summary": "The Problem\n\nBuilding a real estate platform from scratch sucks. You have to wrangle authentication, property management, admin dashboards, uploads, and a million moving parts. Most boilerplates don’t cover the full stack or they’re glued together with duct tape and hope. You need something that actually works, isn’t a mess, and doesn’t force you to reinvent the wheel every time.\n\nWhat This Does\n\nHozn-RealEstate-Fullstack handles the heavy lifting. The frontend lives in Hozn-RealEstate/, built with React, Next.js, and TypeScript. You get folders like components/ for UI, redux/ for state, and hooks/ for logic—none of that “where does this go?” nonsense. The backend is in real-estate-backend/, running on Express, wired to PostgreSQL via Sequelize. JWT authentication is baked in, so you’re not copy-pasting token logic from Stack Overflow.\n\nWant to add a new property? Hit the API with Axios from the frontend. The backend handles uploads via Multer, hashes passwords with bcrypt.js, and spits out clean endpoints for listings, profile edits, and admin stuff. Styles are handled with Tailwind and SCSS in styles/, so you can make it look less like 2012 Craigslist.\n\nReal-World Use\n\nSay you want to let users list their own properties. You’d hook a form in components/PropertyForm.tsx to the backend with an API call—something like:\n\nconst handleSubmit = async (data) => {\n  await axios.post('/api/properties', data, { headers: { Authorization: Bearer ${token} } });\n};\n\nThe backend endpoint in real-estate-backend/routes/properties.js checks your JWT, validates the payload, stores the listing, and updates the database. Admins can update or delete listings from the dashboard, which is just another React page hitting secured endpoints.\n\nThe Bottom Line\n\nIf you want a real estate platform that’s actually full-stack and doesn’t look like it was made for a hackathon, this is solid. It covers the basics—auth, CRUD, admin, uploads, responsive UI—without making you dig through spaghetti code. Not for tiny projects, but saves weeks for anything serious. Could use more docs, but you get the gist fast.",
      "url": "https://github.com/yebeai/Hozn-RealEstate-Fullstack",
      "language": null,
      "stars": 1,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "AHMAD-JX/Hozn-RealEstate-Fullstack",
        "url": "https://github.com/AHMAD-JX/Hozn-RealEstate-Fullstack",
        "stars": 135
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 14, 2026",
      "updatedAt": "January 14, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 7,
          "public": 193
        },
        "languages": {
          "JSON": 4,
          "Markdown": 1,
          "JavaScript": 1,
          "CSS": 10,
          "SCSS": 1
        },
        "frameworks": [
          "React",
          "Next.js"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [
          ".eslintrc.json",
          "next.config.js",
          "package.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".json": 4,
          ".md": 1,
          ".js": 1,
          ".css": 10,
          ".map": 5,
          ".scss": 1,
          ".woff": 11,
          ".woff2": 22,
          ".ttf": 20,
          ".eot": 10,
          ".jpg": 44,
          ".png": 18,
          ".svg": 51
        }
      }
    },
    {
      "id": 1134493827,
      "name": "maplibre-gl-usgs-lidar",
      "displayName": "maplibre gl usgs lidar",
      "description": "A web-based LiDAR point cloud viewer for USGS 3DEP LiDAR",
      "summary": "The Problem\nVisualizing LiDAR data can be a pain in the neck, especially when you're trying to parse through massive datasets from USGS. If you’ve ever tried to wrangle point cloud data into a usable format, you know how frustrating it can be to find a tool that doesn’t require a Ph.D. in GIS. This repository aims to simplify that.\n\nWhat This Does\nThe maplibre-gl-usgs-lidar project is a MapLibre GL JS plugin that makes it easy to search and visualize USGS 3DEP LiDAR data. With files like UsgsLidarControl.ts and UsgsLidarControlReact.tsx, you can easily integrate the control into both vanilla JavaScript and React apps. The examples/basic and examples/react directories provide straightforward setups, so you can hit the ground running without endless configuration.\n\nIt supports dynamic streaming of point cloud data, which means you can work with large datasets without crashing your browser. You can also customize color schemes for elevation, intensity, classification, and RGB, making your visualizations not just functional but visually appealing. Check out the src/lib/hooks/useUsgsLidarState.ts for managing the component's state in React; it’s a neat touch for those who prefer the React way of doing things.\n\nReal-World Use\nImagine you're a geospatial analyst tasked with presenting a new LiDAR dataset to stakeholders. You can set up your viewer with just a few lines of code. Here’s a quick setup in React:\n\nconst { state, toggle } = useUsgsLidarState({ collapsed: false });\n\n<UsgsLidarControlReact\n  map={map}\n  title=\"USGS LiDAR\"\n  collapsed={state.collapsed}\n  onSearchComplete={(items) => console.log('Found:', items.length)}\n/>\n\nIn just a couple of minutes, you can visualize your point clouds and let your audience interact with the data live. This beats the hell out of static maps or exporting data to other formats.\n\nThe Bottom Line\nThis is a handy tool if you need to work with USGS LiDAR data in a web application. It's well-structured, and the TypeScript support is a nice bonus for those who want type safety. On the downside, it’s a bit heavy if you just need basic mapping features without the LiDAR capabilities. If you’re dealing with large datasets and want to present them interactively, this is worth a look. But if you just need to map a few points, this might be overkill.",
      "url": "https://github.com/yebeai/maplibre-gl-usgs-lidar",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "opengeos/maplibre-gl-usgs-lidar",
        "url": "https://github.com/opengeos/maplibre-gl-usgs-lidar",
        "stars": 144
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 14, 2026",
      "updatedAt": "January 14, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 44,
        "directories": {
          ".github": 3,
          "(root)": 13,
          "examples": 4,
          "public": 2,
          "src": 20,
          "tests": 2
        },
        "languages": {
          "YAML": 4,
          "Markdown": 1,
          "HTML": 4,
          "TypeScript": 23,
          "TSX": 2,
          "JSON": 4,
          "CSS": 2
        },
        "frameworks": [
          "React",
          "Docker"
        ],
        "packageManager": "npm",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "examples/basic/index.html",
          "examples/basic/main.ts",
          "examples/react/index.html",
          "index.html",
          "src/index.ts",
          "src/lib/adapters/index.ts",
          "src/lib/gui/index.ts",
          "src/lib/hooks/index.ts",
          "src/lib/results/index.ts",
          "src/lib/stac/index.ts",
          "src/lib/utils/index.ts"
        ],
        "configFiles": [
          "Dockerfile",
          "package.json",
          "tsconfig.json",
          "vite.config.ts"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [
          "tests/setup.ts",
          "tests/stac-searcher.test.ts",
          "vitest.config.ts"
        ],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".yml": 3,
          ".yaml": 1,
          ".md": 1,
          ".html": 4,
          ".ts": 23,
          ".tsx": 2,
          ".json": 4,
          ".css": 2
        }
      }
    },
    {
      "id": 1134493195,
      "name": "LAN-Orangutan",
      "displayName": "LAN Orangutan",
      "description": "LAN Orangutan is a lightweight network scanner with persistent device labeling, multi-network support, and Tailscale integration. Built by 291 Group.",
      "summary": "The Problem\n\nTracking devices on a home or office LAN is a pain. Routers suck at it, nmap output is ugly, and every time you reboot, you forget which Raspberry Pi is which. Most network scanners spit out a list of IPs and call it a day—no labels, no history, no help when you’re juggling multiple VLANs or Tailscale networks.\n\nWhat This Does\n\nLAN-Orangutan gives you a real device tracker with persistent labels, notes, and multi-network awareness. The CLI (cmd/orangutan/main.go) does the heavy lifting: scan networks (internal/cli/scan.go), list devices (internal/cli/list.go), and export results (internal/cli/export.go). The web UI (auto-served from orangutan serve) makes it actually usable for humans. Unlike most nmap wrappers, you get proper device grouping, search, and status tracking—check out internal/api/api.go for how the backend pulls it off.\n\nConfig is dead simple—tweak config.example.ini, drop it in your user directory, and you’re set. Tailscale integration (internal/network/tailscale.go) means you can scan remote networks without SSH tunnels or VPN voodoo. Device info sticks between scans, so your labels don’t vanish every time your router hands out new IPs.\n\nReal-World Use\n\nSay you’ve got a homelab with a couple VLANs and a Tailscale mesh. Install nmap, grab the Orangutan binary, and run:\n\nsudo ./orangutan serve\n\nHit http://localhost:291 and you’ll see every device—grouped, labeled, searchable. Track your Pi cluster, see which laptop is online, add notes (“don’t reboot this!”), and export to CSV when your boss wants a spreadsheet. Use orangutan scan all to sweep every subnet, or orangutan list --online --format json if you’re piping data into something else.\n\nThe Bottom Line\n\nIf you want real device tracking for your LAN or homelab, this is miles ahead of cobbling together nmap scripts and sticky notes. Setup is easy, the UI doesn’t suck, and the labeling actually works. Not for people who think their router’s device list is “good enough.” If you care about your network, Orangutan is worth running.",
      "url": "https://github.com/yebeai/LAN-Orangutan",
      "language": null,
      "stars": 1,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "291-Group/LAN-Orangutan",
        "url": "https://github.com/291-Group/LAN-Orangutan",
        "stars": 148
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 14, 2026",
      "updatedAt": "January 14, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 53,
        "directories": {
          ".github": 2,
          "(root)": 10,
          "cli": 1,
          "cmd": 1,
          "docs": 4,
          "internal": 23,
          "scanner": 3,
          "scripts": 1,
          "snap": 1,
          "systemd": 1,
          "web": 6
        },
        "languages": {
          "YAML": 3,
          "Markdown": 3,
          "Go": 19,
          "Shell": 3,
          "JavaScript": 2,
          "CSS": 2,
          "HTML": 2,
          "Python": 2,
          "PHP": 3
        },
        "frameworks": [
          "Express",
          "Docker"
        ],
        "packageManager": "pip",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "cmd/orangutan/main.go",
          "internal/web/static/app.js",
          "internal/web/templates/index.html",
          "web/assets/app.js"
        ],
        "configFiles": [
          "Dockerfile",
          "Makefile",
          "go.mod",
          "scanner/requirements.txt"
        ],
        "dependencies": [
          "go.mod",
          "scanner/requirements.txt"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md",
          "docs/INSTALL.md",
          "docs/LO1.png",
          "docs/LO2.png",
          "docs/TROUBLESHOOTING.md"
        ],
        "fileTypes": {
          ".yml": 2,
          ".md": 3,
          ".go": 19,
          ".ini": 1,
          ".png": 2,
          ".mod": 1,
          ".sum": 1,
          ".sh": 3,
          ".js": 2,
          ".svg": 2,
          ".css": 2,
          ".html": 2,
          ".txt": 1,
          ".py": 2,
          ".yaml": 1,
          ".service": 1,
          ".php": 3
        }
      }
    },
    {
      "id": 1134352925,
      "name": "Claude-Cowork",
      "displayName": "Claude Cowork",
      "description": "OpenSource Claude Cowork. A desktop AI assistant that helps you with programming, file management, and any task you can describe.",
      "summary": "The Problem\nManaging programming tasks and file operations through a terminal can be a nightmare. You get no visual feedback, can’t track multiple sessions easily, and it’s a pain to inspect tool outputs. If you've ever dealt with a complex codebase, you know that the terminal is not exactly user-friendly.\n\nWhat This Does\nEnter Open Claude Cowork, a desktop AI assistant that’s designed to smooth out these rough edges. It's built on the back of Claude Code, which means it shares the same configuration file found in ~/.claude/settings.json. This allows you to reuse your existing API keys and settings without a hassle.\n\nThe file structure shows us where the magic happens: src/electron/main.ts is where the main Electron app initializes, while src/electron/ipc-handlers.ts manages your inter-process communication, letting you interact with the app smoothly. Need to manage files or run commands? Check out the src/electron/libs/runner.ts where the heavy lifting occurs.\n\nReal-World Use\nImagine you’re deep into a project and need to move files around and execute commands without jumping back and forth between your IDE and terminal. With Open Claude Cowork, you can create a session with a custom working directory, run commands, and manage files all from a single interface. For example, you could have a session that looks something like this:\n\nStart a session with a specific directory\nclaude run --dir /path/to/project\n\nFrom there, you can ask Claude to run tests, check for bugs, or even edit code, all while getting real-time feedback in a visual format.\n\nThe Bottom Line\nOpen Claude Cowork is a solid tool for those who want to enhance their coding experience with a friendly AI assistant. It’s great for developers who feel constrained by terminal-only environments. However, if you’re working on smaller projects or scripting tasks, this might be overkill. For teams that need a collaborative edge, though, it's worth a look. Just don’t expect it to solve all your problems—it's an assistant, not a miracle worker.",
      "url": "https://github.com/yebeai/Claude-Cowork",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "DevAgentForge/Open-Claude-Cowork",
        "url": "https://github.com/DevAgentForge/Open-Claude-Cowork",
        "stars": 2943
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 14, 2026",
      "updatedAt": "January 14, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 44,
        "directories": {
          "(root)": 16,
          "assets": 1,
          "src": 27
        },
        "languages": {
          "Markdown": 2,
          "JSON": 7,
          "JavaScript": 1,
          "HTML": 1,
          "TypeScript": 16,
          "CSS": 2,
          "TSX": 8
        },
        "frameworks": [
          "React",
          "Express"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "index.html",
          "src/electron/main.ts",
          "src/ui/App.tsx"
        ],
        "configFiles": [
          "package.json",
          "src/electron/tsconfig.json",
          "tsconfig.json",
          "vite.config.ts"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [
          "src/electron/test.ts"
        ],
        "docs": [
          "README.md",
          "README_ZH.md"
        ],
        "fileTypes": {
          ".md": 2,
          ".jpg": 1,
          ".lock": 1,
          ".png": 2,
          ".json": 7,
          ".js": 1,
          ".html": 1,
          ".ts": 16,
          ".cts": 1,
          ".css": 2,
          ".tsx": 8,
          ".svg": 1
        }
      }
    },
    {
      "id": 1134345761,
      "name": "Finance-Guru",
      "displayName": "Finance Guru",
      "description": "Finance Guru™ - AI-powered family office system built on BMAD-CORE™ v6 architecture",
      "summary": "The Problem\n\nManaging investments sucks if you’re not a quant. Every question turns into a scavenger hunt across Yahoo Finance, spreadsheets, random Google searches, and half-baked calculators. You’re constantly guessing if you missed something. The result: you don’t trust your own analysis.\n\nWhat This Does\n\nFinance Guru™ turns your portfolio into a circus of AI specialists, each with a job. Fire off /finance-orchestrator and eight agents jump in—files like .claude/commands/fin-guru/agents/quant-analyst.md and .claude/commands/fin-guru/agents/strategy-advisor.md spell out what each agent does. The brains sit in BMAD-CORE™ v6 (whatever that means, probably some internal magic), but config lives in .beads/config.yaml—it handles agent settings, tool paths, and who gets to see what.\n\nAnalysis tools aren’t just glued together scripts. Everything runs through Pydantic models, calculator classes, and CLI wrappers—check out .claude/hooks/load-fin-core-config.ts for how config loads, or any of the cli.py files (see the example in the README) for actual tool usage. Agents call these tools, coordinate answers, and make sure you don’t blow up your portfolio.\n\nReal-World Use\n\nLet’s say you want to add TSLA to your portfolio. Forget manual googling. One command triggers:\n\nuv run python src/utils/momentumcli.py TSLA --days 90\nuv run python src/analysis/riskmetricscli.py TSLA --days 90 --benchmark SPY\nuv run python src/analysis/correlationcli.py TSLA PLTR NVDA --days 90\n\nThe orchestrator pulls market data, runs risk metrics, checks correlations, and validates compliance. You get a decision backed by actual math, not gut feeling.\n\nThe Bottom Line\n\nFinance Guru™ is for people who want real answers—not AI-generated nonsense. The architecture is overkill for hobbyists, but if you’ve got more money than patience (or just want to flex), it’s perfect. You get clarity without spreadsheet hell. Downsides? It’s private-license only, so good luck customizing. If you’re tired of juggling tabs and second-guessing everything, this is the upgrade.",
      "url": "https://github.com/yebeai/Finance-Guru",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "AojdevStudio/Finance-Guru",
        "url": "https://github.com/AojdevStudio/Finance-Guru",
        "stars": 284
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1531482615713-2afd69097998?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 14, 2026",
      "updatedAt": "January 14, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          ".beads": 5,
          ".claude": 72,
          ".cursor": 1,
          "(root)": 9,
          ".rbp": 2,
          "apps": 55,
          "docs": 7,
          "fin-guru": 49
        },
        "languages": {
          "Markdown": 110,
          "YAML": 8,
          "JSON": 16,
          "Shell": 6,
          "TypeScript": 26,
          "Python": 2,
          "TSX": 7,
          "CSS": 1,
          "SQL": 1
        },
        "frameworks": [
          "React",
          "Next.js",
          "Tailwind",
          "Docker"
        ],
        "packageManager": "npm",
        "hasDocker": true,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "apps/plaid-dashboard/db/src/index.ts",
          "apps/plaid-dashboard/engine/src/db/index.ts",
          "apps/plaid-dashboard/engine/src/index.ts",
          "apps/plaid-dashboard/engine/src/providers/plaid/index.ts"
        ],
        "configFiles": [
          ".claude/hooks/package.json",
          ".claude/hooks/tsconfig.json",
          ".env.example",
          "apps/plaid-dashboard/.env.example",
          "apps/plaid-dashboard/dashboard/next.config.ts",
          "apps/plaid-dashboard/dashboard/package.json",
          "apps/plaid-dashboard/dashboard/tailwind.config.ts",
          "apps/plaid-dashboard/dashboard/tsconfig.json",
          "apps/plaid-dashboard/db/package.json",
          "apps/plaid-dashboard/db/tsconfig.json",
          "apps/plaid-dashboard/docker-compose.yml",
          "apps/plaid-dashboard/engine/package.json",
          "apps/plaid-dashboard/engine/tsconfig.json",
          "apps/plaid-dashboard/package.json"
        ],
        "dependencies": [
          ".claude/hooks/package-lock.json",
          ".claude/hooks/package.json",
          "apps/plaid-dashboard/dashboard/package.json",
          "apps/plaid-dashboard/db/package.json",
          "apps/plaid-dashboard/engine/package.json",
          "apps/plaid-dashboard/package.json"
        ],
        "testFiles": [
          ".claude/commands/fin-guru/agents/dividend-specialist.md",
          ".claude/commands/fin-guru/agents/margin-specialist.md",
          ".claude/commands/fin-guru/agents/onboarding-specialist.md",
          ".claude/commands/fin-guru/agents/teaching-specialist.md",
          ".claude/skills/backend-dev-guidelines/resources/testing-guide.md",
          ".claude/skills/route-tester/SKILL.md",
          ".rbp/current-spec-bead",
          ".rbp/test-command",
          "fin-guru/agents/dividend-specialist.md",
          "fin-guru/agents/margin-specialist.md",
          "fin-guru/agents/onboarding-specialist.md",
          "fin-guru/agents/specialist.md",
          "fin-guru/agents/teaching-specialist.md"
        ],
        "docs": [
          ".beads/README.md",
          ".claude/hooks/README.md",
          ".claude/skills/FinanceReport/StyleGuide.md",
          ".claude/skills/FinanceReport/VisGuide.md",
          ".claude/skills/README.md",
          ".claude/skills/backend-dev-guidelines/SKILL.md",
          ".claude/skills/backend-dev-guidelines/resources/architecture-overview.md",
          ".claude/skills/backend-dev-guidelines/resources/async-and-errors.md",
          ".claude/skills/backend-dev-guidelines/resources/complete-examples.md",
          ".claude/skills/backend-dev-guidelines/resources/configuration.md",
          ".claude/skills/backend-dev-guidelines/resources/database-patterns.md",
          ".claude/skills/backend-dev-guidelines/resources/middleware-guide.md",
          ".claude/skills/backend-dev-guidelines/resources/routing-and-controllers.md",
          ".claude/skills/backend-dev-guidelines/resources/sentry-and-monitoring.md",
          ".claude/skills/backend-dev-guidelines/resources/services-and-repositories.md",
          ".claude/skills/backend-dev-guidelines/resources/testing-guide.md",
          ".claude/skills/backend-dev-guidelines/resources/validation-patterns.md",
          ".claude/skills/fin-core/README.md",
          "LICENSE",
          "README.md",
          "apps/plaid-dashboard/README.md",
          "apps/plaid-dashboard/docs/access-control-policy.md",
          "apps/plaid-dashboard/docs/access-control-policy.pdf",
          "apps/plaid-dashboard/docs/data-retention-policy.md",
          "apps/plaid-dashboard/docs/data-retention-policy.pdf",
          "apps/plaid-dashboard/docs/information-security-policy.md",
          "apps/plaid-dashboard/docs/information-security-policy.pdf",
          "docs/api.md",
          "docs/contributing.md",
          "docs/hooks.md",
          "docs/images/finance-guru-architecture-diagram.png",
          "docs/images/finance-guru-architecture.png",
          "docs/images/finance-guru-logo.png",
          "docs/index.md",
          "fin-guru/README.md"
        ],
        "fileTypes": {
          ".md": 110,
          ".yaml": 7,
          ".jsonl": 1,
          ".json": 16,
          ".sh": 6,
          ".ts": 26,
          ".py": 2,
          ".mdc": 1,
          ".example": 2,
          ".lock": 2,
          ".mjs": 1,
          ".tsx": 7,
          ".css": 1,
          ".sql": 1,
          ".yml": 1,
          ".pdf": 3,
          ".png": 4
        }
      }
    },
    {
      "id": 1133803979,
      "name": "llm-god",
      "displayName": "llm god",
      "description": "Desktop app to multi-prompt ChatGPT, Gemini and more at the same time!",
      "summary": "The Problem\nIf you're tired of juggling multiple tabs for different LLMs, copying and pasting prompts like it's 1999, and generally feeling like a hamster on a wheel, this app is for you. It consolidates the chaos into one neat desktop application, letting you prompt ChatGPT, Gemini, and a few others all at once. Seriously, who has the time to manage multiple interfaces?\n\nWhat This Does\nThe llm-god app is structured to let you multi-prompt various LLM interfaces from a single window. The main functionality resides in src/dropdown.ts, where you can easily select which LLM to use. The index.html file serves as the UI entry point, while the dev-runner.js handles the app's startup process. You can even plug in your text or screenshots directly into the input area. Want to kick off the prompts? Just hit Ctrl + Enter. Easy as pie.\n\nThe app's testing suite is in the tests folder, which covers various components like dropdowns and renderer logic. This should give you peace of mind if you're diving into the code—at least someone is testing this stuff.\n\nReal-World Use\nImagine you're a developer working on a project that requires insights from both ChatGPT and Gemini. You fire up llm-god, select both LLMs from the dropdown in the bottom right, type your prompt, and hit Ctrl + Enter. Instantly, both models churn out responses, saving you the hassle of switching tabs and losing your train of thought. If you're developing or just brainstorming ideas, this single window is a huge productivity boost.\n\nThe Bottom Line\nllm-god is a handy tool for anyone who regularly interacts with multiple LLMs. It's not perfect—Windows-only and lacking some polish, like code signing—but the core functionality is solid. If you're a developer or a power user, this app can save you time and sanity. Just be prepared to deal with the occasional warning from Windows about untrusted software. Trust me, the code is worth your scrutiny.",
      "url": "https://github.com/yebeai/llm-god",
      "language": null,
      "stars": 1,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "czhou578/llm-god",
        "url": "https://github.com/czhou578/llm-god",
        "stars": 245
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1542831371-29b0f74f9713?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 13, 2026",
      "updatedAt": "January 13, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 45,
        "directories": {
          ".github": 1,
          "(root)": 16,
          "__tests__": 10,
          "answer_scrapers": 2,
          "src": 16
        },
        "languages": {
          "YAML": 1,
          "Markdown": 3,
          "TypeScript": 20,
          "JavaScript": 4,
          "HTML": 5,
          "JSON": 4,
          "CSS": 1
        },
        "frameworks": [
          "React"
        ],
        "packageManager": "npm",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "index.html",
          "src/main.ts"
        ],
        "configFiles": [
          "jest.config.js",
          "package.json",
          "tsconfig.json"
        ],
        "dependencies": [
          "package-lock.json",
          "package.json"
        ],
        "testFiles": [
          "__tests__/dropdown.test.ts",
          "__tests__/main.ipc.test.ts",
          "__tests__/main.test.ts",
          "__tests__/main.views.test.ts",
          "__tests__/main.windows.test.ts",
          "__tests__/renderer.test.ts",
          "__tests__/save_edited_prompts.test.ts",
          "__tests__/save_prompts.test.ts",
          "__tests__/select_model_renderer.test.ts",
          "__tests__/utilities.test.ts"
        ],
        "docs": [
          "LICENSE",
          "readme.md"
        ],
        "fileTypes": {
          ".yml": 1,
          ".md": 3,
          ".ts": 20,
          ".js": 4,
          ".ico": 2,
          ".cjs": 1,
          ".png": 1,
          ".html": 5,
          ".json": 4,
          ".cts": 1,
          ".css": 1
        }
      }
    },
    {
      "id": 1133775173,
      "name": "llama.cpp",
      "displayName": "llama.cpp",
      "description": "LLM inference in C/C++",
      "summary": "The Problem\n\nMost LLM libraries are bloated, come with a tangled web of Python dependencies, and need a GPU farm to run at a reasonable speed. If you just want to run a model locally—maybe on a laptop, maybe on some weird cloud VM—you’re usually stuck wrangling Docker images or praying Conda doesn’t break. There’s no clean, dependency-free, C/C++ solution that just works.\n\nWhat This Does\n\nllama.cpp is pure C/C++ code for running LLM inference. No Python. No external libraries. The main logic sits in llama.cpp and llama-cli, which handles model loading and inference directly. Hardware support is serious: check out .devops/cuda.Dockerfile for NVIDIA GPU setups, or the Metal/AVX code paths optimized for Apple and x86 chips. Need RISC-V or AMD? There’s a Dockerfile for that. Quantization, including 1.5-bit and up, is baked into the core logic—no need for separate scripts or toolchains. The build system doesn't assume you want Docker or Nix, but if you do, they've got you covered in devops/.\n\nReal-World Use\n\nSay you want to run Gemma-3B IT on your Macbook or Linux box. Clone the repo, build with make, and run:\n\nllama-cli -hf ggml-org/gemma-3-1b-it-GGUF\n\nNo CUDA? No problem. Want OpenAI-compatible API? Swap in llama-server. Need Docker for reproducibility? Grab one of the many Dockerfiles in .devops/. You can even run with mixed CPU/GPU if your VRAM is tiny—no out-of-memory crashes.\n\nThe Bottom Line\n\nllama.cpp is for people who hate dependencies and just want local LLM inference that isn’t a dumpster fire. The code is surprisingly readable, deployment is flexible, and it runs on almost anything. If you’re prototyping, hacking, or shipping AI features without a Python monolith, use it. If you like GUIs and hand-holding, look elsewhere.",
      "url": "https://github.com/yebeai/llama.cpp",
      "language": null,
      "stars": 1,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "ggml-org/llama.cpp",
        "url": "https://github.com/ggml-org/llama.cpp",
        "stars": 96079
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1607799279861-4dd421887fb3?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 13, 2026",
      "updatedAt": "January 13, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 200,
        "directories": {
          "(root)": 25,
          ".devops": 23,
          ".gemini": 1,
          ".github": 37,
          "benches": 5,
          "ci": 3,
          "cmake": 10,
          "common": 41,
          "docs": 50,
          "examples": 5
        },
        "languages": {
          "Docker": 10,
          "Shell": 3,
          "JSON": 5,
          "YAML": 36,
          "Markdown": 45,
          "HTML": 1,
          "C++": 19,
          "C/C++ Header": 19,
          "Python": 4,
          "Swift": 1
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          "CMakeLists.txt",
          "Makefile",
          "common/CMakeLists.txt",
          "examples/CMakeLists.txt",
          "examples/batched.swift/Makefile"
        ],
        "dependencies": [],
        "testFiles": [
          ".devops/llama-cpp-cuda.srpm.spec",
          ".devops/llama-cpp.srpm.spec",
          "common/speculative.cpp",
          "common/speculative.h",
          "docs/development/debugging-tests.md"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md",
          "ci/README-MUSA.md",
          "ci/README.md",
          "cmake/license.cmake",
          "docs/android.md",
          "docs/android/imported-into-android-studio.jpg",
          "docs/backend/BLIS.md",
          "docs/backend/CANN.md",
          "docs/backend/CUDA-FEDORA.md",
          "docs/backend/OPENCL.md",
          "docs/backend/SYCL.md",
          "docs/backend/ZenDNN.md",
          "docs/backend/hexagon/CMakeUserPresets.json",
          "docs/backend/hexagon/README.md",
          "docs/backend/hexagon/developer.md",
          "docs/backend/zDNN.md",
          "docs/build-riscv64-spacemit.md",
          "docs/build-s390x.md",
          "docs/build.md",
          "docs/development/HOWTO-add-model.md",
          "docs/development/debugging-tests.md",
          "docs/development/llama-star/idea-arch.key",
          "docs/development/llama-star/idea-arch.pdf",
          "docs/development/parsing.md",
          "docs/development/token_generation_performance_tips.md",
          "docs/docker.md",
          "docs/function-calling.md",
          "docs/install.md",
          "docs/llguidance.md",
          "docs/multimodal.md",
          "docs/multimodal/MobileVLM.md",
          "docs/multimodal/gemma3.md",
          "docs/multimodal/glmedge.md",
          "docs/multimodal/granitevision.md",
          "docs/multimodal/llava.md",
          "docs/multimodal/minicpmo2.6.md",
          "docs/multimodal/minicpmo4.0.md",
          "docs/multimodal/minicpmv2.5.md",
          "docs/multimodal/minicpmv2.6.md",
          "docs/multimodal/minicpmv4.0.md",
          "docs/multimodal/minicpmv4.5.md",
          "docs/ops.md",
          "docs/ops/BLAS.csv",
          "docs/ops/CANN.csv",
          "docs/ops/CPU.csv",
          "docs/ops/CUDA.csv",
          "docs/ops/Metal.csv",
          "docs/ops/OpenCL.csv",
          "docs/ops/SYCL.csv",
          "docs/ops/Vulkan.csv",
          "docs/ops/WebGPU.csv",
          "docs/ops/ZenDNN.csv",
          "docs/ops/zDNN.csv",
          "docs/preset.md",
          "examples/batched.swift/README.md"
        ],
        "fileTypes": {
          ".dockerfile": 10,
          ".spec": 2,
          ".nix": 10,
          ".sh": 3,
          ".json": 5,
          ".yml": 35,
          ".md": 45,
          ".disabled": 1,
          ".yaml": 1,
          ".txt": 3,
          ".html": 1,
          ".log": 1,
          ".cmake": 8,
          ".in": 3,
          ".cpp": 19,
          ".h": 19,
          ".hpp": 1,
          ".py": 4,
          ".jpg": 1,
          ".key": 1,
          ".pdf": 1,
          ".csv": 11,
          ".swift": 1
        }
      }
    },
    {
      "id": 1133770707,
      "name": "tailspin",
      "displayName": "tailspin",
      "description": "🌀 A log file highlighter",
      "summary": "Tailspin: A Log File Highlighter That Actually Works\n\nThe Problem\nWorking with log files can be a pain. You often need to sift through mountains of text without any visual cues, making it hard to spot important information. You end up squinting at lines of text, which is as fun as a toothache. Enter tailspin—a tool designed to highlight key aspects of your log files without making you jump through hoops.\n\nWhat This Does\ntailspin operates by reading log files line by line and applying regex patterns to identify dates, IP addresses, UUIDs, and other useful data. No configuration is required, so you can just run tspin application.log and see the highlights. The Cargo.toml file contains the dependencies for the project, reflecting the simplicity and efficiency of this tool.\n\nIf you want to customize the highlighting, you can create a theme.toml in ~/.config/tailspin, which is straightforward and allows for personalization without diving deep into code.\n\nReal-World Use\nImagine you're debugging a production issue with a log file. Instead of manually searching for patterns, just pipe the log output through tspin. For example:\n\nkubectl logs [pod_name] --follow | tspin\n\nYou get an instant visual breakdown of dates, URLs, and error messages. This time-saving trick allows you to focus on what matters instead of wasting time deciphering log lines.\n\nThe Bottom Line\ntailspin is an incredibly useful tool for developers who work with logs regularly. Its no-nonsense approach saves you time and headache. The lack of a complex setup means you can dive right in, though the single star on GitHub suggests it might not be on everyone’s radar yet. If you handle log files often, give it a shot. You might find it’s just what you needed to cut through the noise.",
      "url": "https://github.com/yebeai/tailspin",
      "language": null,
      "stars": 1,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "bensadeh/tailspin",
        "url": "https://github.com/bensadeh/tailspin",
        "stars": 7681
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 13, 2026",
      "updatedAt": "January 13, 2026",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 100,
        "directories": {
          "(root)": 13,
          ".github": 4,
          "assets": 15,
          "completions": 3,
          "example-logs": 5,
          "man": 1,
          "src": 52,
          "tests": 3,
          "util": 4
        },
        "languages": {
          "YAML": 4,
          "Markdown": 2,
          "TOML": 4,
          "Shell": 5,
          "Rust": 54
        },
        "frameworks": [],
        "packageManager": "cargo",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "src/lib.rs",
          "src/main.rs"
        ],
        "configFiles": [
          "Cargo.toml"
        ],
        "dependencies": [
          "Cargo.toml"
        ],
        "testFiles": [
          ".github/workflows/BuildAndTest.yml",
          "src/core/tests/escape_code_converter.rs",
          "tests/files/empty.log",
          "tests/integration_tests.rs",
          "tests/utils.rs"
        ],
        "docs": [
          "CHANGELOG.md",
          "README.md"
        ],
        "fileTypes": {
          ".yml": 4,
          ".md": 2,
          ".lock": 2,
          ".toml": 4,
          ".png": 15,
          ".bash": 1,
          ".fish": 1,
          ".zsh": 1,
          ".nix": 1,
          ".1": 1,
          ".rs": 54,
          ".log": 1,
          ".sh": 3,
          ".adoc": 1
        }
      }
    },
    {
      "id": 605572406,
      "name": "YOLOv8_Segmentation_DeepSORT_TRACKING_SpeedEstimation",
      "displayName": "YOLOv8 Segmentation DeepSORT TRACKING SpeedEstimation",
      "description": "Estimating speed using YoloV8 , Google Colab by modifying predict.py Script in segmentation folder.",
      "summary": "The Problem\n\nTracking objects is nice. Counting them is useful. But if you’re trying to measure how fast something’s moving—cars, people, whatever—most open-source tools just shrug and walk away. Wrangling speed estimation from YOLOv8 and DeepSORT isn’t exactly plug-and-play, especially if you want to do it in Google Colab without writing your own tracking logic from scratch.\n\nWhat This Does\n\nYou get object detection, segmentation, tracking, and speed estimation all glued together in a single notebook: CopyofYOLOv8objecttrackingcountingspeed.ipynb. The magic sauce is a hacked-up version of the usual predict.py inside the segmentation folder, tweaked to spit out speed info alongside the usual bounding boxes and masks. Everything runs in Colab, so you don’t need a local GPU or a Frankenstein environment.\n\nThe repo is tiny—just a notebook and a README—but that makes it easy to dive in and see exactly what’s happening. Want to know how speed is calculated? It’s all right there. No hidden bash scripts or weird configs. The notebook handles detection with YOLOv8, tracks objects using DeepSORT, and estimates speed by calculating pixel movement across frames (and, yes, you’ll have to deal with scaling if you want real-world units).\n\nReal-World Use\n\nLet’s say you want to track cars in a traffic video and get their speeds. You toss your video into Colab, run the notebook, and watch as it spits out bounding boxes, track IDs, and speed values frame-by-frame. Here’s a workflow snippet:\n\nvideopath = \"/content/mytrafficvideo.mp4\"\nresults = runspeedestimation(videopath)  # function in notebook\nfor obj in results:\n    print(obj['track_id'], obj['speed'])\n\nYou get per-object speed estimates, ready for plotting or yelling at city planners.\n\nThe Bottom Line\n\nIt’s barebones, but it works. If you actually need object speed from YOLOv8 and DeepSORT, and you want to play in Colab, this repo saves you a bunch of headache. Don’t expect polished code or a fancy UI. Good for quick experiments, not production. If you want more features, you’ll have to roll up your sleeves.",
      "url": "https://github.com/yebeai/YOLOv8_Segmentation_DeepSORT_TRACKING_SpeedEstimation",
      "language": "Jupyter Notebook",
      "stars": 2,
      "forks": 0,
      "topics": [],
      "parent": null,
      "type": "original",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 23, 2023",
      "updatedAt": "July 14, 2025",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 2,
        "directories": {
          "(root)": 2
        },
        "languages": {
          "Markdown": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".ipynb": 1,
          ".md": 1
        }
      }
    },
    {
      "id": 951980885,
      "name": "ecommerce-chatbot",
      "displayName": "ecommerce chatbot",
      "description": "This repo contains an Agentic Chatbot (Ari) to query a Database and get Order Status Delivery , Request to speak with a Customer Care Agent or ask about Return. All done using Google Gemini AI.",
      "summary": "The Problem\nCustomers often have questions about their orders, return policies, and need quick assistance without waiting on hold forever. A typical support system can be a mess—long wait times and unhelpful responses. Enter the need for a chatbot that can handle these common inquiries efficiently.\n\nWhat This Does\nThe ecommerce-chatbot repo provides a straightforward solution with Ari, an intelligent chatbot built using Google Gemini for natural language understanding. The architecture is modular, with different agents handling specific tasks. For instance, src/agents/orderstatusagent.py checks the order status using alphanumeric IDs, while src/agents/returnpolicyagent.py delivers return policy information from data/policies.json.\n\nThe bot’s interface is powered by Gradio, making it user-friendly for customers. The main application entry point is in app.py, where the bot is initialized and run. Plus, if users need human support, the humanrepagent.py guides them through providing their contact details for follow-up.\n\nReal-World Use\nImagine a customer trying to track their order. They type their order ID into the chat interface. The bot, through orderstatusagent.py, quickly queries the database (handled by SQLAlchemy in src/db/database.py) and responds with the order status. If the customer wants to return something, they can ask about the return policy, and the bot pulls the relevant information from policies.json. \n\nHere’s a quick snippet of how you might interact with the bot:\n\nresponse = orderstatusagent.getorderstatus(\"ABC123XYZ4567890\")\nprint(response)  # \"Your order is currently in transit and should arrive by Thursday.\"\n\nThe Bottom Line\nAri is a solid tool for e-commerce businesses looking to automate customer support without drowning in complexity. It’s well-structured, making it easy to extend with additional features if needed. However, for smaller businesses or simple use cases, this might be overkill. If you need a quick solution for handling common queries, Ari could be your go-to.",
      "url": "https://github.com/yebeai/ecommerce-chatbot",
      "language": "Python",
      "stars": 1,
      "forks": 0,
      "topics": [],
      "parent": null,
      "type": "original",
      "image": "https://images.unsplash.com/photo-1504639725590-34d0984388bd?w=800&h=400&fit=crop&q=80",
      "forkedAt": "March 20, 2025",
      "updatedAt": "June 30, 2025",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 55,
        "directories": {
          "(root)": 12,
          ".github": 1,
          ".space": 1,
          "assets": 2,
          "data": 2,
          "docs": 7,
          "src": 26,
          "tests": 4
        },
        "languages": {
          "YAML": 4,
          "Markdown": 8,
          "Python": 32,
          "JSON": 1
        },
        "frameworks": [
          "Flask",
          "Docker"
        ],
        "packageManager": "pip",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "app.py"
        ],
        "configFiles": [
          ".env.example",
          "Dockerfile",
          "docker-compose.yml",
          "requirements.txt"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [
          "docs/development/testing.md",
          "tests/__init__.py",
          "tests/conftest.py",
          "tests/test_fallback_llm.py",
          "tests/test_main_flows.py"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "docs/EVALUATION.md",
          "docs/development/SETUP.md",
          "docs/development/architecture.md",
          "docs/development/deployment.md",
          "docs/development/testing.md",
          "docs/index.md",
          "docs/usage.md"
        ],
        "fileTypes": {
          ".example": 1,
          ".yml": 4,
          ".md": 8,
          ".py": 32,
          ".png": 2,
          ".csv": 1,
          ".json": 1,
          ".txt": 2
        }
      }
    },
    {
      "id": 1004131322,
      "name": "ICCLexAI",
      "displayName": "ICCLexAI",
      "description": " AI-Powered Evidence Analysis Platform for ICC Legal Professionals - Production Ready with React Frontend & Groq AI Integration",
      "summary": "The Problem\n\nLegal professionals at the ICC drown in evidence—audio, video, PDFs—most of it unstructured, and manually parsing metadata or context is a nightmare. Nobody wants to dig through EXIF data or write their own Python scripts just to get GPS or timestamps. And let's be honest: relying on interns to summarize hundreds of submissions is a recipe for errors.\n\nWhat This Does\n\nICCLexAI grabs your evidence files, runs them through multimodal LLMs (like DeepSeek R1 Distill Llama 70B and Llama 3.3 70B), and spits out legal summaries, extracted metadata, and context—all via a React frontend (apps/frontend/src/App.tsx, AgenticDashboard.tsx) or a legacy Streamlit UI if you’re nostalgic. The backend (apps/backend/fastapibackend.py) handles async file processing, routes uploads, and talks to Groq for AI inference. You get real-time status, drag-and-drop file uploads, and instant results. Redis is wired in for caching/rate limits, so you don’t get throttled mid-upload.\n\nConfiguration is dead simple: env vars (GROQAPIKEY, etc.) and Docker deployment (Dockerfile.production, nginx.conf). Want to swap models or tweak token limits? Edit the model config directly—no cryptic YAML hell.\n\nReal-World Use\n\nLet’s say you’re a prosecutor with a folder full of PDFs and JPEGs. Fire up the React frontend, drag them into FileUploadArea.tsx, and watch AI-generated legal descriptions pop up in seconds. Need EXIF metadata? It’s there. Want to run this from the terminal instead? Just launch fastapibackend.py and hit the API with a POST request. Here’s a dead-simple curl example:\n\ncurl -X POST -F \"file=@evidence.pdf\" http://localhost:8000/analyze\n\nGet JSON back with legal context, metadata, and AI summary. No more copy-pasting into ChatGPT.\n\nThe Bottom Line\n\nICCLexAI is legit if you’re dealing with complex evidence and want AI to do the grunt work. The frontend is slick, the backend is fast, and the integration with Groq delivers real-time analysis—no waiting around. Not lightweight: this isn’t for your weekend hackathon. If you need production-ready, plug-and-play AI for legal evidence, it’s worth your time. If you just want a fancy file uploader, look elsewhere.",
      "url": "https://github.com/yebeai/ICCLexAI",
      "language": "Python",
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": null,
      "type": "original",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "June 18, 2025",
      "updatedAt": "June 18, 2025",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 88,
        "directories": {
          "(root)": 16,
          ".github": 2,
          "apps": 29,
          "docker": 5,
          "docs": 17,
          "libs": 7,
          "tools": 12
        },
        "languages": {
          "YAML": 3,
          "Markdown": 26,
          "Python": 12,
          "JSON": 5,
          "JavaScript": 2,
          "TSX": 11,
          "TypeScript": 3,
          "CSS": 3,
          "TOML": 1,
          "Shell": 3
        },
        "frameworks": [
          "React",
          "Flask",
          "FastAPI",
          "Tailwind",
          "Docker"
        ],
        "packageManager": "pip",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "apps/frontend/src/App.tsx"
        ],
        "configFiles": [
          "apps/frontend/.eslintrc.cjs",
          "apps/frontend/Dockerfile.production",
          "apps/frontend/package.json",
          "apps/frontend/tailwind.config.js",
          "apps/frontend/tsconfig.json",
          "apps/frontend/vite.config.ts",
          "docker/Dockerfile",
          "docker/Dockerfile.fastapi",
          "docker/Dockerfile.react",
          "docker/Dockerfile.streamlit",
          "docker/docker-compose.yml",
          "pyproject.toml",
          "requirements.txt"
        ],
        "dependencies": [
          "apps/frontend/package-lock.json",
          "apps/frontend/package.json",
          "pyproject.toml",
          "requirements.txt"
        ],
        "testFiles": [
          "pytest.ini"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "README_NEW.md",
          "docs/AGENTIC_ICC_PRD.md",
          "docs/AGENTIC_ICC_SUCCESS.md",
          "docs/AGENTIC_IMPLEMENTATION.md",
          "docs/CORE_AGENTS_CONSOLIDATION.md",
          "docs/FINAL_SETUP_GUIDE.md",
          "docs/FRONTEND_DEPLOYMENT_STRATEGY.md",
          "docs/GROQ_ORGANIZATION.md",
          "docs/IMPLEMENTATION_SUMMARY.md",
          "docs/LAUNCH_DAY_SUCCESS.md",
          "docs/MONOREPO_REORGANIZATION_PLAN.md",
          "docs/PLATFORM_OPERATIONAL.md",
          "docs/PRD.md",
          "docs/QUICK_START.md",
          "docs/REACT_FRONTEND_GUIDE.md",
          "docs/SMART_LAUNCHER_SOLUTION.md",
          "docs/ai-models.md",
          "docs/deployment.md"
        ],
        "fileTypes": {
          ".yml": 3,
          ".md": 26,
          ".py": 12,
          ".cjs": 1,
          ".production": 1,
          ".conf": 2,
          ".json": 5,
          ".js": 2,
          ".tsx": 11,
          ".ts": 3,
          ".css": 3,
          ".fastapi": 1,
          ".react": 1,
          ".streamlit": 1,
          ".toml": 1,
          ".ini": 1,
          ".txt": 1,
          ".sh": 3,
          ".ps1": 1,
          ".bat": 4,
          ".lock": 1
        }
      }
    },
    {
      "id": 989521438,
      "name": "gdg",
      "displayName": "gdg",
      "description": "No description available",
      "summary": "The Problem\nUnderstanding complex legislation like the Finance Bill 2025 can be a nightmare for the average citizen. Legal jargon and intricate clauses aren't exactly user-friendly, leaving many people confused and disengaged. This project tackles that by providing a conversational AI agent that breaks down the bill into digestible bits, making it easier for anyone to grasp.\n\nWhat This Does\nThis repo, named gdg, contains everything you need to deploy a static site that connects users to a conversational AI agent powered by Google Dialogflow CX. The index.html file sets up the basic structure of the web interface, while styles.css provides the necessary styling to keep things looking decent. The real magic happens in script.js, which handles user interactions and connects to your Dialogflow agent for processing queries.\n\nWhen users type in their questions, the input is sent to the Dialogflow CX endpoint you configured. The response from Dialogflow gets displayed right back in the browser, allowing for an interactive Q&A experience about the Finance Bill 2025. It's straightforward and doesn’t require a build step—just clone the repo and open index.html in your browser.\n\nReal-World Use\nImagine a citizen curious about how the Finance Bill affects their taxes. They visit the deployed site at https://moses-y.github.io/GDG/, type in a question like \"How will my income tax change?\" The AI agent processes this inquiry, retrieves relevant information from Dialogflow, and responds with clear, concise data. You can easily test this locally by running index.html after cloning the repo. \n\nFor deployment, just push changes to the main branch, and GitHub Actions takes care of the rest, ensuring that updates are live almost instantly.\n\nThe Bottom Line\nThis project is a solid starting point for anyone looking to make legislation more accessible through AI. The setup is simple, and the integration with Dialogflow is straightforward, though it does require some Google Cloud setup. However, if you’re expecting a fully polished product, you’re going to need to put in some work. It's ideal for developers interested in making civic engagement easier but may not be the best fit for small-scale projects due to the overhead of setting up Dialogflow.",
      "url": "https://github.com/yebeai/gdg",
      "language": "CSS",
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": null,
      "type": "original",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "May 24, 2025",
      "updatedAt": "May 24, 2025",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 5,
        "directories": {
          ".github": 1,
          "(root)": 4
        },
        "languages": {
          "YAML": 1,
          "Markdown": 1,
          "HTML": 1,
          "JavaScript": 1,
          "CSS": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "index.html"
        ],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".yml": 1,
          ".md": 1,
          ".html": 1,
          ".js": 1,
          ".css": 1
        }
      }
    },
    {
      "id": 989525869,
      "name": "mikoko-guardian",
      "displayName": "mikoko guardian",
      "description": "An autonomous AI agent using Google ADK for Mangrove Health monitoring",
      "summary": "The Problem\n\nNobody wants to spend hours googling mangrove facts, calculating carbon credits, or piecing together restoration plans from random PDFs. Conservationists and educators need actual answers, not vague summaries or hand-waving. Mikoko Guardian tackles this by packaging real data and practical tools for Kenya’s coastal mangroves into an AI agent you can actually talk to.\n\nWhat This Does\n\nEverything important lives in mikokoguardian/agent.py. That file has the guts: species data, site info, carbon math, restoration planning, and general Q&A. It pulls from a focused dataset—five mangrove species and five coastal regions. The agent’s tools are straight-up functions like identifymangrovespecies, calculatecarbonstorage, and planrestoration. Conversational memory means you can ask follow-up questions without getting \"Sorry, I don't know\" as an answer every time. Integration with Gemini 2.0 Flash lets it handle anything outside the hardcoded data. The repo is minimal: just agent.py, a init.py to make it importable, and a .env for whatever secrets or config you need.\n\nReal-World Use\n\nSay you’re a conservation NGO in Mombasa. You want to know the carbon credits for a 10-hectare Rhizophora mucronata patch, then need a restoration plan for a site hit by illegal logging. Instead of hiring a consultant, you drop a question into the agent:\n\nfrom mikokoguardian.agent import calculatecarbonstorage, planrestoration\n\ncarbon = calculatecarbonstorage(species=\"Rhizophora mucronata\", areahectares=10)\nplan = planrestoration(site=\"Mombasa Creek\", species=\"Rhizophora mucronata\", area_hectares=10)\nprint(carbon)\nprint(plan)\n\nYou get real numbers and a customized action plan. No guesswork, no PDFs, no waiting.\n\nThe Bottom Line\n\nMikoko Guardian is clean, focused, and actually useful if you care about mangroves in Kenya. The code is simple—almost too simple for big conservation projects, but perfect for educators and small NGOs. If you want a no-nonsense AI agent that doesn’t drown you in jargon, this is it. If you need global coverage or fancy dashboards, look elsewhere.",
      "url": "https://github.com/yebeai/mikoko-guardian",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "mwanyumba7/mikoko-guardian",
        "url": "https://github.com/mwanyumba7/mikoko-guardian",
        "stars": 0
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "May 24, 2025",
      "updatedAt": "May 24, 2025",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 37,
        "directories": {
          "(root)": 2,
          "agent-venv": 32,
          "codelab": 1,
          "mikoko_guardian": 2
        },
        "languages": {
          "Markdown": 2,
          "C/C++ Header": 1,
          "Python": 2
        },
        "frameworks": [
          "FastAPI"
        ],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".md": 2,
          ".h": 1,
          ".ps1": 1,
          ".bat": 2,
          ".exe": 26,
          ".cfg": 1,
          ".py": 2
        }
      }
    },
    {
      "id": 972101968,
      "name": "retail-analytics",
      "displayName": "retail analytics",
      "description": "This repo contains Retail Analytics with LLMs for sentiment analysis",
      "summary": "The Problem\nRetail analytics can be a nightmare with the sheer volume of data and the lack of actionable insights. Businesses struggle to make sense of sales trends, customer behaviors, and product reviews. If you're trying to forecast sales or understand customer sentiment from reviews, good luck without a proper framework.\n\nWhat This Does\nThe retail-analytics repo provides a solid foundation for tackling these issues. It blends multiple functionalities into one package. For instance, the api/main.py serves up a FastAPI application to handle requests, while api/routers/reviews.py extracts sentiment from product reviews using NLP techniques. \n\nThe architecture is clean and modular. The config/ folder contains all your configuration files, like api_config.yml, which sets up the API parameters and other variables. If you want to visualize your data, the dashboard/app.py leverages Streamlit for an interactive experience. You can run everything locally or via Docker using the included docker-compose.yml.\n\nReal-World Use\nImagine you run a retail chain and want to analyze customer sentiment from reviews to improve your product offerings. You can fire up the API by running uvicorn api.main:app --reload --port 8000, and then hit the /reviews endpoint to get sentiment scores. Pair that with the sales forecasting from api/routers/forecasting.py, and you've got a solid basis for making informed business decisions.\n\nHere’s how you might set up your environment quickly:\n\ngit clone https://github.com/moses-y/retail-analytics.git\ncd retail-analytics\npython -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt\nuvicorn api.main:app --reload\n\nThe Bottom Line\nThis project is a decent option for teams looking to build a retail analytics platform without reinventing the wheel. It's got a solid structure and enough flexibility for customization, though it might be overkill for small businesses just dipping their toes into analytics. If you're serious about retail insights and have the resources, give it a shot. Otherwise, stick to simpler solutions.",
      "url": "https://github.com/yebeai/retail-analytics",
      "language": "Python",
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": null,
      "type": "original",
      "image": "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=800&h=400&fit=crop&q=80",
      "forkedAt": "April 24, 2025",
      "updatedAt": "May 19, 2025",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 118,
        "directories": {
          "(root)": 12,
          ".github": 5,
          "api": 10,
          "config": 4,
          "dashboard": 9,
          "data": 4,
          "docs": 5,
          "notebooks": 32,
          "src": 26,
          "tests": 11
        },
        "languages": {
          "Markdown": 11,
          "YAML": 8,
          "Python": 57
        },
        "frameworks": [
          "Flask",
          "Docker"
        ],
        "packageManager": "pip",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "api/main.py",
          "dashboard/app.py",
          "setup.py",
          "src/cli.py"
        ],
        "configFiles": [
          ".env.example",
          "Dockerfile",
          "Makefile",
          "docker-compose.yml",
          "requirements.txt",
          "setup.py"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [
          ".github/workflows/tests.yml",
          "tests/__init__.py",
          "tests/integration/__init__.py",
          "tests/integration/test_endpoints.py",
          "tests/integration/test_pipeline.py",
          "tests/test_api.py",
          "tests/test_models.py",
          "tests/test_preprocessing.py",
          "tests/unit/__init__.py",
          "tests/unit/test_api.py",
          "tests/unit/test_models.py",
          "tests/unit/test_preprocessing.py"
        ],
        "docs": [
          "LICENSE",
          "README.md",
          "docs/api_documentation.md",
          "docs/dashboard_guide.md",
          "docs/evaluation_metrics.md",
          "docs/implementation_plan.md",
          "docs/mlops_design.md"
        ],
        "fileTypes": {
          ".example": 1,
          ".md": 11,
          ".yml": 8,
          ".py": 57,
          ".csv": 2,
          ".jsonl": 1,
          ".ipynb": 3,
          ".png": 29,
          ".txt": 1
        }
      }
    },
    {
      "id": 610009502,
      "name": "Data-Annotation-for-Beginners",
      "displayName": "Data Annotation for Beginners",
      "description": "Data Annotation for Beginners: A Guide to Understanding and Automating the Process Using Python.",
      "summary": "The Problem\n\nGetting clean, labeled data is the first wall you hit in any machine learning project. Annotation is boring, repetitive, and easy to screw up—especially if you’re new and don’t have a fat budget for fancy tools or armies of labelers. Most guides are either hopelessly vague or assume you already know what you’re doing.\n\nWhat This Does\n\nData-Annotation-for-Beginners is a no-nonsense intro. The README.md walks you through what data annotation actually means, why it matters, and—finally—how to write Python code that automates some grunt work. It covers image classification and object detection, with real code using Keras, OpenCV, and pandas. The repo doesn’t drown you in structure: it’s just a README.md and a LICENSE file. No bloated scaffolding or mystery folders. You get direct code samples, like how to use a ResNet50 model to classify images, and step-by-step pointers for drawing bounding boxes.\n\nReal-World Use\n\nLet’s say you’ve got a folder of dog and cat photos and you want to build a classifier. You can take the Keras snippet from the README, point it at your images, and get predictions in minutes. Or maybe you’re labeling objects for a side project—there’s a section showing you how to draw on images with OpenCV. It’s the stuff you actually need to get started, not just hand-wavy theory.\n\nThe Bottom Line\n\nIf you’re new to ML or data annotation and want to stop reading buzzwords and start doing, this is a solid place to start. The code is basic but practical. Don’t expect a full annotation platform—this is for learning, not production. Perfect for beginners; if you already know how to use LabelImg, move along.",
      "url": "https://github.com/yebeai/Data-Annotation-for-Beginners",
      "language": null,
      "stars": 1,
      "forks": 0,
      "topics": [],
      "parent": null,
      "type": "original",
      "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop&q=80",
      "forkedAt": "March 5, 2023",
      "updatedAt": "March 31, 2025",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 2,
        "directories": {
          "(root)": 2
        },
        "languages": {
          "Markdown": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".md": 1
        }
      }
    },
    {
      "id": 943861639,
      "name": "Real-Estate-Chatbot",
      "displayName": "Real Estate Chatbot",
      "description": "This repo contains a Real Estate Q&A Chatbot",
      "summary": "The Problem\nReal estate inquiries can be a hassle. Buyers and renters often have a million questions about properties, neighborhoods, and pricing that can bog down agents. Chatbots can handle the repetitive stuff, but many lack the smarts to give useful answers. Enter the Real-Estate-Chatbot—it's designed to tackle those common questions without making you pull your hair out.\n\nWhat This Does\nThis chatbot leverages Flask for the backend, allowing you to set up a simple web server with app.py. It processes user input through natural language processing techniques like TF-IDF and cosine similarity found in data/qadata.py. When a user types a question, the system converts it into a vector and matches it against a database of 50+ FAQs to serve an appropriate answer.\n\nThe frontend is straightforward, using HTML, CSS, and JavaScript to create a responsive design that works on both desktop and mobile. The static/js/script.js file handles user interactions, while the templates in templates/ serve up the necessary HTML. Want to see it in action? Check out the live demo linked in the README.\n\nReal-World Use\nImagine a potential buyer visiting your real estate website late at night. They have questions about a property, but no one is there to answer. With this chatbot, they can type in their inquiries, and boom—instant replies. For instance, if they ask, “What’s the square footage of 123 Main St.?” the chatbot finds the closest match, pulls the relevant answer from its database, and responds in real-time. You can even log these queries in querylogs.json for future improvements.\n\nThe Bottom Line\nThe Real-Estate-Chatbot is a decent starting point for anyone looking to automate basic real estate inquiries. It’s not going to win any awards, but it gets the job done. If you’re a small agency or an individual agent, this can save you time and effort. Just keep in mind, if you need more complex features or a more nuanced conversation, you might want to look at more advanced solutions.",
      "url": "https://github.com/yebeai/Real-Estate-Chatbot",
      "language": "HTML",
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": null,
      "type": "original",
      "image": "https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800&h=400&fit=crop&q=80",
      "forkedAt": "March 6, 2025",
      "updatedAt": "March 11, 2025",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 21,
        "directories": {
          "(root)": 9,
          "data": 2,
          "images": 3,
          "static": 3,
          "templates": 4
        },
        "languages": {
          "Markdown": 1,
          "Python": 4,
          "JSON": 2,
          "HTML": 5,
          "CSS": 1,
          "JavaScript": 1
        },
        "frameworks": [
          "Flask"
        ],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "app.py",
          "index.html",
          "templates/index.html"
        ],
        "configFiles": [
          "requirements.txt"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".md": 1,
          ".py": 4,
          ".ipynb": 1,
          ".json": 2,
          ".png": 4,
          ".html": 5,
          ".txt": 1,
          ".css": 1,
          ".js": 1
        }
      }
    },
    {
      "id": 763039998,
      "name": "mypackage",
      "displayName": "mypackage",
      "description": "No description available",
      "summary": "The Problem\n\nPublishing Python packages shouldn't feel like assembling Ikea furniture with missing instructions. Most devs just want a clear template to get their code out there, but official docs are a maze and most tutorials skip the gritty details. This repo tries to make package publishing less painful.\n\nWhat This Does\n\nEverything important lives in mypackage/. You get a basic init.py and a single module, myModule.py, so nothing fancy—just enough to show structure. The setup.py is the minimum viable setup script, not bloated with extra metadata. All your egg-info junk ends up in mypackage.egg-info/ after building, but you don’t have to touch it.\n\nTests are dumped into tests/test.py, which is a single script, not some overengineered pytest suite. A pre-built tarball sits in dist/, so you can see what the output should look like instead of guessing. The README.md is straight to the point, no fluff.\n\nReal-World Use\n\nSay you want to package your own utility. Clone this repo, slap your functions into mypackage/myModule.py, update setup.py with your project name and details, and run:\n\npython setup.py sdist\n\nNow you’ve got a tarball in dist/ ready for upload. Want to test it? Install locally:\n\npip install dist/mypackage-0.1.tar.gz\n\nImport your module in Python:\n\nfrom mypackage.myModule import your_function\n\nDone. No magic, no mystery.\n\nThe Bottom Line\n\nIf you’re tired of bloated cookiecutter templates, this repo keeps it barebones. It’s good for beginners or anyone who wants to publish a single-file package without reading the packaging PEPs. Not great for larger projects—there’s zero structure for docs, CI, or serious testing. But for quick-and-dirty publishing, it does the job.",
      "url": "https://github.com/yebeai/mypackage",
      "language": "Python",
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": null,
      "type": "original",
      "image": "https://images.unsplash.com/photo-1531482615713-2afd69097998?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 25, 2024",
      "updatedAt": "February 25, 2024",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 12,
        "directories": {
          "(root)": 3,
          "dist": 1,
          "mypackage.egg-info": 5,
          "mypackage": 2,
          "tests": 1
        },
        "languages": {
          "Markdown": 1,
          "Python": 4
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "setup.py"
        ],
        "configFiles": [
          "setup.py"
        ],
        "dependencies": [],
        "testFiles": [
          "tests/test.py"
        ],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".md": 1,
          ".gz": 1,
          ".txt": 4,
          ".py": 4
        }
      }
    },
    {
      "id": 735262554,
      "name": "Transformers",
      "displayName": "Transformers",
      "description": "No description available",
      "summary": "The Problem\nWriting Python code can be a pain, especially when you’re stuck on a syntax issue or trying to remember that one library function. You want to generate code snippets quickly, but manually typing them out isn’t efficient. Enter the need for an AI-based solution that can generate code based on learned patterns.\n\nWhat This Does\nThe TRANSFORMERS repository fine-tunes the GPT-2 model specifically for Python code generation. You kick things off with traindata.py located in the src/data directory to prepare your dataset. Once that’s done, you run gpt2finetune.py in the src/models folder to fine-tune the model on your specific dataset. Finally, textgeneration.py in src/scripts allows you to generate code snippets on demand.\n\nBy leveraging this workflow, you can go from raw data to functional code generation in a few steps. The README gives you commands to run each part, but it’s not exactly plug-and-play unless you have a decent dataset. \n\nReal-World Use\nImagine you need to generate a function that calculates Fibonacci numbers, but you’re stuck. Instead of Googling for snippets or scratching your head, you run the model after training it on your data. You execute:\n\npython src/scripts/text_generation.py\n\nAnd voila! The model spits out a function that not only works but may also have some optimizations you didn't consider. You can tweak the dataset and retrain as needed to improve accuracy.\n\nThe Bottom Line\nThis repo is a neat starting point for anyone interested in code generation, especially if you’re comfortable with Python and deep learning basics. It’s not for small projects or casual users; you need a bit of dataset and fine-tuning magic to make it useful. If you’re serious about automating code generation, dive in—but be prepared to roll up your sleeves.",
      "url": "https://github.com/yebeai/Transformers",
      "language": "Python",
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": null,
      "type": "original",
      "image": "https://images.unsplash.com/photo-1542831371-29b0f74f9713?w=800&h=400&fit=crop&q=80",
      "forkedAt": "December 24, 2023",
      "updatedAt": "December 24, 2023",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 7,
        "directories": {
          "(root)": 3,
          "__pycache__": 1,
          "src": 3
        },
        "languages": {
          "Markdown": 1,
          "Python": 3
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [
          "requirements.txt"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".md": 1,
          ".pyc": 1,
          ".txt": 1,
          ".py": 3
        }
      }
    },
    {
      "id": 734789281,
      "name": "speedtest",
      "displayName": "speedtest",
      "description": "The `Internet Speed Test Script` is a Python tool for measuring and tracking internet performance. It utilizes `speedtest-cli` to gather data on download and upload speeds, plus latency, saving the results for trend analysis and visualization over time with `matplotlib`.",
      "summary": "The Problem\n\nEver had your internet crawl and wondered if it’s your provider or just a bad day? ISPs love to blame your router, weather, or alignment of the planets. You need real numbers over time, not a one-off speed test buried in your browser history. Tracking trends is the only way to call their bluff.\n\nWhat This Does\n\nspeedtest.py runs speedtest-cli via subprocess (so yes, you need the CLI installed—don’t ask, just pip install it). It grabs your download, upload, and latency, then appends the results to speedtestresults.txt—plain old text, no fancy database. Functions like performspeedtest() and savespeedtestresult() do all the grunt work. Want pretty graphs? plotspeedtestresults() uses matplotlib to visualize your connection over time. No magic, just honest Python scripts, no frameworks or unnecessary layers.\n\nReal-World Use\n\nLet’s say you’re sick of your provider’s excuses. You set up a cron job to run python speedtest.py every hour. After a week, crack open speedtestresults.txt and see the ugly truth. Fire up the script again to get a plot:\n\nIn your terminal\npython speedtest.py\nOr call plotspeedtest_results() in your own script\n\nNow you’ve got ammo for your next support call. Or just a reason to switch providers.\n\nThe Bottom Line\n\nIt’s simple, works, and sticks to the basics. If you want real monitoring, you’ll outgrow flat files fast, but for home or small office, it’s all you need. Not fancy, not bloated—just Python doing what Python should.",
      "url": "https://github.com/yebeai/speedtest",
      "language": "Python",
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": null,
      "type": "original",
      "image": "https://images.unsplash.com/photo-1607799279861-4dd421887fb3?w=800&h=400&fit=crop&q=80",
      "forkedAt": "December 22, 2023",
      "updatedAt": "December 22, 2023",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 5,
        "directories": {
          ".github": 1,
          "(root)": 4
        },
        "languages": {
          "YAML": 1,
          "Markdown": 1,
          "Python": 1
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [],
        "configFiles": [
          "requirements.txt"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [
          "speedtest.py"
        ],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".yml": 1,
          ".md": 1,
          ".txt": 1,
          ".py": 1
        }
      }
    },
    {
      "id": 719814481,
      "name": "narratorAI",
      "displayName": "narratorAI",
      "description": "David Attenborough narrates your life",
      "summary": "The Problem\nEver wanted your life narrated by David Attenborough? No? Well, too bad, because this repo aims to provide just that. It addresses the absurd yet oddly appealing need for personal narration, turning mundane moments into cinematic experiences. It’s a novelty that can either amuse or annoy your friends—your call.\n\nWhat This Does\nThe narratorAI repo is a playful fork of the cbh123/narrator project, but instead of generic narration, it channels the iconic voice of Attenborough. The magic happens in narrator.py, which handles the actual narration logic, while capture.py captures your life’s moments—probably through a webcam or something. You’ll also find audio files in the assets/ folder, like stopslouching.mp3 and wonderfulposture.wav, which can be triggered based on your posture. Yes, your bad back has finally met its match.\n\nTo get this running, you’ll need to set up a virtual environment and install dependencies listed in requirements.txt. You also have to wrangle API keys from OpenAI and ElevenLabs, which is a bit of a pain. But hey, nothing says “I’m important” like juggling multiple API tokens, right?\n\nReal-World Use\nImagine you’ve been slouching again. The capture.py script detects your posture and triggers the wonderful_posture.wav audio file, narrated by Attenborough, proclaiming how magnificent you are for sitting up straight. You could set this up to run in the background while you work from home, providing a constant stream of encouragement (or judgment). Here’s how you’d typically run it:\n\npython capture.py  # Start capturing your life\n\nIn a separate terminal, get the narration going:\n\npython narrator.py  # Let the magic unfold\n\nThe Bottom Line\nThis project is niche—perfect for those who lean heavily into the absurd or want to impress that one friend who loves nature documentaries. It’s fun but honestly, it feels a bit overkill for anyone who doesn’t already have a penchant for theatrics. If you're looking for a creative side project, give it a shot; just don’t expect it to change your life.",
      "url": "https://github.com/yebeai/narratorAI",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "cbh123/narrator",
        "url": "https://github.com/cbh123/narrator",
        "stars": 4417
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "November 17, 2023",
      "updatedAt": "November 17, 2023",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 10,
        "directories": {
          "(root)": 5,
          "assets": 4,
          "frames": 1
        },
        "languages": {
          "Markdown": 1,
          "Python": 2
        },
        "frameworks": [],
        "packageManager": "pip",
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [
          "requirements.txt"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".md": 1,
          ".mp3": 2,
          ".wav": 2,
          ".py": 2,
          ".txt": 1
        }
      }
    },
    {
      "id": 677993108,
      "name": "mosesyebei",
      "displayName": "mosesyebei",
      "description": "No description available",
      "summary": "The Problem\n\nMost blog templates are either bland one-pagers or crammed with useless widgets, making them a pain for anyone just wanting to publish long-form articles with big visuals. If you want something that looks sharp, handles text-heavy content, and doesn't make you fight with a million config files, you're usually out of luck.\n\nWhat This Does\n\nmosesyebei is basically the Massively template from HTML5 UP, dropped into a folder and ready to roll. The assets/css/main.css handles layout and typography, while assets/css/fontawesome-all.min.css gives you icons without digging through CDN links. There's a bunch of SASS partials in assets/sass/ if you want to tweak things properly—think page.scss for page layout, button.scss for button styles, etc.\n\nScroll effects are wired up with assets/js/jquery.scrollex.min.js and background tricks are managed by assets/js/main.js. No crazy build tools; just static CSS and JS. So if you want to change colors or fonts, edit the SASS files and recompile—no hunting through ten layers of abstraction.\n\nReal-World Use\n\nSay you want to launch a personal blog with some big Unsplash images and readable articles. Clone the repo, toss your blog content into the HTML, and update the main image in the template. If you need to add a contact button, just use the button styles from _button.scss like so:\n\n<a href=\"mailto:me@example.com\" class=\"button primary\">Contact</a>\n\nWant to ditch the parallax effect? Crack open assets/js/main.js and comment out the Scrollex calls. No React, no Webpack, just edit-and-refresh.\n\nThe Bottom Line\n\nIf you want a stylish, article-focused site with zero hassle, this template nails it. It's overkill for tiny landing pages, but great for blogs and portfolios. You get clean code, easy tweaks, and no bloat—unless you count jQuery as bloat (which, yeah, it's 2024, but whatever). If you hate fighting with build scripts and just want to ship, grab it.",
      "url": "https://github.com/yebeai/mosesyebei",
      "language": "CSS",
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": null,
      "type": "original",
      "image": "https://images.unsplash.com/photo-1555066931-4365d14bab8c?w=800&h=400&fit=crop&q=80",
      "forkedAt": "August 13, 2023",
      "updatedAt": "August 13, 2023",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 72,
        "directories": {
          "(root)": 5,
          "assets": 56,
          "images": 11
        },
        "languages": {
          "CSS": 3,
          "JavaScript": 7,
          "SCSS": 31,
          "HTML": 3
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [
          "assets/js/main.js",
          "index.html"
        ],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "LICENSE.txt",
          "README.txt"
        ],
        "fileTypes": {
          ".txt": 2,
          ".css": 3,
          ".js": 7,
          ".scss": 31,
          ".eot": 3,
          ".svg": 3,
          ".ttf": 3,
          ".woff": 3,
          ".woff2": 3,
          ".html": 3,
          ".jpg": 10,
          ".png": 1
        }
      }
    },
    {
      "id": 649106325,
      "name": "TradeDataCoinbase",
      "displayName": "TradeDataCoinbase",
      "description": "a process for fetching real-time trade data from the Coinbase Websocket API, transforming the trade data into OHLC (Open, High, Low, Close) data using Bytewax, and then plotting the OHLC data using Bokeh and Streamlit.",
      "summary": "The Problem  \nGetting real-time trade data from an exchange like Coinbase is one thing. Turning that firehose of data into something actually usable—like OHLC (Open, High, Low, Close) charts—is another. Add in the need for a clean web dashboard to display the results in real-time, and suddenly you’re staring at a weekend project that could easily spiral into a month-long rabbit hole.  \n\nWhat This Does  \nThis repo connects to the Coinbase WebSocket API, pulls in real-time trade data, processes it into OHLC format using Bytewax, and then visualizes it with Bokeh and Streamlit. Here's how it breaks down:  \nWebSocket Data Fetching: The repo listens to Coinbase’s WebSocket API, grabbing real-time trade data like price, volume, and timestamps.  \nData Transformation: Using Bytewax, it groups the trade data into time-based intervals (candlesticks) and calculates the open, high, low, and close prices for each time window. This is the heavy lifting, and Bytewax handles it well.  \nVisualization: The processed OHLC data is visualized using Bokeh, and the interactive charts are rendered in a Streamlit dashboard.  \n\nThe setup is straightforward if you’re comfortable with Python and don’t break into a cold sweat when you see a WebSocket endpoint.  \n\nReal-World Use  \nLet’s say you’re a crypto trader or just someone who wants to monitor price trends in real time. Clone this repo, tweak the Bytewax pipeline to set your desired time intervals (e.g., 1-minute, 5-minute candles), and fire it up.  \n\nHere’s a simplified example:  \n\nInside your Bytewax pipeline\ndef ohlcaggregator(trades):\n    for window, tradedata in trades:\n        yield (\n            window,\n            {\n                \"open\": tradedata[0][\"price\"],\n                \"high\": max(t[\"price\"] for t in tradedata),\n                \"low\": min(t[\"price\"] for t in tradedata),\n                \"close\": tradedata[-1][\"price\"],\n            },\n        )\n\nPush this into the Bokeh charting logic, and boom—you’ve got a live OHLC chart updating in your browser.  \n\nThe Bottom Line  \nThis is a solid starting point if you need a quick and dirty way to visualize real-time crypto trade data. It’s not going to win design awards (the included Streamlit app is pretty barebones), and you’ll need to handle deployment yourself. But if you’re just looking to hack together a functional real-time dashboard without reinventing the wheel, this repo gets the job done.",
      "url": "https://github.com/yebeai/TradeDataCoinbase",
      "language": "HTML",
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": null,
      "type": "original",
      "image": "https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?w=800&h=400&fit=crop&q=80",
      "forkedAt": "June 3, 2023",
      "updatedAt": "June 3, 2023",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 11,
        "directories": {
          "(root)": 5,
          "_layouts": 1,
          "images": 4,
          "pdf": 1
        },
        "languages": {
          "Markdown": 3,
          "YAML": 1,
          "HTML": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".md": 3,
          ".yml": 1,
          ".html": 1,
          ".jpg": 2,
          ".gif": 1,
          ".png": 1,
          ".pdf": 1
        }
      }
    },
    {
      "id": 625041724,
      "name": "Auto-GPT",
      "displayName": "Auto GPT",
      "description": "An experimental open-source attempt to make GPT-4 fully autonomous.",
      "summary": "The Problem\nAI has made massive strides, but running a fully autonomous AI capable of business management is still a pipe dream for most developers. The pain point? Most applications require constant human intervention, making them less efficient and more cumbersome to manage. Enter Auto-GPT, which dares to tackle this issue head-on.\n\nWhat This Does\nAuto-GPT is an open-source tool that lets GPT-4 operate autonomously to manage businesses. The structure is straightforward yet packed with useful scripts. For instance, the scripts/agentmanager.py is crucial for overseeing the AI’s operations, while aisettings.yaml holds the configuration necessary to customize the AI's behavior. The outputs folder is where Auto-GPT keeps track of its generated content, like outputs/guestpostemail.txt, which shows its potential for content creation.\n\nThe project also includes a Dockerfile, enabling you to containerize your setup quickly. If you’re into CI/CD, the .github/workflows/autoformat.yml automates your code formatting tasks, saving you from the tedious manual cleanup. \n\nReal-World Use\nImagine you need an AI assistant to handle marketing emails for a new product launch. You can modify aisettings.yaml to target specific demographics and set up tasks in scripts/commands.py to generate email content. Once everything is configured, you can sit back while Auto-GPT writes and sends the emails, tracks responses, and even adjusts its strategy based on engagement metrics. \n\nHere's a quick snippet for triggering an email generation:\n\nfrom scripts.aifunctions import generateemail\n\nemailcontent = generateemail(\"Product Launch\", targetaudience=\"young professionals\")\nprint(emailcontent)\n\nThe Bottom Line\nAuto-GPT is ambitious and can do some impressive things, but it's not without its quirks. If you're looking to dabble in autonomous AI, this repo is worth checking out, but prepare for a learning curve. It's overkill for small projects but could be a gold mine for anyone wanting to experiment with AI-driven business management. Just don't expect it to replace your team—yet.",
      "url": "https://github.com/yebeai/Auto-GPT",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "Significant-Gravitas/AutoGPT",
        "url": "https://github.com/Significant-Gravitas/AutoGPT",
        "stars": 182075
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&h=400&fit=crop&q=80",
      "forkedAt": "April 7, 2023",
      "updatedAt": "April 7, 2023",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 41,
        "directories": {
          "(root)": 8,
          ".github": 5,
          "outputs": 8,
          "scripts": 19,
          "tests": 1
        },
        "languages": {
          "YAML": 5,
          "Markdown": 3,
          "Python": 19
        },
        "frameworks": [
          "Docker"
        ],
        "packageManager": "pip",
        "hasDocker": true,
        "hasCI": true,
        "ciPlatform": "GitHub Actions",
        "entryPoints": [
          "scripts/main.py"
        ],
        "configFiles": [
          "Dockerfile",
          "requirements.txt"
        ],
        "dependencies": [
          "requirements.txt"
        ],
        "testFiles": [
          "tests/json_tests.py"
        ],
        "docs": [
          "CONTRIBUTING.md",
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".template": 1,
          ".yml": 4,
          ".md": 3,
          ".yaml": 1,
          ".txt": 10,
          ".py": 19
        }
      }
    },
    {
      "id": 597005930,
      "name": "ObjectCountingYOLOv8DeepSORT",
      "displayName": "ObjectCountingYOLOv8DeepSORT",
      "description": "Counting cars using Yolov8 and DeepSORT",
      "summary": "The Problem\n\nCounting cars in traffic videos is a pain. Manual logging is slow and error-prone; you can't trust that intern to get the numbers right. You need something that just works, ideally without reinventing the wheel every time someone wants basic analytics.\n\nWhat This Does\n\nObjectCountingYOLOv8DeepSORT pairs YOLOv8 for detecting cars and DeepSORT for tracking them across frames. Everything happens inside YOLOv8ObjectCountingSegmentationSpeed.ipynb, so you don’t have to set up a dozen scripts or hunt for configs. Load your video, run the notebook, and watch detections and counts appear frame by frame.\n\nThe repo skips fancy folder hierarchies—just a README.md and the main notebook. No mystery files, no hidden dependencies (except the usual suspects: ultralytics, deepsort, etc.). The notebook does both segmentation and counting, and shows FPS so you know if your GPU’s crying for help.\n\nReal-World Use\n\nSay you’ve got a dashcam video and want daily vehicle counts for your city council report. Drop the video path into the cell in YOLOv8ObjectCountingSegmentationSpeed.ipynb, tweak the confidence threshold if you care, and hit run. The notebook spits out annotated frames, running counts, and speed stats. Example:\n\nvideopath = \"traffic_video.mp4\"\nmodel = YOLO(\"yolov8n.pt\")\ntracker = DeepSORT()\nLoop through frames, detect, track, count\n\nYou get results fast, no extra scripts needed.\n\nThe Bottom Line\n\nIf you just want to count vehicles in a video and don’t care about fancy dashboards or scalable APIs, this repo does the job. It’s barebones and lives in a notebook, so it’s not great for production—but it’s perfect for quick experiments or demos. Anyone who’s tired of writing their own object tracking loop should check it out; anyone building a full pipeline should keep looking.",
      "url": "https://github.com/yebeai/ObjectCountingYOLOv8DeepSORT",
      "language": "Jupyter Notebook",
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": null,
      "type": "original",
      "image": "https://images.unsplash.com/photo-1451187580459-43490279c0fa?w=800&h=400&fit=crop&q=80",
      "forkedAt": "February 3, 2023",
      "updatedAt": "February 3, 2023",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 2,
        "directories": {
          "(root)": 2
        },
        "languages": {
          "Markdown": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".md": 1,
          ".ipynb": 1
        }
      }
    },
    {
      "id": 594873631,
      "name": "YOLOv8_Segmentation_DeepSORT_TRACKING_Colab",
      "displayName": "YOLOv8 Segmentation DeepSORT TRACKING Colab",
      "description": "Using Yolov8 and Deep Sort for Computer Vision",
      "summary": "The Problem  \nTracking objects in video feeds is a classic computer vision problem, but it's a pain to set up. You need detection (what's in the frame?) and tracking (where is it moving?). Solutions like YOLO are great for detection, but tracking adds complexity. If you're not a PhD in CV, wiring up detection with tracking can feel like assembling IKEA furniture without instructions. This repo claims to handle that headache by combining YOLOv8 (detection) with DeepSORT (tracking) in one package.\n\nWhat This Does  \nThis project uses YOLOv8 for object detection and DeepSORT for tracking, stitched together in a Google Colab notebook for easy use. There's not much detail provided (thanks, non-existent README), but based on the title, it probably lets you feed in video data, detect objects frame-by-frame with YOLOv8, and then track their movement using DeepSORT. DeepSORT assigns persistent IDs to objects, so you know that \"person #3\" in frame 1 is the same \"person #3\" in frame 42.  \n\nI’d bet the Colab notebook is the main entry point, but without a file structure, I can only guess at what’s inside. Likely, there’s code to load YOLOv8 weights, set up DeepSORT’s Kalman filter, and run the whole thing on video input. If there’s a config.yaml anywhere, that’s probably where you’d tweak detection thresholds and other settings. \n\nReal-World Use  \nImagine you’re working on a security system for a store. You want to detect and track people who enter, follow their movement around the aisles, and see if they’re lingering suspiciously near the candy section (we’ve all been there). You’d start by feeding your video footage into the Colab notebook, letting YOLOv8 handle the detection (e.g., \"person,\" \"bag,\" \"cat\") and DeepSORT handle the tracking.  \n\nHere’s a basic (hypothetical) workflow:  \n\nfrom yolov8deepsorttracking import runtracking  \n\nvideopath = 'storesecurity.mp4'  \noutputpath = 'outputannotated.mp4'  \n\nruntracking(videopath, outputpath)  \n\nNow you've got a video where each person is tracked with an ID, and their path is annotated. Congrats, you're one step closer to catching candy thieves.\n\nThe Bottom Line  \nThis repo might save you time if you need detection and tracking in one bundle, but without a README or file structure, you’re flying blind. It’s probably useful for quick prototyping, especially in Colab, but don’t expect polished tools or production-ready code. If you’re doing anything serious, you’ll need to dig into the source and pray the code isn’t a spaghetti mess. Use it if you’re experimenting; skip it for mission-critical work.",
      "url": "https://github.com/yebeai/YOLOv8_Segmentation_DeepSORT_TRACKING_Colab",
      "language": null,
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": null,
      "type": "original",
      "image": "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 29, 2023",
      "updatedAt": "January 29, 2023",
      "readTime": 3,
      "knowledgeGraph": null
    },
    {
      "id": 590887739,
      "name": "Object-Detection-in-YOLOv8",
      "displayName": "Object Detection in YOLOv8",
      "description": "No description available",
      "summary": "The Problem\nObject detection is a headache for anyone who's tried to implement it from scratch. You’ve got to wrangle datasets, tweak algorithms, and fight with libraries that seem to have a mind of their own. If you want to get decent results without pulling your hair out, you need a solid framework. Enter YOLOv8.\n\nWhat This Does\nThis repository presents a Jupyter Notebook named ObjectdetectionYOLOv8.ipynb, which is your playground for object detection using YOLOv8. The notebook walks you through setting up your environment, training a model, and running inference on images. You’ll find everything you need in one place, so you don't have to hunt through a bunch of different files just to get started.\n\nThe README.md is pretty bare-bones, which is a missed opportunity. It should at least outline the basic dependencies and how to run the notebook. Documentation matters when you're diving into a new project, and a few examples could save a lot of confusion.\n\nReal-World Use\nImagine you’re building a surveillance system that needs to detect specific objects, like cars or people, in real-time. You can modify the YOLOv8 parameters directly in the notebook to adjust for your use case. With a few lines of code, you can load your dataset and start training your model:\n\nLoad your dataset\ndataset = loaddataset('path/to/your/dataset')\n\nTrain the model\nmodel.train(dataset)\n\nRun inference\nresults = model.predict('path/to/test/image.jpg')\n\nThis lets you get up and running without a ton of boilerplate code. \n\nThe Bottom Line\nThis repo is a good starting point for anyone looking to dive into YOLOv8 without the hassle of setup. However, the lack of documentation is a drawback; it could scare off newcomers who aren’t sure what to do next. If you're already familiar with Python and Jupyter Notebooks, this could save you time. But if you're just starting out, be prepared to do some digging.",
      "url": "https://github.com/yebeai/Object-Detection-in-YOLOv8",
      "language": "Jupyter Notebook",
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": null,
      "type": "original",
      "image": "https://images.unsplash.com/photo-1558494949-ef010cbdcc31?w=800&h=400&fit=crop&q=80",
      "forkedAt": "January 19, 2023",
      "updatedAt": "January 19, 2023",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 2,
        "directories": {
          "(root)": 2
        },
        "languages": {
          "Markdown": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".ipynb": 1,
          ".md": 1
        }
      }
    },
    {
      "id": 498430066,
      "name": "Object-Detection-using-Yolov7",
      "displayName": "Object Detection using Yolov7",
      "description": "Config files for my GitHub profile.",
      "summary": "The Problem\n\nGetting started with object detection is usually a mess. You spend more time wrangling configs and dependencies than actually training models. Most YOLO tutorials throw you into a swamp of scripts, missing files, broken links, and “just pip install XYZ.” If you want something quick and reproducible, good luck.\n\nWhat This Does\n\nObjectDetectionusingYOLOv7.ipynb is a Jupyter Notebook that walks through setting up YOLOv7 for object detection. It’s not some bloated all-in-one package — it’s a minimal config and workflow, with everything stored in the notebook. No mystery folders, no weird bash scripts. The README.md gives you context (mostly about the author, but hey, at least there’s a LinkedIn link). The repo is dead simple: one notebook, one README, and that's it.\n\nIf you’ve ever wanted a clean starting point for YOLOv7 experiments, without digging through junk folders or trying to reverse-engineer someone’s spaghetti code, this is it. The notebook handles the setup, data prep, and config tweaks in one place. No hidden dependencies, no surprise YAMLs.\n\nReal-World Use\n\nLet’s say you want to try out YOLOv7 on a new dataset. Clone the repo, open ObjectDetectionusingYOLOv7.ipynb, and run through the cells. Change the dataset path or tweak hyperparameters directly in the notebook. No need to hunt for config files — just edit code cells and re-run. If you want to test with your own images, drop them in, update the cell, and you’re good. Example:\n\nimgpath = '/your/image/folder/'\nresults = model(imgpath)\n\nYou can see results, tweak settings, and actually focus on your data, not the setup.\n\nThe Bottom Line\n\nIf you hate bloated repos and just want a minimal YOLOv7 config you can actually use, this is worth checking out. It’s not fancy, but it’s clear and easy. Good for beginners or anyone who wants to prototype fast. If you need production-level stuff or advanced configs, look elsewhere. For quick experiments and learning, this does the job.",
      "url": "https://github.com/yebeai/Object-Detection-using-Yolov7",
      "language": "Jupyter Notebook",
      "stars": 0,
      "forks": 0,
      "topics": [
        "config",
        "github-config"
      ],
      "parent": null,
      "type": "original",
      "image": "https://images.unsplash.com/photo-1485827404703-89b55fcc595e?w=800&h=400&fit=crop&q=80",
      "forkedAt": "May 31, 2022",
      "updatedAt": "January 11, 2023",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 2,
        "directories": {
          "(root)": 2
        },
        "languages": {
          "Markdown": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".ipynb": 1,
          ".md": 1
        }
      }
    },
    {
      "id": 582018627,
      "name": "Drawing-a-Christmas-Tree-in-Python",
      "displayName": "Drawing a Christmas Tree in Python",
      "description": "No description available",
      "summary": "Drawing a Christmas Tree in Python\n\nThe Problem  \nSometimes, you just want to draw a Christmas tree in Python. Maybe it's for fun, maybe it's for a beginner project, or maybe you're just procrastinating on something more important. Whatever the case, you don't want to reinvent the wheel—or in this case, the tree. Using Python's turtle library can be clunky if you're starting from scratch, so having a pre-built example can save you time and frustration.\n\nWhat This Does  \nThis repo gives you a simple way to draw a Christmas tree using Python's turtle module. The code lives in xmas.py, which contains all the logic to set up the turtle graphics, draw the tree, and display the result in a GUI window.  \n\nThe drawing itself is, well, pretty basic—it's a green triangle (the tree) and a brown rectangle (the trunk). The turtle library handles the graphics, so you don't have to mess with anything too low-level. No fancy animations or dynamic features here; it just runs, draws the tree, and stops.  \n\nThe README.md is as barebones as the project itself. It tells you what the code does in one sentence, but don't expect any hand-holding. If you don't already know how to run Python scripts, you're on your own.  \n\nReal-World Use  \nLet's be honest—this isn't solving world hunger. But it's a great example for Python beginners who want to try out the turtle library without building something from scratch.  \n\nFor example, you can run the script like this:  \n\npython xmas.py\n\nAnd boom, Christmas tree on your screen.  \n\nWant to customize it? You could tweak the tree's size, colors, or even add ornaments. Just modify the drawing logic inside xmas.py. Here's a simple way to make the tree taller:  \n\nChange this in xmas.py\nt.forward(100)  # original\nto something like\nt.forward(150)  # taller tree\n\nThe Bottom Line  \nIf you're a Python newbie or just want a quick holiday-themed script to show off, this repo does the job. It's simple, functional, and easy to modify. That said, it's not going to win any design awards, and the lack of documentation means you'll need to poke around the code if you want to make changes.  \n\nGood for: beginners, holiday procrastinators, and anyone who just wants a Python-powered Christmas tree. Not so great for: anyone expecting more than the absolute basics.",
      "url": "https://github.com/yebeai/Drawing-a-Christmas-Tree-in-Python",
      "language": "Python",
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": null,
      "type": "original",
      "image": "https://images.unsplash.com/photo-1531482615713-2afd69097998?w=800&h=400&fit=crop&q=80",
      "forkedAt": "December 25, 2022",
      "updatedAt": "December 25, 2022",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 2,
        "directories": {
          "(root)": 2
        },
        "languages": {
          "Markdown": 1,
          "Python": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".md": 1,
          ".py": 1
        }
      }
    },
    {
      "id": 580938057,
      "name": "Neural-Networks",
      "displayName": "Neural Networks",
      "description": "No description available",
      "summary": "The Problem\nClassifying handwritten digits is still a pain point in many applications, even with all the advances in machine learning. The MNIST dataset has been the go-to benchmark for decades, but it’s still a rite of passage for anyone getting into neural networks. If you can’t classify a simple digit, you’re probably in the wrong field.\n\nWhat This Does\nThis repo contains a couple of Jupyter Notebooks that tackle the MNIST classification problem and another one for object detection using YOLOv7. The main player here is MNISTNeuralnetworks.ipynb, which defines a neural network with three dense layers—128, 64, and 16 units—using relu and softmax activation functions. It compiles the model with the adam optimizer and evaluates it using categoricalcrossentropy. You’ll get the test accuracy printed in the console, so you know how badly you’ve messed up.\n\nThe second notebook, ObjectDetectionusingYOLOv7.ipynb, is a bit of a wildcard. It doesn’t have a description, but if you’re into object detection, YOLOv7 is a solid choice. You’ll find that diving into this notebook will have you exploring the depths of real-time object detection, assuming you can figure out the specifics of loading your dataset and the model architecture.\n\nReal-World Use\nPicture this: you’re building a simple application to help kids practice their handwriting. You can use the MNIST model to verify if they’re writing their numbers correctly. Load the MNISTNeuralnetworks.ipynb, train it on the dataset, and then use the model to predict the digits they input. You can even tweak the architecture if you want to get fancy, but let’s be real: the default setup will probably do just fine for most scenarios.\n\nThe Bottom Line\nThis repo is fine for beginners who want to dip their toes into neural networks without drowning in complexity. The MNIST example is a classic, but the object detection part feels tacked on without much guidance. If you're just getting started with machine learning, this is a decent resource. But if you're looking for something production-ready or more sophisticated, keep looking.",
      "url": "https://github.com/yebeai/Neural-Networks",
      "language": "Jupyter Notebook",
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": null,
      "type": "original",
      "image": "https://images.unsplash.com/photo-1542831371-29b0f74f9713?w=800&h=400&fit=crop&q=80",
      "forkedAt": "December 21, 2022",
      "updatedAt": "December 21, 2022",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 3,
        "directories": {
          "(root)": 3
        },
        "languages": {
          "Markdown": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".ipynb": 2,
          ".md": 1
        }
      }
    },
    {
      "id": 517570318,
      "name": "qwiklabs_challenges",
      "displayName": "qwiklabs challenges",
      "description": "Qwiklabs challenges helper guide",
      "summary": "The Problem\n\nQwiklabs challenge labs are notorious for throwing you into the deep end with vague instructions, broken docs, and weird edge cases that Google doesn’t bother explaining. You waste too much time Googling stuff or redoing labs because you missed some hidden requirement. Nobody needs to fail a Google Cloud challenge just because the instructions suck.\n\nWhat This Does\n\nThe qwiklabs_challenges repo is basically a cheat sheet for the “30 Days of Google Cloud” labs. Everything’s in markdown: step-by-step solutions for both the Cloud Engineering and Data Science & Machine Learning tracks. Files like Build and Secure Networks in Google Cloud: Challenge Lab.md and Engineer Data in Google Cloud: Challenge Lab.md walk you through the exact commands—no fluff, just what you need to pass the lab. Screenshots in screenshots/cluster.png and screenshots/IAM.png make it idiot-proof if you’re lost in the UI.\n\nThe README.md links every solution and breaks down the syllabus, so you know what you need to do (and what you can skip). There’s a handful of Google Cloud resource links, but the real value is in those markdown files. Ignore the corporate banners and badge images; they’re just decoration.\n\nReal-World Use\n\nSay you’re stuck on the “Deploy to Kubernetes in Google Cloud” lab. Crack open Deploy to Kubernetes in Google Cloud: Challenge Lab.md, copy the gcloud commands, check the screenshots for what your cluster should look like, and finish the lab in half the time. If you’re prepping for certs or just want to breeze through the 30 Days program without fighting Google’s broken docs, this repo is your shortcut.\n\nThe Bottom Line\n\nIf you’re tired of vague Qwiklabs instructions and want to pass the labs without drama, grab these markdown files. It’s not fancy, but it works. Perfect for students and anyone grinding through Google Cloud basics. Don’t expect deep explanations or advanced stuff—this is strictly about ticking the boxes and getting your badge.",
      "url": "https://github.com/yebeai/qwiklabs_challenges",
      "language": null,
      "stars": 1,
      "forks": 0,
      "topics": [],
      "parent": {
        "name": "GDSC-IIIT-Kalyani/qwiklabs_challenges",
        "url": "https://github.com/GDSC-IIIT-Kalyani/qwiklabs_challenges",
        "stars": 133
      },
      "type": "fork",
      "image": "https://images.unsplash.com/photo-1607799279861-4dd421887fb3?w=800&h=400&fit=crop&q=80",
      "forkedAt": "July 25, 2022",
      "updatedAt": "July 25, 2022",
      "readTime": 2,
      "knowledgeGraph": {
        "totalFiles": 24,
        "directories": {
          "(root)": 13,
          "assets": 4,
          "screenshots": 7
        },
        "languages": {
          "Markdown": 12
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "LICENSE",
          "README.md"
        ],
        "fileTypes": {
          ".md": 12,
          ".png": 11
        }
      }
    },
    {
      "id": 482038562,
      "name": "Data-Science-Machine-Learning",
      "displayName": "Data Science Machine Learning",
      "description": "data science with python.",
      "summary": "The Problem  \nDoing data science in Python is great until you hit the classic wall: random tutorials scattered across the internet, projects with no structure, and libraries you can't keep straight. You need a single place where you can learn the basics, dive into real-world projects, and see how everything fits together. This repo tries to be that place—though it’s a bit of a mixed bag.\n\nWhat This Does  \nThis repository is basically a buffet of Python data science projects, tutorials, and experiments. It has some decent starting points for popular Python libraries like NumPy (Python Libraries For Data Science - NumPy.ipynb), Pandas (Python Libraries For Data Science - Pandas..ipynb), and visualization tools like Matplotlib (Python Libraries- Visualization with Matplotlib.ipynb). There are also project folders that tackle specific problems, like sentiment analysis in Amazon Product Review Sentiment Analysis or stock price prediction in Linear Regression-Decision Tree Models.  \n\nThe structure is... inconsistent. Some folders contain projects with decent .ipynb files (e.g., Cape Town Airbnb Data Science Project/Cape Town Airbnb data exploration, analysis and feature engineering.ipynb), while others only have vague subfolders (Fourier Analysis/Signal Processing). The tutorials are scattered, but you can piece them together to get a basic understanding of popular Python tools. There’s even a StreamlitApp1.py file tucked away in Streamlit Projects for building interactive web apps, though you’ll need to dig to understand how it works.\n\nReal-World Use  \nSay you’re a beginner data scientist trying to analyze Airbnb data in Cape Town. You could start with Cape Town Airbnb data exploration, analysis and feature engineering.ipynb and get a feel for cleaning data, building features, and running analysis. Pair it with the Pandas and Matplotlib tutorials to understand how those libraries work. Want to build something interactive? Look at StreamlitApp1.py to see how you can share your results via a simple web app.\n\nHere’s a sample workflow:  \n\nimport pandas as pd  \nimport matplotlib.pyplot as plt  \n\nLoad your Airbnb data  \ndf = pd.readcsv('airbnbdata.csv')  \n\nQuick visualization  \nplt.hist(df['price'], bins=20)  \nplt.show()  \n\nThe repo gives you just enough to get started, though you’ll be googling for details a lot.\n\nThe Bottom Line  \nThis repo is like a junk drawer for Python data science. You’ll find some useful stuff if you’re willing to dig—basic tutorials, semi-finished projects, and examples of Streamlit apps. Beginners will get the most out of it, but don’t expect polished workflows or deep insights. It’s a starting point, not a masterpiece. For zero stars, it’s not bad.",
      "url": "https://github.com/yebeai/Data-Science-Machine-Learning",
      "language": "Jupyter Notebook",
      "stars": 0,
      "forks": 0,
      "topics": [],
      "parent": null,
      "type": "original",
      "image": "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800&h=400&fit=crop&q=80",
      "forkedAt": "April 15, 2022",
      "updatedAt": "April 15, 2022",
      "readTime": 3,
      "knowledgeGraph": {
        "totalFiles": 20,
        "directories": {
          "Amazon Product Review Sentiment Analysis": 2,
          "(root)": 5,
          "Britam Data Science Project": 1,
          "Cape Town Airbnb Data Science Project": 1,
          "Fourier Analysis": 2,
          "Generalised Linear Models in Insurance Motor Claims": 2,
          "Linear Regression-Decision Tree Models": 2,
          "Python Libraries - Pandas & Seaborn": 2,
          "Python Library": 2,
          "Streamlit Projects": 1
        },
        "languages": {
          "Markdown": 1,
          "Python": 1
        },
        "frameworks": [],
        "packageManager": null,
        "hasDocker": false,
        "hasCI": false,
        "ciPlatform": null,
        "entryPoints": [],
        "configFiles": [],
        "dependencies": [],
        "testFiles": [],
        "docs": [
          "README.md"
        ],
        "fileTypes": {
          ".ipynb": 11,
          ".md": 1,
          ".py": 1
        }
      }
    }
  ]
}